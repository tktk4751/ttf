#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ§  **Neural Adaptive UKF Demo** ğŸ§ 

è«–æ–‡ã€ŒAdaptive Neural Unscented Kalman Filterã€
by Amit Levy & Itzik Klein, arXiv:2503.05490v2 ã®ãƒ‡ãƒ¢

ğŸŒŸ **ç‰¹å¾´:**
1. **ProcessNet**: CNNãƒ™ãƒ¼ã‚¹å›å¸°ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
2. **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å­¦ç¿’**: ã‚»ãƒ³ã‚µãƒ¼èª­ã¿å€¤ã®ã¿ã§ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚¤ã‚ºæ¨å®š
3. **ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰**: å®Œå…¨è‡ªå‹•é©å¿œã‚·ã‚¹ãƒ†ãƒ 
4. **AUVèˆªè¡Œ**: è‡ªå¾‹æ°´ä¸­èˆªè¡Œä½“ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³å¿œç”¨
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings
from pathlib import Path
import sys

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‘ã‚¹ã®è¿½åŠ 
project_root = Path(__file__).parent.parent
if project_root not in sys.path:
    sys.path.append(str(project_root))

try:
    from indicators.neural_adaptive_ukf import NeuralAdaptiveUnscentedKalmanFilter
    from indicators.unscented_kalman_filter import UnscentedKalmanFilter
except ImportError as e:
    print(f"âš ï¸ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    sys.exit(1)

# è¨­å®š
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings('ignore')


def generate_auv_navigation_data(n_points: int = 1000) -> tuple:
    """
    AUVèˆªè¡Œãƒ‡ãƒ¼ã‚¿æ¨¡æ“¬ç”Ÿæˆ
    
    æ°´ä¸­èˆªè¡Œä½“ã®ç‰¹å¾´ã‚’æ¨¡æ“¬ï¼š
    - è¤‡é›‘ãª3æ¬¡å…ƒè»Œé“
    - ã‚»ãƒ³ã‚µãƒ¼ãƒã‚¤ã‚ºå¤‰å‹•
    - ç’°å¢ƒå¤–ä¹±
    - DVLä¿¡å·æ–­ç¶š
    """
    t = np.linspace(0, 100, n_points)  # 100ç§’é–“
    
    # åŸºæœ¬è»Œé“ï¼ˆèºæ—‹ + ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ï¼‰
    spiral_x = 50 * np.cos(0.2 * t) + np.cumsum(np.random.normal(0, 0.1, n_points))
    spiral_y = 50 * np.sin(0.2 * t) + np.cumsum(np.random.normal(0, 0.1, n_points))
    spiral_z = -t * 0.5 + 10 * np.sin(0.1 * t)  # æ·±åº¦å¤‰åŒ–
    
    # è¤‡é›‘è»Œé“
    true_position = spiral_x + spiral_y + spiral_z * 0.1
    
    # ç’°å¢ƒãƒã‚¤ã‚ºï¼ˆæ·±åº¦ãƒ»æµã‚Œã«ä¾å­˜ï¼‰
    depth_factor = np.abs(spiral_z) / 50 + 0.1
    current_noise = depth_factor * np.random.normal(0, 1, n_points)
    
    # ã‚»ãƒ³ã‚µãƒ¼ãƒã‚¤ã‚ºï¼ˆæ™‚å¤‰ï¼‰
    sensor_quality = 1.0 + 0.5 * np.sin(0.05 * t)  # å‘¨æœŸçš„å“è³ªå¤‰åŒ–
    sensor_noise = np.random.normal(0, sensor_quality, n_points)
    
    # DVLä¿¡å·æ–­ç¶šæ¨¡æ“¬
    dvl_outage = np.zeros(n_points, dtype=bool)
    outage_periods = [(200, 220), (450, 480), (700, 730)]  # ä¿¡å·æ–­ç¶šæœŸé–“
    for start, end in outage_periods:
        if start < n_points and end < n_points:
            dvl_outage[start:end] = True
    
    # è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿
    observed_position = true_position + current_noise + sensor_noise
    observed_position[dvl_outage] += np.random.normal(0, 5, np.sum(dvl_outage))  # æ–­ç¶šæ™‚ã®å¤§ããªãƒã‚¤ã‚º
    
    return true_position, observed_position, sensor_quality, dvl_outage, depth_factor


def run_neural_adaptive_ukf_demo():
    """Neural Adaptive UKFãƒ‡ãƒ¢å®Ÿè¡Œ"""
    print("ğŸ§  **Neural Adaptive UKF Demo (Levy & Klein 2025)** ğŸ§ ")
    print("="*60)
    
    # AUVèˆªè¡Œãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    print("ğŸŒŠ AUVèˆªè¡Œãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
    true_pos, observed_pos, sensor_quality, dvl_outage, depth_factor = generate_auv_navigation_data(800)
    
    print(f"   - ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°: {len(observed_pos)}")
    print(f"   - DVLä¿¡å·æ–­ç¶šæœŸé–“: {np.sum(dvl_outage)}ç‚¹ ({np.sum(dvl_outage)/len(observed_pos)*100:.1f}%)")
    
    # Neural Adaptive UKFå®Ÿè¡Œ
    print("\nğŸ§  Neural Adaptive UKFå®Ÿè¡Œä¸­...")
    neural_aukf = NeuralAdaptiveUnscentedKalmanFilter(window_size=100)
    neural_result = neural_aukf.calculate(observed_pos)
    
    # æ¨™æº–UKFæ¯”è¼ƒç”¨
    print("ğŸ“Š æ¨™æº–UKFæ¯”è¼ƒå®Ÿè¡Œä¸­...")
    standard_ukf = UnscentedKalmanFilter()
    standard_result = standard_ukf.calculate(observed_pos)
    
    # æ€§èƒ½è©•ä¾¡
    neural_rmse = np.sqrt(np.mean((neural_result.filtered_values - true_pos) ** 2))
    standard_rmse = np.sqrt(np.mean((standard_result.filtered_values - true_pos) ** 2))
    improvement = (standard_rmse - neural_rmse) / standard_rmse * 100
    
    print(f"\nğŸ“ˆ **æ€§èƒ½çµæœ:**")
    print(f"   ğŸ§  Neural AUKF RMSE: {neural_rmse:.4f}")
    print(f"   ğŸ“Š Standard UKF RMSE: {standard_rmse:.4f}")
    print(f"   ğŸš€ æ”¹å–„ç‡: {improvement:+.1f}%")
    
    # Neuralå›ºæœ‰æƒ…å ±
    neural_summary = neural_aukf.get_neural_summary()
    print(f"\nğŸ§  **Neuralç‰¹å¾´:**")
    for key, value in neural_summary.items():
        if isinstance(value, list):
            print(f"   {key}: {', '.join(value)}")
        elif isinstance(value, (int, float)):
            print(f"   {key}: {value:.6f}")
        else:
            print(f"   {key}: {value}")
    
    # å¯è¦–åŒ–
    create_neural_visualization(
        true_pos, observed_pos, neural_result, standard_result, 
        sensor_quality, dvl_outage, depth_factor
    )
    
    print("\nğŸ‰ Neural Adaptive UKFãƒ‡ãƒ¢å®Œäº†ï¼")


def create_neural_visualization(
    true_pos, observed_pos, neural_result, standard_result, 
    sensor_quality, dvl_outage, depth_factor
):
    """Neuralç‰¹æœ‰ã®å¯è¦–åŒ–"""
    
    fig, axes = plt.subplots(3, 2, figsize=(18, 15))
    
    # 1. ãƒ¡ã‚¤ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæœ
    ax1 = axes[0, 0]
    ax1.plot(true_pos, 'k-', linewidth=2, label='True Position', alpha=0.8)
    ax1.plot(observed_pos, color='lightgray', alpha=0.5, label='Observed', linewidth=0.5)
    ax1.plot(neural_result.filtered_values, 'g-', linewidth=2, label='Neural AUKF', alpha=0.9)
    ax1.plot(standard_result.filtered_values, 'b--', linewidth=2, label='Standard UKF', alpha=0.7)
    
    # DVLæ–­ç¶šæœŸé–“ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
    dvl_periods = np.where(dvl_outage)[0]
    if len(dvl_periods) > 0:
        ax1.scatter(dvl_periods, observed_pos[dvl_periods], 
                   color='red', s=20, alpha=0.7, label='DVL Outage')
    
    ax1.set_title('ğŸ§  Neural AUKF vs Standard UKF', fontweight='bold')
    ax1.set_xlabel('Time Steps')
    ax1.set_ylabel('Position')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æ¨å®šãƒã‚¤ã‚º
    ax2 = axes[0, 1]
    ax2.plot(neural_result.neural_process_noise, 'g-', linewidth=2, label='Process Noise', alpha=0.8)
    ax2.plot(neural_result.neural_observation_noise, 'r-', linewidth=2, label='Observation Noise', alpha=0.8)
    ax2.set_title('ğŸ”§ Neural Noise Estimation', fontweight='bold')
    ax2.set_xlabel('Time Steps')
    ax2.set_ylabel('Noise Level')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. å­¦ç¿’æ›²ç·šã¨é©å¿œä¿¡å·
    ax3 = axes[1, 0]
    ax3.plot(neural_result.learning_curves, 'purple', linewidth=2, label='Learning Curve', alpha=0.8)
    ax3.plot(neural_result.adaptation_signals, 'orange', linewidth=2, label='Adaptation Signal', alpha=0.8)
    ax3.set_title('ğŸ“š Learning Progress', fontweight='bold')
    ax3.set_xlabel('Time Steps')
    ax3.set_ylabel('Signal Strength')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¿¡é ¼åº¦
    ax4 = axes[1, 1]
    ax4.plot(neural_result.network_confidence, 'cyan', linewidth=2, label='Network Confidence', alpha=0.8)
    ax4.fill_between(range(len(neural_result.network_confidence)), 
                     neural_result.network_confidence, alpha=0.3, color='cyan')
    ax4.set_title('ğŸ¯ Network Confidence', fontweight='bold')
    ax4.set_xlabel('Time Steps')
    ax4.set_ylabel('Confidence Score')
    ax4.set_ylim(0, 1.1)
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    # 5. é€Ÿåº¦ãƒ»åŠ é€Ÿåº¦æ¨å®š
    ax5 = axes[2, 0]
    ax5.plot(neural_result.velocity_estimates, 'g-', linewidth=2, label='Velocity', alpha=0.8)
    ax5.plot(neural_result.acceleration_estimates, 'r--', linewidth=2, label='Acceleration', alpha=0.8)
    ax5.set_title('ğŸš€ Velocity & Acceleration Estimates', fontweight='bold')
    ax5.set_xlabel('Time Steps')
    ax5.set_ylabel('Derivative Values')
    ax5.legend()
    ax5.grid(True, alpha=0.3)
    
    # 6. ç’°å¢ƒè¦å› ã¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å‡ºåŠ›
    ax6 = axes[2, 1]
    ax6.plot(sensor_quality, 'blue', linewidth=2, label='Sensor Quality', alpha=0.7)
    ax6.plot(depth_factor, 'brown', linewidth=2, label='Depth Factor', alpha=0.7)
    ax6.plot(neural_result.network_outputs / np.max(neural_result.network_outputs), 
             'green', linewidth=2, label='Network Output (norm)', alpha=0.8)
    ax6.set_title('ğŸŒŠ Environmental Factors', fontweight='bold')
    ax6.set_xlabel('Time Steps')
    ax6.set_ylabel('Normalized Values')
    ax6.legend()
    ax6.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # ä¿å­˜
    output_file = project_root / "output" / "neural_adaptive_ukf_demo.png"
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"\nğŸ“Š Neural UKFå¯è¦–åŒ–ä¿å­˜: {output_file}")
    
    plt.show()


if __name__ == "__main__":
    run_neural_adaptive_ukf_demo() 