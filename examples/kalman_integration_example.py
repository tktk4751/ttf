#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Kalman Integration Example - ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ±åˆä½¿ç”¨ä¾‹

æ—¢å­˜ã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã§ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ±åˆã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Optional, NamedTuple

from indicators.kalman_filter_unified import KalmanFilterUnified, KalmanFilterResult

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.style.use('default')


class UltimateMaWithUnifiedKalman:
    """
    Ultimate MAã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ±åˆç‰ˆ
    
    å¾“æ¥ã®ultimate_ma.pyã®adaptive_kalman_filter_numbaã‚’
    çµ±åˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ç½®ãæ›ãˆãŸæ”¹è‰¯ç‰ˆ
    """
    
    def __init__(
        self,
        kalman_filter_type: str = 'quantum_adaptive',
        super_smooth_period: int = 10,
        zero_lag_period: int = 21,
        src_type: str = 'hlc3'
    ):
        self.kalman_filter_type = kalman_filter_type
        self.super_smooth_period = super_smooth_period
        self.zero_lag_period = zero_lag_period
        self.src_type = src_type
        
        # çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        self.kalman_filter = KalmanFilterUnified(
            filter_type=kalman_filter_type,
            src_type=src_type,
            base_process_noise=0.01,
            base_measurement_noise=0.01,
            volatility_window=20
        )
    
    def calculate(self, data: pd.DataFrame) -> Dict:
        """Ultimate MAã‚’è¨ˆç®—ï¼ˆçµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä½¿ç”¨ï¼‰"""
        
        # 1. ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
        kalman_result = self.kalman_filter.calculate(data)
        kalman_values = kalman_result.filtered_values
        
        # 2. ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        super_smooth_values = self._super_smoother_filter(kalman_values)
        
        # 3. ã‚¼ãƒ­ãƒ©ã‚°EMA
        zero_lag_values = self._zero_lag_ema(super_smooth_values)
        
        # 4. ãƒˆãƒ¬ãƒ³ãƒ‰ã‚·ã‚°ãƒŠãƒ«è¨ˆç®—
        trend_signals = self._calculate_trend_signals(zero_lag_values)
        
        return {
            'values': zero_lag_values,
            'kalman_values': kalman_values,
            'super_smooth_values': super_smooth_values,
            'trend_signals': trend_signals,
            'kalman_confidence': kalman_result.confidence_scores,
            'kalman_trend': kalman_result.trend_estimate,
            'filter_type': kalman_result.filter_type,
            'quantum_coherence': kalman_result.quantum_coherence
        }
    
    def _super_smoother_filter(self, prices: np.ndarray) -> np.ndarray:
        """ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼"""
        n = len(prices)
        smoothed = np.zeros(n)
        
        if n < 4:
            return prices.copy()
        
        # åˆæœŸå€¤è¨­å®š
        for i in range(3):
            smoothed[i] = prices[i]
        
        # ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ä¿‚æ•°
        a1 = np.exp(-1.414 * np.pi / self.super_smooth_period)
        b1 = 2.0 * a1 * np.cos(1.414 * np.pi / self.super_smooth_period)
        c2 = b1
        c3 = -a1 * a1
        c1 = 1.0 - c2 - c3
        
        for i in range(3, n):
            smoothed[i] = (c1 * (prices[i] + prices[i-1]) / 2.0 + 
                          c2 * smoothed[i-1] + 
                          c3 * smoothed[i-2])
        
        return smoothed
    
    def _zero_lag_ema(self, prices: np.ndarray) -> np.ndarray:
        """ã‚¼ãƒ­ãƒ©ã‚°EMA"""
        n = len(prices)
        zero_lag = np.zeros(n)
        
        if n < 2:
            return prices.copy()
        
        alpha = 2.0 / (self.zero_lag_period + 1.0)
        zero_lag[0] = prices[0]
        
        for i in range(1, n):
            # æ¨™æº–EMA
            ema = alpha * prices[i] + (1 - alpha) * zero_lag[i-1]
            
            # ã‚¼ãƒ­ãƒ©ã‚°è£œæ­£
            if i >= 2:
                momentum = prices[i] - prices[i-1]
                lag_correction = alpha * momentum
                zero_lag[i] = ema + lag_correction
            else:
                zero_lag[i] = ema
        
        return zero_lag
    
    def _calculate_trend_signals(self, values: np.ndarray) -> np.ndarray:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ã‚·ã‚°ãƒŠãƒ«è¨ˆç®—"""
        n = len(values)
        signals = np.zeros(n)
        
        for i in range(5, n):
            # çŸ­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆ5æœŸé–“ï¼‰
            short_trend = np.mean(np.diff(values[i-5:i]))
            
            # ã‚·ã‚°ãƒŠãƒ«åˆ¤å®š
            if short_trend > 0.001:
                signals[i] = 1  # ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰
            elif short_trend < -0.001:
                signals[i] = -1  # ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰
            else:
                signals[i] = 0  # ãƒ¬ãƒ³ã‚¸
        
        return signals


class VolatilityIndicatorWithUnifiedKalman:
    """
    ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ±åˆç‰ˆ
    
    Ultimate Volatilityã®é‡å­é©å¿œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’
    çµ±åˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ç½®ãæ›ãˆãŸæ”¹è‰¯ç‰ˆ
    """
    
    def __init__(
        self,
        kalman_filter_type: str = 'hyper_quantum',
        period: int = 14,
        src_type: str = 'hlc3'
    ):
        self.kalman_filter_type = kalman_filter_type
        self.period = period
        self.src_type = src_type
        
        # çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        self.kalman_filter = KalmanFilterUnified(
            filter_type=kalman_filter_type,
            src_type=src_type,
            base_process_noise=0.01,
            base_measurement_noise=0.01,
            volatility_window=period
        )
    
    def calculate(self, data: pd.DataFrame) -> Dict:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã‚’è¨ˆç®—"""
        
        # True Rangeè¨ˆç®—
        high = data['high'].values
        low = data['low'].values
        close = data['close'].values
        
        true_range = self._calculate_true_range(high, low, close)
        
        # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆTrue Rangeã«å¯¾ã—ã¦ï¼‰
        # PriceSourceã®ãŸã‚ã«å¿…è¦ãªåˆ—ã‚’ä½œæˆï¼ˆTrue Rangeãƒ™ãƒ¼ã‚¹ï¼‰
        tr_data = pd.DataFrame({
            'open': true_range,
            'high': true_range * 1.01,  # è‹¥å¹²ã®å¤‰å‹•ã‚’æŒãŸã›ã‚‹
            'low': true_range * 0.99,
            'close': true_range
        })
        kalman_result = self.kalman_filter.calculate(tr_data)
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿True Rangeã‚’ç§»å‹•å¹³å‡
        filtered_tr = kalman_result.filtered_values
        ultimate_volatility = self._moving_average(filtered_tr, self.period)
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒˆãƒ¬ãƒ³ãƒ‰
        volatility_trend = self._calculate_volatility_trend(ultimate_volatility)
        
        return {
            'ultimate_volatility': ultimate_volatility,
            'raw_true_range': true_range,
            'filtered_true_range': filtered_tr,
            'volatility_trend': volatility_trend,
            'kalman_confidence': kalman_result.confidence_scores,
            'kalman_uncertainty': kalman_result.uncertainty,
            'filter_type': kalman_result.filter_type
        }
    
    def _calculate_true_range(self, high: np.ndarray, low: np.ndarray, close: np.ndarray) -> np.ndarray:
        """True Rangeè¨ˆç®—"""
        n = len(high)
        tr = np.zeros(n)
        
        tr[0] = high[0] - low[0]
        
        for i in range(1, n):
            tr1 = high[i] - low[i]
            tr2 = abs(high[i] - close[i-1])
            tr3 = abs(low[i] - close[i-1])
            tr[i] = max(tr1, tr2, tr3)
        
        return tr
    
    def _moving_average(self, values: np.ndarray, period: int) -> np.ndarray:
        """ç§»å‹•å¹³å‡"""
        n = len(values)
        ma = np.zeros(n)
        
        for i in range(n):
            start_idx = max(0, i - period + 1)
            ma[i] = np.mean(values[start_idx:i+1])
        
        return ma
    
    def _calculate_volatility_trend(self, volatility: np.ndarray) -> np.ndarray:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—"""
        n = len(volatility)
        trend = np.zeros(n)
        
        for i in range(10, n):
            # 10æœŸé–“ã§ã®ç·šå½¢å›å¸°å‚¾ã
            x = np.arange(10)
            y = volatility[i-10:i]
            
            # æœ€å°äºŒä¹—æ³•
            x_mean = np.mean(x)
            y_mean = np.mean(y)
            
            numerator = np.sum((x - x_mean) * (y - y_mean))
            denominator = np.sum((x - x_mean) ** 2)
            
            if denominator > 0:
                slope = numerator / denominator
                trend[i] = slope
        
        return trend


class EnsembleIndicatorWithMultipleKalman:
    """
    è¤‡æ•°ã®ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
    
    è¤‡æ•°ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¿ã‚¤ãƒ—ã‚’åŒæ™‚ã«å®Ÿè¡Œã—ã€
    å‹•çš„ã«æœ€é©ãªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é¸æŠã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
    """
    
    def __init__(
        self,
        filter_types: List[str] = ['adaptive', 'quantum_adaptive', 'unscented', 'hyper_quantum'],
        src_type: str = 'hlc3'
    ):
        self.filter_types = filter_types
        self.src_type = src_type
        
        # å„ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–
        self.filters = {}
        for filter_type in filter_types:
            self.filters[filter_type] = KalmanFilterUnified(
                filter_type=filter_type,
                src_type=src_type,
                base_process_noise=0.01,
                base_measurement_noise=0.01,
                volatility_window=20
            )
    
    def calculate(self, data: pd.DataFrame) -> Dict:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã‚’è¨ˆç®—"""
        
        # å„ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’å®Ÿè¡Œ
        filter_results = {}
        performance_scores = {}
        
        for filter_type in self.filter_types:
            try:
                result = self.filters[filter_type].calculate(data)
                filter_results[filter_type] = result
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢è¨ˆç®—
                score = self._calculate_performance_score(result, data['close'].values)
                performance_scores[filter_type] = score
                
            except Exception as e:
                print(f"Warning: {filter_type} filter failed: {e}")
                performance_scores[filter_type] = 0.0
        
        # å‹•çš„é‡ã¿è¨ˆç®—
        weights = self._calculate_dynamic_weights(performance_scores)
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµæœè¨ˆç®—
        ensemble_result = self._calculate_ensemble(filter_results, weights)
        
        # æœ€é©ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é¸æŠ
        best_filter = max(performance_scores, key=performance_scores.get)
        
        return {
            'ensemble_values': ensemble_result['ensemble_values'],
            'ensemble_confidence': ensemble_result['ensemble_confidence'],
            'ensemble_trend': ensemble_result['ensemble_trend'],
            'filter_weights': weights,
            'performance_scores': performance_scores,
            'best_filter': best_filter,
            'individual_results': filter_results,
            'filter_ranking': sorted(performance_scores.items(), key=lambda x: x[1], reverse=True)
        }
    
    def _calculate_performance_score(self, kalman_result: KalmanFilterResult, original_prices: np.ndarray) -> float:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        if len(kalman_result.filtered_values) < 10:
            return 0.0
        
        # ãƒã‚¤ã‚ºé™¤å»åŠ¹æœ
        original_noise = np.std(np.diff(original_prices))
        filtered_noise = np.std(np.diff(kalman_result.filtered_values))
        noise_reduction = max(0, 1 - filtered_noise / original_noise) if original_noise > 0 else 0
        
        # è¿½å¾“æ€§
        correlation = np.corrcoef(original_prices, kalman_result.filtered_values)[0, 1]
        correlation = max(0, correlation)
        
        # ä¿¡é ¼åº¦
        avg_confidence = np.nanmean(kalman_result.confidence_scores)
        
        # ç·åˆã‚¹ã‚³ã‚¢
        score = (noise_reduction * 0.4 + correlation * 0.4 + avg_confidence * 0.2)
        return score
    
    def _calculate_dynamic_weights(self, performance_scores: Dict[str, float]) -> Dict[str, float]:
        """å‹•çš„é‡ã¿è¨ˆç®—"""
        total_score = sum(performance_scores.values())
        
        if total_score == 0:
            # å‡ç­‰é‡ã¿
            n_filters = len(performance_scores)
            return {filter_type: 1.0/n_filters for filter_type in performance_scores.keys()}
        
        # æ€§èƒ½ãƒ™ãƒ¼ã‚¹é‡ã¿
        weights = {}
        for filter_type, score in performance_scores.items():
            weights[filter_type] = score / total_score
        
        return weights
    
    def _calculate_ensemble(self, filter_results: Dict[str, KalmanFilterResult], weights: Dict[str, float]) -> Dict:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµæœè¨ˆç®—"""
        if not filter_results:
            return {'ensemble_values': np.array([]), 'ensemble_confidence': np.array([]), 'ensemble_trend': np.array([])}
        
        # æœ€åˆã®çµæœã®é•·ã•ã‚’å–å¾—
        first_result = next(iter(filter_results.values()))
        n = len(first_result.filtered_values)
        
        ensemble_values = np.zeros(n)
        ensemble_confidence = np.zeros(n)
        ensemble_trend = np.zeros(n)
        
        for i in range(n):
            weighted_value = 0.0
            weighted_confidence = 0.0
            weighted_trend = 0.0
            total_weight = 0.0
            
            for filter_type, result in filter_results.items():
                if filter_type in weights and i < len(result.filtered_values):
                    weight = weights[filter_type]
                    
                    weighted_value += weight * result.filtered_values[i]
                    weighted_confidence += weight * result.confidence_scores[i]
                    if result.trend_estimate is not None:
                        weighted_trend += weight * result.trend_estimate[i]
                    total_weight += weight
            
            if total_weight > 0:
                ensemble_values[i] = weighted_value / total_weight
                ensemble_confidence[i] = weighted_confidence / total_weight
                ensemble_trend[i] = weighted_trend / total_weight
        
        return {
            'ensemble_values': ensemble_values,
            'ensemble_confidence': ensemble_confidence,
            'ensemble_trend': ensemble_trend
        }


def generate_test_data(n_samples: int = 500) -> pd.DataFrame:
    """ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    np.random.seed(42)
    
    t = np.arange(n_samples)
    trend = 100 + 0.05 * t
    cycle = 5 * np.sin(2 * np.pi * t / 50)
    noise = np.random.normal(0, 1, n_samples)
    
    close = trend + cycle + noise
    high = close + np.random.uniform(0, 2, n_samples)
    low = close - np.random.uniform(0, 2, n_samples)
    open_price = close + np.random.uniform(-1, 1, n_samples)
    
    return pd.DataFrame({
        'open': open_price,
        'high': high,
        'low': low,
        'close': close,
        'volume': np.random.randint(1000, 10000, n_samples)
    })


def demo_ultimate_ma_integration():
    """Ultimate MAçµ±åˆãƒ‡ãƒ¢"""
    print("\nğŸ¯ Ultimate MA ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ±åˆãƒ‡ãƒ¢")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    data = generate_test_data(500)
    
    # å¾“æ¥ç‰ˆvsçµ±åˆç‰ˆã®æ¯”è¼ƒ
    filter_types = ['adaptive', 'quantum_adaptive', 'unscented', 'hyper_quantum']
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('Ultimate MA: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ±åˆæ¯”è¼ƒ', fontsize=16, fontweight='bold')
    
    original_prices = data['close'].values
    
    for i, filter_type in enumerate(filter_types):
        row = i // 2
        col = i % 2
        ax = axes[row, col]
        
        # çµ±åˆUltimate MA
        uma_integrated = UltimateMaWithUnifiedKalman(
            kalman_filter_type=filter_type,
            super_smooth_period=10,
            zero_lag_period=21
        )
        
        result = uma_integrated.calculate(data)
        
        # ãƒ—ãƒ­ãƒƒãƒˆ
        ax.plot(original_prices, label='å…ƒã®ä¾¡æ ¼', color='gray', alpha=0.7, linewidth=1)
        ax.plot(result['values'], label=f'UMA({filter_type})', color='blue', linewidth=2)
        ax.plot(result['kalman_values'], label='Kalmanãƒ•ã‚£ãƒ«ã‚¿ãƒ¼', color='red', alpha=0.7, linewidth=1)
        
        # ä¿¡é ¼åº¦èƒŒæ™¯
        confidence = result['kalman_confidence']
        ax.fill_between(range(len(confidence)), 
                       np.min(original_prices) + (np.max(original_prices) - np.min(original_prices)) * confidence,
                       np.min(original_prices), alpha=0.1, color='blue')
        
        ax.set_title(f'{filter_type.upper()} Filter')
        ax.set_ylabel('ä¾¡æ ¼')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('examples/output/ultimate_ma_integration.png', dpi=300, bbox_inches='tight')
    plt.show()


def demo_volatility_integration():
    """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çµ±åˆãƒ‡ãƒ¢"""
    print("\nğŸ“Š ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼çµ±åˆãƒ‡ãƒ¢")
    print("=" * 60)
    
    data = generate_test_data(500)
    
    # çµ±åˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
    vol_indicator = VolatilityIndicatorWithUnifiedKalman(
        kalman_filter_type='hyper_quantum',
        period=14
    )
    
    result = vol_indicator.calculate(data)
    
    # ãƒ—ãƒ­ãƒƒãƒˆ
    fig, axes = plt.subplots(2, 1, figsize=(12, 8))
    fig.suptitle('ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ±åˆ', fontsize=16, fontweight='bold')
    
    # ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆ
    ax1 = axes[0]
    ax1.plot(data['close'].values, label='ä¾¡æ ¼', color='black', linewidth=1)
    ax1.set_title('ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆ')
    ax1.set_ylabel('ä¾¡æ ¼')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æ¯”è¼ƒ
    ax2 = axes[1]
    ax2.plot(result['raw_true_range'], label='ç”ŸTrue Range', color='gray', alpha=0.7, linewidth=1)
    ax2.plot(result['filtered_true_range'], label='ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿TR', color='blue', linewidth=2)
    ax2.plot(result['ultimate_volatility'], label='Ultimate Volatility', color='red', linewidth=2)
    
    # ä¿¡é ¼åº¦
    confidence = result['kalman_confidence']
    ax2_twin = ax2.twinx()
    ax2_twin.plot(confidence, label='ä¿¡é ¼åº¦', color='green', alpha=0.7)
    ax2_twin.set_ylabel('ä¿¡é ¼åº¦', color='green')
    ax2_twin.set_ylim(0, 1)
    
    ax2.set_title('ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ')
    ax2.set_xlabel('æ™‚é–“')
    ax2.set_ylabel('ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£')
    ax2.legend(loc='upper left')
    ax2_twin.legend(loc='upper right')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('examples/output/volatility_integration.png', dpi=300, bbox_inches='tight')
    plt.show()


def demo_ensemble_integration():
    """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆãƒ‡ãƒ¢"""
    print("\nğŸ­ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼çµ±åˆãƒ‡ãƒ¢")
    print("=" * 60)
    
    data = generate_test_data(500)
    
    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
    ensemble_indicator = EnsembleIndicatorWithMultipleKalman(
        filter_types=['adaptive', 'quantum_adaptive', 'unscented', 'hyper_quantum']
    )
    
    result = ensemble_indicator.calculate(data)
    
    # çµæœè¡¨ç¤º
    print(f"ğŸ† æœ€é«˜æ€§èƒ½ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼: {result['best_filter']}")
    print(f"ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ©ãƒ³ã‚­ãƒ³ã‚°:")
    for i, (filter_type, score) in enumerate(result['filter_ranking']):
        print(f"  {i+1}. {filter_type}: {score:.3f}")
    
    print(f"\nâš–ï¸ å‹•çš„é‡ã¿:")
    for filter_type, weight in result['filter_weights'].items():
        print(f"  {filter_type}: {weight:.3f}")
    
    # ãƒ—ãƒ­ãƒƒãƒˆ
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼: ãƒãƒ«ãƒã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ±åˆ', fontsize=16, fontweight='bold')
    
    original_prices = data['close'].values
    
    # 1. å€‹åˆ¥ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœ
    ax1 = axes[0, 0]
    ax1.plot(original_prices, label='å…ƒã®ä¾¡æ ¼', color='gray', alpha=0.7, linewidth=1)
    
    colors = ['red', 'blue', 'green', 'orange']
    for i, (filter_type, filter_result) in enumerate(result['individual_results'].items()):
        ax1.plot(filter_result.filtered_values, label=filter_type, 
                color=colors[i % len(colors)], linewidth=1.5, alpha=0.8)
    
    ax1.set_title('å€‹åˆ¥ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœ')
    ax1.set_ylabel('ä¾¡æ ¼')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµæœ
    ax2 = axes[0, 1]
    ax2.plot(original_prices, label='å…ƒã®ä¾¡æ ¼', color='gray', alpha=0.7, linewidth=1)
    ax2.plot(result['ensemble_values'], label='ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«', color='purple', linewidth=3)
    
    # ä¿¡é ¼åº¦
    confidence = result['ensemble_confidence']
    ax2.fill_between(range(len(confidence)), result['ensemble_values'] + confidence * 5,
                    result['ensemble_values'] - confidence * 5, alpha=0.2, color='purple')
    
    ax2.set_title('ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµæœ')
    ax2.set_ylabel('ä¾¡æ ¼')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢
    ax3 = axes[1, 0]
    filter_names = list(result['performance_scores'].keys())
    scores = list(result['performance_scores'].values())
    
    bars = ax3.bar(filter_names, scores, color=colors[:len(filter_names)])
    ax3.set_title('ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢')
    ax3.set_ylabel('ã‚¹ã‚³ã‚¢')
    ax3.set_xticklabels(filter_names, rotation=45, ha='right')
    
    # ã‚¹ã‚³ã‚¢å€¤ã‚’è¡¨ç¤º
    for bar, score in zip(bars, scores):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{score:.3f}', ha='center', va='bottom')
    
    # 4. å‹•çš„é‡ã¿
    ax4 = axes[1, 1]
    weights = list(result['filter_weights'].values())
    
    pie_colors = colors[:len(filter_names)]
    wedges, texts, autotexts = ax4.pie(weights, labels=filter_names, colors=pie_colors, 
                                      autopct='%1.1f%%', startangle=90)
    ax4.set_title('å‹•çš„é‡ã¿åˆ†å¸ƒ')
    
    plt.tight_layout()
    plt.savefig('examples/output/ensemble_integration.png', dpi=300, bbox_inches='tight')
    plt.show()


def show_migration_guide():
    """ç§»è¡Œã‚¬ã‚¤ãƒ‰ã®è¡¨ç¤º"""
    print("\nğŸ“š ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ±åˆã‚¯ãƒ©ã‚¹ç§»è¡Œã‚¬ã‚¤ãƒ‰")
    print("=" * 70)
    
    migration_examples = [
        {
            'title': '1. Ultimate MA ã®ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç½®ãæ›ãˆ',
            'before': '''
# å¾“æ¥ã®ã‚³ãƒ¼ãƒ‰ (ultimate_ma.py)
filtered_prices = adaptive_kalman_filter_numba(prices)
            ''',
            'after': '''
# çµ±åˆç‰ˆ
kalman_filter = KalmanFilterUnified(filter_type='adaptive')
result = kalman_filter.calculate(data)
filtered_prices = result.filtered_values
            '''
        },
        {
            'title': '2. Ultimate Breakout ã®é‡å­ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç½®ãæ›ãˆ',
            'before': '''
# å¾“æ¥ã®ã‚³ãƒ¼ãƒ‰ (ultimate_breakout_channel.py)
filtered_prices, quantum_coherence = quantum_adaptive_kalman_filter(
    prices, amplitude, phase)
            ''',
            'after': '''
# çµ±åˆç‰ˆ
kalman_filter = KalmanFilterUnified(
    filter_type='quantum_adaptive', 
    enable_hilbert=True)
result = kalman_filter.calculate(data)
filtered_prices = result.filtered_values
quantum_coherence = result.quantum_coherence
            '''
        },
        {
            'title': '3. Ultimate Chop Trend ã®ç„¡é¦™æ–™ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç½®ãæ›ãˆ',
            'before': '''
# å¾“æ¥ã®ã‚³ãƒ¼ãƒ‰ (ultimate_chop_trend.py)
filtered_prices, trend_estimate, uncertainty = unscented_kalman_filter(
    prices, volatility, alpha=0.001, beta=2.0, kappa=0.0)
            ''',
            'after': '''
# çµ±åˆç‰ˆ
kalman_filter = KalmanFilterUnified(
    filter_type='unscented',
    ukf_alpha=0.001, ukf_beta=2.0, ukf_kappa=0.0)
result = kalman_filter.calculate(data)
filtered_prices = result.filtered_values
trend_estimate = result.trend_estimate
uncertainty = result.uncertainty
            '''
        }
    ]
    
    for example in migration_examples:
        print(f"\n{example['title']}")
        print("-" * len(example['title']))
        print(f"å¾“æ¥ç‰ˆ:{example['before']}")
        print(f"çµ±åˆç‰ˆ:{example['after']}")
    
    print(f"\nğŸ’¡ çµ±åˆã®åˆ©ç‚¹:")
    print(f"  â€¢ ä¸€è²«ã—ãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹")
    print(f"  â€¢ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–")
    print(f"  â€¢ è¤‡æ•°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ç°¡å˜åˆ‡ã‚Šæ›¿ãˆ")
    print(f"  â€¢ çµ±ä¸€ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°")
    print(f"  â€¢ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã®è‡ªå‹•è¨ˆç®—")
    print(f"  â€¢ ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã«ã‚ˆã‚‹é«˜é€ŸåŒ–")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ±åˆä½¿ç”¨ä¾‹ãƒ‡ãƒ¢ã‚’é–‹å§‹")
    print("=" * 70)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs('examples/output', exist_ok=True)
    
    # 1. Ultimate MAçµ±åˆãƒ‡ãƒ¢
    demo_ultimate_ma_integration()
    
    # 2. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çµ±åˆãƒ‡ãƒ¢
    demo_volatility_integration()
    
    # 3. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆãƒ‡ãƒ¢
    demo_ensemble_integration()
    
    # 4. ç§»è¡Œã‚¬ã‚¤ãƒ‰è¡¨ç¤º
    show_migration_guide()
    
    print("\nâœ… çµ±åˆä½¿ç”¨ä¾‹ãƒ‡ãƒ¢å®Œäº†ï¼")
    print("   çµæœç”»åƒã¯ examples/output/ ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
    print("   ã“ã‚Œã§æ—¢å­˜ã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã§ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ±åˆã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚")


if __name__ == "__main__":
    main() 