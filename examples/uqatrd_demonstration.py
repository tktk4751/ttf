#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸŒŸ Ultra Quantum Adaptive Trend-Range Discriminator (UQATRD) ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

John Ehlersã®é©æ–°çš„ãªé‡å­ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚‹ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ¤åˆ¥ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®å®Ÿæ¼”
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import sys
import time

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
output_dir = Path(__file__).parent / "output"
output_dir.mkdir(exist_ok=True)

def load_sample_data():
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
        data_files = [
            project_root / "data" / "sample_data.csv",
            project_root / "examples" / "sample_data.csv"
        ]
        
        for file_path in data_files:
            if file_path.exists():
                print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {file_path}")
                df = pd.read_csv(file_path)
                if len(df) > 0:
                    return df
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        print("ğŸ”„ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
        return generate_sample_data()
        
    except Exception as e:
        print(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return generate_sample_data()


def generate_sample_data(n_points=1000):
    """è¤‡é›‘ãªå¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    np.random.seed(42)
    
    # åŸºæœ¬ãƒˆãƒ¬ãƒ³ãƒ‰
    trend = np.cumsum(np.random.randn(n_points) * 0.1)
    
    # ã‚µã‚¤ã‚¯ãƒ«æˆåˆ†
    cycle1 = 10 * np.sin(np.linspace(0, 10*np.pi, n_points))
    cycle2 = 5 * np.sin(np.linspace(0, 20*np.pi, n_points))
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯
    random_walk = np.cumsum(np.random.randn(n_points) * 0.5)
    
    # ä¾¡æ ¼ã®æ§‹ç¯‰
    base_price = 100 + trend + cycle1 + cycle2 + random_walk
    
    # OHLCç”Ÿæˆ
    high = base_price + np.abs(np.random.randn(n_points) * 0.8)
    low = base_price - np.abs(np.random.randn(n_points) * 0.8)
    open_price = base_price + np.random.randn(n_points) * 0.3
    close = base_price + np.random.randn(n_points) * 0.3
    
    # æ—¥ä»˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    dates = pd.date_range('2023-01-01', periods=n_points, freq='D')
    
    df = pd.DataFrame({
        'timestamp': dates,
        'open': open_price,
        'high': high,
        'low': low,
        'close': close,
        'volume': np.random.randint(1000, 10000, n_points)
    })
    
    return df


def run_uqatrd_analysis():
    """UQATRDåˆ†æã®å®Ÿè¡Œ"""
    print("ğŸš€ Ultra Quantum Adaptive Trend-Range Discriminator åˆ†æé–‹å§‹")
    print("=" * 80)
    
    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    df = load_sample_data()
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(df)} rows")
    
    # UQATRDã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®åˆæœŸåŒ–
    try:
        from indicators.ultra_quantum_adaptive_trend_range_discriminator import UltraQuantumAdaptiveTrendRangeDiscriminator
        
        # ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã§ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        uqatrd_standard = UltraQuantumAdaptiveTrendRangeDiscriminator(
            coherence_window=21,
            entanglement_window=34,
            efficiency_window=21,
            uncertainty_window=14,
            src_type='hlc3',
            sensitivity=1.0
        )
        
        uqatrd_sensitive = UltraQuantumAdaptiveTrendRangeDiscriminator(
            coherence_window=14,
            entanglement_window=21,
            efficiency_window=14,
            uncertainty_window=10,
            src_type='close',
            sensitivity=1.5
        )
        
        print("âœ… UQATRD ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–å®Œäº†")
        
    except Exception as e:
        print(f"âŒ ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # åˆ†æå®Ÿè¡Œ
    print("\nğŸ”¬ é‡å­ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åˆ†æå®Ÿè¡Œä¸­...")
    
    start_time = time.time()
    
    # æ¨™æº–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    result_standard = uqatrd_standard.calculate(df)
    
    # é«˜æ„Ÿåº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿  
    result_sensitive = uqatrd_sensitive.calculate(df)
    
    calculation_time = time.time() - start_time
    
    print(f"âš¡ è¨ˆç®—æ™‚é–“: {calculation_time:.4f}ç§’")
    
    # çµæœã®åˆ†æ
    print("\nğŸ“Š åˆ†æçµæœã‚µãƒãƒªãƒ¼")
    print("-" * 40)
    
    # æ¨™æº–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµæœ
    trend_signal = result_standard.trend_range_signal
    signal_strength = result_standard.signal_strength
    confidence = result_standard.confidence_score
    
    print(f"ğŸ¯ ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ¤å®š:")
    print(f"   - å¹³å‡ä¿¡å·: {np.mean(trend_signal):.3f}")
    print(f"   - ä¿¡å·å¼·åº¦: {np.mean(signal_strength):.3f}")
    print(f"   - ä¿¡é ¼åº¦: {np.mean(confidence):.3f}")
    
    # å„é‡å­ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®çµæœ
    print(f"\nğŸ”¬ é‡å­ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è©³ç´°:")
    print(f"   - é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹: {np.mean(result_standard.quantum_coherence):.3f}")
    print(f"   - ãƒˆãƒ¬ãƒ³ãƒ‰æŒç¶šæ€§: {np.mean(result_standard.trend_persistence):.3f}")
    print(f"   - åŠ¹ç‡ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ : {np.mean(result_standard.efficiency_spectrum):.3f}")
    print(f"   - ä¸ç¢ºå®šæ€§ãƒ¬ãƒ³ã‚¸: {np.mean(result_standard.uncertainty_range):.3f}")
    
    # å¯è¦–åŒ–
    print("\nğŸ“ˆ å¯è¦–åŒ–ä½œæˆä¸­...")
    create_comprehensive_visualization(df, result_standard, result_sensitive)
    
    # å‹•çš„é–¾å€¤åˆ†æ
    print("\nğŸ¯ å‹•çš„é©å¿œé–¾å€¤åˆ†æ")
    analyze_adaptive_threshold(uqatrd_standard, df)
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
    print("\nğŸ† ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ")
    analyze_performance(result_standard, df)
    
    return result_standard, result_sensitive


def create_comprehensive_visualization(df, result_standard, result_sensitive):
    """åŒ…æ‹¬çš„ãªå¯è¦–åŒ–ã®ä½œæˆ"""
    
    # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    prices = df['close'].values
    dates = df['timestamp'] if 'timestamp' in df.columns else range(len(df))
    
    # å›³ã®ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
    plt.style.use('seaborn-v0_8')
    fig = plt.figure(figsize=(20, 16))
    
    # 1. ãƒ¡ã‚¤ãƒ³ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆ + ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ¤å®š
    ax1 = plt.subplot(4, 2, 1)
    ax1.plot(dates, prices, 'k-', linewidth=0.8, alpha=0.7, label='ä¾¡æ ¼')
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ¤å®šã®ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—
    trend_signal = result_standard.trend_range_signal
    confidence = result_standard.confidence_score
    
    # ä¿¡å·ã«åŸºã¥ãè‰²ä»˜ã‘ï¼ˆ0=ãƒ¬ãƒ³ã‚¸ã€1=ãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰
    for i in range(len(prices)-1):
        if trend_signal[i] > 0.7:
            color = 'green'  # å¼·ã„ãƒˆãƒ¬ãƒ³ãƒ‰
            alpha = min(0.8, confidence[i] + 0.2)
        elif trend_signal[i] > 0.4:
            color = 'yellow'  # å¼±ã„ãƒˆãƒ¬ãƒ³ãƒ‰
            alpha = min(0.6, confidence[i] + 0.1)
        else:
            color = 'red'  # ãƒ¬ãƒ³ã‚¸
            alpha = min(0.8, confidence[i] + 0.2)
        
        ax1.axvspan(dates[i], dates[i+1], color=color, alpha=alpha*0.2)
    
    ax1.set_title('ğŸ¯ UQATRD ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ¤å®š', fontsize=14, fontweight='bold')
    ax1.set_ylabel('ä¾¡æ ¼', fontsize=12)
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹
    ax2 = plt.subplot(4, 2, 2)
    ax2.plot(dates, result_standard.quantum_coherence, 'b-', linewidth=1.5, label='é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹')
    ax2.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)
    ax2.fill_between(dates, 0, result_standard.quantum_coherence, alpha=0.3, color='blue')
    ax2.set_title('ğŸŒ€ é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹æ–¹å‘æ€§æ¸¬å®š', fontsize=14, fontweight='bold')
    ax2.set_ylabel('ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹', fontsize=12)
    ax2.set_ylim(0, 1)
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. ãƒˆãƒ¬ãƒ³ãƒ‰æŒç¶šæ€§
    ax3 = plt.subplot(4, 2, 3)
    ax3.plot(dates, result_standard.trend_persistence, 'r-', linewidth=1.5, label='ãƒˆãƒ¬ãƒ³ãƒ‰æŒç¶šæ€§')
    ax3.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='ãƒ¬ãƒ³ã‚¸/ãƒˆãƒ¬ãƒ³ãƒ‰å¢ƒç•Œ')
    ax3.fill_between(dates, 0.5, result_standard.trend_persistence, 
                     alpha=0.3, color='green', where=(result_standard.trend_persistence > 0.5))
    ax3.fill_between(dates, 0, result_standard.trend_persistence, 
                     alpha=0.3, color='red', where=(result_standard.trend_persistence <= 0.5))
    ax3.set_title('ğŸ”— é‡å­ã‚¨ãƒ³ã‚¿ãƒ³ã‚°ãƒ«ãƒ¡ãƒ³ãƒˆãƒˆãƒ¬ãƒ³ãƒ‰æŒç¶šæ€§', fontsize=14, fontweight='bold')
    ax3.set_ylabel('ãƒˆãƒ¬ãƒ³ãƒ‰æŒç¶šæ€§', fontsize=12)
    ax3.set_ylim(0, 1)
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. åŠ¹ç‡ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ 
    ax4 = plt.subplot(4, 2, 4)
    ax4.plot(dates, result_standard.efficiency_spectrum, 'g-', linewidth=1.5, label='åŠ¹ç‡ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ ')
    ax4.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)
    ax4.fill_between(dates, 0, result_standard.efficiency_spectrum, alpha=0.3, color='green')
    ax4.set_title('ğŸ“Š é‡å­åŠ¹ç‡ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ ', fontsize=14, fontweight='bold')
    ax4.set_ylabel('åŠ¹ç‡æ€§', fontsize=12)
    ax4.set_ylim(0, 1)
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    # 5. ä¸ç¢ºå®šæ€§ãƒ¬ãƒ³ã‚¸
    ax5 = plt.subplot(4, 2, 5)
    ax5.plot(dates, result_standard.uncertainty_range, 'purple', linewidth=1.5, label='ä¸ç¢ºå®šæ€§ãƒ¬ãƒ³ã‚¸')
    ax5.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)
    ax5.fill_between(dates, 0, result_standard.uncertainty_range, alpha=0.3, color='purple')
    ax5.set_title('ğŸ¯ é‡å­ä¸ç¢ºå®šæ€§ãƒ¬ãƒ³ã‚¸æ¤œå‡º', fontsize=14, fontweight='bold')
    ax5.set_ylabel('ä¸ç¢ºå®šæ€§', fontsize=12)
    ax5.set_ylim(0, 1)
    ax5.legend()
    ax5.grid(True, alpha=0.3)
    
    # 6. ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
    ax6 = plt.subplot(4, 2, 6)
    ax6.plot(dates, result_standard.confidence_score, 'orange', linewidth=1.5, label='ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢')
    ax6.axhline(y=0.7, color='red', linestyle='--', alpha=0.5, label='é–¾å€¤')
    ax6.fill_between(dates, 0, result_standard.confidence_score, alpha=0.3, color='orange')
    ax6.set_title('ğŸ“ˆ ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢', fontsize=14, fontweight='bold')
    ax6.set_ylabel('ä¿¡é ¼åº¦', fontsize=12)
    ax6.set_ylim(0, 1)
    ax6.legend()
    ax6.grid(True, alpha=0.3)
    
    # 7. æœ€çµ‚çµ±åˆä¿¡å·
    ax7 = plt.subplot(4, 2, 7)
    ax7.plot(dates, result_standard.trend_range_signal, 'black', linewidth=2, label='UQATRDä¿¡å·')
    ax7.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='ãƒ¬ãƒ³ã‚¸/ãƒˆãƒ¬ãƒ³ãƒ‰å¢ƒç•Œ')
    ax7.axhline(y=0.7, color='green', linestyle=':', alpha=0.5, label='å¼·ã„ãƒˆãƒ¬ãƒ³ãƒ‰é–¾å€¤')
    ax7.axhline(y=0.3, color='orange', linestyle=':', alpha=0.5, label='å¼±ã„ãƒˆãƒ¬ãƒ³ãƒ‰é–¾å€¤')
    ax7.fill_between(dates, 0.5, result_standard.trend_range_signal, 
                     alpha=0.3, color='green', where=(result_standard.trend_range_signal > 0.5))
    ax7.fill_between(dates, 0, result_standard.trend_range_signal, 
                     alpha=0.3, color='red', where=(result_standard.trend_range_signal <= 0.5))
    ax7.set_title('ğŸ¯ æœ€çµ‚çµ±åˆä¿¡å· (0=ãƒ¬ãƒ³ã‚¸, 1=ãƒˆãƒ¬ãƒ³ãƒ‰)', fontsize=14, fontweight='bold')
    ax7.set_ylabel('ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸ä¿¡å·', fontsize=12)
    ax7.set_ylim(0, 1)
    ax7.legend()
    ax7.grid(True, alpha=0.3)
    
    # 8. æ„Ÿåº¦æ¯”è¼ƒ
    ax8 = plt.subplot(4, 2, 8)
    ax8.plot(dates, result_standard.trend_range_signal, 'blue', linewidth=1.5, label='æ¨™æº–æ„Ÿåº¦')
    ax8.plot(dates, result_sensitive.trend_range_signal, 'red', linewidth=1.5, label='é«˜æ„Ÿåº¦')
    ax8.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='ãƒ¬ãƒ³ã‚¸/ãƒˆãƒ¬ãƒ³ãƒ‰å¢ƒç•Œ')
    ax8.set_title('âš¡ æ„Ÿåº¦æ¯”è¼ƒ (0=ãƒ¬ãƒ³ã‚¸, 1=ãƒˆãƒ¬ãƒ³ãƒ‰)', fontsize=14, fontweight='bold')
    ax8.set_ylabel('ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸ä¿¡å·', fontsize=12)
    ax8.set_ylim(0, 1)
    ax8.legend()
    ax8.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # ä¿å­˜
    output_path = output_dir / "uqatrd_comprehensive_analysis.png"
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š ç·åˆåˆ†æãƒãƒ£ãƒ¼ãƒˆä¿å­˜: {output_path}")
    
    plt.show()


def analyze_adaptive_threshold(indicator, df):
    """å‹•çš„é©å¿œé–¾å€¤åˆ†æ"""
    
    # é–¾å€¤æƒ…å ±ã®å–å¾—
    threshold_info = indicator.get_threshold_info()
    adaptive_threshold = indicator.get_adaptive_threshold()
    classification = indicator.get_trend_range_classification()
    
    if threshold_info is None:
        print("âŒ é–¾å€¤æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # é–¾å€¤çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
    print(f"ğŸ“Š å‹•çš„é©å¿œé–¾å€¤çµ±è¨ˆ:")
    print(f"   - å¹³å‡é–¾å€¤: {threshold_info['mean_threshold']:.3f}")
    print(f"   - æ¨™æº–åå·®: {threshold_info['std_threshold']:.3f}")
    print(f"   - æœ€å°é–¾å€¤: {threshold_info['min_threshold']:.3f}")
    print(f"   - æœ€å¤§é–¾å€¤: {threshold_info['max_threshold']:.3f}")
    print(f"   - ä¸­å¤®å€¤: {threshold_info['median_threshold']:.3f}")
    print(f"   - ç¾åœ¨ã®é–¾å€¤: {threshold_info['current_threshold']:.3f}")
    
    # å‹•çš„é–¾å€¤ã«ã‚ˆã‚‹åˆ†é¡çµ±è¨ˆ
    if classification is not None:
        trend_count = np.sum(classification == 1.0)
        range_count = np.sum(classification == 0.0)
        total_count = len(classification)
        
        print(f"\nğŸ¯ å‹•çš„é–¾å€¤ã«ã‚ˆã‚‹åˆ†é¡çµæœ:")
        print(f"   - ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š: {trend_count}ç‚¹ ({trend_count/total_count*100:.1f}%)")
        print(f"   - ãƒ¬ãƒ³ã‚¸åˆ¤å®š: {range_count}ç‚¹ ({range_count/total_count*100:.1f}%)")
    
    # é–¾å€¤ã®é©å¿œæ€§åˆ†æ
    if adaptive_threshold is not None:
        threshold_changes = np.abs(np.diff(adaptive_threshold))
        avg_change = np.mean(threshold_changes)
        max_change = np.max(threshold_changes)
        
        print(f"\nâš¡ é–¾å€¤é©å¿œæ€§åˆ†æ:")
        print(f"   - å¹³å‡å¤‰åŒ–é‡: {avg_change:.4f}")
        print(f"   - æœ€å¤§å¤‰åŒ–é‡: {max_change:.4f}")
        print(f"   - é–¾å€¤å®‰å®šæ€§: {1.0 - avg_change:.3f}")
        
        # é–¾å€¤ã®åˆ†å¸ƒ
        threshold_bins = np.histogram(adaptive_threshold, bins=5)
        print(f"   - é–¾å€¤åˆ†å¸ƒ:")
        for i, (count, bin_edge) in enumerate(zip(threshold_bins[0], threshold_bins[1][:-1])):
            next_edge = threshold_bins[1][i+1]
            print(f"     [{bin_edge:.2f}-{next_edge:.2f}]: {count}ç‚¹ ({count/len(adaptive_threshold)*100:.1f}%)")
    
    # å‹•çš„é–¾å€¤ã®å¯è¦–åŒ–
    create_adaptive_threshold_visualization(df, indicator)


def create_adaptive_threshold_visualization(df, indicator):
    """å‹•çš„é–¾å€¤å¯è¦–åŒ–"""
    
    # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    result = indicator._result_cache[indicator._cache_keys[-1]]
    prices = df['close'].values
    dates = df['timestamp'] if 'timestamp' in df.columns else range(len(df))
    
    # å›³ã®ä½œæˆ
    fig, axes = plt.subplots(3, 1, figsize=(16, 12))
    
    # 1. ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆ + å‹•çš„é–¾å€¤ã«ã‚ˆã‚‹åˆ†é¡
    ax1 = axes[0]
    ax1.plot(dates, prices, 'k-', linewidth=1.0, alpha=0.7, label='ä¾¡æ ¼')
    
    # å‹•çš„é–¾å€¤ã«ã‚ˆã‚‹åˆ†é¡ã®è‰²ä»˜ã‘
    classification = indicator.get_trend_range_classification()
    if classification is not None:
        for i in range(len(prices)-1):
            if classification[i] == 1.0:
                color = 'green'  # ãƒˆãƒ¬ãƒ³ãƒ‰
                alpha = 0.2
            else:
                color = 'red'    # ãƒ¬ãƒ³ã‚¸
                alpha = 0.2
            
            ax1.axvspan(dates[i], dates[i+1], color=color, alpha=alpha)
    
    ax1.set_title('ğŸ¯ å‹•çš„é–¾å€¤ã«ã‚ˆã‚‹ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ†é¡', fontsize=14, fontweight='bold')
    ax1.set_ylabel('ä¾¡æ ¼', fontsize=12)
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. UQATRDä¿¡å· + å‹•çš„é–¾å€¤
    ax2 = axes[1]
    ax2.plot(dates, result.trend_range_signal, 'blue', linewidth=2, label='UQATRDä¿¡å·')
    ax2.plot(dates, result.adaptive_threshold, 'red', linewidth=2, label='å‹•çš„é–¾å€¤')
    ax2.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='å›ºå®šé–¾å€¤ (0.5)')
    
    # é–¾å€¤ã‚’è¶…ãˆãŸéƒ¨åˆ†ã®è‰²ä»˜ã‘
    mask_above = result.trend_range_signal >= result.adaptive_threshold
    ax2.fill_between(dates, 0, result.trend_range_signal, 
                     alpha=0.3, color='green', where=mask_above, label='ãƒˆãƒ¬ãƒ³ãƒ‰é ˜åŸŸ')
    ax2.fill_between(dates, 0, result.trend_range_signal, 
                     alpha=0.3, color='red', where=~mask_above, label='ãƒ¬ãƒ³ã‚¸é ˜åŸŸ')
    
    ax2.set_title('ğŸ“ˆ UQATRDä¿¡å· vs å‹•çš„é©å¿œé–¾å€¤', fontsize=14, fontweight='bold')
    ax2.set_ylabel('å€¤', fontsize=12)
    ax2.set_ylim(0, 1)
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. é–¾å€¤ã®æ™‚ç³»åˆ—å¤‰åŒ–
    ax3 = axes[2]
    ax3.plot(dates, result.adaptive_threshold, 'red', linewidth=2, label='å‹•çš„é–¾å€¤')
    ax3.axhline(y=np.mean(result.adaptive_threshold), color='orange', 
                linestyle='--', alpha=0.7, label=f'å¹³å‡é–¾å€¤ ({np.mean(result.adaptive_threshold):.3f})')
    ax3.fill_between(dates, 0.4, 0.6, alpha=0.1, color='gray', label='é–¾å€¤ç¯„å›² (0.4-0.6)')
    
    ax3.set_title('âš¡ å‹•çš„é–¾å€¤ã®æ™‚ç³»åˆ—å¤‰åŒ–', fontsize=14, fontweight='bold')
    ax3.set_ylabel('é–¾å€¤', fontsize=12)
    ax3.set_xlabel('æ™‚é–“', fontsize=12)
    ax3.set_ylim(0.35, 0.65)
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # ä¿å­˜
    output_path = output_dir / "uqatrd_adaptive_threshold_analysis.png"
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ¯ å‹•çš„é–¾å€¤åˆ†æãƒãƒ£ãƒ¼ãƒˆä¿å­˜: {output_path}")
    
    plt.show()


def analyze_performance(result, df):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ¤å®šã®ç²¾åº¦åˆ†æ
    trend_signal = result.trend_range_signal
    confidence = result.confidence_score
    
    # é«˜ä¿¡é ¼åº¦ãƒã‚¤ãƒ³ãƒˆã®æŠ½å‡º
    high_confidence_mask = confidence > 0.7
    high_confidence_signals = trend_signal[high_confidence_mask]
    
    # çµ±è¨ˆã‚µãƒãƒªãƒ¼
    print(f"ğŸ“Š çµ±è¨ˆã‚µãƒãƒªãƒ¼:")
    print(f"   - é«˜ä¿¡é ¼åº¦ãƒã‚¤ãƒ³ãƒˆ: {np.sum(high_confidence_mask)}/{len(confidence)} ({np.sum(high_confidence_mask)/len(confidence)*100:.1f}%)")
    print(f"   - å¹³å‡ä¿¡é ¼åº¦: {np.mean(confidence):.3f}")
    print(f"   - ä¿¡é ¼åº¦ç¯„å›²: {np.min(confidence):.3f} - {np.max(confidence):.3f}")
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸ã®åˆ†å¸ƒï¼ˆ0=ãƒ¬ãƒ³ã‚¸ã€1=ãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰
    strong_trend_count = np.sum(trend_signal > 0.7)
    weak_trend_count = np.sum((trend_signal > 0.4) & (trend_signal <= 0.7))
    range_count = np.sum(trend_signal <= 0.4)
    
    print(f"   - å¼·ã„ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š: {strong_trend_count} ({strong_trend_count/len(trend_signal)*100:.1f}%)")
    print(f"   - å¼±ã„ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š: {weak_trend_count} ({weak_trend_count/len(trend_signal)*100:.1f}%)")
    print(f"   - ãƒ¬ãƒ³ã‚¸åˆ¤å®š: {range_count} ({range_count/len(trend_signal)*100:.1f}%)")
    
    # é‡å­ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®‰å®šæ€§
    algorithms = {
        'Quantum Coherence': result.quantum_coherence,
        'Trend Persistence': result.trend_persistence,
        'Efficiency Spectrum': result.efficiency_spectrum,
        'Uncertainty Range': result.uncertainty_range
    }
    
    print(f"\nğŸ”¬ é‡å­ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å®‰å®šæ€§:")
    for name, values in algorithms.items():
        std_dev = np.std(values)
        mean_val = np.mean(values)
        stability = 1.0 - std_dev / (abs(mean_val) + 1e-10)
        print(f"   - {name}: å¹³å‡={mean_val:.3f}, æ¨™æº–åå·®={std_dev:.3f}, å®‰å®šæ€§={stability:.3f}")


if __name__ == "__main__":
    print("ğŸŒŸ Ultra Quantum Adaptive Trend-Range Discriminator (UQATRD)")
    print("=" * 70)
    print("John Ehlersã®é©æ–°çš„é‡å­ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å®Ÿæ¼”")
    print("=" * 70)
    
    try:
        result_standard, result_sensitive = run_uqatrd_analysis()
        
        print("\nğŸ¯ åˆ†æå®Œäº†!")
        print(f"çµæœã¯ {output_dir}/uqatrd_comprehensive_analysis.png ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
        
    except Exception as e:
        print(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc() 