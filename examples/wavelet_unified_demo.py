#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸŒŠ **Wavelet Unified Demo V1.0** ğŸŒŠ

ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆçµ±åˆè§£æã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- å…¨ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆæ‰‹æ³•ã®æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
- çµæœã®å¯è¦–åŒ–
- ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚µã‚¤ã‚¯ãƒ«ãƒ»ãƒã‚¤ã‚ºæˆåˆ†ã®åˆ†é›¢è©•ä¾¡
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')
import yaml

from indicators.wavelet_unified import WaveletUnified
# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼é–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from data.data_loader import DataLoader, CSVDataSource
from data.data_processor import DataProcessor
from data.binance_data_source import BinanceDataSource

plt.style.use('dark_background')


def create_synthetic_data(n_points: int = 1000) -> pd.DataFrame:
    """
    ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆè§£æç”¨ã®åˆæˆä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆè¤‡é›‘ãªå‘¨æ³¢æ•°æˆåˆ†ã‚’å«ã‚€ï¼‰
    """
    np.random.seed(42)
    
    # æ™‚é–“è»¸
    t = np.linspace(0, 20, n_points)
    
    # 1. é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†ï¼ˆä½å‘¨æ³¢ï¼‰
    long_trend = 100 + 15 * np.sin(t * 0.3) + 0.8 * t
    
    # 2. ä¸­æœŸã‚µã‚¤ã‚¯ãƒ«æˆåˆ†ï¼ˆä¸­å‘¨æ³¢ï¼‰
    medium_cycle1 = 8 * np.sin(t * 1.2)
    medium_cycle2 = 5 * np.cos(t * 2.1)
    
    # 3. çŸ­æœŸã‚µã‚¤ã‚¯ãƒ«æˆåˆ†ï¼ˆé«˜å‘¨æ³¢ï¼‰
    short_cycle1 = 3 * np.sin(t * 4.5)
    short_cycle2 = 2 * np.cos(t * 6.8)
    
    # 4. è¶…çŸ­æœŸå¤‰å‹•ï¼ˆè¶…é«˜å‘¨æ³¢ï¼‰
    ultra_short = 1.5 * np.sin(t * 12) + 0.8 * np.cos(t * 18)
    
    # 5. ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚º
    white_noise = np.random.normal(0, 1.5, n_points)
    
    # 6. çªç™ºçš„ãªã‚¹ãƒ‘ã‚¤ã‚¯ï¼ˆéå®šå¸¸æˆåˆ†ï¼‰
    spikes = np.zeros(n_points)
    spike_indices = np.random.choice(n_points, size=15, replace=False)
    spike_magnitudes = np.random.normal(0, 8, 15)
    spikes[spike_indices] = spike_magnitudes
    
    # 7. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    volatility = 1 + 0.5 * np.sin(t * 0.8)
    scaled_noise = white_noise * volatility
    
    # æœ€çµ‚ä¾¡æ ¼åˆæˆ
    close_prices = (long_trend + medium_cycle1 + medium_cycle2 + 
                   short_cycle1 + short_cycle2 + ultra_short + 
                   scaled_noise + spikes)
    
    # OHLCç”Ÿæˆ
    high_prices = close_prices + np.abs(np.random.normal(0, 0.8, n_points))
    low_prices = close_prices - np.abs(np.random.normal(0, 0.8, n_points))
    open_prices = np.roll(close_prices, 1)
    open_prices[0] = close_prices[0]
    
    # ãƒœãƒªãƒ¥ãƒ¼ãƒ 
    volume = np.random.lognormal(10, 0.4, n_points)
    
    # æ—¥æ™‚
    start_date = datetime.now() - timedelta(days=n_points)
    dates = [start_date + timedelta(days=i) for i in range(n_points)]
    
    df = pd.DataFrame({
        'datetime': dates,
        'open': open_prices,
        'high': high_prices,
        'low': low_prices,
        'close': close_prices,
        'volume': volume,
        # ç†è«–å€¤ï¼ˆè©•ä¾¡ç”¨ï¼‰
        'true_trend': long_trend,
        'true_cycle': medium_cycle1 + medium_cycle2,
        'true_noise': scaled_noise + spikes
    })
    
    # datetimeã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¨­å®š
    df.set_index('datetime', inplace=True)
    return df


def test_all_wavelets(data: pd.DataFrame) -> dict:
    """
    å…¨ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆæ‰‹æ³•ã‚’ãƒ†ã‚¹ãƒˆã—ã¦çµæœã‚’æ¯”è¼ƒ
    """
    wavelets = WaveletUnified.get_available_wavelets()
    results = {}
    
    print("ğŸŒŠ å…¨ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆæ‰‹æ³•ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
    
    for wavelet_type, description in wavelets.items():
        print(f"   ğŸ“Š {wavelet_type}: {description}")
        
        try:
            # ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆè§£æå™¨åˆæœŸåŒ–
            wavelet_analyzer = WaveletUnified(
                wavelet_type=wavelet_type,
                src_type='close',
                haar_levels=4,
                daubechies_levels=6,
                morlet_scales=np.array([6, 10, 16, 24, 32, 48])
            )
            
            # è§£æå®Ÿè¡Œ
            result = wavelet_analyzer.calculate(data)
            
            # ğŸŒŒ å®‡å®™æœ€å¼·ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆç‰¹åˆ¥å‡¦ç†
            cosmic_summary = None
            if wavelet_type == 'ultimate_cosmic' and hasattr(wavelet_analyzer.wavelet_analyzer, 'get_cosmic_analysis_summary'):
                try:
                    cosmic_summary = wavelet_analyzer.wavelet_analyzer.get_cosmic_analysis_summary()
                    print(f"         ğŸŒŒ å®‡å®™ãƒ‘ãƒ¯ãƒ¼ãƒ¬ãƒ™ãƒ«: {cosmic_summary.get('cosmic_power_level', 1.0)}")
                    print(f"         ğŸ”¬ é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹å¹³å‡: {cosmic_summary.get('performance_metrics', {}).get('avg_quantum_coherence', 0):.3f}")
                except Exception as e:
                    print(f"         ğŸŒŒ å®‡å®™è§£æã‚µãƒãƒªãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
            performance = evaluate_wavelet_performance(
                original=data['close'].values,
                wavelet_result=result,
                true_trend=data.get('true_trend', None),
                true_cycle=data.get('true_cycle', None),
                true_noise=data.get('true_noise', None)
            )
            
            results[wavelet_type] = {
                'result': result,
                'performance': performance,
                'metadata': wavelet_analyzer.get_wavelet_info(),
                'description': description,
                'cosmic_summary': cosmic_summary  # ğŸŒŒ å®‡å®™ç‰¹åˆ¥æƒ…å ±
            }
            
            print(f"      âœ… æˆåŠŸ - ç·åˆã‚¹ã‚³ã‚¢: {performance['total_score']:.3f}")
            
        except Exception as e:
            print(f"      âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            print(f"         è©³ç´°: {traceback.format_exc()}")
            results[wavelet_type] = None
    
    return results


def evaluate_wavelet_performance(original: np.ndarray, wavelet_result, 
                                true_trend=None, true_cycle=None, true_noise=None) -> dict:
    """
    ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆè§£æã®æ€§èƒ½ã‚’è©•ä¾¡
    """
    if len(original) < 10:
        return {'total_score': 0.0}
    
    # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    n_points = len(original)
    
    # 1. ãƒã‚¤ã‚ºé™¤å»åŠ¹æœ
    if wavelet_result.detail_component is not None:
        # ãƒ‡ã‚£ãƒ†ãƒ¼ãƒ«æˆåˆ†ï¼ˆé«˜å‘¨æ³¢ãƒã‚¤ã‚ºï¼‰ã®é™¤å»åŠ¹æœ
        detail_energy = np.nanvar(wavelet_result.detail_component)
        original_noise_energy = np.var(np.diff(original))
        noise_reduction = max(0, 1 - detail_energy / original_noise_energy) if original_noise_energy > 0 else 0
    else:
        # æ»‘ã‚‰ã‹ã•ã«ã‚ˆã‚‹è©•ä¾¡
        smoothed_diff = np.var(np.diff(wavelet_result.values))
        original_diff = np.var(np.diff(original))
        noise_reduction = max(0, 1 - smoothed_diff / original_diff) if original_diff > 0 else 0
    
    # 2. ãƒˆãƒ¬ãƒ³ãƒ‰æŠ½å‡ºç²¾åº¦
    if wavelet_result.trend_component is not None and true_trend is not None:
        trend_component = wavelet_result.trend_component
        valid_mask = ~(np.isnan(trend_component) | np.isnan(true_trend))
        if np.sum(valid_mask) > 10:
            trend_correlation = np.corrcoef(trend_component[valid_mask], true_trend[valid_mask])[0, 1]
            trend_accuracy = max(0, trend_correlation) if not np.isnan(trend_correlation) else 0
        else:
            trend_accuracy = 0
    else:
        # ä½å‘¨æ³¢æˆåˆ†ã«ã‚ˆã‚‹è©•ä¾¡
        try:
            from scipy import signal
            # ãƒ­ãƒ¼ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
            b, a = signal.butter(3, 0.1, btype='low')
            low_freq_original = signal.filtfilt(b, a, original)
            trend_correlation = np.corrcoef(wavelet_result.values, low_freq_original)[0, 1]
            trend_accuracy = max(0, trend_correlation) if not np.isnan(trend_correlation) else 0
        except:
            trend_accuracy = 0.5
    
    # 3. ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºèƒ½åŠ›
    if wavelet_result.cycle_component is not None and true_cycle is not None:
        cycle_component = wavelet_result.cycle_component
        valid_mask = ~(np.isnan(cycle_component) | np.isnan(true_cycle))
        if np.sum(valid_mask) > 10:
            cycle_correlation = np.corrcoef(cycle_component[valid_mask], true_cycle[valid_mask])[0, 1]
            cycle_accuracy = max(0, cycle_correlation) if not np.isnan(cycle_correlation) else 0
        else:
            cycle_accuracy = 0
    else:
        # ä¸­å‘¨æ³¢æˆåˆ†ã«ã‚ˆã‚‹è©•ä¾¡
        try:
            from scipy import signal
            b, a = signal.butter(3, [0.1, 0.4], btype='band')
            band_freq_original = signal.filtfilt(b, a, original)
            if wavelet_result.cycle_component is not None:
                cycle_correlation = np.corrcoef(wavelet_result.cycle_component, band_freq_original)[0, 1]
            else:
                # ãƒ¡ã‚¤ãƒ³å€¤ã‹ã‚‰ä½å‘¨æ³¢ã‚’å¼•ã„ãŸæˆåˆ†ã§è©•ä¾¡
                detrended = wavelet_result.values - signal.filtfilt(*signal.butter(3, 0.1, btype='low'), wavelet_result.values)
                cycle_correlation = np.corrcoef(detrended, band_freq_original)[0, 1]
            cycle_accuracy = max(0, cycle_correlation) if not np.isnan(cycle_correlation) else 0
        except:
            cycle_accuracy = 0.5
    
    # 4. ä¿¡å·ä¿å­˜æ€§ï¼ˆå…ƒä¿¡å·ã¨ã®è¿½å¾“æ€§ï¼‰
    valid_values = wavelet_result.values[~np.isnan(wavelet_result.values)]
    valid_original = original[~np.isnan(wavelet_result.values)]
    
    if len(valid_values) > 10:
        tracking_error = np.mean(np.abs(valid_values - valid_original))
        price_std = np.std(valid_original)
        signal_preservation = max(0, 1 - tracking_error / price_std) if price_std > 0 else 0
    else:
        signal_preservation = 0
    
    # 5. è¨ˆç®—åŠ¹ç‡æ€§ï¼ˆé…å»¶è©•ä¾¡ï¼‰
    # NaNå€¤ã®æ•°ã§é…å»¶ã‚’è©•ä¾¡
    nan_count = np.sum(np.isnan(wavelet_result.values))
    delay_score = max(0, 1 - nan_count / n_points)
    
    # 6. ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¿å­˜å‰‡
    if (wavelet_result.trend_component is not None and 
        wavelet_result.cycle_component is not None and 
        wavelet_result.noise_component is not None):
        
        trend_energy = np.nansum(wavelet_result.trend_component ** 2)
        cycle_energy = np.nansum(wavelet_result.cycle_component ** 2)
        noise_energy = np.nansum(wavelet_result.noise_component ** 2)
        total_wavelet_energy = trend_energy + cycle_energy + noise_energy
        
        original_energy = np.sum(original ** 2)
        energy_preservation = min(1.0, total_wavelet_energy / original_energy) if original_energy > 0 else 0
    else:
        energy_preservation = 0.7  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    # 7. ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
    if wavelet_result.confidence_score is not None:
        confidence_score = np.nanmean(wavelet_result.confidence_score)
    else:
        confidence_score = 0.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    # 8. ç·åˆã‚¹ã‚³ã‚¢ï¼ˆé‡ã¿ä»˜ãå¹³å‡ï¼‰
    weights = [0.2, 0.2, 0.15, 0.15, 0.1, 0.1, 0.1]  # å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®é‡ã¿
    scores = [noise_reduction, trend_accuracy, cycle_accuracy, signal_preservation, 
              delay_score, energy_preservation, confidence_score]
    total_score = sum(w * s for w, s in zip(weights, scores))
    
    return {
        'noise_reduction': noise_reduction,
        'trend_accuracy': trend_accuracy,
        'cycle_accuracy': cycle_accuracy,
        'signal_preservation': signal_preservation,
        'delay_score': delay_score,
        'energy_preservation': energy_preservation,
        'confidence_score': confidence_score,
        'total_score': total_score
    }


def visualize_wavelet_comparison(data: pd.DataFrame, results: dict, save_path: str = None):
    """
    ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆè§£æçµæœã®æ¯”è¼ƒå¯è¦–åŒ–
    """
    # æœ‰åŠ¹ãªçµæœã®ã¿æŠ½å‡º
    valid_results = {k: v for k, v in results.items() if v is not None}
    n_wavelets = len(valid_results)
    
    if n_wavelets == 0:
        print("è¡¨ç¤ºå¯èƒ½ãªçµæœãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # å›³ã®è¨­å®š
    fig = plt.figure(figsize=(24, 16))
    fig.patch.set_facecolor('black')
    
    # ã‚°ãƒªãƒƒãƒ‰è¨­å®š
    rows = 4
    cols = 3
    
    colors = ['cyan', 'yellow', 'lime', 'magenta', 'orange', 'red', 'pink', 'lightblue']
    
    # 1. åŸä¿¡å· vs ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆè§£æçµæœ
    ax1 = plt.subplot(rows, cols, 1)
    ax1.plot(data.index, data['close'], 'white', alpha=0.8, linewidth=1.5, label='Original Signal')
    
    for i, (wavelet_type, result_data) in enumerate(valid_results.items()):
        if result_data and result_data['result']:
            ax1.plot(data.index, result_data['result'].values, 
                    colors[i % len(colors)], alpha=0.8, linewidth=2, 
                    label=f"{wavelet_type}")
    
    ax1.set_title('ğŸŒŠ Wavelet Analysis Comparison', fontsize=14, color='white', fontweight='bold')
    ax1.set_ylabel('Price', color='white')
    ax1.legend(fontsize=9, loc='upper left')
    ax1.grid(True, alpha=0.3)
    
    # 2. æ€§èƒ½ã‚¹ã‚³ã‚¢æ¯”è¼ƒ
    ax2 = plt.subplot(rows, cols, 2)
    wavelet_names = []
    total_scores = []
    
    for wavelet_type, result_data in valid_results.items():
        if result_data and result_data['performance']:
            wavelet_names.append(wavelet_type.replace('_', '\n'))
            total_scores.append(result_data['performance']['total_score'])
    
    bars = ax2.bar(wavelet_names, total_scores, color=colors[:len(wavelet_names)], alpha=0.8)
    ax2.set_title('ğŸ“Š Performance Scores', fontsize=14, color='white', fontweight='bold')
    ax2.set_ylabel('Total Score', color='white')
    ax2.set_ylim(0, 1)
    plt.setp(ax2.get_xticklabels(), rotation=45, ha='right', fontsize=10)
    
    # ã‚¹ã‚³ã‚¢å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
    for bar, score in zip(bars, total_scores):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{score:.3f}', ha='center', va='bottom', color='white', fontsize=9)
    
    ax2.grid(True, alpha=0.3)
    
    # 3. ãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†æ¯”è¼ƒ
    ax3 = plt.subplot(rows, cols, 3)
    if 'true_trend' in data.columns:
        ax3.plot(data.index, data['true_trend'], 'white', alpha=0.8, linewidth=2, label='True Trend')
    
    for i, (wavelet_type, result_data) in enumerate(valid_results.items()):
        if (result_data and result_data['result'] and 
            result_data['result'].trend_component is not None):
            ax3.plot(data.index, result_data['result'].trend_component,
                    colors[i % len(colors)], alpha=0.7, linewidth=1.5,
                    label=f"{wavelet_type}")
    
    ax3.set_title('ğŸ“ˆ Trend Components', fontsize=14, color='white', fontweight='bold')
    ax3.set_ylabel('Trend Value', color='white')
    ax3.legend(fontsize=9)
    ax3.grid(True, alpha=0.3)
    
    # 4. ã‚µã‚¤ã‚¯ãƒ«æˆåˆ†æ¯”è¼ƒ
    ax4 = plt.subplot(rows, cols, 4)
    if 'true_cycle' in data.columns:
        ax4.plot(data.index, data['true_cycle'], 'white', alpha=0.8, linewidth=2, label='True Cycle')
    
    for i, (wavelet_type, result_data) in enumerate(valid_results.items()):
        if (result_data and result_data['result'] and 
            result_data['result'].cycle_component is not None):
            ax4.plot(data.index, result_data['result'].cycle_component,
                    colors[i % len(colors)], alpha=0.7, linewidth=1.5,
                    label=f"{wavelet_type}")
    
    ax4.set_title('ğŸ”„ Cycle Components', fontsize=14, color='white', fontweight='bold')
    ax4.set_ylabel('Cycle Value', color='white')
    ax4.legend(fontsize=9)
    ax4.grid(True, alpha=0.3)
    
    # 5. ãƒã‚¤ã‚ºæˆåˆ†æ¯”è¼ƒ
    ax5 = plt.subplot(rows, cols, 5)
    if 'true_noise' in data.columns:
        ax5.plot(data.index, data['true_noise'], 'white', alpha=0.8, linewidth=2, label='True Noise')
    
    for i, (wavelet_type, result_data) in enumerate(valid_results.items()):
        if (result_data and result_data['result'] and 
            result_data['result'].noise_component is not None):
            ax5.plot(data.index, result_data['result'].noise_component,
                    colors[i % len(colors)], alpha=0.7, linewidth=1.5,
                    label=f"{wavelet_type}")
    
    ax5.set_title('âš¡ Noise Components', fontsize=14, color='white', fontweight='bold')
    ax5.set_ylabel('Noise Value', color='white')
    ax5.legend(fontsize=9)
    ax5.grid(True, alpha=0.3)
    
    # 6. ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ¬ã‚¸ãƒ¼ãƒ æ¯”è¼ƒ
    ax6 = plt.subplot(rows, cols, 6)
    for i, (wavelet_type, result_data) in enumerate(valid_results.items()):
        if (result_data and result_data['result'] and 
            result_data['result'].market_regime is not None):
            ax6.plot(data.index, result_data['result'].market_regime,
                    colors[i % len(colors)], alpha=0.7, linewidth=1.5,
                    label=f"{wavelet_type}")
    
    ax6.set_title('ğŸ›ï¸ Market Regime', fontsize=14, color='white', fontweight='bold')
    ax6.set_ylabel('Regime Value', color='white')
    ax6.legend(fontsize=9)
    ax6.grid(True, alpha=0.3)
    
    # 7. è©³ç´°æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆæœ€é«˜æ€§èƒ½ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆï¼‰
    ax7 = plt.subplot(rows, cols, 7)
    metrics = ['noise_reduction', 'trend_accuracy', 'cycle_accuracy', 'signal_preservation', 
               'delay_score', 'energy_preservation', 'confidence_score']
    metric_labels = ['Noise\nReduction', 'Trend\nAccuracy', 'Cycle\nAccuracy', 'Signal\nPreservation',
                    'Low\nDelay', 'Energy\nPreservation', 'Confidence']
    
    # æœ€é«˜æ€§èƒ½ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆç‰¹å®š
    best_wavelet = None
    best_score = 0
    for wavelet_type, result_data in valid_results.items():
        if result_data and result_data['performance']['total_score'] > best_score:
            best_score = result_data['performance']['total_score']
            best_wavelet = wavelet_type
    
    if best_wavelet and valid_results[best_wavelet]:
        perf = valid_results[best_wavelet]['performance']
        values = [perf[metric] for metric in metrics]
        
        bars = ax7.bar(metric_labels, values, color='lime', alpha=0.8)
        ax7.set_title(f'ğŸ† Best: {best_wavelet}', fontsize=14, color='white', fontweight='bold')
        ax7.set_ylabel('Score', color='white')
        ax7.set_ylim(0, 1)
        plt.setp(ax7.get_xticklabels(), rotation=45, ha='right', fontsize=9)
        
        # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
        for bar, value in zip(bars, values):
            ax7.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{value:.2f}', ha='center', va='bottom', color='white', fontsize=9)
        
        ax7.grid(True, alpha=0.3)
    
    # 8. å€‹åˆ¥æ€§èƒ½æ¯”è¼ƒï¼ˆãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆé¢¨ï¼‰
    ax8 = plt.subplot(rows, cols, 8)
    metrics_short = ['Noise\nReduc.', 'Trend\nAccu.', 'Cycle\nAccu.', 'Signal\nPres.']
    n_metrics = len(metrics_short)
    
    for i, (wavelet_type, result_data) in enumerate(list(valid_results.items())[:4]):  # ä¸Šä½4ã¤ã®ã¿
        if result_data and result_data['performance']:
            perf = result_data['performance']
            values = [perf['noise_reduction'], perf['trend_accuracy'], 
                     perf['cycle_accuracy'], perf['signal_preservation']]
            
            x_pos = np.arange(n_metrics)
            ax8.plot(x_pos, values, 'o-', color=colors[i % len(colors)], 
                    linewidth=2, markersize=6, alpha=0.8, label=wavelet_type)
    
    ax8.set_title('âš¡ Multi-Metric Comparison', fontsize=14, color='white', fontweight='bold')
    ax8.set_xticks(range(n_metrics))
    ax8.set_xticklabels(metrics_short, fontsize=9)
    ax8.set_ylabel('Score', color='white')
    ax8.set_ylim(0, 1)
    ax8.legend(fontsize=9)
    ax8.grid(True, alpha=0.3)
    
    # 9. ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ æ¯”è¼ƒ
    ax9 = plt.subplot(rows, cols, 9)
    for i, (wavelet_type, result_data) in enumerate(valid_results.items()):
        if (result_data and result_data['result'] and 
            result_data['result'].energy_spectrum is not None):
            spectrum = result_data['result'].energy_spectrum
            spectrum_freq = np.arange(len(spectrum))
            ax9.plot(spectrum_freq, spectrum, colors[i % len(colors)], 
                    alpha=0.7, linewidth=2, label=f"{wavelet_type}")
    
    ax9.set_title('ğŸŒˆ Energy Spectrum', fontsize=14, color='white', fontweight='bold')
    ax9.set_xlabel('Frequency Index', color='white')
    ax9.set_ylabel('Energy', color='white')
    ax9.legend(fontsize=9)
    ax9.grid(True, alpha=0.3)
    
    # 10. ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨
    ax10 = plt.subplot(rows, cols, 10)
    ax10.axis('off')
    
    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä½œæˆ
    ranking = sorted([(k, v['performance']['total_score']) for k, v in valid_results.items() 
                     if v and v['performance']], key=lambda x: x[1], reverse=True)
    
    ranking_text = "ğŸ† Wavelet Ranking:\n\n"
    for i, (wavelet_name, score) in enumerate(ranking):
        emoji = "ğŸ¥‡" if i == 0 else "ğŸ¥ˆ" if i == 1 else "ğŸ¥‰" if i == 2 else f"{i+1}."
        ranking_text += f"{emoji} {wavelet_name}:\n    {score:.3f}\n"
    
    ax10.text(0.05, 0.95, ranking_text, transform=ax10.transAxes, fontsize=11, 
            color='white', verticalalignment='top', fontfamily='monospace')
    
    # 11. è¨ˆç®—æ™‚é–“ãƒ»åŠ¹ç‡æ€§ï¼ˆä»®æƒ³ãƒ‡ãƒ¼ã‚¿ï¼‰
    ax11 = plt.subplot(rows, cols, 11)
    computation_times = [np.random.uniform(0.1, 2.0) for _ in valid_results]  # ä»®æƒ³æ™‚é–“
    wavelet_names_short = [name.replace('_', '\n') for name in valid_results.keys()]
    
    bars = ax11.bar(wavelet_names_short, computation_times, 
                   color=colors[:len(computation_times)], alpha=0.8)
    ax11.set_title('â±ï¸ Computation Time', fontsize=14, color='white', fontweight='bold')
    ax11.set_ylabel('Time (seconds)', color='white')
    plt.setp(ax11.get_xticklabels(), rotation=45, ha='right', fontsize=9)
    ax11.grid(True, alpha=0.3)
    
    # 12. æ¨å¥¨ç”¨é€”
    ax12 = plt.subplot(rows, cols, 12)
    ax12.axis('off')
    
    recommendations = {
        'haar_denoising': 'ãƒã‚¤ã‚ºé™¤å»\né«˜é€Ÿå‡¦ç†',
        'multiresolution': 'æ±ç”¨è§£æ\nãƒãƒ©ãƒ³ã‚¹é‡è¦–',
        'financial_adaptive': 'é‡‘èãƒ‡ãƒ¼ã‚¿\né«˜ç²¾åº¦',
        'quantum_analysis': 'è¤‡é›‘ãƒ‘ã‚¿ãƒ¼ãƒ³\næœ€é«˜ç²¾åº¦',
        'morlet_continuous': 'å‘¨æ³¢æ•°è§£æ\nè©³ç´°åˆ†æ',
        'daubechies_advanced': 'å¤šæˆåˆ†åˆ†é›¢\nå®Œå…¨åˆ†è§£',
        'ultimate_cosmic': 'ğŸŒŒ å®‡å®™æœ€å¼·\näººé¡å²ä¸Šæœ€é«˜'
    }
    
    rec_text = "ğŸ’¡ æ¨å¥¨ç”¨é€”:\n\n"
    for i, (wavelet_type, _) in enumerate(ranking[:6]):
        rec = recommendations.get(wavelet_type, 'æ±ç”¨')
        rec_text += f"â€¢ {wavelet_type}:\n  {rec}\n\n"
    
    ax12.text(0.05, 0.95, rec_text, transform=ax12.transAxes, fontsize=10,
            color='white', verticalalignment='top')
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, facecolor='black', edgecolor='none', dpi=300, bbox_inches='tight')
        print(f"ğŸŒŠ ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆæ¯”è¼ƒçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_path}")
    
    plt.show()


def detailed_wavelet_analysis(wavelet_type: str, data: pd.DataFrame):
    """
    ç‰¹å®šã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆæ‰‹æ³•ã®è©³ç´°åˆ†æ
    """
    print(f"\nğŸ” è©³ç´°åˆ†æ: {wavelet_type}")
    print("=" * 60)
    
    # ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå®Ÿè¡Œ
    try:
        wavelet_analyzer = WaveletUnified(wavelet_type=wavelet_type, src_type='close')
        result = wavelet_analyzer.calculate(data)
        metadata = wavelet_analyzer.get_wavelet_info()
    except Exception as e:
        print(f"âŒ ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # åŸºæœ¬æƒ…å ±è¡¨ç¤º
    print(f"ğŸ“Š åŸºæœ¬æƒ…å ±:")
    print(f"   ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆæ‰‹æ³•: {metadata.get('wavelet_type', 'N/A')}")
    print(f"   èª¬æ˜: {metadata.get('description', 'N/A')}")
    print(f"   ä¾¡æ ¼ã‚½ãƒ¼ã‚¹: {metadata.get('src_type', 'N/A')}")
    print(f"   è§£æå™¨å: {metadata.get('analyzer_name', 'N/A')}")
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æƒ…å ±
    params = metadata.get('parameters', {})
    if params:
        print(f"\nâš™ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
        for key, value in params.items():
            if value is not None:
                print(f"   {key}: {value}")
    
    # æˆåˆ†åˆ†æ
    print(f"\nğŸ”¬ æˆåˆ†åˆ†æ:")
    if result.trend_component is not None:
        trend_std = np.nanstd(result.trend_component)
        print(f"   ãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†æ¨™æº–åå·®: {trend_std:.4f}")
    
    if result.cycle_component is not None:
        cycle_std = np.nanstd(result.cycle_component)
        print(f"   ã‚µã‚¤ã‚¯ãƒ«æˆåˆ†æ¨™æº–åå·®: {cycle_std:.4f}")
    
    if result.noise_component is not None:
        noise_std = np.nanstd(result.noise_component)
        print(f"   ãƒã‚¤ã‚ºæˆåˆ†æ¨™æº–åå·®: {noise_std:.4f}")
    
    if result.detail_component is not None:
        detail_std = np.nanstd(result.detail_component)
        print(f"   ãƒ‡ã‚£ãƒ†ãƒ¼ãƒ«æˆåˆ†æ¨™æº–åå·®: {detail_std:.4f}")
    
    # ã‚¨ãƒãƒ«ã‚®ãƒ¼åˆ†æ
    if result.energy_spectrum is not None:
        max_energy = np.nanmax(result.energy_spectrum)
        mean_energy = np.nanmean(result.energy_spectrum)
        print(f"   æœ€å¤§ã‚¨ãƒãƒ«ã‚®ãƒ¼: {max_energy:.4f}")
        print(f"   å¹³å‡ã‚¨ãƒãƒ«ã‚®ãƒ¼: {mean_energy:.4f}")
    
    # ä¿¡é ¼åº¦åˆ†æ
    if result.confidence_score is not None:
        avg_confidence = np.nanmean(result.confidence_score)
        min_confidence = np.nanmin(result.confidence_score)
        max_confidence = np.nanmax(result.confidence_score)
        print(f"   å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.4f}")
        print(f"   ä¿¡é ¼åº¦ç¯„å›²: {min_confidence:.4f} - {max_confidence:.4f}")
    
    # æ€§èƒ½è©•ä¾¡
    performance = evaluate_wavelet_performance(
        data['close'].values, result,
        data.get('true_trend', None), data.get('true_cycle', None), data.get('true_noise', None)
    )
    
    print(f"\nğŸ¯ æ€§èƒ½è©•ä¾¡:")
    print(f"   ãƒã‚¤ã‚ºé™¤å»åŠ¹æœ: {performance['noise_reduction']:.3f}")
    print(f"   ãƒˆãƒ¬ãƒ³ãƒ‰æŠ½å‡ºç²¾åº¦: {performance['trend_accuracy']:.3f}")
    print(f"   ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºèƒ½åŠ›: {performance['cycle_accuracy']:.3f}")
    print(f"   ä¿¡å·ä¿å­˜æ€§: {performance['signal_preservation']:.3f}")
    print(f"   è¨ˆç®—åŠ¹ç‡æ€§: {performance['delay_score']:.3f}")
    print(f"   ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¿å­˜: {performance['energy_preservation']:.3f}")
    print(f"   ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢: {performance['confidence_score']:.3f}")
    print(f"   ç·åˆã‚¹ã‚³ã‚¢: {performance['total_score']:.3f}")


def load_data_from_config(config_path: str = 'config.yaml') -> pd.DataFrame:
    """
    config.yamlã‹ã‚‰å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
    """
    try:
        print(f"ğŸ“¡ {config_path} ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
            
        # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        binance_config = config.get('binance_data', {})
        data_dir = binance_config.get('data_dir', 'data/binance')
        binance_data_source = BinanceDataSource(data_dir)
        
        # CSVãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã¯ãƒ€ãƒŸãƒ¼ã¨ã—ã¦æ¸¡ã™ï¼ˆBinanceãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®ã¿ã‚’ä½¿ç”¨ï¼‰
        dummy_csv_source = CSVDataSource("dummy")
        data_loader = DataLoader(
            data_source=dummy_csv_source,
            binance_data_source=binance_data_source
        )
        data_processor = DataProcessor()
        
        # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‡¦ç†
        raw_data = data_loader.load_data_from_config(config)
        processed_data = {
            symbol: data_processor.process(df)
            for symbol, df in raw_data.items()
        }
        
        # æœ€åˆã®ã‚·ãƒ³ãƒœãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        first_symbol = next(iter(processed_data))
        data = processed_data[first_symbol]
        
        print(f"âœ… å®Ÿãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {first_symbol}")
        print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ•°: {len(data)}")
        return data
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        print("ğŸ”„ åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™")
        return create_synthetic_data(800)


def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    """
    print("ğŸŒŠ Wavelet Unified Demo V1.0")
    print("=" * 60)
    
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    print("\n1ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿æº–å‚™")
    
    # å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’è©¦ã—ã€å¤±æ•—ã—ãŸã‚‰åˆæˆãƒ‡ãƒ¼ã‚¿
    data = load_data_from_config('config.yaml')
    
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:")
    print(f"   æœŸé–“: {len(data)} ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ")
    print(f"   ä¾¡æ ¼ç¯„å›²: ${data['close'].min():.2f} - ${data['close'].max():.2f}")
    print(f"   å¹³å‡ä¾¡æ ¼: ${data['close'].mean():.2f}")
    print(f"   ä¾¡æ ¼æ¨™æº–åå·®: ${data['close'].std():.2f}")
    
    # å…¨ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆæ‰‹æ³•ãƒ†ã‚¹ãƒˆ
    print("\n2ï¸âƒ£ å…¨ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆæ‰‹æ³•ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    results = test_all_wavelets(data)
    
    # çµæœæ¯”è¼ƒãƒ»å¯è¦–åŒ–
    print("\n3ï¸âƒ£ çµæœã®å¯è¦–åŒ–")
    output_path = os.path.join('output', 'wavelet_unified_comparison.png')
    os.makedirs('output', exist_ok=True)
    visualize_wavelet_comparison(data, results, output_path)
    
    # è©³ç´°åˆ†æ
    print("\n4ï¸âƒ£ è©³ç´°åˆ†æ")
    
    # æœ€é«˜æ€§èƒ½ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆã®è©³ç´°åˆ†æ
    valid_results = {k: v for k, v in results.items() if v is not None}
    if valid_results:
        best_wavelet = max(valid_results.keys(), 
                          key=lambda k: valid_results[k]['performance']['total_score'])
        detailed_wavelet_analysis(best_wavelet, data)
    
    # ç·åˆãƒ¬ãƒãƒ¼ãƒˆ
    print("\nğŸ“‹ ç·åˆãƒ¬ãƒãƒ¼ãƒˆ")
    print("=" * 60)
    
    valid_count = len(valid_results)
    total_wavelets = len(WaveletUnified.get_available_wavelets())
    
    print(f"âœ… ãƒ†ã‚¹ãƒˆæˆåŠŸ: {valid_count}/{total_wavelets} ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆæ‰‹æ³•")
    
    if valid_results:
        # ãƒˆãƒƒãƒ—3
        ranking = sorted([(k, v['performance']['total_score']) for k, v in valid_results.items()], 
                        key=lambda x: x[1], reverse=True)
        
        print(f"\nğŸ† ãƒˆãƒƒãƒ—3ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆæ‰‹æ³•:")
        for i, (name, score) in enumerate(ranking[:3]):
            emoji = "ğŸ¥‡" if i == 0 else "ğŸ¥ˆ" if i == 1 else "ğŸ¥‰"
            print(f"   {emoji} {name}: {score:.3f}")
        
        # æ¨å¥¨ç”¨é€”
        print(f"\nğŸ’¡ æ¨å¥¨ç”¨é€”:")
        if ranking[0][0] == 'multiresolution':
            print("   - æ±ç”¨çš„ãªè§£æã«ã¯ multiresolution ãŒãŠå‹§ã‚")
        elif ranking[0][0] == 'financial_adaptive':
            print("   - é‡‘èãƒ‡ãƒ¼ã‚¿ã®é«˜ç²¾åº¦è§£æã«ã¯ financial_adaptive ãŒãŠå‹§ã‚")
        elif ranking[0][0] == 'quantum_analysis':
            print("   - è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºã«ã¯ quantum_analysis ãŒãŠå‹§ã‚")
        elif ranking[0][0] == 'haar_denoising':
            print("   - é«˜é€Ÿãƒã‚¤ã‚ºé™¤å»ã«ã¯ haar_denoising ãŒãŠå‹§ã‚")
        elif ranking[0][0] == 'ultimate_cosmic':
            print("   ğŸŒŒ å®‡å®™æœ€å¼·ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆè§£æãŒå‹åˆ©ã‚’åã‚ã¾ã—ãŸï¼")
            print("   ğŸš€ é©å‘½çš„ãª7ã¤ã®æŠ€è¡“çµ±åˆã«ã‚ˆã‚‹å²ä¸Šæœ€é«˜ã®æ€§èƒ½ã‚’å®Ÿç¾")
        else:
            print(f"   - {ranking[0][0]} ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆæ‰‹æ³•ãŒæœ€é©ã§ã™")
    
    print(f"\nğŸ‰ ãƒ‡ãƒ¢å®Œäº†!")
    print(f"ğŸŒŠ çµæœã¯ {output_path} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
    print(f"\nğŸ“ å„ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆæ‰‹æ³•ã®ç‰¹å¾´:")
    for wavelet_type, description in WaveletUnified.get_available_wavelets().items():
        print(f"   â€¢ {wavelet_type}: {description}")


if __name__ == "__main__":
    main() 