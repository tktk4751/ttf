#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ðŸŒ€ **Hilbert Transform Unified ä½¿ç”¨ä¾‹** ðŸŒ€

å„ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’
çµ±åˆã—ãŸã‚¯ãƒ©ã‚¹ã®ä½¿ç”¨ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from indicators.hilbert_unified import HilbertTransformUnified

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
def generate_sample_data(n=1000):
    """ã‚µãƒ³ãƒ—ãƒ«ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    np.random.seed(42)
    
    # åŸºæœ¬ãƒˆãƒ¬ãƒ³ãƒ‰ + ãƒŽã‚¤ã‚º + ã‚µã‚¤ã‚¯ãƒ«æˆåˆ†
    t = np.arange(n)
    trend = 100 + 0.01 * t
    cycle = 5 * np.sin(2 * np.pi * t / 50) + 3 * np.cos(2 * np.pi * t / 30)
    noise = np.random.normal(0, 1, n)
    
    prices = trend + cycle + noise
    
    # DataFrameå½¢å¼ã§è¿”ã™
    data = pd.DataFrame({
        'open': prices * 0.999,
        'high': prices * 1.001,
        'low': prices * 0.998,
        'close': prices,
        'volume': np.random.randint(1000, 10000, n)
    })
    
    return data

def demonstrate_algorithms():
    """å„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ€§èƒ½ã‚’æ¯”è¼ƒãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    print("ðŸŒ€ ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›çµ±åˆã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ðŸŒ€\n")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    data = generate_sample_data(500)
    prices = data['close'].values
    
    # åˆ©ç”¨å¯èƒ½ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’è¡¨ç¤º
    algorithms = HilbertTransformUnified.get_available_algorithms()
    print("ðŸ“‹ åˆ©ç”¨å¯èƒ½ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ :")
    for name, description in algorithms.items():
        print(f"  â€¢ {name}: {description}")
    print()
    
    # å„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ã‚’å®Ÿè¡Œ
    results = {}
    
    for algorithm_name in algorithms.keys():
        print(f"ðŸ”„ {algorithm_name} ã‚’å®Ÿè¡Œä¸­...")
        
        try:
            # ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
            hilbert = HilbertTransformUnified(
                algorithm_type=algorithm_name,
                src_type='close'
            )
            
            # è¨ˆç®—å®Ÿè¡Œ
            result = hilbert.calculate(data)
            results[algorithm_name] = {
                'hilbert': hilbert,
                'result': result,
                'metadata': hilbert.get_algorithm_metadata()
            }
            
            print(f"  âœ… æˆåŠŸ: ãƒ‡ãƒ¼ã‚¿ç‚¹æ•° = {len(result.amplitude)}")
            print(f"  ðŸ“Š å¹³å‡æŒ¯å¹… = {np.nanmean(result.amplitude):.4f}")
            print(f"  ðŸ“Š å¹³å‡å‘¨æ³¢æ•° = {np.nanmean(result.frequency):.6f}")
            
            # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å›ºæœ‰ã®æƒ…å ±
            if result.trend_strength is not None:
                print(f"  ðŸ“ˆ å¹³å‡ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ = {np.nanmean(result.trend_strength):.4f}")
            if result.quantum_entanglement is not None:
                print(f"  ðŸ”¬ å¹³å‡é‡å­ã‚‚ã¤ã‚Œ = {np.nanmean(result.quantum_entanglement):.4f}")
            if result.quantum_coherence is not None:
                print(f"  ðŸ”¬ å¹³å‡é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ = {np.nanmean(result.quantum_coherence):.4f}")
            if result.confidence_score is not None:
                print(f"  ðŸŽ¯ å¹³å‡ä¿¡é ¼åº¦ = {np.nanmean(result.confidence_score):.4f}")
            
        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        
        print()
    
    return results, data

def create_comparison_chart(results, data):
    """æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ"""
    
    print("ðŸ“Š æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆä½œæˆä¸­...")
    
    fig, axes = plt.subplots(3, 3, figsize=(18, 15))
    fig.suptitle('ðŸŒ€ ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ¯”è¼ƒ', fontsize=16, fontweight='bold')
    
    prices = data['close'].values
    x = np.arange(len(prices))
    
    # åŽŸä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
    axes[0, 0].plot(x, prices, 'b-', alpha=0.7, label='ä¾¡æ ¼')
    axes[0, 0].set_title('åŽŸä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # å„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®çµæžœã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    algorithm_positions = [
        (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 0), (2, 1)
    ]
    
    for i, (algorithm_name, data_dict) in enumerate(results.items()):
        if i >= len(algorithm_positions):
            break
            
        row, col = algorithm_positions[i]
        result = data_dict['result']
        
        # çž¬æ™‚æŒ¯å¹…ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
        valid_indices = ~np.isnan(result.amplitude)
        if np.any(valid_indices):
            axes[row, col].plot(x[valid_indices], result.amplitude[valid_indices], 
                              'r-', alpha=0.8, linewidth=1.5)
            axes[row, col].set_title(f'{algorithm_name}\nçž¬æ™‚æŒ¯å¹…')
            axes[row, col].grid(True, alpha=0.3)
            
            # Yè»¸ã®ç¯„å›²ã‚’è¨­å®š
            y_min, y_max = np.nanpercentile(result.amplitude[valid_indices], [5, 95])
            axes[row, col].set_ylim(y_min, y_max)
    
    # æœ€å¾Œã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã§å‘¨æ³¢æ•°æ¯”è¼ƒ
    if len(results) > 0:
        axes[2, 2].set_title('çž¬æ™‚å‘¨æ³¢æ•°æ¯”è¼ƒ')
        colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink']
        
        for i, (algorithm_name, data_dict) in enumerate(results.items()):
            result = data_dict['result']
            valid_indices = ~np.isnan(result.frequency)
            
            if np.any(valid_indices) and i < len(colors):
                # å‘¨æ³¢æ•°ã‚’ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
                freq_smooth = pd.Series(result.frequency[valid_indices]).rolling(window=20, center=True).mean()
                axes[2, 2].plot(x[valid_indices], freq_smooth, 
                              color=colors[i], alpha=0.7, linewidth=1.5, 
                              label=algorithm_name[:10])
        
        axes[2, 2].legend(fontsize=8)
        axes[2, 2].grid(True, alpha=0.3)
        axes[2, 2].set_ylabel('å‘¨æ³¢æ•°')
    
    plt.tight_layout()
    
    # ä¿å­˜
    output_path = os.path.join(os.path.dirname(__file__), 'output', 'hilbert_unified_comparison.png')
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"ðŸ“Š ãƒãƒ£ãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
    
    plt.show()

def demonstrate_usage_patterns():
    """å®Ÿç”¨çš„ãªä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    print("\nðŸŽ¯ å®Ÿç”¨çš„ãªä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³\n")
    
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    data = generate_sample_data(200)
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: åŸºæœ¬çš„ãªä½¿ç”¨
    print("1ï¸âƒ£ åŸºæœ¬çš„ãªä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³:")
    hilbert_basic = HilbertTransformUnified(algorithm_type='basic')
    result_basic = hilbert_basic.calculate(data)
    
    print(f"   æŒ¯å¹…ç¯„å›²: {np.nanmin(result_basic.amplitude):.3f} - {np.nanmax(result_basic.amplitude):.3f}")
    print(f"   ä½ç›¸ç¯„å›²: {np.nanmin(result_basic.phase):.3f} - {np.nanmax(result_basic.phase):.3f}")
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: é‡å­å¼·åŒ–ç‰ˆã®ä½¿ç”¨
    print("\n2ï¸âƒ£ é‡å­å¼·åŒ–ç‰ˆã®ä½¿ç”¨:")
    hilbert_quantum = HilbertTransformUnified(algorithm_type='quantum_enhanced')
    result_quantum = hilbert_quantum.calculate(data)
    
    quantum_components = hilbert_quantum.get_quantum_components()
    if quantum_components:
        print(f"   é‡å­ã‚‚ã¤ã‚Œå¹³å‡: {np.nanmean(quantum_components['quantum_entanglement']):.4f}")
    
    trend_components = hilbert_quantum.get_trend_components()
    if trend_components:
        print(f"   ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦å¹³å‡: {np.nanmean(trend_components['trend_strength']):.4f}")
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³3: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ´»ç”¨
    print("\n3ï¸âƒ£ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ´»ç”¨:")
    metadata = hilbert_quantum.get_algorithm_metadata()
    for key, value in metadata.items():
        if isinstance(value, (int, float)):
            print(f"   {key}: {value:.4f}")
        else:
            print(f"   {key}: {value}")
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³4: è¤‡æ•°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®çµ„ã¿åˆã‚ã›
    print("\n4ï¸âƒ£ è¤‡æ•°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®çµ„ã¿åˆã‚ã›ä½¿ç”¨:")
    algorithms_to_test = ['basic', 'quantum_enhanced', 'quantum_supreme']
    
    ensemble_amplitude = np.zeros(len(data))
    ensemble_phase = np.zeros(len(data))
    
    for algorithm_name in algorithms_to_test:
        hilbert = HilbertTransformUnified(algorithm_type=algorithm_name)
        result = hilbert.calculate(data)
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å¹³å‡
        valid_mask = ~np.isnan(result.amplitude)
        ensemble_amplitude[valid_mask] += result.amplitude[valid_mask] / len(algorithms_to_test)
        ensemble_phase[valid_mask] += result.phase[valid_mask] / len(algorithms_to_test)
    
    print(f"   ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æŒ¯å¹…å¹³å‡: {np.nanmean(ensemble_amplitude):.4f}")
    print(f"   ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ä½ç›¸å¹³å‡: {np.nanmean(ensemble_phase):.4f}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    try:
        # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ¯”è¼ƒãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        results, data = demonstrate_algorithms()
        
        # æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆä½œæˆ
        if results:
            create_comparison_chart(results, data)
        
        # å®Ÿç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        demonstrate_usage_patterns()
        
        print("\nðŸŽ‰ ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("\nðŸ“ åˆ©ç”¨æ–¹æ³•:")
        print("   â€¢ å„ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã‹ã‚‰ HilbertTransformUnified ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
        print("   â€¢ é©åˆ‡ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚¿ã‚¤ãƒ—ã‚’é¸æŠž")
        print("   â€¢ calculate() ãƒ¡ã‚½ãƒƒãƒ‰ã§è¨ˆç®—å®Ÿè¡Œ")
        print("   â€¢ çµæžœã‹ã‚‰å¿…è¦ãªæˆåˆ†ã‚’å–å¾—")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 