#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ðŸ§  **å››ç¨®ã®Adaptive UKFæ¯”è¼ƒãƒ‡ãƒ¢** ðŸ§ 

4ã¤ã®æ‰‹æ³•ã‚’æ¯”è¼ƒï¼š
1. **æ¨™æº–UKF** (åŸºæº–)
2. **ç§ã®å®Ÿè£…ç‰ˆAUKF** (çµ±è¨ˆçš„ç›£è¦–ãƒ»é©å¿œåˆ¶å¾¡)
3. **è«–æ–‡ç‰ˆAUKF** (Ge et al. 2019 - ç›¸äº’ç›¸é–¢ç†è«–)
4. **Neuralç‰ˆAUKF** (Levy & Klein 2025 - CNN ProcessNet)

ðŸŒŸ **æ¯”è¼ƒé …ç›®:**
- ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç²¾åº¦ (RMSE)
- é©å¿œæ€§èƒ½
- è¨ˆç®—åŠ¹çŽ‡
- ç†è«–çš„åŽ³å¯†æ€§
- å®Ÿç”¨æ€§
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings
import time
from pathlib import Path
import sys

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‘ã‚¹ã®è¿½åŠ 
project_root = Path(__file__).parent.parent
if project_root not in sys.path:
    sys.path.append(str(project_root))

try:
    from indicators.unscented_kalman_filter import UnscentedKalmanFilter
    from indicators.adaptive_ukf import AdaptiveUnscentedKalmanFilter
    from indicators.academic_adaptive_ukf import AcademicAdaptiveUnscentedKalmanFilter
    from indicators.neural_adaptive_ukf import NeuralAdaptiveUnscentedKalmanFilter
except ImportError as e:
    print(f"âš ï¸ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    print("indicators/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«UKFãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    sys.exit(1)

# æ—¥æœ¬èªžãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

# è­¦å‘Šç„¡åŠ¹åŒ–
warnings.filterwarnings('ignore')


def generate_complex_test_data(n_points: int = 1000, noise_level: float = 0.5) -> tuple:
    """
    è¤‡é›‘ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    
    ç‰¹å¾´ï¼š
    - è¤‡æ•°ã®ãƒˆãƒ¬ãƒ³ãƒ‰å¤‰åŒ–
    - ç•°å¸¸å€¤ã‚’å«ã‚€
    - æ™‚å¤‰ãƒŽã‚¤ã‚º
    - å‘¨æœŸæ€§æˆåˆ†
    
    Returns:
        (true_signal, noisy_signal, outliers, noise_changes)
    """
    t = np.linspace(0, 10, n_points)
    
    # çœŸã®ä¿¡å·ï¼ˆè¤‡é›‘ãªæ§‹é€ ï¼‰
    trend1 = 100 + 10 * t
    trend2 = np.where(t > 3, 15 * (t - 3), 0)  # 3ç§’å¾Œã‹ã‚‰ãƒˆãƒ¬ãƒ³ãƒ‰å¤‰åŒ–
    trend3 = np.where(t > 7, -20 * (t - 7), 0)  # 7ç§’å¾Œã‹ã‚‰ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰
    
    # å‘¨æœŸæˆåˆ†
    seasonal = 5 * np.sin(2 * np.pi * t / 2) + 2 * np.cos(2 * np.pi * t / 0.5)
    
    # çœŸã®ä¿¡å·
    true_signal = trend1 + trend2 + trend3 + seasonal
    
    # æ™‚å¤‰ãƒŽã‚¤ã‚º
    noise_phases = np.array([0.1, 0.3, 0.8, 0.4])  # 4æ®µéšŽã®ãƒŽã‚¤ã‚ºãƒ¬ãƒ™ãƒ«
    phase_boundaries = [0, 0.25, 0.5, 0.75, 1.0]
    
    noise = np.zeros(n_points)
    noise_changes = np.zeros(n_points)
    
    for i in range(len(noise_phases)):
        start_idx = int(phase_boundaries[i] * n_points)
        end_idx = int(phase_boundaries[i + 1] * n_points)
        
        phase_noise = noise_phases[i] * noise_level
        noise[start_idx:end_idx] = np.random.normal(0, phase_noise, end_idx - start_idx)
        noise_changes[start_idx:end_idx] = phase_noise
    
    # ç•°å¸¸å€¤è¿½åŠ ï¼ˆå…¨ä½“ã®3%ï¼‰
    n_outliers = int(n_points * 0.03)
    outlier_indices = np.random.choice(n_points, n_outliers, replace=False)
    outlier_values = np.random.normal(0, noise_level * 5, n_outliers)
    
    outliers = np.zeros(n_points, dtype=bool)
    outliers[outlier_indices] = True
    
    # ãƒŽã‚¤ã‚¸ãƒ¼ä¿¡å·
    noisy_signal = true_signal + noise
    noisy_signal[outlier_indices] += outlier_values
    
    print(f"ðŸ“Š **ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†**")
    print(f"   - ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°: {n_points}")
    print(f"   - ç•°å¸¸å€¤æ•°: {n_outliers} ({n_outliers/n_points*100:.1f}%)")
    print(f"   - ãƒŽã‚¤ã‚ºæ®µéšŽ: {len(noise_phases)}æ®µéšŽ")
    print(f"   - ãƒŽã‚¤ã‚ºãƒ¬ãƒ™ãƒ«: {noise_phases}")
    
    return true_signal, noisy_signal, outliers, noise_changes


def run_four_methods_comparison(data: np.ndarray, true_values: np.ndarray) -> dict:
    """
    4ã¤ã®æ‰‹æ³•ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
    
    Args:
        data: è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿
        true_values: çœŸã®å€¤
    
    Returns:
        å„æ‰‹æ³•ã®çµæžœè¾žæ›¸
    """
    methods = {}
    
    print(f"\nðŸ”„ **4æ‰‹æ³•æ¯”è¼ƒå®Ÿè¡Œä¸­...**")
    
    # 1. æ¨™æº–UKFï¼ˆåŸºæº–ï¼‰
    print("   1ï¸âƒ£ æ¨™æº–UKFè¨ˆç®—ä¸­...")
    start_time = time.time()
    
    try:
        ukf_standard = UnscentedKalmanFilter()
        ukf_result = ukf_standard.calculate(data)
        
        methods['Standard UKF'] = {
            'result': ukf_result,
            'filtered_values': ukf_result.filtered_values,
            'computation_time': time.time() - start_time,
            'type': 'baseline',
            'description': 'æ¨™æº–UKFï¼ˆå›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰'
        }
        print(f"      âœ… å®Œäº† ({methods['Standard UKF']['computation_time']:.3f}ç§’)")
        
    except Exception as e:
        print(f"      âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
        methods['Standard UKF'] = None
    
    # 2. ç§ã®å®Ÿè£…ç‰ˆAUKFï¼ˆçµ±è¨ˆçš„ç›£è¦–ãƒ»é©å¿œåˆ¶å¾¡ï¼‰
    print("   2ï¸âƒ£ ç§ã®å®Ÿè£…ç‰ˆAUKFè¨ˆç®—ä¸­...")
    start_time = time.time()
    
    try:
        aukf_mine = AdaptiveUnscentedKalmanFilter()
        aukf_result = aukf_mine.calculate(data)
        
        methods['My Implementation AUKF'] = {
            'result': aukf_result,
            'filtered_values': aukf_result.filtered_values,
            'computation_time': time.time() - start_time,
            'type': 'statistical_adaptive',
            'description': 'çµ±è¨ˆçš„ç›£è¦–ãƒ»é©å¿œåˆ¶å¾¡ç‰ˆ'
        }
        print(f"      âœ… å®Œäº† ({methods['My Implementation AUKF']['computation_time']:.3f}ç§’)")
        
    except Exception as e:
        print(f"      âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
        methods['My Implementation AUKF'] = None
    
    # 3. è«–æ–‡ç‰ˆAUKFï¼ˆGe et al. 2019 - ç›¸äº’ç›¸é–¢ç†è«–ï¼‰
    print("   3ï¸âƒ£ è«–æ–‡ç‰ˆAUKF (Ge et al. 2019) è¨ˆç®—ä¸­...")
    start_time = time.time()
    
    try:
        aukf_academic = AcademicAdaptiveUnscentedKalmanFilter()
        academic_result = aukf_academic.calculate(data)
        
        methods['Academic AUKF (Ge 2019)'] = {
            'result': academic_result,
            'filtered_values': academic_result.filtered_values,
            'computation_time': time.time() - start_time,
            'type': 'mathematical_rigorous',
            'description': 'ç›¸äº’ç›¸é–¢ç†è«–ç‰ˆï¼ˆGe et al.ï¼‰'
        }
        print(f"      âœ… å®Œäº† ({methods['Academic AUKF (Ge 2019)']['computation_time']:.3f}ç§’)")
        
    except Exception as e:
        print(f"      âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
        methods['Academic AUKF (Ge 2019)'] = None
    
    # 4. Neuralç‰ˆAUKFï¼ˆLevy & Klein 2025 - CNN ProcessNetï¼‰
    print("   4ï¸âƒ£ Neuralç‰ˆAUKF (Levy & Klein 2025) è¨ˆç®—ä¸­...")
    start_time = time.time()
    
    try:
        aukf_neural = NeuralAdaptiveUnscentedKalmanFilter()
        neural_result = aukf_neural.calculate(data)
        
        methods['Neural AUKF (Levy 2025)'] = {
            'result': neural_result,
            'filtered_values': neural_result.filtered_values,
            'computation_time': time.time() - start_time,
            'type': 'neural_adaptive',
            'description': 'CNN ProcessNetç‰ˆï¼ˆLevy & Kleinï¼‰'
        }
        print(f"      âœ… å®Œäº† ({methods['Neural AUKF (Levy 2025)']['computation_time']:.3f}ç§’)")
        
    except Exception as e:
        print(f"      âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
        methods['Neural AUKF (Levy 2025)'] = None
    
    return methods


def calculate_performance_metrics(methods: dict, true_values: np.ndarray, outliers: np.ndarray) -> pd.DataFrame:
    """
    æ€§èƒ½æŒ‡æ¨™è¨ˆç®—
    
    Args:
        methods: å„æ‰‹æ³•ã®çµæžœ
        true_values: çœŸã®å€¤
        outliers: ç•°å¸¸å€¤ãƒžã‚¹ã‚¯
    
    Returns:
        æ€§èƒ½æŒ‡æ¨™ã®DataFrame
    """
    metrics_list = []
    
    for method_name, method_data in methods.items():
        if method_data is None:
            continue
        
        filtered_values = method_data['filtered_values']
        
        if len(filtered_values) != len(true_values):
            continue
        
        # åŸºæœ¬æŒ‡æ¨™
        rmse_all = np.sqrt(np.mean((filtered_values - true_values) ** 2))
        mae_all = np.mean(np.abs(filtered_values - true_values))
        
        # ã‚¯ãƒªãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½ï¼ˆç•°å¸¸å€¤é™¤å¤–ï¼‰
        clean_mask = ~outliers
        if np.sum(clean_mask) > 0:
            rmse_clean = np.sqrt(np.mean((filtered_values[clean_mask] - true_values[clean_mask]) ** 2))
            mae_clean = np.mean(np.abs(filtered_values[clean_mask] - true_values[clean_mask]))
        else:
            rmse_clean = rmse_all
            mae_clean = mae_all
        
        # è¨ˆç®—æ™‚é–“
        comp_time = method_data['computation_time']
        
        # æ‰‹æ³•ã‚¿ã‚¤ãƒ—
        method_type = method_data['type']
        description = method_data['description']
        
        metrics_list.append({
            'Method': method_name,
            'Type': method_type,
            'Description': description,
            'RMSE_All': rmse_all,
            'MAE_All': mae_all,
            'RMSE_Clean': rmse_clean,
            'MAE_Clean': mae_clean,
            'Computation_Time': comp_time,
            'Speed_Rank': 0  # å¾Œã§è¨­å®š
        })
    
    metrics_df = pd.DataFrame(metrics_list)
    
    # é€Ÿåº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    if len(metrics_df) > 0:
        metrics_df = metrics_df.sort_values('Computation_Time')
        metrics_df['Speed_Rank'] = range(1, len(metrics_df) + 1)
        
        # RMSEæ”¹å–„çŽ‡è¨ˆç®—ï¼ˆæ¨™æº–UKFã‚’åŸºæº–ã¨ã™ã‚‹ï¼‰
        baseline_rmse = None
        for _, row in metrics_df.iterrows():
            if 'Standard' in row['Method']:
                baseline_rmse = row['RMSE_All']
                break
        
        if baseline_rmse is not None:
            metrics_df['RMSE_Improvement'] = ((baseline_rmse - metrics_df['RMSE_All']) / baseline_rmse * 100)
        else:
            metrics_df['RMSE_Improvement'] = 0
    
    return metrics_df


def create_comprehensive_visualization(
    methods: dict,
    true_values: np.ndarray,
    noisy_data: np.ndarray,
    outliers: np.ndarray,
    metrics_df: pd.DataFrame
):
    """
    åŒ…æ‹¬çš„å¯è¦–åŒ–ä½œæˆ
    """
    # æ‰‹æ³•ã®è‰²ã¨ã‚¹ã‚¿ã‚¤ãƒ«
    method_styles = {
        'Standard UKF': {'color': 'gray', 'linestyle': '-', 'alpha': 0.8},
        'My Implementation AUKF': {'color': 'blue', 'linestyle': '-', 'alpha': 0.9},
        'Academic AUKF (Ge 2019)': {'color': 'red', 'linestyle': '-', 'alpha': 0.9},
        'Neural AUKF (Levy 2025)': {'color': 'green', 'linestyle': '-', 'alpha': 0.9}
    }
    
    # ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    fig = plt.figure(figsize=(20, 16))
    
    # 1. ãƒ¡ã‚¤ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæžœæ¯”è¼ƒ
    ax1 = plt.subplot(3, 2, (1, 2))
    
    # çœŸã®å€¤
    plt.plot(true_values, 'k-', linewidth=2, label='True Signal', alpha=0.8)
    
    # ãƒŽã‚¤ã‚¸ãƒ¼ãƒ‡ãƒ¼ã‚¿
    plt.plot(noisy_data, color='lightgray', alpha=0.5, label='Noisy Data', linewidth=0.5)
    
    # ç•°å¸¸å€¤ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
    outlier_indices = np.where(outliers)[0]
    if len(outlier_indices) > 0:
        plt.scatter(outlier_indices, noisy_data[outlier_indices], 
                   color='orange', s=30, alpha=0.7, label='Outliers', zorder=5)
    
    # å„æ‰‹æ³•ã®çµæžœ
    for method_name, method_data in methods.items():
        if method_data is None:
            continue
        
        style = method_styles.get(method_name, {'color': 'purple', 'linestyle': '-', 'alpha': 0.8})
        plt.plot(method_data['filtered_values'], 
                label=method_name,
                color=style['color'],
                linestyle=style['linestyle'],
                linewidth=2,
                alpha=style['alpha'])
    
    plt.title('ðŸ§  Four Adaptive UKF Methods Comparison', fontsize=16, fontweight='bold')
    plt.xlabel('Time Steps')
    plt.ylabel('Value')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)
    
    # 2. æ€§èƒ½æŒ‡æ¨™ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
    ax2 = plt.subplot(3, 2, 3)
    
    if len(metrics_df) > 0:
        methods_short = [name.split('(')[0].strip() for name in metrics_df['Method']]
        colors = [method_styles.get(full_name, {'color': 'purple'})['color'] 
                 for full_name in metrics_df['Method']]
        
        bars = plt.bar(methods_short, metrics_df['RMSE_All'], color=colors, alpha=0.7)
        
        # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
        for bar, rmse in zip(bars, metrics_df['RMSE_All']):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.01,
                    f'{rmse:.3f}', ha='center', va='bottom', fontweight='bold')
        
        plt.title('RMSE Comparison (All Data)', fontweight='bold')
        plt.ylabel('RMSE')
        plt.xticks(rotation=45)
    
    # 3. ã‚¯ãƒªãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã§ã®RMSE
    ax3 = plt.subplot(3, 2, 4)
    
    if len(metrics_df) > 0:
        bars = plt.bar(methods_short, metrics_df['RMSE_Clean'], color=colors, alpha=0.7)
        
        for bar, rmse in zip(bars, metrics_df['RMSE_Clean']):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.01,
                    f'{rmse:.3f}', ha='center', va='bottom', fontweight='bold')
        
        plt.title('RMSE Comparison (Clean Data)', fontweight='bold')
        plt.ylabel('RMSE')
        plt.xticks(rotation=45)
    
    # 4. è¨ˆç®—æ™‚é–“æ¯”è¼ƒ
    ax4 = plt.subplot(3, 2, 5)
    
    if len(metrics_df) > 0:
        bars = plt.bar(methods_short, metrics_df['Computation_Time'], color=colors, alpha=0.7)
        
        for bar, time_val in zip(bars, metrics_df['Computation_Time']):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.01,
                    f'{time_val:.3f}s', ha='center', va='bottom', fontweight='bold')
        
        plt.title('Computation Time Comparison', fontweight='bold')
        plt.ylabel('Time (seconds)')
        plt.xticks(rotation=45)
    
    # 5. RMSEæ”¹å–„çŽ‡
    ax5 = plt.subplot(3, 2, 6)
    
    if len(metrics_df) > 0 and 'RMSE_Improvement' in metrics_df.columns:
        colors_improvement = ['green' if x > 0 else 'red' for x in metrics_df['RMSE_Improvement']]
        bars = plt.bar(methods_short, metrics_df['RMSE_Improvement'], 
                      color=colors_improvement, alpha=0.7)
        
        for bar, improvement in zip(bars, metrics_df['RMSE_Improvement']):
            plt.text(bar.get_x() + bar.get_width()/2, 
                    bar.get_height() + (5 if bar.get_height() >= 0 else -8),
                    f'{improvement:+.1f}%', ha='center', va='bottom' if bar.get_height() >= 0 else 'top',
                    fontweight='bold')
        
        plt.title('RMSE Improvement vs Standard UKF', fontweight='bold')
        plt.ylabel('Improvement (%)')
        plt.xticks(rotation=45)
        plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    
    plt.tight_layout()
    
    # ä¿å­˜
    output_file = project_root / "output" / "adaptive_ukf_four_methods_comparison.png"
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"\nðŸ“Š **æ¯”è¼ƒå¯è¦–åŒ–ä¿å­˜**: {output_file}")
    
    plt.show()


def print_detailed_analysis(metrics_df: pd.DataFrame, methods: dict):
    """
    è©³ç´°åˆ†æžçµæžœå‡ºåŠ›
    """
    print("\n" + "="*80)
    print("ðŸ§  **FOUR ADAPTIVE UKF METHODS - DETAILED ANALYSIS** ðŸ§ ")
    print("="*80)
    
    if len(metrics_df) == 0:
        print("âŒ æœ‰åŠ¹ãªçµæžœãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # åŸºæœ¬çµ±è¨ˆ
    print("\nðŸ“Š **åŸºæœ¬æ€§èƒ½çµ±è¨ˆ:**")
    print("-"*60)
    
    for _, row in metrics_df.iterrows():
        print(f"ðŸ”¹ **{row['Method']}**")
        print(f"   ðŸ“ èª¬æ˜Ž: {row['Description']}")
        print(f"   ðŸ“ˆ å…¨ä½“RMSE: {row['RMSE_All']:.6f}")
        print(f"   ðŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³RMSE: {row['RMSE_Clean']:.6f}")
        print(f"   âš¡ è¨ˆç®—æ™‚é–“: {row['Computation_Time']:.4f}ç§’")
        
        if 'RMSE_Improvement' in row:
            improvement = row['RMSE_Improvement']
            if improvement > 0:
                print(f"   âœ… æ”¹å–„çŽ‡: +{improvement:.1f}% (æ”¹å–„)")
            elif improvement < 0:
                print(f"   âŒ æ”¹å–„çŽ‡: {improvement:.1f}% (æ‚ªåŒ–)")
            else:
                print(f"   âž– æ”¹å–„çŽ‡: 0.0% (åŸºæº–)")
        
        print()
    
    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    print("\nðŸ† **æ€§èƒ½ãƒ©ãƒ³ã‚­ãƒ³ã‚°:**")
    print("-"*60)
    
    # RMSEãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆå…¨ä½“ï¼‰
    rmse_ranking = metrics_df.sort_values('RMSE_All')
    print("ðŸŽ¯ **RMSE (å…¨ä½“) ãƒ©ãƒ³ã‚­ãƒ³ã‚°:**")
    for i, (_, row) in enumerate(rmse_ranking.iterrows(), 1):
        medal = "ðŸ¥‡" if i == 1 else "ðŸ¥ˆ" if i == 2 else "ðŸ¥‰" if i == 3 else f"{i}ä½"
        print(f"   {medal} {row['Method']}: {row['RMSE_All']:.6f}")
    
    # RMSEãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆã‚¯ãƒªãƒ¼ãƒ³ï¼‰
    rmse_clean_ranking = metrics_df.sort_values('RMSE_Clean')
    print("\nðŸ§¹ **RMSE (ã‚¯ãƒªãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿) ãƒ©ãƒ³ã‚­ãƒ³ã‚°:**")
    for i, (_, row) in enumerate(rmse_clean_ranking.iterrows(), 1):
        medal = "ðŸ¥‡" if i == 1 else "ðŸ¥ˆ" if i == 2 else "ðŸ¥‰" if i == 3 else f"{i}ä½"
        print(f"   {medal} {row['Method']}: {row['RMSE_Clean']:.6f}")
    
    # é€Ÿåº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    speed_ranking = metrics_df.sort_values('Computation_Time')
    print("\nâš¡ **è¨ˆç®—é€Ÿåº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°:**")
    for i, (_, row) in enumerate(speed_ranking.iterrows(), 1):
        medal = "ðŸ¥‡" if i == 1 else "ðŸ¥ˆ" if i == 2 else "ðŸ¥‰" if i == 3 else f"{i}ä½"
        print(f"   {medal} {row['Method']}: {row['Computation_Time']:.4f}ç§’")
    
    # ç†è«–çš„ç‰¹æ€§åˆ†æž
    print("\nðŸ”¬ **ç†è«–çš„ç‰¹æ€§åˆ†æž:**")
    print("-"*60)
    
    for _, row in metrics_df.iterrows():
        method_type = row['Type']
        method_name = row['Method']
        
        if method_type == 'baseline':
            print(f"ðŸ“‹ **{method_name}**: æ¨™æº–å®Ÿè£… - å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ç†è«–åŸºæº–")
        elif method_type == 'statistical_adaptive':
            print(f"ðŸ“Š **{method_name}**: çµ±è¨ˆé©å¿œ - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã€ç•°å¸¸å€¤æ¤œå‡º")
        elif method_type == 'mathematical_rigorous':
            print(f"ðŸ”¬ **{method_name}**: æ•°å­¦åŽ³å¯† - ç›¸äº’ç›¸é–¢ç†è«–ã€ç·šå½¢è¡Œåˆ—æ–¹ç¨‹å¼")
        elif method_type == 'neural_adaptive':
            print(f"ðŸ§  **{method_name}**: ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ« - CNN ProcessNetã€æ·±å±¤å­¦ç¿’")
    
    # ç·åˆè©•ä¾¡
    print("\nðŸŽ–ï¸ **ç·åˆè©•ä¾¡:**")
    print("-"*60)
    
    best_rmse = rmse_ranking.iloc[0]['Method']
    best_speed = speed_ranking.iloc[0]['Method']
    
    print(f"ðŸ† **æœ€é«˜ç²¾åº¦**: {best_rmse}")
    print(f"âš¡ **æœ€é«˜é€Ÿåº¦**: {best_speed}")
    
    # æ”¹å–„çŽ‡ã§è©•ä¾¡
    if 'RMSE_Improvement' in metrics_df.columns:
        improvement_ranking = metrics_df.sort_values('RMSE_Improvement', ascending=False)
        best_improvement = improvement_ranking.iloc[0]
        print(f"ðŸ“ˆ **æœ€å¤§æ”¹å–„**: {best_improvement['Method']} ({best_improvement['RMSE_Improvement']:+.1f}%)")
    
    print("\n" + "="*80)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ðŸ§  **FOUR ADAPTIVE UKF METHODS COMPARISON** ðŸ§ ")
    print("="*60)
    print("æ¯”è¼ƒå¯¾è±¡:")
    print("1. Standard UKF (åŸºæº–)")
    print("2. My Implementation AUKF (çµ±è¨ˆçš„ç›£è¦–ãƒ»é©å¿œåˆ¶å¾¡)")
    print("3. Academic AUKF (Ge et al. 2019 - ç›¸äº’ç›¸é–¢ç†è«–)")
    print("4. Neural AUKF (Levy & Klein 2025 - CNN ProcessNet)")
    print("="*60)
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    n_points = 800
    noise_level = 2.0
    
    true_values, noisy_data, outliers, noise_changes = generate_complex_test_data(
        n_points=n_points, 
        noise_level=noise_level
    )
    
    # 4æ‰‹æ³•æ¯”è¼ƒå®Ÿè¡Œ
    methods = run_four_methods_comparison(noisy_data, true_values)
    
    # æœ‰åŠ¹ãªçµæžœã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    valid_methods = {k: v for k, v in methods.items() if v is not None}
    
    if len(valid_methods) == 0:
        print("âŒ æœ‰åŠ¹ãªçµæžœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # æ€§èƒ½æŒ‡æ¨™è¨ˆç®—
    metrics_df = calculate_performance_metrics(valid_methods, true_values, outliers)
    
    # è©³ç´°åˆ†æžå‡ºåŠ›
    print_detailed_analysis(metrics_df, valid_methods)
    
    # å¯è¦–åŒ–ä½œæˆ
    create_comprehensive_visualization(
        valid_methods,
        true_values,
        noisy_data,
        outliers,
        metrics_df
    )
    
    # çµæžœCSVä¿å­˜
    output_csv = project_root / "output" / "adaptive_ukf_four_methods_metrics.csv"
    metrics_df.to_csv(output_csv, index=False)
    print(f"ðŸ“Š **æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜**: {output_csv}")
    
    print("\nðŸŽ‰ **å››ç¨®Adaptive UKFæ¯”è¼ƒå®Œäº†ï¼**")


if __name__ == "__main__":
    main() 