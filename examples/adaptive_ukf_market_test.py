#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸš€ **4ã¤ã®Adaptive UKFæ‰‹æ³• - å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ** ğŸš€

ã“ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š
1. å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ã§ã®4ã¤ã®Adaptive UKFæ‰‹æ³•ã®æ¯”è¼ƒ
2. è¤‡æ•°ã®ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª
3. è©³ç´°ãªæ€§èƒ½åˆ†æ
4. å¯è¦–åŒ–ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
"""

import sys
import os
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from visualization.adaptive_ukf_comparison_chart import AdaptiveUKFComparisonChart, create_sample_data
    from indicators.unscented_kalman_filter import UnscentedKalmanFilter
    from indicators.adaptive_ukf import AdaptiveUnscentedKalmanFilter
    from indicators.academic_adaptive_ukf import AcademicAdaptiveUnscentedKalmanFilter
    from indicators.neural_adaptive_ukf import NeuralAdaptiveUnscentedKalmanFilter
except ImportError as e:
    print(f"âš ï¸ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    print("   å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

warnings.filterwarnings('ignore')


class AdaptiveUKFMarketTester:
    """
    4ã¤ã®Adaptive UKFæ‰‹æ³•ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ã‚¿ãƒ¼
    """
    
    def __init__(self, output_dir: str = "output/market_tests"):
        """
        åˆæœŸåŒ–
        
        Args:
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.test_results = {}
        self.charts = {}
        
        print("ğŸš€ **Adaptive UKF Market Tester** ğŸš€")
        print("="*50)
    
    def run_comprehensive_test(self) -> None:
        """åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        print("\nğŸ”¥ **åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆé–‹å§‹** ğŸ”¥")
        
        # ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªå®šç¾©
        test_scenarios = [
            {
                'name': 'ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰',
                'type': 'sample',
                'points': 500,
                'description': 'äººå·¥çš„ãªãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å«ã‚€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿'
            },
            {
                'name': 'ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼‰',
                'type': 'sample_volatile',
                'points': 800,
                'description': 'é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿'
            },
            {
                'name': 'ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚µã‚¤ã‚¯ãƒªãƒƒã‚¯ï¼‰',
                'type': 'sample_cyclic',
                'points': 1000,
                'description': 'ã‚µã‚¤ã‚¯ãƒªãƒƒã‚¯ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿'
            }
        ]
        
        # å„ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªã‚’å®Ÿè¡Œ
        for scenario in test_scenarios:
            print(f"\nğŸ“Š **ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª: {scenario['name']}**")
            print(f"   èª¬æ˜: {scenario['description']}")
            
            try:
                # ãƒ‡ãƒ¼ã‚¿ä½œæˆ
                data_file = self._create_test_data(scenario)
                
                # ãƒãƒ£ãƒ¼ãƒˆä½œæˆãƒ»ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
                self._run_single_test(scenario['name'], data_file)
                
                print(f"   âœ… {scenario['name']} ãƒ†ã‚¹ãƒˆå®Œäº†")
                
            except Exception as e:
                print(f"   âŒ {scenario['name']} ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
                continue
        
        # çµæœã‚µãƒãƒªãƒ¼
        self._generate_summary_report()
        
        print("\nğŸ‰ **åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Œäº†ï¼**")
    
    def _create_test_data(self, scenario: dict) -> str:
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        scenario_type = scenario['type']
        points = scenario['points']
        
        filename = f"test_data_{scenario_type}.csv"
        filepath = self.output_dir / filename
        
        # æ™‚ç³»åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
        dates = pd.date_range(start='2024-01-01', periods=points, freq='1H')
        
        if scenario_type == 'sample':
            # æ¨™æº–çš„ãªãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿
            df = self._create_trend_data(dates, points)
        elif scenario_type == 'sample_volatile':
            # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ‡ãƒ¼ã‚¿
            df = self._create_volatile_data(dates, points)
        elif scenario_type == 'sample_cyclic':
            # ã‚µã‚¤ã‚¯ãƒªãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿
            df = self._create_cyclic_data(dates, points)
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            df = self._create_trend_data(dates, points)
        
        # ä¿å­˜
        df.to_csv(filepath)
        print(f"   ğŸ“ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä¿å­˜: {filepath}")
        
        return str(filepath)
    
    def _create_trend_data(self, dates: pd.DatetimeIndex, points: int) -> pd.DataFrame:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        np.random.seed(42)
        base_price = 50000
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†
        trend = np.linspace(0, 0.3, points)
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯
        returns = np.random.normal(0, 0.015, points)
        log_prices = np.log(base_price) + np.cumsum(returns) + trend
        prices = np.exp(log_prices)
        
        return self._create_ohlc_from_prices(dates, prices)
    
    def _create_volatile_data(self, dates: pd.DatetimeIndex, points: int) -> pd.DataFrame:
        """é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        np.random.seed(123)
        base_price = 45000
        
        # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        volatility = np.random.uniform(0.02, 0.05, points)
        returns = np.random.normal(0, volatility)
        
        # æ™‚ã€…ã®ã‚¹ãƒ‘ã‚¤ã‚¯
        spike_indices = np.random.choice(points, size=int(points * 0.1), replace=False)
        returns[spike_indices] *= np.random.choice([-1, 1], size=len(spike_indices)) * 3
        
        log_prices = np.log(base_price) + np.cumsum(returns)
        prices = np.exp(log_prices)
        
        return self._create_ohlc_from_prices(dates, prices)
    
    def _create_cyclic_data(self, dates: pd.DatetimeIndex, points: int) -> pd.DataFrame:
        """ã‚µã‚¤ã‚¯ãƒªãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        np.random.seed(456)
        base_price = 55000
        
        # ã‚µã‚¤ã‚¯ãƒªãƒƒã‚¯æˆåˆ†
        t = np.linspace(0, 4*np.pi, points)
        cycle1 = 0.1 * np.sin(t) + 0.05 * np.sin(2*t)
        cycle2 = 0.03 * np.sin(0.5*t)
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯
        returns = np.random.normal(0, 0.01, points)
        log_prices = np.log(base_price) + np.cumsum(returns) + cycle1 + cycle2
        prices = np.exp(log_prices)
        
        return self._create_ohlc_from_prices(dates, prices)
    
    def _create_ohlc_from_prices(self, dates: pd.DatetimeIndex, prices: np.ndarray) -> pd.DataFrame:
        """ä¾¡æ ¼ã‹ã‚‰OHLCãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        df = pd.DataFrame(index=dates)
        df['close'] = prices
        df['open'] = df['close'].shift(1).fillna(df['close'])
        
        # High/Lowç”Ÿæˆ
        high_factor = 1 + np.random.uniform(0.001, 0.03, len(prices))
        low_factor = 1 - np.random.uniform(0.001, 0.03, len(prices))
        
        df['high'] = np.maximum(df['close'] * high_factor, np.maximum(df['close'], df['open']))
        df['low'] = np.minimum(df['close'] * low_factor, np.minimum(df['close'], df['open']))
        
        # ãƒœãƒªãƒ¥ãƒ¼ãƒ 
        df['volume'] = np.random.uniform(100000, 1000000, len(prices))
        
        return df
    
    def _run_single_test(self, test_name: str, data_file: str) -> None:
        """å˜ä¸€ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        print(f"   ğŸ”„ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨ˆç®—ä¸­...")
        
        # ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
        chart = AdaptiveUKFComparisonChart()
        chart.load_simple_data(data_file)
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨ˆç®—
        chart.calculate_filters(src_type='close', window_size=50)
        
        # ãƒãƒ£ãƒ¼ãƒˆæç”»
        output_path = self.output_dir / f"{test_name.replace(' ', '_')}_chart.png"
        chart.plot(
            title=f"4ã¤ã®Adaptive UKFæ¯”è¼ƒ - {test_name}",
            savefig=str(output_path)
        )
        
        # æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        performance_df = chart.get_performance_summary()
        if not performance_df.empty:
            csv_path = self.output_dir / f"{test_name.replace(' ', '_')}_performance.csv"
            performance_df.to_csv(csv_path)
            print(f"   ğŸ“Š æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {csv_path}")
        
        # çµæœä¿å­˜
        self.test_results[test_name] = {
            'chart': chart,
            'performance': performance_df,
            'chart_path': str(output_path),
            'data_file': data_file
        }
        
        print(f"   ğŸ“ˆ ãƒãƒ£ãƒ¼ãƒˆä¿å­˜: {output_path}")
    
    def _generate_summary_report(self) -> None:
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        print("\nğŸ“‹ **ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆä½œæˆä¸­...**")
        
        # å…¨ãƒ†ã‚¹ãƒˆã®æ€§èƒ½æŒ‡æ¨™ã‚’çµ±åˆ
        all_performance = []
        
        for test_name, results in self.test_results.items():
            performance_df = results['performance']
            if not performance_df.empty:
                performance_df['Test_Scenario'] = test_name
                all_performance.append(performance_df)
        
        if all_performance:
            # çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
            combined_df = pd.concat(all_performance, axis=0)
            
            # ã‚µãƒãƒªãƒ¼ä¿å­˜
            summary_path = self.output_dir / "comprehensive_test_summary.csv"
            combined_df.to_csv(summary_path)
            
            # çµ±è¨ˆã‚µãƒãƒªãƒ¼
            stats_summary = self._calculate_summary_statistics(combined_df)
            stats_path = self.output_dir / "performance_statistics.csv"
            stats_summary.to_csv(stats_path)
            
            print(f"   ğŸ“Š çµ±åˆãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {summary_path}")
            print(f"   ğŸ“ˆ çµ±è¨ˆã‚µãƒãƒªãƒ¼ä¿å­˜: {stats_path}")
            
            # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
            self._print_summary_statistics(stats_summary)
        
        # ãƒ†ã‚¹ãƒˆçµæœã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        self._create_index_file()
    
    def _calculate_summary_statistics(self, combined_df: pd.DataFrame) -> pd.DataFrame:
        """çµ±è¨ˆã‚µãƒãƒªãƒ¼ã‚’è¨ˆç®—"""
        # æ‰‹æ³•åˆ¥ã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        method_stats = []
        
        for method in combined_df.index.unique():
            method_data = combined_df.loc[method]
            
            if isinstance(method_data, pd.Series):
                method_data = method_data.to_frame().T
            
            stats = {
                'Method': method,
                'Avg_RMSE': method_data['RMSE'].mean(),
                'Min_RMSE': method_data['RMSE'].min(),
                'Max_RMSE': method_data['RMSE'].max(),
                'Std_RMSE': method_data['RMSE'].std(),
                'Avg_MAE': method_data['MAE'].mean(),
                'Avg_Improvement': method_data.get('Improvement', pd.Series([0])).mean(),
                'Test_Count': len(method_data)
            }
            
            method_stats.append(stats)
        
        return pd.DataFrame(method_stats)
    
    def _print_summary_statistics(self, stats_df: pd.DataFrame) -> None:
        """çµ±è¨ˆã‚µãƒãƒªãƒ¼ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›"""
        print("\nğŸ“Š **å…¨ä½“çµ±è¨ˆã‚µãƒãƒªãƒ¼**")
        print("="*60)
        
        # RMSEé †ã§ã‚½ãƒ¼ãƒˆ
        sorted_stats = stats_df.sort_values('Avg_RMSE')
        
        for i, row in sorted_stats.iterrows():
            medal = "ğŸ¥‡" if i == 0 else "ğŸ¥ˆ" if i == 1 else "ğŸ¥‰" if i == 2 else f"{i+1}ä½"
            print(f"   {medal} {row['Method']}")
            print(f"      å¹³å‡RMSE: {row['Avg_RMSE']:.4f} (Â±{row['Std_RMSE']:.4f})")
            print(f"      å¹³å‡MAE: {row['Avg_MAE']:.4f}")
            print(f"      å¹³å‡æ”¹å–„ç‡: {row['Avg_Improvement']:+.1f}%")
            print(f"      ãƒ†ã‚¹ãƒˆæ•°: {row['Test_Count']}")
    
    def _create_index_file(self) -> None:
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        index_path = self.output_dir / "test_index.md"
        
        with open(index_path, 'w', encoding='utf-8') as f:
            f.write("# 4ã¤ã®Adaptive UKFæ‰‹æ³• - ç›¸å ´ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆçµæœ\n\n")
            f.write("## ãƒ†ã‚¹ãƒˆæ¦‚è¦\n")
            f.write("ã“ã®ãƒ†ã‚¹ãƒˆã¯4ã¤ã®Adaptive UKFæ‰‹æ³•ã‚’æ§˜ã€…ãªç›¸å ´ãƒ‡ãƒ¼ã‚¿ã§æ¯”è¼ƒè©•ä¾¡ã—ãŸã‚‚ã®ã§ã™ã€‚\n\n")
            
            f.write("## æ¯”è¼ƒæ‰‹æ³•\n")
            f.write("1. **æ¨™æº–UKF** - åŸºæº–æ‰‹æ³•\n")
            f.write("2. **ç§ã®å®Ÿè£…ç‰ˆAUKF** - çµ±è¨ˆçš„ç›£è¦–ãƒ»é©å¿œåˆ¶å¾¡\n")
            f.write("3. **è«–æ–‡ç‰ˆAUKF** - Ge et al. (2019) ç›¸äº’ç›¸é–¢ç†è«–\n")
            f.write("4. **Neuralç‰ˆAUKF** - Levy & Klein (2025) CNN ProcessNet\n\n")
            
            f.write("## ãƒ†ã‚¹ãƒˆçµæœ\n")
            for test_name, results in self.test_results.items():
                f.write(f"### {test_name}\n")
                f.write(f"- ãƒãƒ£ãƒ¼ãƒˆ: [{test_name}_chart.png]({Path(results['chart_path']).name})\n")
                if not results['performance'].empty:
                    f.write(f"- æ€§èƒ½ãƒ‡ãƒ¼ã‚¿: [{test_name}_performance.csv]({test_name.replace(' ', '_')}_performance.csv)\n")
                f.write("\n")
            
            f.write("## çµ±åˆçµæœ\n")
            f.write("- [çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ](comprehensive_test_summary.csv)\n")
            f.write("- [çµ±è¨ˆã‚µãƒãƒªãƒ¼](performance_statistics.csv)\n")
        
        print(f"   ğŸ“‹ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {index_path}")


def run_quick_test():
    """ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ"""
    print("âš¡ **ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–‹å§‹** âš¡")
    
    try:
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        sample_file = create_sample_data("quick_test_data.csv", 300)
        
        # ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
        chart = AdaptiveUKFComparisonChart()
        chart.load_simple_data(sample_file)
        chart.calculate_filters(src_type='close', window_size=30)
        
        # ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º
        chart.plot(title="4ã¤ã®Adaptive UKF - ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ")
        
        # æ€§èƒ½ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        performance_df = chart.get_performance_summary()
        if not performance_df.empty:
            print("\nğŸ“Š **æ€§èƒ½ã‚µãƒãƒªãƒ¼**")
            print(performance_df.round(4))
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        os.remove(sample_file)
        
        print("\nâœ… ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
        
    except Exception as e:
        print(f"âŒ ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='4ã¤ã®Adaptive UKFæ‰‹æ³•ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ')
    parser.add_argument('--quick', action='store_true', help='ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ')
    parser.add_argument('--comprehensive', action='store_true', help='åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ')
    parser.add_argument('--output-dir', type=str, default='output/market_tests', help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    args = parser.parse_args()
    
    if args.quick:
        run_quick_test()
    elif args.comprehensive:
        tester = AdaptiveUKFMarketTester(args.output_dir)
        tester.run_comprehensive_test()
    else:
        print("âš ï¸ ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„:")
        print("   --quick: ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ")
        print("   --comprehensive: åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ")
        print("\nä¾‹:")
        print("   python adaptive_ukf_market_test.py --quick")
        print("   python adaptive_ukf_market_test.py --comprehensive")


if __name__ == "__main__":
    main() 