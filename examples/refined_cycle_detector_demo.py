#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from typing import Dict, Any
import warnings
warnings.filterwarnings('ignore')

# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from indicators.ehlers_refined_cycle_detector import EhlersRefinedCycleDetector
from indicators.ehlers_absolute_ultimate_cycle import EhlersAbsoluteUltimateCycle
from indicators.ehlers_unified_dc import EhlersUnifiedDC


def create_test_data(n_samples: int = 1000) -> pd.DataFrame:
    """
    ãƒ†ã‚¹ãƒˆç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹
    
    Args:
        n_samples: ã‚µãƒ³ãƒ—ãƒ«æ•°
    
    Returns:
        OHLCä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
    """
    np.random.seed(42)
    
    # åŸºæœ¬ãƒˆãƒ¬ãƒ³ãƒ‰
    base_trend = np.linspace(100, 120, n_samples)
    
    # è¤‡æ•°ã®ã‚µã‚¤ã‚¯ãƒ«æˆåˆ†
    cycle_20 = 8 * np.sin(2 * np.pi * np.arange(n_samples) / 20)
    cycle_35 = 5 * np.sin(2 * np.pi * np.arange(n_samples) / 35)
    cycle_50 = 3 * np.sin(2 * np.pi * np.arange(n_samples) / 50)
    
    # ãƒã‚¤ã‚º
    noise = np.random.normal(0, 1, n_samples)
    
    # åˆæˆä¾¡æ ¼
    close_price = base_trend + cycle_20 + cycle_35 + cycle_50 + noise
    
    # OHLCç”Ÿæˆ
    data = pd.DataFrame({
        'open': close_price + np.random.normal(0, 0.5, n_samples),
        'high': close_price + np.abs(np.random.normal(2, 1, n_samples)),
        'low': close_price - np.abs(np.random.normal(2, 1, n_samples)),
        'close': close_price,
        'volume': np.random.randint(1000, 10000, n_samples)
    })
    
    return data


def compare_cycle_detectors(data: pd.DataFrame) -> Dict[str, Any]:
    """
    è¤‡æ•°ã®ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã‚’æ¯”è¼ƒã™ã‚‹
    
    Args:
        data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        æ¯”è¼ƒçµæœã®è¾æ›¸
    """
    print("ğŸš€ ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®æ¯”è¼ƒåˆ†æã‚’é–‹å§‹ã—ã¾ã™...")
    
    # 1. æ´—ç·´ã•ã‚ŒãŸã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ï¼ˆæ–°è¨­è¨ˆï¼‰
    print("\n1. æ´—ç·´ã•ã‚ŒãŸã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ï¼ˆRefined Cycle Detectorï¼‰")
    refined_detector = EhlersRefinedCycleDetector(
        cycle_part=0.5,
        max_output=50,
        min_output=5,
        period_range=(6.0, 50.0),
        alpha=0.07,
        src_type='hlc3',
        ultimate_smoother_period=20.0,
        use_ultimate_smoother=True
    )
    
    refined_cycles = refined_detector.calculate(data)
    refined_confidence = refined_detector.confidence_scores
    refined_summary = refined_detector.get_analysis_summary()
    
    print(f"   è¨ˆç®—å®Œäº†: {len(refined_cycles)} ç‚¹")
    print(f"   å¹³å‡å‘¨æœŸ: {np.mean(refined_cycles):.2f}")
    print(f"   å¹³å‡ä¿¡é ¼åº¦: {np.mean(refined_confidence):.3f}")
    
    # 2. çµ¶å¯¾çš„ç©¶æ¥µã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ï¼ˆæ¯”è¼ƒç”¨ï¼‰
    print("\n2. çµ¶å¯¾çš„ç©¶æ¥µã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ï¼ˆAbsolute Ultimate Cycleï¼‰")
    absolute_detector = EhlersAbsoluteUltimateCycle(
        cycle_part=0.5,
        max_output=50,
        min_output=5,
        period_range=(6, 50),
        src_type='hlc3'
    )
    
    absolute_cycles = absolute_detector.calculate(data)
    absolute_confidence = absolute_detector.confidence_scores
    
    print(f"   è¨ˆç®—å®Œäº†: {len(absolute_cycles)} ç‚¹")
    print(f"   å¹³å‡å‘¨æœŸ: {np.mean(absolute_cycles):.2f}")
    print(f"   å¹³å‡ä¿¡é ¼åº¦: {np.mean(absolute_confidence):.3f}")
    
    # 3. çµ±åˆDCæ¤œå‡ºå™¨ï¼ˆãƒ›ãƒ¢ãƒ€ã‚¤ãƒ³ï¼‰
    print("\n3. çµ±åˆDCæ¤œå‡ºå™¨ï¼ˆHomodyne Discriminatorï¼‰")
    unified_detector = EhlersUnifiedDC(
        detector_type='hody',
        cycle_part=0.5,
        max_output=50,
        min_output=5,
        src_type='hlc3'
    )
    
    unified_cycles = unified_detector.calculate(data)
    
    print(f"   è¨ˆç®—å®Œäº†: {len(unified_cycles)} ç‚¹")
    print(f"   å¹³å‡å‘¨æœŸ: {np.mean(unified_cycles):.2f}")
    
    # çµæœã®æ¯”è¼ƒ
    results = {
        'refined': {
            'cycles': refined_cycles,
            'confidence': refined_confidence,
            'summary': refined_summary,
            'name': 'Refined Cycle Detector',
            'color': '#2E86AB'  # é’
        },
        'absolute': {
            'cycles': absolute_cycles,
            'confidence': absolute_confidence,
            'name': 'Absolute Ultimate Cycle',
            'color': '#A23B72'  # èµ¤ç´«
        },
        'unified': {
            'cycles': unified_cycles,
            'confidence': None,
            'name': 'Unified DC (Homodyne)',
            'color': '#F18F01'  # ã‚ªãƒ¬ãƒ³ã‚¸
        },
        'data': data
    }
    
    return results


def calculate_performance_metrics(results: Dict[str, Any]) -> Dict[str, Dict[str, float]]:
    """
    å„æ¤œå‡ºå™¨ã®æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—ã™ã‚‹
    
    Args:
        results: æ¯”è¼ƒçµæœ
    
    Returns:
        æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    """
    print("\nğŸ“Š æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—...")
    
    metrics = {}
    
    # çœŸã®ã‚µã‚¤ã‚¯ãƒ«ï¼ˆç†è«–å€¤ï¼‰
    true_cycles = [20, 35, 50]  # ç”Ÿæˆæ™‚ã«ä½¿ç”¨ã—ãŸã‚µã‚¤ã‚¯ãƒ«
    
    for detector_name, detector_data in results.items():
        if detector_name == 'data':
            continue
            
        cycles = detector_data['cycles']
        confidence = detector_data['confidence']
        
        # åŸºæœ¬çµ±è¨ˆ
        mean_cycle = np.mean(cycles)
        std_cycle = np.std(cycles)
        
        # å®‰å®šæ€§ï¼ˆå¤‰å‹•ä¿‚æ•°ï¼‰
        stability = 1.0 - (std_cycle / mean_cycle) if mean_cycle > 0 else 0.0
        
        # çœŸå€¤ã¨ã®è¿‘ä¼¼åº¦
        proximity_scores = []
        for true_cycle in true_cycles:
            proximity = 1.0 - np.abs(mean_cycle - true_cycle) / true_cycle
            proximity_scores.append(max(0, proximity))
        
        best_proximity = max(proximity_scores)
        
        # ä¿¡é ¼åº¦å¹³å‡
        avg_confidence = np.mean(confidence) if confidence is not None else 0.5
        
        # è¨ˆç®—é€Ÿåº¦ï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°ã§æ­£è¦åŒ–ï¼‰
        computation_speed = len(cycles) / 1000.0  # ç›¸å¯¾çš„ãªé€Ÿåº¦æŒ‡æ¨™
        
        # ç·åˆã‚¹ã‚³ã‚¢
        overall_score = (stability * 0.3 + 
                        best_proximity * 0.3 + 
                        avg_confidence * 0.2 + 
                        computation_speed * 0.2)
        
        metrics[detector_name] = {
            'mean_cycle': mean_cycle,
            'stability': stability,
            'proximity': best_proximity,
            'confidence': avg_confidence,
            'computation_speed': computation_speed,
            'overall_score': overall_score
        }
        
        print(f"\n{detector_data['name']}:")
        print(f"  å¹³å‡å‘¨æœŸ: {mean_cycle:.2f}")
        print(f"  å®‰å®šæ€§: {stability:.3f}")
        print(f"  çœŸå€¤è¿‘ä¼¼åº¦: {best_proximity:.3f}")
        print(f"  ä¿¡é ¼åº¦: {avg_confidence:.3f}")
        print(f"  ç·åˆã‚¹ã‚³ã‚¢: {overall_score:.3f}")
    
    return metrics


def visualize_results(results: Dict[str, Any], metrics: Dict[str, Dict[str, float]]):
    """
    çµæœã‚’å¯è¦–åŒ–ã™ã‚‹
    
    Args:
        results: æ¯”è¼ƒçµæœ
        metrics: æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    """
    print("\nğŸ“ˆ çµæœã®å¯è¦–åŒ–...")
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('ğŸ¯ æ´—ç·´ã•ã‚ŒãŸã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ - æ€§èƒ½æ¯”è¼ƒåˆ†æ', fontsize=16, fontweight='bold')
    
    # 1. ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºçµæœ
    ax1 = axes[0, 0]
    data = results['data']
    
    ax1.plot(data['close'], label='Close Price', color='black', alpha=0.7, linewidth=1)
    
    # å„æ¤œå‡ºå™¨ã®çµæœã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    for detector_name, detector_data in results.items():
        if detector_name == 'data':
            continue
        
        cycles = detector_data['cycles']
        # ã‚µã‚¤ã‚¯ãƒ«å€¤ã‚’ä¾¡æ ¼ç¯„å›²ã«ã‚¹ã‚±ãƒ¼ãƒ«
        scaled_cycles = ((cycles - np.min(cycles)) / (np.max(cycles) - np.min(cycles))) * 20 + np.min(data['close'])
        
        ax1.plot(scaled_cycles, label=detector_data['name'], 
                color=detector_data['color'], alpha=0.8, linewidth=2)
    
    ax1.set_title('ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºçµæœ')
    ax1.set_xlabel('æ™‚é–“')
    ax1.set_ylabel('ä¾¡æ ¼ / ã‚¹ã‚±ãƒ¼ãƒ«æ¸ˆã¿ã‚µã‚¤ã‚¯ãƒ«')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. ã‚µã‚¤ã‚¯ãƒ«å‘¨æœŸã®æ™‚ç³»åˆ—
    ax2 = axes[0, 1]
    
    for detector_name, detector_data in results.items():
        if detector_name == 'data':
            continue
        
        cycles = detector_data['cycles']
        ax2.plot(cycles, label=detector_data['name'], 
                color=detector_data['color'], alpha=0.8, linewidth=2)
    
    # çœŸã®ã‚µã‚¤ã‚¯ãƒ«å‘¨æœŸã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    ax2.axhline(y=20, color='red', linestyle='--', alpha=0.5, label='True Cycle 20')
    ax2.axhline(y=35, color='red', linestyle='--', alpha=0.5, label='True Cycle 35')
    ax2.axhline(y=50, color='red', linestyle='--', alpha=0.5, label='True Cycle 50')
    
    ax2.set_title('ã‚µã‚¤ã‚¯ãƒ«å‘¨æœŸã®æ™‚ç³»åˆ—')
    ax2.set_xlabel('æ™‚é–“')
    ax2.set_ylabel('ã‚µã‚¤ã‚¯ãƒ«å‘¨æœŸ')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
    ax3 = axes[1, 0]
    
    for detector_name, detector_data in results.items():
        if detector_name == 'data' or detector_data['confidence'] is None:
            continue
        
        confidence = detector_data['confidence']
        ax3.plot(confidence, label=detector_data['name'], 
                color=detector_data['color'], alpha=0.8, linewidth=2)
    
    ax3.set_title('ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã®æ™‚ç³»åˆ—')
    ax3.set_xlabel('æ™‚é–“')
    ax3.set_ylabel('ä¿¡é ¼åº¦')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ¯”è¼ƒ
    ax4 = axes[1, 1]
    
    metric_names = ['stability', 'proximity', 'confidence', 'overall_score']
    metric_labels = ['å®‰å®šæ€§', 'çœŸå€¤è¿‘ä¼¼åº¦', 'ä¿¡é ¼åº¦', 'ç·åˆã‚¹ã‚³ã‚¢']
    
    x = np.arange(len(metric_labels))
    width = 0.25
    
    for i, (detector_name, detector_data) in enumerate(results.items()):
        if detector_name == 'data':
            continue
        
        values = [metrics[detector_name][metric] for metric in metric_names]
        ax4.bar(x + i * width, values, width, label=detector_data['name'], 
               color=detector_data['color'], alpha=0.8)
    
    ax4.set_title('æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ¯”è¼ƒ')
    ax4.set_xlabel('ãƒ¡ãƒˆãƒªã‚¯ã‚¹')
    ax4.set_ylabel('ã‚¹ã‚³ã‚¢')
    ax4.set_xticks(x + width)
    ax4.set_xticklabels(metric_labels)
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('output/refined_cycle_detector_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("ğŸ“Š å¯è¦–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚'output/refined_cycle_detector_comparison.png'ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")


def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    """
    print("ğŸ¯ æ´—ç·´ã•ã‚ŒãŸã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ - ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("=" * 60)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    os.makedirs('output', exist_ok=True)
    
    # 1. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
    print("\nğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ...")
    data = create_test_data(n_samples=500)
    print(f"   ç”Ÿæˆå®Œäº†: {len(data)} ç‚¹ã®OHLCãƒ‡ãƒ¼ã‚¿")
    print(f"   ä¾¡æ ¼ç¯„å›²: {data['close'].min():.2f} - {data['close'].max():.2f}")
    
    # 2. ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®æ¯”è¼ƒ
    results = compare_cycle_detectors(data)
    
    # 3. æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—
    metrics = calculate_performance_metrics(results)
    
    # 4. çµæœã®å¯è¦–åŒ–
    visualize_results(results, metrics)
    
    # 5. è©³ç´°åˆ†æã®è¡¨ç¤º
    print("\nğŸ† æœ€çµ‚çµæœåˆ†æ:")
    print("=" * 40)
    
    # æœ€é«˜ã‚¹ã‚³ã‚¢ã®æ¤œå‡ºå™¨ã‚’ç‰¹å®š
    best_detector = max(metrics.items(), key=lambda x: x[1]['overall_score'])
    print(f"ğŸ¥‡ æœ€é«˜æ€§èƒ½: {results[best_detector[0]]['name']}")
    print(f"   ç·åˆã‚¹ã‚³ã‚¢: {best_detector[1]['overall_score']:.3f}")
    
    # æ´—ç·´ã•ã‚ŒãŸã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®è©³ç´°æƒ…å ±
    if 'refined' in results:
        refined_summary = results['refined']['summary']
        print(f"\nğŸ“‹ æ´—ç·´ã•ã‚ŒãŸã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®è©³ç´°:")
        print(f"   ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ : {refined_summary['algorithm']}")
        print(f"   ã‚³ã‚¢æŠ€è¡“: {', '.join(refined_summary['core_technologies'])}")
        print(f"   ç‰¹æ€§: é…å»¶={refined_summary['characteristics']['latency']}, "
              f"ç²¾åº¦={refined_summary['characteristics']['accuracy']}")
        print(f"   è¨ˆç®—åŠ¹ç‡: {refined_summary['characteristics']['computation']}")
    
    print("\nâœ¨ ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Œäº†ã—ã¾ã—ãŸï¼")


if __name__ == "__main__":
    main() 