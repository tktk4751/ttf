#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ Ultimate Choppiness Index Demo
ã‚¸ãƒ§ãƒ³ãƒ»ã‚¨ãƒ©ãƒ¼ã‚ºã®ã‚¢ãƒ«ãƒ†ã‚£ãƒ¡ãƒƒãƒˆãƒãƒ§ãƒ”ãƒã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®Ÿæ¼”

å¾“æ¥ã®ãƒãƒ§ãƒ”ãƒã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã®æ¯”è¼ƒåˆ†æ:
- é…å»¶ç‰¹æ€§ã®æ¯”è¼ƒ
- ç²¾åº¦ã®æ¯”è¼ƒ
- é©å¿œæ€§ã®æ¯”è¼ƒ
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import time

# ãƒ‘ã‚¹ã®è¨­å®š
import sys
sys.path.append(str(Path(__file__).parent.parent))

from indicators.ultimate_choppiness_index import UltimateChoppinessIndex
from indicators.choppiness import ChoppinessIndex

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = 'DejaVu Sans'
try:
    plt.style.use('seaborn-v0_8')
except:
    try:
        plt.style.use('seaborn')
    except:
        plt.style.use('default')

class ChoppinessComparison:
    """ãƒãƒ§ãƒ”ãƒã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¯”è¼ƒåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, data: pd.DataFrame):
        """
        Parameters:
        -----------
        data : pd.DataFrame
            OHLCVä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        """
        self.data = data
        self.results = {}
        
        # ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–
        self.ultimate_chop = UltimateChoppinessIndex(
            base_period=14,
            min_period=8,
            max_period=50,
            smoothing_period=3
        )
        
        self.classic_chop = ChoppinessIndex(period=14)
        
    def run_comparison(self):
        """æ¯”è¼ƒåˆ†æã‚’å®Ÿè¡Œ"""
        print("ğŸš€ Ultimate Choppiness Index vs Classic Choppiness Index")
        print("=" * 60)
        
        # 1. è¨ˆç®—æ™‚é–“ã®æ¯”è¼ƒ
        self._benchmark_performance()
        
        # 2. é…å»¶ç‰¹æ€§ã®æ¯”è¼ƒ
        self._analyze_lag_characteristics()
        
        # 3. ç²¾åº¦ã®æ¯”è¼ƒ
        self._analyze_accuracy()
        
        # 4. é©å¿œæ€§ã®æ¯”è¼ƒ
        self._analyze_adaptivity()
        
        # 5. è¦–è¦šåŒ–
        self._create_visualizations()
        
        return self.results
        
    def _benchmark_performance(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š"""
        print("\nğŸ“Š Performance Benchmark")
        print("-" * 30)
        
        # Ultimate Choppiness Index
        start_time = time.time()
        ultimate_values = self.ultimate_chop.calculate(self.data)
        ultimate_time = time.time() - start_time
        
        # Classic Choppiness Index
        start_time = time.time()
        classic_values = self.classic_chop.calculate(self.data)
        classic_time = time.time() - start_time
        
        print(f"Ultimate Choppiness: {ultimate_time:.4f}ç§’")
        print(f"Classic Choppiness:  {classic_time:.4f}ç§’")
        print(f"é€Ÿåº¦æ¯”: {classic_time/ultimate_time:.1f}x faster")
        
        # çµæœä¿å­˜
        self.results['performance'] = {
            'ultimate_time': ultimate_time,
            'classic_time': classic_time,
            'speed_ratio': classic_time/ultimate_time,
            'ultimate_values': ultimate_values,
            'classic_values': classic_values
        }
        
    def _analyze_lag_characteristics(self):
        """é…å»¶ç‰¹æ€§åˆ†æ"""
        print("\nâš¡ Lag Analysis")
        print("-" * 30)
        
        # æ€¥æ¿€ãªä¾¡æ ¼å¤‰åŒ–ãƒã‚¤ãƒ³ãƒˆã‚’æ¤œå‡º
        price_changes = np.abs(np.diff(self.data['close']))
        significant_changes = np.where(price_changes > np.percentile(price_changes, 95))[0]
        
        ultimate_values = self.results['performance']['ultimate_values']
        classic_values = self.results['performance']['classic_values']
        
        # å¿œç­”æ™‚é–“ã®è¨ˆç®—
        ultimate_response_times = []
        classic_response_times = []
        
        for change_idx in significant_changes:
            if change_idx < len(ultimate_values) - 10:
                # å¤‰åŒ–å¾Œã®å¿œç­”æ™‚é–“ã‚’æ¸¬å®š
                ultimate_response = self._calculate_response_time(
                    ultimate_values[change_idx:change_idx+10]
                )
                classic_response = self._calculate_response_time(
                    classic_values[change_idx:change_idx+10]
                )
                
                ultimate_response_times.append(ultimate_response)
                classic_response_times.append(classic_response)
        
        avg_ultimate_lag = np.mean(ultimate_response_times)
        avg_classic_lag = np.mean(classic_response_times)
        
        print(f"Ultimate Choppinesså¹³å‡é…å»¶: {avg_ultimate_lag:.1f}ãƒãƒ¼")
        print(f"Classic Choppinesså¹³å‡é…å»¶:  {avg_classic_lag:.1f}ãƒãƒ¼")
        print(f"é…å»¶æ”¹å–„: {(avg_classic_lag - avg_ultimate_lag)/avg_classic_lag*100:.1f}%")
        
        self.results['lag_analysis'] = {
            'ultimate_lag': avg_ultimate_lag,
            'classic_lag': avg_classic_lag,
            'improvement': (avg_classic_lag - avg_ultimate_lag)/avg_classic_lag*100
        }
        
    def _calculate_response_time(self, values):
        """å¿œç­”æ™‚é–“è¨ˆç®—"""
        if len(values) < 2:
            return 0
        
        initial_value = values[0]
        threshold = 0.1  # 10%ã®å¤‰åŒ–ã‚’æ¤œå‡º
        
        for i, value in enumerate(values[1:], 1):
            if abs(value - initial_value) > threshold:
                return i
        
        return len(values)
        
    def _analyze_accuracy(self):
        """ç²¾åº¦åˆ†æ"""
        print("\nğŸ¯ Accuracy Analysis")
        print("-" * 30)
        
        ultimate_result = self.ultimate_chop.get_result()
        
        # ä¿¡é ¼åº¦ã®çµ±è¨ˆ
        confidence_stats = {
            'mean': np.nanmean(ultimate_result.confidence),
            'std': np.nanstd(ultimate_result.confidence),
            'min': np.nanmin(ultimate_result.confidence),
            'max': np.nanmax(ultimate_result.confidence)
        }
        
        high_confidence_ratio = np.sum(ultimate_result.confidence > 0.7) / len(ultimate_result.confidence)
        
        print(f"å¹³å‡ä¿¡é ¼åº¦: {confidence_stats['mean']:.3f}")
        print(f"é«˜ä¿¡é ¼åº¦æ¯”ç‡: {high_confidence_ratio*100:.1f}%")
        print(f"ä¿¡é ¼åº¦ç¯„å›²: {confidence_stats['min']:.3f} - {confidence_stats['max']:.3f}")
        
        self.results['accuracy'] = {
            'confidence_stats': confidence_stats,
            'high_confidence_ratio': high_confidence_ratio
        }
        
    def _analyze_adaptivity(self):
        """é©å¿œæ€§åˆ†æ"""
        print("\nğŸ”„ Adaptivity Analysis")
        print("-" * 30)
        
        ultimate_result = self.ultimate_chop.get_result()
        
        # é©å¿œæœŸé–“ã®çµ±è¨ˆ
        period_stats = {
            'mean': np.nanmean(ultimate_result.adaptive_period),
            'std': np.nanstd(ultimate_result.adaptive_period),
            'min': np.nanmin(ultimate_result.adaptive_period),
            'max': np.nanmax(ultimate_result.adaptive_period)
        }
        
        # åŠ¹ç‡æ¯”ã®çµ±è¨ˆ
        efficiency_stats = {
            'mean': np.nanmean(ultimate_result.efficiency),
            'std': np.nanstd(ultimate_result.efficiency),
            'min': np.nanmin(ultimate_result.efficiency),
            'max': np.nanmax(ultimate_result.efficiency)
        }
        
        print(f"é©å¿œæœŸé–“: {period_stats['mean']:.1f} Â± {period_stats['std']:.1f}")
        print(f"åŠ¹ç‡æ¯”: {efficiency_stats['mean']:.3f} Â± {efficiency_stats['std']:.3f}")
        
        self.results['adaptivity'] = {
            'period_stats': period_stats,
            'efficiency_stats': efficiency_stats
        }
        
    def _create_visualizations(self):
        """è¦–è¦šåŒ–ä½œæˆ"""
        print("\nğŸ“ˆ Creating Visualizations...")
        
        # å›³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        fig = plt.figure(figsize=(20, 16))
        gs = fig.add_gridspec(4, 2, hspace=0.3, wspace=0.3)
        
        # 1. ä¾¡æ ¼ã¨ãƒãƒ§ãƒ”ãƒã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ¯”è¼ƒ
        ax1 = fig.add_subplot(gs[0, :])
        self._plot_price_and_choppiness(ax1)
        
        # 2. é…å»¶ç‰¹æ€§ã®æ¯”è¼ƒ
        ax2 = fig.add_subplot(gs[1, 0])
        self._plot_lag_comparison(ax2)
        
        # 3. ç²¾åº¦ã®æ¯”è¼ƒ
        ax3 = fig.add_subplot(gs[1, 1])
        self._plot_accuracy_comparison(ax3)
        
        # 4. é©å¿œæ€§ã®å¯è¦–åŒ–
        ax4 = fig.add_subplot(gs[2, 0])
        self._plot_adaptivity(ax4)
        
        # 5. ä¿¡é ¼åº¦ã®åˆ†å¸ƒ
        ax5 = fig.add_subplot(gs[2, 1])
        self._plot_confidence_distribution(ax5)
        
        # 6. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ
        ax6 = fig.add_subplot(gs[3, :])
        self._plot_performance_comparison(ax6)
        
        plt.suptitle('ğŸš€ Ultimate Choppiness Index vs Classic Choppiness Index', 
                    fontsize=16, fontweight='bold')
        
        # ä¿å­˜
        output_dir = Path("examples/output")
        output_dir.mkdir(exist_ok=True)
        plt.savefig(output_dir / "ultimate_choppiness_comparison.png", 
                   dpi=300, bbox_inches='tight')
        plt.show()
        
    def _plot_price_and_choppiness(self, ax):
        """ä¾¡æ ¼ã¨ãƒãƒ§ãƒ”ãƒã‚¹æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ"""
        dates = range(len(self.data))
        
        # ä¾¡æ ¼ãƒ—ãƒ­ãƒƒãƒˆ
        ax2 = ax.twinx()
        ax2.plot(dates, self.data['close'], 'k-', alpha=0.7, linewidth=1, label='Price')
        ax2.set_ylabel('Price', color='black')
        
        # ãƒãƒ§ãƒ”ãƒã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
        ultimate_values = self.results['performance']['ultimate_values']
        classic_values = self.results['performance']['classic_values']
        
        ax.plot(dates, ultimate_values, 'r-', linewidth=2, label='Ultimate Choppiness', alpha=0.8)
        ax.plot(dates, classic_values, 'b-', linewidth=1, label='Classic Choppiness', alpha=0.6)
        
        ax.set_xlabel('Time')
        ax.set_ylabel('Choppiness Index')
        ax.set_title('Price vs Choppiness Index Comparison')
        ax.legend(loc='upper left')
        ax2.legend(loc='upper right')
        ax.grid(True, alpha=0.3)
        
    def _plot_lag_comparison(self, ax):
        """é…å»¶æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ"""
        categories = ['Ultimate', 'Classic']
        lag_values = [
            self.results['lag_analysis']['ultimate_lag'],
            self.results['lag_analysis']['classic_lag']
        ]
        
        bars = ax.bar(categories, lag_values, color=['red', 'blue'], alpha=0.7)
        ax.set_ylabel('Average Lag (bars)')
        ax.set_title('Response Lag Comparison')
        
        # å€¤ã‚’ãƒãƒ¼ã«è¡¨ç¤º
        for bar, value in zip(bars, lag_values):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{value:.1f}', ha='center', va='bottom')
        
    def _plot_accuracy_comparison(self, ax):
        """ç²¾åº¦æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ"""
        ultimate_result = self.ultimate_chop.get_result()
        confidence = ultimate_result.confidence
        
        # ä¿¡é ¼åº¦ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
        ax.hist(confidence[~np.isnan(confidence)], bins=20, alpha=0.7, color='red')
        ax.set_xlabel('Confidence Level')
        ax.set_ylabel('Frequency')
        ax.set_title('Confidence Distribution')
        ax.axvline(0.7, color='black', linestyle='--', alpha=0.5, label='High Confidence Threshold')
        ax.legend()
        
    def _plot_adaptivity(self, ax):
        """é©å¿œæ€§ãƒ—ãƒ­ãƒƒãƒˆ"""
        ultimate_result = self.ultimate_chop.get_result()
        dates = range(len(ultimate_result.adaptive_period))
        
        ax.plot(dates, ultimate_result.adaptive_period, 'g-', linewidth=1, alpha=0.7)
        ax.set_xlabel('Time')
        ax.set_ylabel('Adaptive Period')
        ax.set_title('Dynamic Period Adaptation')
        ax.grid(True, alpha=0.3)
        
    def _plot_confidence_distribution(self, ax):
        """ä¿¡é ¼åº¦åˆ†å¸ƒãƒ—ãƒ­ãƒƒãƒˆ"""
        ultimate_result = self.ultimate_chop.get_result()
        
        # åŠ¹ç‡æ¯” vs ä½ç›¸ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹
        valid_mask = ~(np.isnan(ultimate_result.efficiency) | np.isnan(ultimate_result.phase_coherence))
        
        scatter = ax.scatter(ultimate_result.efficiency[valid_mask], 
                           ultimate_result.phase_coherence[valid_mask],
                           c=ultimate_result.confidence[valid_mask], 
                           cmap='viridis', alpha=0.6)
        
        ax.set_xlabel('Efficiency Ratio')
        ax.set_ylabel('Phase Coherence')
        ax.set_title('Efficiency vs Phase Coherence')
        
        cbar = plt.colorbar(scatter, ax=ax)
        cbar.set_label('Confidence')
        
    def _plot_performance_comparison(self, ax):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ"""
        metrics = ['Speed', 'Lag Improvement', 'Accuracy']
        values = [
            self.results['performance']['speed_ratio'],
            self.results['lag_analysis']['improvement'],
            self.results['accuracy']['high_confidence_ratio'] * 100
        ]
        
        bars = ax.bar(metrics, values, color=['green', 'orange', 'purple'], alpha=0.7)
        ax.set_ylabel('Performance Score')
        ax.set_title('Overall Performance Comparison')
        
        # å€¤ã‚’ãƒãƒ¼ã«è¡¨ç¤º
        for bar, value in zip(bars, values):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{value:.1f}', ha='center', va='bottom')


def load_sample_data():
    """ã‚µãƒ³ãƒ—ãƒ«OHLCãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ï¼ˆãƒªã‚¢ãƒ«ãªå¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’æ¨¡æ“¬ï¼‰"""
    np.random.seed(42)  # å†ç¾æ€§ã®ãŸã‚
    n = 1000  # ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°
    
    # åŸºæœ¬çš„ãªä¾¡æ ¼ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ + ãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰
    base = np.cumsum(np.random.normal(0, 1, n)) + np.linspace(0, 25, n)
    
    # å‘¨æœŸçš„ãªæˆåˆ†ã‚’è¿½åŠ ï¼ˆå¸‚å ´ã‚µã‚¤ã‚¯ãƒ«ã‚’æ¨¡æ“¬ï¼‰
    cycles = 10 * np.sin(np.linspace(0, 8 * np.pi, n)) + 5 * np.sin(np.linspace(0, 20 * np.pi, n))
    
    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®å¤‰åŒ–ï¼ˆVIXæŒ‡æ•°ã®ã‚ˆã†ãªå¤‰å‹•ï¼‰
    volatility = np.abs(np.sin(np.linspace(0, 6 * np.pi, n))) * 4 + 3
    
    # çµ‚å€¤ã‚’ä½œæˆ
    close = 100 + base + cycles
    
    # é«˜å€¤ã€å®‰å€¤ã€å§‹å€¤ã‚’ä½œæˆï¼ˆãƒªã‚¢ãƒ«ãªä¾¡æ ¼å¤‰å‹•ï¼‰
    high = close + np.random.exponential(1, n) * volatility
    low = close - np.random.exponential(1, n) * volatility
    open_ = close + np.random.normal(0, 0.5, n) * volatility
    
    # ä¾¡æ ¼ã®æ•´åˆæ€§ã‚’ç¢ºä¿
    high = np.maximum(high, np.maximum(open_, close))
    low = np.minimum(low, np.minimum(open_, close))
    
    # DataFrameã«å¤‰æ›
    df = pd.DataFrame({
        'open': open_,
        'high': high,
        'low': low,
        'close': close,
        'volume': np.random.randint(1000, 50000, n)
    })
    
    return df


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ Ultimate Choppiness Index Demonstration")
    print("=" * 50)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
    try:
        data = load_sample_data()
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(data)} rows")
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        print("ğŸ“Š ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
        data = generate_sample_data()
    
    # æ¯”è¼ƒåˆ†æå®Ÿè¡Œ
    comparison = ChoppinessComparison(data)
    results = comparison.run_comparison()
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\nğŸ¯ Final Results Summary")
    print("=" * 50)
    print(f"âš¡ é…å»¶æ”¹å–„: {results['lag_analysis']['improvement']:.1f}%")
    print(f"ğŸš€ å‡¦ç†é€Ÿåº¦: {results['performance']['speed_ratio']:.1f}x faster")
    print(f"ğŸ¯ é«˜ä¿¡é ¼åº¦æ¯”ç‡: {results['accuracy']['high_confidence_ratio']*100:.1f}%")
    print(f"ğŸ“ˆ å¹³å‡ä¿¡é ¼åº¦: {results['accuracy']['confidence_stats']['mean']:.3f}")
    print("\nâœ… åˆ†æå®Œäº†ï¼çµæœã¯ examples/output/ultimate_choppiness_comparison.png ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")


def generate_sample_data(n_points=1000):
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    np.random.seed(42)
    
    # åŸºæœ¬ãƒˆãƒ¬ãƒ³ãƒ‰
    trend = np.cumsum(np.random.randn(n_points) * 0.01)
    
    # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    dates = pd.date_range('2023-01-01', periods=n_points, freq='H')
    close = 100 + trend + np.random.randn(n_points) * 0.5
    
    # OHLCç”Ÿæˆ
    high = close + np.random.rand(n_points) * 2
    low = close - np.random.rand(n_points) * 2
    open_price = close + np.random.randn(n_points) * 0.3
    volume = np.random.randint(1000, 10000, n_points)
    
    return pd.DataFrame({
        'open': open_price,
        'high': high,
        'low': low,
        'close': close,
        'volume': volume
    }, index=dates)


if __name__ == "__main__":
    main() 