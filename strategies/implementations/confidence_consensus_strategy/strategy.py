#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ¯ **ä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹ãƒ»ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹æˆ¦ç•¥** ğŸ¯

éšå±¤çš„é©å¿œå‹ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹æ³•ã«ã‚ˆã‚‹é«˜åº¦ãªä¿¡é ¼åº¦ç®—å‡ºæˆ¦ç•¥ã€‚
è¤‡æ•°ã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã‚·ã‚°ãƒŠãƒ«ã‚’é‡ã¿ä»˜ãã§çµ„ã¿åˆã‚ã›ã€
å¸‚å ´çŠ¶æ³ã«å¿œã˜ã¦å‹•çš„ã«èª¿æ•´ã™ã‚‹æ´—ç·´ã•ã‚ŒãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€‚

ğŸŒŸ **ä¸»è¦æ©Ÿèƒ½:**
1. **ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼åˆæ„åº¦ãƒ¬ã‚¤ãƒ¤ãƒ¼** (40%): ãƒã‚¤ãƒ‘ãƒ¼ADXã€ãƒã‚¤ãƒ‘ãƒ¼ERã€ãƒã‚¤ãƒ‘ãƒ¼ãƒˆãƒ¬ãƒ³ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆå…¨ã¦-1â†’0å¤‰æ›ï¼‰
2. **æ–¹å‘æ€§å¼·åº¦ãƒ¬ã‚¤ãƒ¤ãƒ¼** (30%): ãƒ‰ãƒ³ãƒãƒ£ãƒ³FRAMA 3æœŸé–“(60, 120, 240)
3. **ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ä¿‚æ•°ãƒ¬ã‚¤ãƒ¤ãƒ¼** (20%): ãƒ©ã‚²ãƒ¼ãƒ«RSIãƒˆãƒ¬ãƒ³ãƒ‰ãƒ•ã‚©ãƒ­ãƒ¼
4. **ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è£œæ­£ãƒ¬ã‚¤ãƒ¤ãƒ¼** (10%): XATRè£œæ­£è¦ç´ 

ğŸ“Š **ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒ»ã‚¨ã‚°ã‚¸ãƒƒãƒˆæ¡ä»¶:**
- ãƒ­ãƒ³ã‚°ã‚¨ãƒ³ãƒˆãƒªãƒ¼: ä¿¡é ¼åº¦ >= 0.6
- ã‚·ãƒ§ãƒ¼ãƒˆã‚¨ãƒ³ãƒˆãƒªãƒ¼: ä¿¡é ¼åº¦ <= -0.6
- ãƒ­ãƒ³ã‚°ã‚¨ã‚°ã‚¸ãƒƒãƒˆ: ä¿¡é ¼åº¦ <= 0.0ï¼ˆãƒ­ãƒ³ã‚°ãƒã‚¸ã‚·ãƒ§ãƒ³æ™‚ï¼‰
- ã‚·ãƒ§ãƒ¼ãƒˆã‚¨ã‚°ã‚¸ãƒƒãƒˆ: ä¿¡é ¼åº¦ >= 0.0ï¼ˆã‚·ãƒ§ãƒ¼ãƒˆãƒã‚¸ã‚·ãƒ§ãƒ³æ™‚ï¼‰
- æ–¹å‘æ€§ã‚·ã‚°ãƒŠãƒ«ãŒè² ã®å ´åˆã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ»ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç¬¦å·é€†è»¢
"""

from dataclasses import dataclass
from typing import Union, Dict, Any, Optional, Tuple
import numpy as np
import pandas as pd
from numba import njit
import optuna

# æˆ¦ç•¥åŸºåº•ã‚¯ãƒ©ã‚¹
from ...base.strategy import BaseStrategy
from ...interfaces.strategy import IStrategy

# ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
from indicators.trend_filter.hyper_adx import HyperADX
from indicators.trend_filter.hyper_er import HyperER
from indicators.hyper_trend_index import HyperTrendIndex
from indicators.volatility.x_atr import XATR

# ã‚·ã‚°ãƒŠãƒ«
from signals.implementations.donchian_frama.entry import DonchianFRAMACrossoverEntrySignal
from signals.implementations.laguerre_rsi.trend_follow_entry import LaguerreRSITrendFollowEntrySignal


@dataclass
class ConfidenceCalculationResult:
    """ä¿¡é ¼åº¦è¨ˆç®—çµæœ"""
    confidence: np.ndarray                # æœ€çµ‚ä¿¡é ¼åº¦ï¼ˆ-1ã€œ1ï¼‰
    filter_consensus: np.ndarray          # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼åˆæ„åº¦
    directional_strength: np.ndarray      # æ–¹å‘æ€§å¼·åº¦
    momentum_factor: np.ndarray           # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ä¿‚æ•°
    volatility_correction: np.ndarray     # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è£œæ­£
    entry_signals: np.ndarray             # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ã‚°ãƒŠãƒ«ï¼ˆ1=ãƒ­ãƒ³ã‚°ã€-1=ã‚·ãƒ§ãƒ¼ãƒˆã€0=ãªã—ï¼‰
    
    # å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®è©³ç´°
    filter_signals: Dict[str, np.ndarray] # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚·ã‚°ãƒŠãƒ«è©³ç´°
    donchian_signals: Dict[str, np.ndarray] # ãƒ‰ãƒ³ãƒãƒ£ãƒ³FRAMAã‚·ã‚°ãƒŠãƒ«è©³ç´°
    laguerre_signal: np.ndarray           # ãƒ©ã‚²ãƒ¼ãƒ«RSIã‚·ã‚°ãƒŠãƒ«
    xatr_signal: np.ndarray               # XATRã‚·ã‚°ãƒŠãƒ«


@njit(fastmath=True, cache=True)
def calculate_filter_consensus_numba(
    hyper_adx: np.ndarray,
    hyper_er: np.ndarray, 
    hyper_trend: np.ndarray
) -> np.ndarray:
    """
    ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼åˆæ„åº¦ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆNumbaæœ€é©åŒ–ç‰ˆï¼‰
    
    Args:
        hyper_adx: ãƒã‚¤ãƒ‘ãƒ¼ADXã®ãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡å·ï¼ˆ-1â†’0ã¨ã—ã¦æ‰±ã†ï¼‰
        hyper_er: ãƒã‚¤ãƒ‘ãƒ¼ERã®ãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡å·ï¼ˆ-1â†’0ã¨ã—ã¦æ‰±ã†ï¼‰
        hyper_trend: ãƒã‚¤ãƒ‘ãƒ¼ãƒˆãƒ¬ãƒ³ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡å·ï¼ˆ-1â†’0ã¨ã—ã¦æ‰±ã†ï¼‰
        
    Returns:
        ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼åˆæ„åº¦ï¼ˆ0ã€œ1ã®ç¯„å›²ï¼‰
    """
    length = len(hyper_adx)
    consensus = np.full(length, np.nan, dtype=np.float64)
    
    for i in range(length):
        # NaNå€¤ã®ãƒã‚§ãƒƒã‚¯
        if (np.isnan(hyper_adx[i]) or np.isnan(hyper_er[i]) or np.isnan(hyper_trend[i])):
            continue
            
        # å…¨ã¦ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚·ã‚°ãƒŠãƒ«ã®-1ã‚’0ã¨ã—ã¦æ‰±ã†ï¼ˆæ–¹å‘æ€§ã‚’ç¤ºã•ãªã„ãŸã‚ï¼‰
        adjusted_adx = 0.0 if hyper_adx[i] < 0 else hyper_adx[i]
        adjusted_er = 0.0 if hyper_er[i] < 0 else hyper_er[i]
        adjusted_trend = 0.0 if hyper_trend[i] < 0 else hyper_trend[i]
        
        # 3ã¤ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å¹³å‡ï¼ˆ0-1ã®ç¯„å›²ï¼‰
        consensus[i] = (adjusted_adx + adjusted_er + adjusted_trend) / 3.0
    
    return consensus


@njit(fastmath=True, cache=True)
def calculate_directional_strength_numba(
    donchian_60: np.ndarray,
    donchian_120: np.ndarray,
    donchian_240: np.ndarray
) -> np.ndarray:
    """
    æ–¹å‘æ€§å¼·åº¦ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆNumbaæœ€é©åŒ–ç‰ˆï¼‰
    
    Args:
        donchian_60: 60æœŸé–“ãƒ‰ãƒ³ãƒãƒ£ãƒ³FRAMAã‚·ã‚°ãƒŠãƒ«
        donchian_120: 120æœŸé–“ãƒ‰ãƒ³ãƒãƒ£ãƒ³FRAMAã‚·ã‚°ãƒŠãƒ«
        donchian_240: 240æœŸé–“ãƒ‰ãƒ³ãƒãƒ£ãƒ³FRAMAã‚·ã‚°ãƒŠãƒ«
        
    Returns:
        æ–¹å‘æ€§å¼·åº¦ï¼ˆ-1ã€œ1ï¼‰
    """
    length = len(donchian_60)
    strength = np.full(length, np.nan, dtype=np.float64)
    
    for i in range(length):
        # NaNå€¤ã®ãƒã‚§ãƒƒã‚¯
        if (np.isnan(donchian_60[i]) or np.isnan(donchian_120[i]) or np.isnan(donchian_240[i])):
            continue
        
        # é‡ã¿ä»˜ãå¹³å‡: çŸ­æœŸ40%, ä¸­æœŸ35%, é•·æœŸ25%
        strength[i] = (donchian_60[i] * 0.4 + 
                      donchian_120[i] * 0.35 + 
                      donchian_240[i] * 0.25)
    
    return strength


@njit(fastmath=True, cache=True)
def calculate_confidence_score_numba(
    filter_consensus: np.ndarray,
    directional_strength: np.ndarray,
    momentum_factor: np.ndarray,
    volatility_signal: np.ndarray
) -> tuple:
    """
    æœ€çµ‚ä¿¡é ¼åº¦ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆNumbaæœ€é©åŒ–ç‰ˆï¼‰
    
    Args:
        filter_consensus: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼åˆæ„åº¦
        directional_strength: æ–¹å‘æ€§å¼·åº¦
        momentum_factor: ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ä¿‚æ•°
        volatility_signal: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚·ã‚°ãƒŠãƒ«
        
    Returns:
        Tuple[np.ndarray, np.ndarray]: (ä¿¡é ¼åº¦, ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è£œæ­£)
    """
    length = len(filter_consensus)
    confidence = np.full(length, np.nan, dtype=np.float64)
    volatility_correction = np.full(length, 1.0, dtype=np.float64)
    
    for i in range(length):
        # NaNå€¤ã®ãƒã‚§ãƒƒã‚¯
        if (np.isnan(filter_consensus[i]) or np.isnan(directional_strength[i]) or 
            np.isnan(momentum_factor[i]) or np.isnan(volatility_signal[i])):
            continue
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è£œæ­£ã®è¨ˆç®—
        volatility_correction[i] = 1.0 + (volatility_signal[i] * 0.1)
        
        # åŸºæœ¬ä¿¡é ¼åº¦
        base_confidence = (filter_consensus[i] * 0.4 + 
                          directional_strength[i] * 0.3 + 
                          momentum_factor[i] * 0.2)
        
        # æ–¹å‘æ€§ã«ã‚ˆã‚‹ç¬¦å·èª¿æ•´ï¼ˆã‚¨ãƒ¬ã‚¬ãƒ³ãƒˆãªãƒã‚¤ãƒ³ãƒˆï¼‰
        if directional_strength[i] < 0:
            # æ–¹å‘æ€§ãŒè² ã®å ´åˆã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¨ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’é€†è»¢
            adjusted_confidence = ((-filter_consensus[i]) * 0.4 + 
                                 directional_strength[i] * 0.3 + 
                                 momentum_factor[i] * 0.2)
            confidence[i] = adjusted_confidence * (1.0 - volatility_signal[i] * 0.1)
        else:
            confidence[i] = base_confidence * volatility_correction[i]
        
        # -1ã‹ã‚‰1ã®ç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—
        confidence[i] = max(-1.0, min(1.0, confidence[i]))
    
    return confidence, volatility_correction


@njit(fastmath=True, cache=True)
def generate_entry_signals_numba(
    confidence: np.ndarray,
    long_threshold: float = 0.6,
    short_threshold: float = -0.6
) -> np.ndarray:
    """
    ä¿¡é ¼åº¦ã‹ã‚‰ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ã‚°ãƒŠãƒ«ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆNumbaæœ€é©åŒ–ç‰ˆï¼‰
    
    Args:
        confidence: ä¿¡é ¼åº¦é…åˆ—
        long_threshold: ãƒ­ãƒ³ã‚°ã‚¨ãƒ³ãƒˆãƒªãƒ¼é–¾å€¤
        short_threshold: ã‚·ãƒ§ãƒ¼ãƒˆã‚¨ãƒ³ãƒˆãƒªãƒ¼é–¾å€¤
        
    Returns:
        ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ã‚°ãƒŠãƒ«ï¼ˆ1=ãƒ­ãƒ³ã‚°ã€-1=ã‚·ãƒ§ãƒ¼ãƒˆã€0=ãªã—ï¼‰
    """
    length = len(confidence)
    signals = np.zeros(length, dtype=np.int8)
    
    for i in range(length):
        if np.isnan(confidence[i]):
            continue
            
        if confidence[i] >= long_threshold:
            signals[i] = 1  # ãƒ­ãƒ³ã‚°ã‚¨ãƒ³ãƒˆãƒªãƒ¼
        elif confidence[i] <= short_threshold:
            signals[i] = -1  # ã‚·ãƒ§ãƒ¼ãƒˆã‚¨ãƒ³ãƒˆãƒªãƒ¼
        # else: 0 (ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãªã—)
    
    return signals


@njit(fastmath=True, cache=True)
def generate_exit_signals_numba(
    confidence: np.ndarray,
    entry_signals: np.ndarray
) -> np.ndarray:
    """
    ä¿¡é ¼åº¦ã‹ã‚‰ã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚°ãƒŠãƒ«ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆNumbaæœ€é©åŒ–ç‰ˆï¼‰
    
    ãƒ­ã‚¸ãƒƒã‚¯:
    - ãƒ­ãƒ³ã‚°ãƒã‚¸ã‚·ãƒ§ãƒ³: ä¿¡é ¼åº¦ãŒ0ä»¥ä¸‹ã«ãªã£ãŸã‚‰ã‚¨ã‚°ã‚¸ãƒƒãƒˆ
    - ã‚·ãƒ§ãƒ¼ãƒˆãƒã‚¸ã‚·ãƒ§ãƒ³: ä¿¡é ¼åº¦ãŒ0ä»¥ä¸Šã«ãªã£ãŸã‚‰ã‚¨ã‚°ã‚¸ãƒƒãƒˆ
    
    Args:
        confidence: ä¿¡é ¼åº¦é…åˆ—
        entry_signals: ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ã‚°ãƒŠãƒ«é…åˆ—
        
    Returns:
        ã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚°ãƒŠãƒ«ï¼ˆ1=ã‚¨ã‚°ã‚¸ãƒƒãƒˆã€0=ãƒ›ãƒ¼ãƒ«ãƒ‰ï¼‰
    """
    length = len(confidence)
    exit_signals = np.zeros(length, dtype=np.int8)
    current_position = 0  # 0=ãƒã‚¸ã‚·ãƒ§ãƒ³ãªã—ã€1=ãƒ­ãƒ³ã‚°ã€-1=ã‚·ãƒ§ãƒ¼ãƒˆ
    
    for i in range(length):
        if np.isnan(confidence[i]):
            continue
        
        # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ã‚°ãƒŠãƒ«ãŒã‚ã‚‹å ´åˆã€ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’æ›´æ–°
        if entry_signals[i] != 0:
            current_position = entry_signals[i]
            continue  # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã¨åŒæ™‚ã«ã‚¨ã‚°ã‚¸ãƒƒãƒˆã¯ã—ãªã„
        
        # ç¾åœ¨ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã«åŸºã¥ã„ã¦ã‚¨ã‚°ã‚¸ãƒƒãƒˆåˆ¤å®š
        if current_position == 1:  # ãƒ­ãƒ³ã‚°ãƒã‚¸ã‚·ãƒ§ãƒ³
            if confidence[i] <= 0.0:
                exit_signals[i] = 1  # ãƒ­ãƒ³ã‚°ã‚¨ã‚°ã‚¸ãƒƒãƒˆ
                current_position = 0  # ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚¯ãƒªã‚¢
        elif current_position == -1:  # ã‚·ãƒ§ãƒ¼ãƒˆãƒã‚¸ã‚·ãƒ§ãƒ³
            if confidence[i] >= 0.0:
                exit_signals[i] = 1  # ã‚·ãƒ§ãƒ¼ãƒˆã‚¨ã‚°ã‚¸ãƒƒãƒˆ  
                current_position = 0  # ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚¯ãƒªã‚¢
    
    return exit_signals


class ConfidenceConsensusStrategy(BaseStrategy, IStrategy):
    """
    ä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹ãƒ»ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹æˆ¦ç•¥
    
    éšå±¤çš„é©å¿œå‹ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹æ³•ã«ã‚ˆã‚Šã€è¤‡æ•°ã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã‚·ã‚°ãƒŠãƒ«ã‚’
    é‡ã¿ä»˜ãã§çµ„ã¿åˆã‚ã›ã¦ä¿¡é ¼åº¦ã‚’ç®—å‡ºã—ã€ã‚¨ãƒ³ãƒˆãƒªãƒ¼åˆ¤å®šã‚’è¡Œã†æˆ¦ç•¥ã€‚
    
    ç‰¹å¾´:
    - 4å±¤ã®éšå±¤çš„ä¿¡é ¼åº¦è¨ˆç®—
    - æ–¹å‘æ€§ã«å¿œã˜ãŸå‹•çš„ç¬¦å·èª¿æ•´  
    - ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç’°å¢ƒã«ã‚ˆã‚‹è£œæ­£
    - é«˜ã„ä¿¡é ¼åº¦é–¾å€¤ã«ã‚ˆã‚‹å³é¸ã‚¨ãƒ³ãƒˆãƒªãƒ¼
    - ä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹ã®è«–ç†çš„ã‚¨ã‚°ã‚¸ãƒƒãƒˆï¼ˆãƒ­ãƒ³ã‚°ï¼šâ‰¤0ã€ã‚·ãƒ§ãƒ¼ãƒˆï¼šâ‰¥0ï¼‰
    """
    
    def __init__(
        self,
        # ã‚¨ãƒ³ãƒˆãƒªãƒ¼é–¾å€¤
        long_threshold: float = 0.5,
        short_threshold: float = -0.5,
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        hyper_adx_period: int = 14,
        hyper_er_period: int = 14,
        hyper_trend_period: int = 14,
        
        # ãƒ‰ãƒ³ãƒãƒ£ãƒ³FRAMAãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        donchian_periods: Tuple[int, int, int] = (60, 120, 240),
        
        # ãƒ©ã‚²ãƒ¼ãƒ«RSIãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿  
        laguerre_gamma: float = 0.5,
        
        # XATRãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        xatr_period: float = 34.0,
        xatr_tr_method: str = 'atr',
        
        # é‡ã¿è¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰
        filter_weight: float = 0.4,
        directional_weight: float = 0.3,
        momentum_weight: float = 0.2,
        volatility_weight: float = 0.1
    ):
        """
        åˆæœŸåŒ–
        
        Args:
            long_threshold: ãƒ­ãƒ³ã‚°ã‚¨ãƒ³ãƒˆãƒªãƒ¼é–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.6ï¼‰
            short_threshold: ã‚·ãƒ§ãƒ¼ãƒˆã‚¨ãƒ³ãƒˆãƒªãƒ¼é–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: -0.6ï¼‰
            hyper_adx_period: ãƒã‚¤ãƒ‘ãƒ¼ADXæœŸé–“
            hyper_er_period: ãƒã‚¤ãƒ‘ãƒ¼ERæœŸé–“
            hyper_trend_period: ãƒã‚¤ãƒ‘ãƒ¼ãƒˆãƒ¬ãƒ³ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœŸé–“
            donchian_periods: ãƒ‰ãƒ³ãƒãƒ£ãƒ³FRAMAæœŸé–“(çŸ­æœŸ, ä¸­æœŸ, é•·æœŸ)
            laguerre_gamma: ãƒ©ã‚²ãƒ¼ãƒ«RSIã‚¬ãƒ³ãƒå€¤
            xatr_period: XATRæœŸé–“
            xatr_tr_method: XATR TRè¨ˆç®—æ–¹æ³•
            filter_weight: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é‡ã¿
            directional_weight: æ–¹å‘æ€§é‡ã¿
            momentum_weight: ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ é‡ã¿
            volatility_weight: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£é‡ã¿
        """
        strategy_name = (f"ConfidenceConsensus(Lâ‰¥{long_threshold:.1f}, Sâ‰¤{short_threshold:.1f}, "
                        f"Î³={laguerre_gamma}, periods={donchian_periods})")
        super().__init__(strategy_name)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¿å­˜
        self.long_threshold = long_threshold
        self.short_threshold = short_threshold
        
        # é‡ã¿è¨­å®š
        self.filter_weight = filter_weight
        self.directional_weight = directional_weight  
        self.momentum_weight = momentum_weight
        self.volatility_weight = volatility_weight
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼
        if long_threshold <= 0 or short_threshold >= 0:
            raise ValueError("é–¾å€¤è¨­å®šãŒç„¡åŠ¹ã§ã™: long_threshold > 0, short_threshold < 0")
        
        weight_sum = filter_weight + directional_weight + momentum_weight + volatility_weight
        if abs(weight_sum - 1.0) > 0.01:
            raise ValueError(f"é‡ã¿ã®åˆè¨ˆãŒ1.0ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {weight_sum}")
        
        # ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®åˆæœŸåŒ–
        try:
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
            self.hyper_adx = HyperADX(
                period=hyper_adx_period,
                use_kalman_filter=True,
                use_roofing_filter=True,
                use_dynamic_period=True
            )
            
            self.hyper_er = HyperER(
                period=hyper_er_period,
                use_kalman_filter=True,
                use_roofing_filter=True,
                use_dynamic_period=True
            )
            
            self.hyper_trend = HyperTrendIndex(
                period=hyper_trend_period,
                use_kalman_filter=True,
                use_roofing_filter=True,
                use_dynamic_period=True
            )
            
            # XATR
            self.xatr = XATR(
                period=xatr_period,
                tr_method=xatr_tr_method,
                smoother_type='ultimate_smoother',
                enable_kalman=False,
                period_mode='dynamic'
            )
            
            self.logger.info("ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–å®Œäº†")
            
        except Exception as e:
            self.logger.error(f"ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–å¤±æ•—: {e}")
            raise
        
        # ã‚·ã‚°ãƒŠãƒ«ã®åˆæœŸåŒ–
        try:
            # ãƒ‰ãƒ³ãƒãƒ£ãƒ³FRAMAã‚·ã‚°ãƒŠãƒ«ï¼ˆ3æœŸé–“ï¼‰
            self.donchian_signals = {}
            for period in donchian_periods:
                # FRAMAæœŸé–“ã¯å¶æ•°ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚èª¿æ•´
                frama_period =16
                self.donchian_signals[f'period_{period}'] = DonchianFRAMACrossoverEntrySignal(
                    donchian_period=period,
                    frama_period=frama_period,
                    donchian_src_type='hlc3',
                    frama_src_type='hlc3',
                    position_mode=True
                )
            
            # ãƒ©ã‚²ãƒ¼ãƒ«RSIã‚·ã‚°ãƒŠãƒ«
            self.laguerre_rsi_signal = LaguerreRSITrendFollowEntrySignal(
                gamma=laguerre_gamma,
                buy_band=0.8,
                sell_band=0.2,
                position_mode=True
            )
            
            self.logger.info("ã‚·ã‚°ãƒŠãƒ«åˆæœŸåŒ–å®Œäº†")
            
        except Exception as e:
            self.logger.error(f"ã‚·ã‚°ãƒŠãƒ«åˆæœŸåŒ–å¤±æ•—: {e}")
            raise
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._result_cache = {}
        self._max_cache_size = 5
        self._cache_keys = []
    
    def _get_data_hash(self, data: Union[pd.DataFrame, np.ndarray]) -> str:
        """ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥å€¤è¨ˆç®—"""
        try:
            if isinstance(data, pd.DataFrame):
                length = len(data)
                if length > 0:
                    first_val = float(data.iloc[0].get('close', data.iloc[0, -1]))
                    last_val = float(data.iloc[-1].get('close', data.iloc[-1, -1]))
                else:
                    first_val = last_val = 0.0
            else:
                length = len(data)
                if length > 0:
                    first_val = float(data[0, -1]) if data.ndim > 1 else float(data[0])
                    last_val = float(data[-1, -1]) if data.ndim > 1 else float(data[-1])
                else:
                    first_val = last_val = 0.0
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚·ã‚°ãƒãƒãƒ£
            param_str = f"{self.long_threshold}_{self.short_threshold}_{self.filter_weight}_{self.directional_weight}"
            
            data_sig = (length, first_val, last_val)
            return f"{hash(data_sig)}_{hash(param_str)}"
            
        except Exception:
            return f"{id(data)}_{self.long_threshold}_{self.short_threshold}"
    
    def calculate_confidence(self, data: Union[pd.DataFrame, np.ndarray]) -> ConfidenceCalculationResult:
        """
        ä¿¡é ¼åº¦ã‚’è¨ˆç®—ã™ã‚‹
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            ConfidenceCalculationResult: ä¿¡é ¼åº¦è¨ˆç®—çµæœ
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿é•·ã®å–å¾—
            data_length = len(data)
            
            # 1. ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚·ã‚°ãƒŠãƒ«ã®è¨ˆç®—
            hyper_adx_result = self.hyper_adx.calculate(data)
            hyper_er_result = self.hyper_er.calculate(data)
            hyper_trend_result = self.hyper_trend.calculate(data)
            
            filter_signals = {
                'hyper_adx': hyper_adx_result.trend_signal,
                'hyper_er': hyper_er_result.trend_signal,
                'hyper_trend': hyper_trend_result.trend_signal
            }
            
            # 2. æ–¹å‘æ€§ã‚·ã‚°ãƒŠãƒ«ã®è¨ˆç®—ï¼ˆãƒ‰ãƒ³ãƒãƒ£ãƒ³FRAMAï¼‰
            donchian_signals = {}
            donchian_arrays = []
            
            for key, signal in self.donchian_signals.items():
                signal_result = signal.generate(data)
                donchian_signals[key] = signal_result
                donchian_arrays.append(signal_result)
            
            # 3ã¤ã®æœŸé–“ã®ã‚·ã‚°ãƒŠãƒ«ã‚’å–å¾—
            donchian_60 = donchian_arrays[0] if len(donchian_arrays) > 0 else np.zeros(data_length)
            donchian_120 = donchian_arrays[1] if len(donchian_arrays) > 1 else np.zeros(data_length)  
            donchian_240 = donchian_arrays[2] if len(donchian_arrays) > 2 else np.zeros(data_length)
            
            # 3. ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã‚·ã‚°ãƒŠãƒ«ã®è¨ˆç®—ï¼ˆãƒ©ã‚²ãƒ¼ãƒ«RSIï¼‰
            laguerre_signal = self.laguerre_rsi_signal.generate(data)
            
            # 4. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚·ã‚°ãƒŠãƒ«ã®è¨ˆç®—ï¼ˆXATRï¼‰
            xatr_result = self.xatr.calculate(data)
            xatr_signal = xatr_result.volatility_signal
            
            # 5. ä¿¡é ¼åº¦è¨ˆç®—
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼åˆæ„åº¦
            filter_consensus = calculate_filter_consensus_numba(
                filter_signals['hyper_adx'],
                filter_signals['hyper_er'], 
                filter_signals['hyper_trend']
            )
            
            # æ–¹å‘æ€§å¼·åº¦
            directional_strength = calculate_directional_strength_numba(
                donchian_60.astype(np.float64),
                donchian_120.astype(np.float64),
                donchian_240.astype(np.float64)
            )
            
            # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ä¿‚æ•°ï¼ˆãã®ã¾ã¾ä½¿ç”¨ï¼‰
            momentum_factor = laguerre_signal.astype(np.float64)
            
            # æœ€çµ‚ä¿¡é ¼åº¦è¨ˆç®—
            confidence, volatility_correction = calculate_confidence_score_numba(
                filter_consensus,
                directional_strength,
                momentum_factor,
                xatr_signal
            )
            
            # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ
            entry_signals = generate_entry_signals_numba(
                confidence, self.long_threshold, self.short_threshold
            )
            
            # çµæœä½œæˆ
            result = ConfidenceCalculationResult(
                confidence=confidence,
                filter_consensus=filter_consensus,
                directional_strength=directional_strength,
                momentum_factor=momentum_factor,
                volatility_correction=volatility_correction,
                entry_signals=entry_signals,
                filter_signals=filter_signals,
                donchian_signals=donchian_signals,
                laguerre_signal=laguerre_signal,
                xatr_signal=xatr_signal
            )
            
            self.logger.debug(f"ä¿¡é ¼åº¦è¨ˆç®—å®Œäº† - ãƒ‡ãƒ¼ã‚¿é•·: {data_length}")
            return result
            
        except Exception as e:
            self.logger.error(f"ä¿¡é ¼åº¦è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºã®çµæœã‚’è¿”ã™
            empty_array = np.full(len(data), np.nan)
            empty_int_array = np.zeros(len(data), dtype=np.int8)
            
            return ConfidenceCalculationResult(
                confidence=empty_array,
                filter_consensus=empty_array,
                directional_strength=empty_array,
                momentum_factor=empty_array,
                volatility_correction=np.ones(len(data)),
                entry_signals=empty_int_array,
                filter_signals={},
                donchian_signals={},
                laguerre_signal=empty_int_array,
                xatr_signal=empty_array
            )
    
    def generate_entry(self, data: Union[pd.DataFrame, np.ndarray]) -> np.ndarray:
        """
        ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ã‚°ãƒŠãƒ«ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆBaseStrategyäº’æ›ï¼‰
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ã‚°ãƒŠãƒ«é…åˆ—ï¼ˆ1=ãƒ­ãƒ³ã‚°ã€-1=ã‚·ãƒ§ãƒ¼ãƒˆã€0=ãªã—ï¼‰
        """
        try:
            signals = self.generate_signals(data)
            return signals['entry']
        except Exception as e:
            self.logger.error(f"ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return np.zeros(len(data), dtype=np.int8)
    
    def generate_exit(self, data: Union[pd.DataFrame, np.ndarray], position: int, index: int = -1) -> bool:
        """
        ã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚°ãƒŠãƒ«ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆBaseStrategyäº’æ›ï¼‰
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            position: ç¾åœ¨ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ï¼ˆ1=ãƒ­ãƒ³ã‚°ã€-1=ã‚·ãƒ§ãƒ¼ãƒˆï¼‰
            index: ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            
        Returns:
            ã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚°ãƒŠãƒ«ï¼ˆTrue=ã‚¨ã‚°ã‚¸ãƒƒãƒˆã€False=ãƒ›ãƒ¼ãƒ«ãƒ‰ï¼‰
        """
        try:
            signals = self.generate_signals(data)
            confidence = signals['confidence']
            
            if index == -1:
                index = len(confidence) - 1
            
            if index < 0 or index >= len(confidence):
                return False
                
            current_confidence = confidence[index]
            if np.isnan(current_confidence):
                return False
            
            # ä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹ã®ã‚¨ã‚°ã‚¸ãƒƒãƒˆåˆ¤å®š
            if position == 1:  # ãƒ­ãƒ³ã‚°ãƒã‚¸ã‚·ãƒ§ãƒ³
                return current_confidence <= -0.3
            elif position == -1:  # ã‚·ãƒ§ãƒ¼ãƒˆãƒã‚¸ã‚·ãƒ§ãƒ³
                return current_confidence >= 0.3
            
            return False
            
        except Exception as e:
            self.logger.error(f"ã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def generate_signals(self, data: Union[pd.DataFrame, np.ndarray]) -> Dict[str, np.ndarray]:
        """
        ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚·ã‚°ãƒŠãƒ«ã‚’ç”Ÿæˆã™ã‚‹
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            ã‚·ã‚°ãƒŠãƒ«è¾æ›¸ï¼ˆentry, exit, positionç­‰ï¼‰
        """
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            data_hash = self._get_data_hash(data)
            
            if data_hash in self._result_cache:
                if data_hash in self._cache_keys:
                    self._cache_keys.remove(data_hash)
                self._cache_keys.append(data_hash)
                return self._result_cache[data_hash]
            
            # ä¿¡é ¼åº¦è¨ˆç®—
            confidence_result = self.calculate_confidence(data)
            
            # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ã‚°ãƒŠãƒ«
            entry_signals = confidence_result.entry_signals
            
            # ä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹ã®ã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚°ãƒŠãƒ«
            exit_signals = generate_exit_signals_numba(
                confidence_result.confidence,
                entry_signals
            )
            
            # ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚·ã‚°ãƒŠãƒ«ï¼ˆã‚¨ãƒ³ãƒˆãƒªãƒ¼ã¨åŒã˜ï¼‰
            position_signals = entry_signals.copy()
            
            # çµæœ
            signals = {
                'entry': entry_signals,
                'exit': exit_signals,
                'position': position_signals,
                'confidence': confidence_result.confidence,
                'filter_consensus': confidence_result.filter_consensus,
                'directional_strength': confidence_result.directional_strength,
                'momentum_factor': confidence_result.momentum_factor,
                'volatility_correction': confidence_result.volatility_correction
            }
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
            if len(self._result_cache) >= self._max_cache_size and self._cache_keys:
                oldest_key = self._cache_keys.pop(0)
                if oldest_key in self._result_cache:
                    del self._result_cache[oldest_key]
            
            self._result_cache[data_hash] = signals
            self._cache_keys.append(data_hash)
            
            self.logger.debug(f"ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆå®Œäº† - ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ•°: {np.sum(entry_signals != 0)}")
            return signals
            
        except Exception as e:
            self.logger.error(f"ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºã®ã‚·ã‚°ãƒŠãƒ«ã‚’è¿”ã™
            empty_signals = np.zeros(len(data), dtype=np.int8)
            empty_values = np.full(len(data), np.nan)
            
            return {
                'entry': empty_signals,
                'exit': empty_signals,
                'position': empty_signals,
                'confidence': empty_values,
                'filter_consensus': empty_values,
                'directional_strength': empty_values,
                'momentum_factor': empty_values,
                'volatility_correction': np.ones(len(data))
            }
    
    @classmethod
    def create_optimization_params(cls, trial: optuna.Trial) -> Dict[str, Any]:
        """
        æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹
        
        Args:
            trial: Optunaãƒˆãƒ©ã‚¤ã‚¢ãƒ«
            
        Returns:
            æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¾æ›¸
        """
        return {
            'long_threshold': trial.suggest_float('long_threshold', 0.4, 0.9, step=0.1),
            'short_threshold': trial.suggest_float('short_threshold', -0.9, -0.4, step=0.1),
            'laguerre_gamma': trial.suggest_float('laguerre_gamma', 0.6, 0.9, step=0.1),
            'donchian_periods': trial.suggest_categorical('donchian_periods', [
                (40, 80, 160), (50, 100, 200), (60, 120, 240), (80, 160, 320)
            ]),
            'hyper_adx_period': trial.suggest_int('hyper_adx_period', 10, 20),
            'hyper_er_period': trial.suggest_int('hyper_er_period', 10, 20),
            'hyper_trend_period': trial.suggest_int('hyper_trend_period', 10, 20),
            'xatr_period': trial.suggest_float('xatr_period', 15.0, 30.0, step=5.0)
        }
    
    @classmethod
    def convert_params_to_strategy_format(cls, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æˆ¦ç•¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹
        
        Args:
            params: æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            
        Returns:
            æˆ¦ç•¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¾æ›¸
        """
        return params.copy()

    def get_strategy_info(self) -> Dict[str, Any]:
        """æˆ¦ç•¥æƒ…å ±ã‚’å–å¾—"""
        return {
            'name': self.name,
            'type': 'ConfidenceConsensus',
            'long_threshold': self.long_threshold,
            'short_threshold': self.short_threshold,
            'weights': {
                'filter': self.filter_weight,
                'directional': self.directional_weight,
                'momentum': self.momentum_weight,
                'volatility': self.volatility_weight
            },
            'indicators': {
                'hyper_adx': self.hyper_adx.get_indicator_info(),
                'hyper_er': self.hyper_er.get_indicator_info(),
                'hyper_trend': self.hyper_trend.get_indicator_info(),
                'xatr': self.xatr.get_configuration()
            },
            'description': 'éšå±¤çš„é©å¿œå‹ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹æ³•ã«ã‚ˆã‚‹ä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹æˆ¦ç•¥'
        }
    
    def reset(self) -> None:
        """æˆ¦ç•¥çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        super().reset()
        self._result_cache = {}
        self._cache_keys = []
        
        # ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ãƒªã‚»ãƒƒãƒˆ
        for indicator in [self.hyper_adx, self.hyper_er, self.hyper_trend, self.xatr]:
            if hasattr(indicator, 'reset'):
                indicator.reset()
        
        # ã‚·ã‚°ãƒŠãƒ«ãƒªã‚»ãƒƒãƒˆ
        for signal in self.donchian_signals.values():
            if hasattr(signal, 'reset'):
                signal.reset()
        
        if hasattr(self.laguerre_rsi_signal, 'reset'):
            self.laguerre_rsi_signal.reset()


# ä¾¿åˆ©é–¢æ•°
def create_confidence_consensus_strategy(
    long_threshold: float = 0.6,
    short_threshold: float = -0.6,
    donchian_periods: Tuple[int, int, int] = (60, 120, 240),
    laguerre_gamma: float = 0.8,
    **kwargs
) -> ConfidenceConsensusStrategy:
    """
    ä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹ãƒ»ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹æˆ¦ç•¥ã‚’ä½œæˆã™ã‚‹ä¾¿åˆ©é–¢æ•°
    
    Args:
        long_threshold: ãƒ­ãƒ³ã‚°ã‚¨ãƒ³ãƒˆãƒªãƒ¼é–¾å€¤
        short_threshold: ã‚·ãƒ§ãƒ¼ãƒˆã‚¨ãƒ³ãƒˆãƒªãƒ¼é–¾å€¤
        donchian_periods: ãƒ‰ãƒ³ãƒãƒ£ãƒ³FRAMAæœŸé–“
        laguerre_gamma: ãƒ©ã‚²ãƒ¼ãƒ«RSIã‚¬ãƒ³ãƒå€¤
        **kwargs: ãã®ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        
    Returns:
        è¨­å®šæ¸ˆã¿ã®æˆ¦ç•¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    return ConfidenceConsensusStrategy(
        long_threshold=long_threshold,
        short_threshold=short_threshold,
        donchian_periods=donchian_periods,
        laguerre_gamma=laguerre_gamma,
        **kwargs
    )


if __name__ == "__main__":
    """ç›´æ¥å®Ÿè¡Œæ™‚ã®ãƒ†ã‚¹ãƒˆ"""
    import numpy as np
    import pandas as pd
    
    print("=== ä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹ãƒ»ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹æˆ¦ç•¥ã®ãƒ†ã‚¹ãƒˆ ===")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    np.random.seed(42)
    length = 300
    base_price = 100.0
    
    # è¤‡é›‘ãªå¸‚å ´ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ + ãƒ¬ãƒ³ã‚¸ + ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å¤‰åŒ–ï¼‰
    prices = [base_price]
    for i in range(1, length):
        if i < 100:  # ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰
            change = 0.003 + np.random.normal(0, 0.008)
        elif i < 200:  # ãƒ¬ãƒ³ã‚¸ç›¸å ´  
            change = np.random.normal(0, 0.012)
        else:  # ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰
            change = -0.002 + np.random.normal(0, 0.010)
        
        new_price = prices[-1] * (1 + change)
        prices.append(new_price)
    
    # OHLC ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    data = []
    for i, close in enumerate(prices):
        daily_range = abs(np.random.normal(0, close * 0.01))
        
        high = close + daily_range * np.random.uniform(0.3, 1.0)
        low = close - daily_range * np.random.uniform(0.3, 1.0)
        
        if i == 0:
            open_price = close
        else:
            gap = np.random.normal(0, close * 0.005)
            open_price = prices[i-1] + gap
        
        # è«–ç†çš„æ•´åˆæ€§ã®ç¢ºä¿
        high = max(high, open_price, close)
        low = min(low, open_price, close)
        
        data.append({
            'open': open_price,
            'high': high,
            'low': low,
            'close': close,
            'volume': np.random.uniform(1000, 10000)
        })
    
    df = pd.DataFrame(data)
    
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(df)}ãƒã‚¤ãƒ³ãƒˆ")
    print(f"ä¾¡æ ¼ç¯„å›²: {df['close'].min():.2f} - {df['close'].max():.2f}")
    
    # æˆ¦ç•¥ãƒ†ã‚¹ãƒˆ
    try:
        print("\næˆ¦ç•¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆä¸­...")
        strategy = ConfidenceConsensusStrategy(
            long_threshold=0.6,
            short_threshold=-0.6,
            donchian_periods=(60, 120, 240),
            laguerre_gamma=0.8
        )
        
        print("ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆä¸­...")
        signals = strategy.generate_signals(df)
        
        # çµæœçµ±è¨ˆ
        entry_signals = signals['entry']
        confidence = signals['confidence']
        
        long_entries = np.sum(entry_signals == 1)
        short_entries = np.sum(entry_signals == -1)
        no_entries = np.sum(entry_signals == 0)
        
        valid_confidence = confidence[~np.isnan(confidence)]
        avg_confidence = np.mean(valid_confidence) if len(valid_confidence) > 0 else 0
        
        print(f"\n=== çµæœçµ±è¨ˆ ===")
        print(f"ãƒ­ãƒ³ã‚°ã‚¨ãƒ³ãƒˆãƒªãƒ¼: {long_entries}")
        print(f"ã‚·ãƒ§ãƒ¼ãƒˆã‚¨ãƒ³ãƒˆãƒªãƒ¼: {short_entries}")
        print(f"ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãªã—: {no_entries}")
        print(f"å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.4f}")
        print(f"ä¿¡é ¼åº¦ç¯„å›²: {np.min(valid_confidence):.4f} - {np.max(valid_confidence):.4f}")
        
        # å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®çµ±è¨ˆ
        filter_consensus = signals['filter_consensus']
        directional_strength = signals['directional_strength']
        momentum_factor = signals['momentum_factor']
        
        print(f"\n=== ãƒ¬ã‚¤ãƒ¤ãƒ¼çµ±è¨ˆ ===")
        print(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼åˆæ„åº¦å¹³å‡: {np.nanmean(filter_consensus):.4f}")
        print(f"æ–¹å‘æ€§å¼·åº¦å¹³å‡: {np.nanmean(directional_strength):.4f}")
        print(f"ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ä¿‚æ•°å¹³å‡: {np.nanmean(momentum_factor):.4f}")
        
        print("\n=== ãƒ†ã‚¹ãƒˆå®Œäº† ===")
        
    except Exception as e:
        print(f"ãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()