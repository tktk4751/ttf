#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
import sys
import numpy as np
import pandas as pd
import yaml
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle

from data.data_loader import DataLoader, CSVDataSource
from data.data_processor import DataProcessor
from data.binance_data_source import BinanceDataSource
from indicators.ultra_refined_volatility_state import UltraRefinedVolatilityState
from logger import get_logger


class UltraRefinedVolatilityAnalyzer:
    """
    è¶…æ´—ç·´ã•ã‚ŒãŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çŠ¶æ…‹åˆ†æã‚·ã‚¹ãƒ†ãƒ 
    æœ€å…ˆç«¯ã®ãƒ‡ã‚¸ã‚¿ãƒ«ä¿¡å·å‡¦ç†æŠ€è¡“ã«ã‚ˆã‚‹é«˜ç²¾åº¦ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ¤å®š
    """
    
    def __init__(self, config_path: str = "config.yaml"):
        self.logger = get_logger(__name__)
        self.config = self._load_config(config_path)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®åˆæœŸåŒ–
        binance_config = self.config.get('binance_data', {})
        data_dir = binance_config.get('data_dir', 'data/binance')
        binance_data_source = BinanceDataSource(data_dir)
        
        dummy_csv_source = CSVDataSource("dummy")
        self.data_loader = DataLoader(
            data_source=dummy_csv_source,
            binance_data_source=binance_data_source
        )
        
        self.data_processor = DataProcessor()
        
        # è¶…æ´—ç·´ã•ã‚ŒãŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çŠ¶æ…‹ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®åˆæœŸåŒ–
        self.vol_indicator = UltraRefinedVolatilityState(
            str_period=14,
            lookback_period=100,
            hilbert_smooth=4,
            wavelet_scales=2,
            entropy_window=16,
            fractal_k=8,
            sensitivity=2.0,
            confidence_threshold=0.7,
            src_type='hlc3',
            smoothing=True
        )
        
        self.logger.info("Ultra-Refined Volatility State Analyzer initialized")
        self.logger.info("ğŸ§  Advanced DSP Features:")
        self.logger.info("   - STR-based ultra-low latency measurement")
        self.logger.info("   - Hilbert transform for envelope/phase analysis")
        self.logger.info("   - Discrete wavelet transform for multi-resolution analysis")
        self.logger.info("   - Spectral entropy for complexity measurement")
        self.logger.info("   - Fractal dimension for self-similarity analysis")
        self.logger.info("   - Adaptive Kalman filtering for noise reduction")
        self.logger.info("   - Adaptive threshold with dynamic market adjustment")
        self.logger.info("   - Confidence-based judgment system")
    
    def _load_config(self, config_path: str) -> dict:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            self.logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
            raise
    
    def load_market_data(self) -> pd.DataFrame:
        """å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
        try:
            self.logger.info("å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            
            raw_data = self.data_loader.load_data_from_config(self.config)
            
            if not raw_data:
                raise ValueError("ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            
            first_symbol = next(iter(raw_data))
            symbol_data = raw_data[first_symbol]
            
            if symbol_data.empty:
                raise ValueError(f"ã‚·ãƒ³ãƒœãƒ« {first_symbol} ã®ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            
            processed_data = self.data_processor.process(symbol_data)
            
            self.logger.info(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {first_symbol}")
            self.logger.info(f"æœŸé–“: {processed_data.index.min()} â†’ {processed_data.index.max()}")
            self.logger.info(f"ãƒ‡ãƒ¼ã‚¿æ•°: {len(processed_data)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
            
            return processed_data
            
        except Exception as e:
            self.logger.error(f"å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
            raise
    
    def run_ultra_refined_analysis(self, show_chart: bool = True) -> dict:
        """è¶…æ´—ç·´ã•ã‚ŒãŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æã®å®Ÿè¡Œ"""
        try:
            self.logger.info("ğŸš€ è¶…æ´—ç·´ã•ã‚ŒãŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çŠ¶æ…‹åˆ†æã‚’é–‹å§‹...")
            
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            data = self.load_market_data()
            
            # è¶…æ´—ç·´ã•ã‚ŒãŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çŠ¶æ…‹è¨ˆç®—
            self.logger.info("ğŸ§  æœ€å…ˆç«¯DSPæŠ€è¡“ã«ã‚ˆã‚‹åˆ†æã‚’å®Ÿè¡Œä¸­...")
            self.logger.info("   âš¡ STRãƒ™ãƒ¼ã‚¹è¶…ä½é…å»¶æ¸¬å®š")
            self.logger.info("   ğŸŒŠ ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ã«ã‚ˆã‚‹åŒ…çµ¡ç·šãƒ»ä½ç›¸è§£æ")
            self.logger.info("   ğŸ“Š ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå¤‰æ›ã«ã‚ˆã‚‹å¤šè§£åƒåº¦è§£æ")
            self.logger.info("   ğŸ” ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã«ã‚ˆã‚‹è¤‡é›‘æ€§æ¸¬å®š")
            self.logger.info("   ğŸ“ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã«ã‚ˆã‚‹è‡ªå·±ç›¸ä¼¼æ€§åˆ†æ")
            self.logger.info("   ğŸ¯ é©å¿œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ã«ã‚ˆã‚‹ãƒã‚¤ã‚ºé™¤å»")
            self.logger.info("   ğŸ›ï¸ é©å¿œçš„é–¾å€¤ã«ã‚ˆã‚‹å‹•çš„å¸‚å ´èª¿æ•´")
            self.logger.info("   âœ¨ ä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ ")
            
            result = self.vol_indicator.calculate(data)
            
            # è©³ç´°çµ±è¨ˆã®è¨ˆç®—
            stats = self._calculate_ultra_refined_stats(result)
            
            # çµæœã®è¡¨ç¤º
            self._display_results(stats, result)
            
            # ãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆ
            if show_chart:
                self._create_ultra_refined_chart(data, result, stats)
            
            return {'data': data, 'result': result, 'stats': stats}
            
        except Exception as e:
            self.logger.error(f"è¶…æ´—ç·´ã•ã‚ŒãŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æã®å®Ÿè¡Œã«å¤±æ•—: {e}")
            raise
    
    def _calculate_ultra_refined_stats(self, result) -> dict:
        """è¶…æ´—ç·´ã•ã‚ŒãŸçµ±è¨ˆåˆ†æ"""
        # åŸºæœ¬çµ±è¨ˆ
        total_periods = len(result.state)
        high_vol_count = np.sum(result.state)
        low_vol_count = total_periods - high_vol_count
        
        # æœŸé–“åˆ¥çµ±è¨ˆ
        transitions = 0
        for i in range(1, len(result.state)):
            if result.state[i] != result.state[i-1]:
                transitions += 1
        
        # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æœŸé–“ã®é€£ç¶šæ€§
        high_vol_streaks = []
        current_streak = 0
        for state in result.state:
            if state == 1:
                current_streak += 1
            else:
                if current_streak > 0:
                    high_vol_streaks.append(current_streak)
                current_streak = 0
        if current_streak > 0:
            high_vol_streaks.append(current_streak)
        
        # ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æœŸé–“ã®é€£ç¶šæ€§
        low_vol_streaks = []
        current_streak = 0
        for state in result.state:
            if state == 0:
                current_streak += 1
            else:
                if current_streak > 0:
                    low_vol_streaks.append(current_streak)
                current_streak = 0
        if current_streak > 0:
            low_vol_streaks.append(current_streak)
        
        # ç¢ºç‡ã¨ä¿¡é ¼åº¦çµ±è¨ˆ
        valid_prob = result.probability[result.probability > 0]
        valid_conf = result.confidence[result.confidence > 0]
        
        # DSPç‰¹å¾´é‡çµ±è¨ˆ
        valid_hilbert = result.hilbert_envelope[result.hilbert_envelope > 0]
        valid_wavelet = result.wavelet_energy[result.wavelet_energy > 0]
        valid_entropy = result.spectral_entropy[result.spectral_entropy > 0]
        valid_fractal = result.fractal_dimension[result.fractal_dimension > 0]
        valid_freq = result.instantaneous_frequency[result.instantaneous_frequency > 0]
        
        # ä¿¡é ¼åº¦çµ±è¨ˆ
        high_confidence_count = np.sum(result.confidence > 0.8)
        medium_confidence_count = np.sum((result.confidence > 0.6) & (result.confidence <= 0.8))
        low_confidence_count = np.sum(result.confidence <= 0.6)
        
        # é©å¿œçš„é–¾å€¤çµ±è¨ˆ
        valid_threshold = result.adaptive_threshold[result.adaptive_threshold > 0]
        
        # å“è³ªæŒ‡æ¨™ã®å–å¾—
        quality_metrics = self.vol_indicator.get_signal_quality_metrics()
        current_confidence = self.vol_indicator.get_current_confidence()
        
        return {
            'total_periods': total_periods,
            'high_volatility_count': high_vol_count,
            'low_volatility_count': low_vol_count,
            'high_volatility_percentage': (high_vol_count / total_periods * 100),
            'low_volatility_percentage': (low_vol_count / total_periods * 100),
            'transitions': transitions,
            'transition_frequency': (transitions / total_periods * 100),
            'avg_high_vol_streak': np.mean(high_vol_streaks) if high_vol_streaks else 0,
            'max_high_vol_streak': np.max(high_vol_streaks) if high_vol_streaks else 0,
            'avg_low_vol_streak': np.mean(low_vol_streaks) if low_vol_streaks else 0,
            'max_low_vol_streak': np.max(low_vol_streaks) if low_vol_streaks else 0,
            'average_probability': np.mean(valid_prob) if len(valid_prob) > 0 else 0,
            'average_confidence': np.mean(valid_conf) if len(valid_conf) > 0 else 0,
            'latest_state': 'High' if result.state[-1] == 1 else 'Low',
            'latest_probability': result.probability[-1],
            'latest_confidence': result.confidence[-1],
            'current_confidence': current_confidence,
            'quality_metrics': quality_metrics,
            
            # DSPç‰¹å¾´é‡çµ±è¨ˆ
            'hilbert_envelope_avg': np.mean(valid_hilbert) if len(valid_hilbert) > 0 else 0,
            'hilbert_envelope_std': np.std(valid_hilbert) if len(valid_hilbert) > 0 else 0,
            'wavelet_energy_avg': np.mean(valid_wavelet) if len(valid_wavelet) > 0 else 0,
            'wavelet_energy_std': np.std(valid_wavelet) if len(valid_wavelet) > 0 else 0,
            'spectral_entropy_avg': np.mean(valid_entropy) if len(valid_entropy) > 0 else 0,
            'spectral_entropy_std': np.std(valid_entropy) if len(valid_entropy) > 0 else 0,
            'fractal_dimension_avg': np.mean(valid_fractal) if len(valid_fractal) > 0 else 0,
            'fractal_dimension_std': np.std(valid_fractal) if len(valid_fractal) > 0 else 0,
            'instantaneous_freq_avg': np.mean(valid_freq) if len(valid_freq) > 0 else 0,
            'instantaneous_freq_std': np.std(valid_freq) if len(valid_freq) > 0 else 0,
            'adaptive_threshold_avg': np.mean(valid_threshold) if len(valid_threshold) > 0 else 0,
            'adaptive_threshold_std': np.std(valid_threshold) if len(valid_threshold) > 0 else 0,
            
            # ä¿¡é ¼åº¦åˆ†å¸ƒ
            'high_confidence_percentage': (high_confidence_count / total_periods * 100),
            'medium_confidence_percentage': (medium_confidence_count / total_periods * 100),
            'low_confidence_percentage': (low_confidence_count / total_periods * 100),
            
            # æœ€æ–°å€¤
            'latest_str': result.str_values[-1],
            'latest_hilbert_envelope': result.hilbert_envelope[-1],
            'latest_hilbert_phase': result.hilbert_phase[-1],
            'latest_instantaneous_freq': result.instantaneous_frequency[-1],
            'latest_wavelet_energy': result.wavelet_energy[-1],
            'latest_spectral_entropy': result.spectral_entropy[-1],
            'latest_fractal_dimension': result.fractal_dimension[-1],
            'latest_adaptive_threshold': result.adaptive_threshold[-1],
            'latest_adaptive_gain': result.adaptive_gain[-1],
            'latest_raw_score': result.raw_score[-1]
        }
    
    def _display_results(self, stats: dict, result) -> None:
        """çµæœã®è©³ç´°è¡¨ç¤º"""
        self.logger.info("\n" + "="*100)
        self.logger.info("ğŸš€ è¶…æ´—ç·´ã•ã‚ŒãŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çŠ¶æ…‹åˆ†æçµæœ")
        self.logger.info("="*100)
        
        self.logger.info(f"ğŸ“ˆ åŸºæœ¬çµ±è¨ˆ:")
        self.logger.info(f"   ç·æœŸé–“æ•°: {stats['total_periods']:,}")
        self.logger.info(f"   é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {stats['high_volatility_count']:,} ({stats['high_volatility_percentage']:.1f}%)")
        self.logger.info(f"   ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {stats['low_volatility_count']:,} ({stats['low_volatility_percentage']:.1f}%)")
        
        self.logger.info(f"\nğŸ”„ çŠ¶æ…‹å¤‰åŒ–åˆ†æ:")
        self.logger.info(f"   çŠ¶æ…‹å¤‰åŒ–å›æ•°: {stats['transitions']:,}")
        self.logger.info(f"   å¤‰åŒ–é »åº¦: {stats['transition_frequency']:.2f}%")
        
        self.logger.info(f"\nâ±ï¸ æœŸé–“åˆ†æ:")
        self.logger.info(f"   å¹³å‡é«˜ãƒœãƒ©ç¶™ç¶šæœŸé–“: {stats['avg_high_vol_streak']:.1f}")
        self.logger.info(f"   æœ€å¤§é«˜ãƒœãƒ©ç¶™ç¶šæœŸé–“: {stats['max_high_vol_streak']:,}")
        self.logger.info(f"   å¹³å‡ä½ãƒœãƒ©ç¶™ç¶šæœŸé–“: {stats['avg_low_vol_streak']:.1f}")
        self.logger.info(f"   æœ€å¤§ä½ãƒœãƒ©ç¶™ç¶šæœŸé–“: {stats['max_low_vol_streak']:,}")
        
        self.logger.info(f"\nâœ¨ ä¿¡é ¼åº¦åˆ†æ:")
        self.logger.info(f"   å¹³å‡ä¿¡é ¼åº¦: {stats['average_confidence']:.3f}")
        self.logger.info(f"   æœ€æ–°ä¿¡é ¼åº¦: {stats['latest_confidence']:.3f}")
        self.logger.info(f"   é«˜ä¿¡é ¼åº¦(>0.8): {stats['high_confidence_percentage']:.1f}%")
        self.logger.info(f"   ä¸­ä¿¡é ¼åº¦(0.6-0.8): {stats['medium_confidence_percentage']:.1f}%")
        self.logger.info(f"   ä½ä¿¡é ¼åº¦(<=0.6): {stats['low_confidence_percentage']:.1f}%")
        
        self.logger.info(f"\nğŸ§  DSPç‰¹å¾´é‡åˆ†æ:")
        self.logger.info(f"   æœ€æ–°STRå€¤: {stats['latest_str']:.6f}")
        self.logger.info(f"   ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆåŒ…çµ¡ç·š: {stats['latest_hilbert_envelope']:.6f} (å¹³å‡: {stats['hilbert_envelope_avg']:.6f})")
        self.logger.info(f"   ç¬é–“å‘¨æ³¢æ•°: {stats['latest_instantaneous_freq']:.6f} (å¹³å‡: {stats['instantaneous_freq_avg']:.6f})")
        self.logger.info(f"   ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆã‚¨ãƒãƒ«ã‚®ãƒ¼: {stats['latest_wavelet_energy']:.6f} (å¹³å‡: {stats['wavelet_energy_avg']:.6f})")
        self.logger.info(f"   ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {stats['latest_spectral_entropy']:.6f} (å¹³å‡: {stats['spectral_entropy_avg']:.6f})")
        self.logger.info(f"   ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ: {stats['latest_fractal_dimension']:.6f} (å¹³å‡: {stats['fractal_dimension_avg']:.6f})")
        
        self.logger.info(f"\nğŸ›ï¸ é©å¿œã‚·ã‚¹ãƒ†ãƒ :")
        self.logger.info(f"   æœ€æ–°é©å¿œé–¾å€¤: {stats['latest_adaptive_threshold']:.3f}")
        self.logger.info(f"   é©å¿œã‚²ã‚¤ãƒ³: {stats['latest_adaptive_gain']:.3f}")
        self.logger.info(f"   ç”Ÿã‚¹ã‚³ã‚¢: {stats['latest_raw_score']:.3f}")
        
        self.logger.info(f"\nğŸ¯ ç¾åœ¨ã®çŠ¶æ³:")
        self.logger.info(f"   çŠ¶æ…‹: {stats['latest_state']} ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£")
        self.logger.info(f"   ç¢ºç‡: {stats['latest_probability']:.3f}")
        
        if stats['quality_metrics']:
            qm = stats['quality_metrics']
            self.logger.info(f"\nğŸ“Š å“è³ªæŒ‡æ¨™:")
            self.logger.info(f"   å¹³å‡ä¿¡é ¼åº¦: {qm['avg_confidence']:.3f}")
            self.logger.info(f"   ä¿¡é ¼åº¦å®‰å®šæ€§: {qm['confidence_stability']:.3f}")
            self.logger.info(f"   å¹³å‡è¤‡é›‘æ€§: {qm['avg_complexity']:.3f}")
            self.logger.info(f"   å¹³å‡ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ: {qm['avg_fractal_dimension']:.3f}")
            self.logger.info(f"   é«˜ä¿¡é ¼åº¦æ¯”ç‡: {qm['high_confidence_ratio']:.3f}")
        
        # å®Ÿç”¨æ€§è©•ä¾¡
        if 20 <= stats['high_volatility_percentage'] <= 40:
            self.logger.info("\nâœ… ç†æƒ³çš„ãªãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†å¸ƒ")
        elif 15 <= stats['high_volatility_percentage'] <= 50:
            self.logger.info("\nâœ… å®Ÿç”¨çš„ãªãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†å¸ƒ")
        else:
            self.logger.info("\nâš ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        # ä¿¡é ¼åº¦è©•ä¾¡
        if stats['high_confidence_percentage'] > 60:
            self.logger.info("âœ… å„ªç§€ãªä¿¡é ¼åº¦åˆ†å¸ƒ")
        elif stats['high_confidence_percentage'] > 40:
            self.logger.info("ğŸ“Š è‰¯å¥½ãªä¿¡é ¼åº¦åˆ†å¸ƒ")
        else:
            self.logger.info("âš ï¸ ä¿¡é ¼åº¦å‘ä¸ŠãŒå¿…è¦")
    
    def _create_ultra_refined_chart(self, data, result, stats) -> None:
        """è¶…æ´—ç·´ã•ã‚ŒãŸãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆ"""
        try:
            symbol = self.config.get('binance_data', {}).get('symbol', 'Unknown')
            timeframe = self.config.get('binance_data', {}).get('timeframe', 'Unknown')
            
            fig = plt.figure(figsize=(20, 28))
            gs = fig.add_gridspec(12, 1, height_ratios=[3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], hspace=0.4)
            
            # 1. ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆ with ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çŠ¶æ…‹
            ax1 = fig.add_subplot(gs[0])
            ax1.plot(data.index, data['close'], linewidth=1, color='black', label='Price')
            
            # ä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹ã®èƒŒæ™¯è‰²
            for i in range(len(data)):
                confidence = result.confidence[i]
                alpha = 0.1 + 0.4 * confidence
                if result.state[i] == 1:
                    color = 'red' if confidence > 0.7 else 'orange'
                else:
                    color = 'blue' if confidence > 0.7 else 'lightblue'
                ax1.axvspan(data.index[i], data.index[min(i+1, len(data)-1)], 
                           alpha=alpha, color=color)
            
            title = f'Ultra-Refined DSP Volatility Analysis - {symbol} ({timeframe})\n'
            title += f'High Vol: {stats["high_volatility_percentage"]:.1f}% | High Confidence: {stats["high_confidence_percentage"]:.1f}%'
            ax1.set_title(title, fontsize=14, fontweight='bold')
            ax1.set_ylabel('Price')
            ax1.grid(True, alpha=0.3)
            ax1.legend()
            
            # 2. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çŠ¶æ…‹ãƒãƒ¼
            ax2 = fig.add_subplot(gs[1])
            colors = ['red' if s == 1 else 'blue' for s in result.state]
            ax2.bar(data.index, result.state, color=colors, alpha=0.7, width=1)
            ax2.set_title('Ultra-Refined Volatility State (1: High, 0: Low)')
            ax2.set_ylabel('State')
            ax2.set_ylim(-0.1, 1.1)
            ax2.grid(True, alpha=0.3)
            
            # 3. STRå€¤ï¼ˆåŸºæœ¬ç‰¹å¾´é‡ï¼‰
            ax3 = fig.add_subplot(gs[2])
            ax3.plot(data.index, result.str_values, color='green', linewidth=1.2, label='STR Values')
            ax3.set_title('STR - Ultra-Low Latency Base Feature')
            ax3.set_ylabel('STR')
            ax3.grid(True, alpha=0.3)
            ax3.legend()
            
            # 4. ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆåŒ…çµ¡ç·šã¨ç¬é–“å‘¨æ³¢æ•°
            ax4 = fig.add_subplot(gs[3])
            ax4.plot(data.index, result.hilbert_envelope, color='purple', linewidth=1.3, label='Hilbert Envelope')
            ax4_twin = ax4.twinx()
            ax4_twin.plot(data.index, result.instantaneous_frequency, color='orange', linewidth=1, alpha=0.7, label='Instantaneous Frequency')
            ax4.set_title('Hilbert Transform - Envelope & Instantaneous Frequency')
            ax4.set_ylabel('Envelope')
            ax4_twin.set_ylabel('Frequency')
            ax4.grid(True, alpha=0.3)
            
            # å‡¡ä¾‹ã‚’çµ±åˆ
            lines1, labels1 = ax4.get_legend_handles_labels()
            lines2, labels2 = ax4_twin.get_legend_handles_labels()
            ax4.legend(lines1 + lines2, labels1 + labels2, loc='upper left')
            
            # 5. ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆã‚¨ãƒãƒ«ã‚®ãƒ¼
            ax5 = fig.add_subplot(gs[4])
            ax5.plot(data.index, result.wavelet_energy, color='darkred', linewidth=1.3, label='Wavelet Energy')
            ax5.set_title('Discrete Wavelet Transform - Multi-Resolution Energy')
            ax5.set_ylabel('Energy')
            ax5.grid(True, alpha=0.3)
            ax5.legend()
            
            # 6. ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
            ax6 = fig.add_subplot(gs[5])
            ax6.plot(data.index, result.spectral_entropy, color='darkblue', linewidth=1.3, label='Spectral Entropy')
            ax6.set_title('Spectral Entropy - Signal Complexity')
            ax6.set_ylabel('Entropy')
            ax6.set_ylim(0, 1)
            ax6.grid(True, alpha=0.3)
            ax6.legend()
            
            # 7. ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ
            ax7 = fig.add_subplot(gs[6])
            ax7.plot(data.index, result.fractal_dimension, color='brown', linewidth=1.3, label='Fractal Dimension')
            ax7.axhline(y=1.5, color='gray', linestyle='--', alpha=0.5, label='Mid-level')
            ax7.set_title('Fractal Dimension - Self-Similarity Analysis')
            ax7.set_ylabel('Dimension')
            ax7.set_ylim(1.0, 2.0)
            ax7.grid(True, alpha=0.3)
            ax7.legend()
            
            # 8. é©å¿œçš„é–¾å€¤ã¨ã‚«ãƒ«ãƒãƒ³ã‚²ã‚¤ãƒ³
            ax8 = fig.add_subplot(gs[7])
            ax8.plot(data.index, result.adaptive_threshold, color='magenta', linewidth=1.3, label='Adaptive Threshold')
            ax8_twin = ax8.twinx()
            ax8_twin.plot(data.index, result.adaptive_gain, color='cyan', linewidth=1, alpha=0.7, label='Kalman Gain')
            ax8.set_title('Adaptive Threshold & Kalman Gain')
            ax8.set_ylabel('Threshold')
            ax8_twin.set_ylabel('Gain')
            ax8.grid(True, alpha=0.3)
            
            # å‡¡ä¾‹ã‚’çµ±åˆ
            lines1, labels1 = ax8.get_legend_handles_labels()
            lines2, labels2 = ax8_twin.get_legend_handles_labels()
            ax8.legend(lines1 + lines2, labels1 + labels2, loc='upper left')
            
            # 9. ä¿¡é ¼åº¦ã¨ç¢ºç‡
            ax9 = fig.add_subplot(gs[8])
            ax9.plot(data.index, result.confidence, color='darkgreen', linewidth=1.3, label='Confidence')
            ax9_twin = ax9.twinx()
            ax9_twin.plot(data.index, result.probability, color='red', linewidth=1.2, alpha=0.8, label='Probability')
            ax9.axhline(y=0.7, color='green', linestyle='--', alpha=0.5, label='High Confidence')
            ax9_twin.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)
            ax9.set_title('Confidence & Probability')
            ax9.set_ylabel('Confidence')
            ax9_twin.set_ylabel('Probability')
            ax9.set_ylim(0, 1)
            ax9_twin.set_ylim(0, 1)
            ax9.grid(True, alpha=0.3)
            
            # å‡¡ä¾‹ã‚’çµ±åˆ
            lines1, labels1 = ax9.get_legend_handles_labels()
            lines2, labels2 = ax9_twin.get_legend_handles_labels()
            ax9.legend(lines1 + lines2, labels1 + labels2, loc='upper left')
            
            # 10. ç”Ÿã‚¹ã‚³ã‚¢
            ax10 = fig.add_subplot(gs[9])
            ax10.plot(data.index, result.raw_score, color='darkred', linewidth=1.5, label='Raw Score')
            ax10.axhline(y=0.5, color='black', linestyle='-', alpha=0.5, label='Neutral')
            ax10.fill_between(data.index, 0, 1, where=(result.raw_score > result.adaptive_threshold), 
                             color='red', alpha=0.1, label='Above Threshold')
            ax10.fill_between(data.index, 0, 1, where=(result.raw_score <= result.adaptive_threshold), 
                             color='blue', alpha=0.1, label='Below Threshold')
            ax10.set_title('Raw Volatility Score vs Adaptive Threshold')
            ax10.set_ylabel('Score')
            ax10.set_ylim(0, 1)
            ax10.grid(True, alpha=0.3)
            ax10.legend()
            
            # 11. DSPç‰¹å¾´é‡ã®çµ±åˆè¡¨ç¤º
            ax11 = fig.add_subplot(gs[10])
            # æ­£è¦åŒ–ã—ã¦è¡¨ç¤º
            norm_envelope = result.hilbert_envelope / np.max(result.hilbert_envelope) if np.max(result.hilbert_envelope) > 0 else result.hilbert_envelope
            norm_wavelet = result.wavelet_energy / np.max(result.wavelet_energy) if np.max(result.wavelet_energy) > 0 else result.wavelet_energy
            norm_freq = result.instantaneous_frequency / np.max(result.instantaneous_frequency) if np.max(result.instantaneous_frequency) > 0 else result.instantaneous_frequency
            
            ax11.plot(data.index, norm_envelope, color='purple', alpha=0.7, linewidth=1, label='Hilbert Envelope (norm)')
            ax11.plot(data.index, norm_wavelet, color='red', alpha=0.7, linewidth=1, label='Wavelet Energy (norm)')
            ax11.plot(data.index, norm_freq, color='orange', alpha=0.7, linewidth=1, label='Inst. Frequency (norm)')
            ax11.plot(data.index, result.spectral_entropy, color='blue', alpha=0.7, linewidth=1, label='Spectral Entropy')
            ax11.set_title('DSP Features Normalized Comparison')
            ax11.set_ylabel('Normalized Value')
            ax11.set_ylim(0, 1)
            ax11.grid(True, alpha=0.3)
            ax11.legend()
            
            # 12. çµ±è¨ˆã‚µãƒãƒªãƒ¼
            ax12 = fig.add_subplot(gs[11])
            ax12.axis('off')
            
            summary_text = f"""
è¶…æ´—ç·´ã•ã‚ŒãŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æã‚µãƒãƒªãƒ¼ - æœ€å…ˆç«¯DSPæŠ€è¡“
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†å¸ƒ: é«˜ãƒœãƒ© {stats['high_volatility_percentage']:.1f}% | ä½ãƒœãƒ© {stats['low_volatility_percentage']:.1f}%

âœ¨ ä¿¡é ¼åº¦åˆ†æ: é«˜ä¿¡é ¼åº¦ {stats['high_confidence_percentage']:.1f}% | å¹³å‡ä¿¡é ¼åº¦ {stats['average_confidence']:.3f}

ğŸ§  DSPç‰¹å¾´é‡: ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆåŒ…çµ¡ç·š {stats['latest_hilbert_envelope']:.6f} | ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆ {stats['latest_wavelet_energy']:.6f} | ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ {stats['latest_spectral_entropy']:.3f}

ğŸ“ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ: {stats['latest_fractal_dimension']:.3f} | ç¬é–“å‘¨æ³¢æ•°: {stats['latest_instantaneous_freq']:.6f}

ğŸ›ï¸ é©å¿œã‚·ã‚¹ãƒ†ãƒ : é–¾å€¤ {stats['latest_adaptive_threshold']:.3f} | ã‚²ã‚¤ãƒ³ {stats['latest_adaptive_gain']:.3f}

ğŸ¯ ç¾åœ¨çŠ¶æ…‹: {stats['latest_state']} Vol (ç¢ºç‡: {stats['latest_probability']:.3f}, ä¿¡é ¼åº¦: {stats['latest_confidence']:.3f})

ğŸ“Š å“è³ªæŒ‡æ¨™: å¹³å‡ä¿¡é ¼åº¦ {stats['quality_metrics']['avg_confidence']:.3f} | å®‰å®šæ€§ {stats['quality_metrics']['confidence_stability']:.3f} | è¤‡é›‘æ€§ {stats['quality_metrics']['avg_complexity']:.3f}
            """
            
            ax12.text(0.05, 0.95, summary_text, transform=ax12.transAxes, 
                    fontsize=9, verticalalignment='top', fontfamily='monospace',
                    bbox=dict(boxstyle='round', facecolor='lightcyan', alpha=0.8))
            
            # ä¿å­˜
            filename = f"ultra_refined_volatility_state_{symbol}_{timeframe}.png"
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            self.logger.info(f"è¶…æ´—ç·´ã•ã‚ŒãŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒãƒ£ãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
            plt.show()
            
        except Exception as e:
            self.logger.error(f"ãƒãƒ£ãƒ¼ãƒˆä½œæˆã«å¤±æ•—: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description='è¶…æ´—ç·´ã•ã‚ŒãŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çŠ¶æ…‹åˆ†æã‚·ã‚¹ãƒ†ãƒ ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ğŸš€ è¶…æ´—ç·´ã•ã‚ŒãŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æã®ç‰¹å¾´:
  ğŸ§  æœ€å…ˆç«¯ãƒ‡ã‚¸ã‚¿ãƒ«ä¿¡å·å‡¦ç†æŠ€è¡“
  âš¡ STRãƒ™ãƒ¼ã‚¹è¶…ä½é…å»¶æ¸¬å®š
  ğŸŒŠ ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ã«ã‚ˆã‚‹åŒ…çµ¡ç·šãƒ»ä½ç›¸è§£æ
  ğŸ“Š ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå¤‰æ›ã«ã‚ˆã‚‹å¤šè§£åƒåº¦è§£æ
  ğŸ” ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã«ã‚ˆã‚‹è¤‡é›‘æ€§æ¸¬å®š
  ğŸ“ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã«ã‚ˆã‚‹è‡ªå·±ç›¸ä¼¼æ€§åˆ†æ
  ğŸ¯ é©å¿œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ã«ã‚ˆã‚‹ãƒã‚¤ã‚ºé™¤å»
  ğŸ›ï¸ é©å¿œçš„é–¾å€¤ã«ã‚ˆã‚‹å‹•çš„å¸‚å ´èª¿æ•´
  âœ¨ ä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ 

ğŸ”¬ DSPæŠ€è¡“ã®å¿œç”¨:
  - ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›: ä¿¡å·ã®åŒ…çµ¡ç·šã¨ç¬é–“ä½ç›¸ã‚’æŠ½å‡º
  - ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå¤‰æ›: æ™‚é–“-å‘¨æ³¢æ•°é ˜åŸŸã§ã®å¤šè§£åƒåº¦è§£æ
  - ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: ä¿¡å·ã®è¤‡é›‘æ€§ãƒ»ä¸è¦å‰‡æ€§ã‚’å®šé‡åŒ–
  - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ: æ™‚ç³»åˆ—ã®è‡ªå·±ç›¸ä¼¼æ€§ãƒ»è¤‡é›‘æ€§ã‚’æ¸¬å®š
  - é©å¿œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿: å‹•çš„ãƒã‚¤ã‚ºé™¤å»ã¨å¹³æ»‘åŒ–
  - é©å¿œçš„é–¾å€¤: å¸‚å ´çŠ¶æ³ã«å¿œã˜ãŸå‹•çš„åˆ¤å®šåŸºæº–
        """
    )
    
    parser.add_argument('--config', '-c', type=str, default='config.yaml', help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--no-show', action='store_true', help='ãƒãƒ£ãƒ¼ãƒˆéè¡¨ç¤º')
    parser.add_argument('--sensitive', action='store_true', help='é«˜æ„Ÿåº¦ãƒ¢ãƒ¼ãƒ‰ï¼ˆsensitivity=3.0ï¼‰')
    parser.add_argument('--conservative', action='store_true', help='ä¿å®ˆçš„ãƒ¢ãƒ¼ãƒ‰ï¼ˆconfidence=0.8ï¼‰')
    parser.add_argument('--high-precision', action='store_true', help='é«˜ç²¾åº¦ãƒ¢ãƒ¼ãƒ‰ï¼ˆå…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼‰')
    parser.add_argument('--debug', action='store_true', help='ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰')
    
    args = parser.parse_args()
    
    try:
        print("ğŸš€ è¶…æ´—ç·´ã•ã‚ŒãŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çŠ¶æ…‹åˆ†æã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ä¸­...")
        print("ğŸ§  æœ€å…ˆç«¯ãƒ‡ã‚¸ã‚¿ãƒ«ä¿¡å·å‡¦ç†æŠ€è¡“ã‚’åˆæœŸåŒ–ä¸­...")
        
        analyzer = UltraRefinedVolatilityAnalyzer(args.config)
        
        # ãƒ¢ãƒ¼ãƒ‰è¨­å®š
        if args.sensitive:
            analyzer.vol_indicator.sensitivity = 3.0
            analyzer.vol_indicator.confidence_threshold = 0.6
            print("âš¡ é«˜æ„Ÿåº¦ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–ï¼ˆsensitivity: 3.0, confidence: 0.6ï¼‰")
        
        if args.conservative:
            analyzer.vol_indicator.sensitivity = 1.5
            analyzer.vol_indicator.confidence_threshold = 0.8
            print("ğŸ›¡ï¸ ä¿å®ˆçš„ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–ï¼ˆsensitivity: 1.5, confidence: 0.8ï¼‰")
        
        if args.high_precision:
            analyzer.vol_indicator.str_period = 10
            analyzer.vol_indicator.entropy_window = 20
            analyzer.vol_indicator.fractal_k = 12
            analyzer.vol_indicator.sensitivity = 2.5
            analyzer.vol_indicator.confidence_threshold = 0.75
            print("ğŸ¯ é«˜ç²¾åº¦ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–ï¼ˆå…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼‰")
        
        # åˆ†æå®Ÿè¡Œ
        results = analyzer.run_ultra_refined_analysis(show_chart=not args.no_show)
        
        print("\nâœ… è¶…æ´—ç·´ã•ã‚ŒãŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
        # çµæœè©•ä¾¡
        high_vol_pct = results['stats']['high_volatility_percentage']
        high_conf_pct = results['stats']['high_confidence_percentage']
        
        if 25 <= high_vol_pct <= 35:
            print("ğŸ¯ ç†æƒ³çš„ãªãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†å¸ƒ")
        elif 20 <= high_vol_pct <= 40:
            print("âœ… å„ªç§€ãªãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†å¸ƒ")
        elif 15 <= high_vol_pct <= 50:
            print("ğŸ“Š å®Ÿç”¨çš„ãªãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†å¸ƒ")
        else:
            print("âš ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        if high_conf_pct > 60:
            print("âœ… å„ªç§€ãªä¿¡é ¼åº¦åˆ†å¸ƒ")
        elif high_conf_pct > 40:
            print("ğŸ“Š è‰¯å¥½ãªä¿¡é ¼åº¦åˆ†å¸ƒ")
        else:
            print("âš ï¸ ä¿¡é ¼åº¦å‘ä¸ŠãŒå¿…è¦")
        
        # DSPç‰¹å¾´é‡è©•ä¾¡
        print(f"\nğŸ§  DSPç‰¹å¾´é‡è©•ä¾¡:")
        if results['stats']['quality_metrics']:
            qm = results['stats']['quality_metrics']
            print(f"   å¹³å‡ä¿¡é ¼åº¦: {qm['avg_confidence']:.3f}")
            print(f"   ä¿¡é ¼åº¦å®‰å®šæ€§: {qm['confidence_stability']:.3f}")
            print(f"   ä¿¡å·è¤‡é›‘æ€§: {qm['avg_complexity']:.3f}")
            print(f"   ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ: {qm['avg_fractal_dimension']:.3f}")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ åˆ†æãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        if args.debug:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()