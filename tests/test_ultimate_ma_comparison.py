#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
UltimateMA V1 vs V2 vs V3 Performance Comparison Test
å®Ÿéš›ã®Binanceãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½æ¯”è¼ƒæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from datetime import datetime, timedelta
import os
import sys
import time
import warnings
warnings.filterwarnings('ignore')

# matplotlibã®ãƒ•ã‚©ãƒ³ãƒˆè­¦å‘Šã‚’ç„¡åŠ¹åŒ–
import matplotlib
matplotlib.rcParams['font.family'] = 'DejaVu Sans'
import logging
logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

# UltimateMAã®å„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from indicators.ultimate_ma import UltimateMA  # V1 (original)
from indicators.ultimate_ma_v3 import UltimateMAV3  # V3 (latest)

# V2ã¯å­˜åœ¨ã—ãªã„ãŸã‚ã€V1ã®æ”¹è‰¯ç‰ˆã¨ã—ã¦è¨­å®š
class UltimateMAV2(UltimateMA):
    """UltimateMA V2 (V1ã®æ”¹è‰¯ç‰ˆã¨ã—ã¦å®šç¾©)"""
    def __init__(self, **kwargs):
        # V2ã¯V1ã®æ”¹è‰¯ç‰ˆã¨ã—ã¦ã€ã‚ˆã‚Šä¿å®ˆçš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        super().__init__(
            super_smooth_period=kwargs.get('super_smooth_period', 12),
            zero_lag_period=kwargs.get('zero_lag_period', 24),
            realtime_window=kwargs.get('realtime_window', 55),
            src_type=kwargs.get('src_type', 'hlc3'),
            slope_index=kwargs.get('slope_index', 2),
            range_threshold=kwargs.get('range_threshold', 0.008)
        )


def load_binance_data(symbol='BTC', market_type='spot', timeframe='4h', data_dir='data/binance'):
    """
    Binanceãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥èª­ã¿è¾¼ã‚€
    """
    file_path = f"{data_dir}/{symbol}/{market_type}/{timeframe}/historical_data.csv"
    
    print(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­: {file_path}")
    
    if not os.path.exists(file_path):
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return None
    
    try:
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        df = pd.read_csv(file_path)
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¨­å®š
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df.set_index('timestamp', inplace=True)
        
        # å¿…è¦ãªã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        required_columns = ['open', 'high', 'low', 'close']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            print(f"âŒ å¿…è¦ãªã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_columns}")
            return None
        
        # ãƒ‡ãƒ¼ã‚¿å‹ã‚’æ•°å€¤ã«å¤‰æ›
        for col in required_columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # NaNã‚’é™¤å»
        df = df.dropna()
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {symbol} {market_type} {timeframe}")
        print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿æœŸé–“: {df.index.min()} - {df.index.max()}")
        print(f"ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}ä»¶")
        
        return df
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def calculate_performance_metrics(data: pd.DataFrame, ma_values: np.ndarray, trend_signals: np.ndarray, version_name: str) -> dict:
    """
    å„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®æ€§èƒ½æŒ‡æ¨™ã‚’è¨ˆç®—
    
    Args:
        data: å…ƒã®OHLCãƒ‡ãƒ¼ã‚¿
        ma_values: ç§»å‹•å¹³å‡å€¤
        trend_signals: ãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡å·
        version_name: ãƒãƒ¼ã‚¸ãƒ§ãƒ³å
    
    Returns:
        dict: æ€§èƒ½æŒ‡æ¨™
    """
    close_prices = data['close'].values
    
    # 1. ãƒã‚¤ã‚ºé™¤å»åŠ¹æœ
    raw_volatility = np.nanstd(close_prices)
    filtered_volatility = np.nanstd(ma_values)
    noise_reduction = (raw_volatility - filtered_volatility) / raw_volatility if raw_volatility > 0 else 0
    
    # 2. ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºç²¾åº¦
    price_changes = np.diff(close_prices)
    ma_changes = np.diff(ma_values)
    
    # æ–¹å‘ä¸€è‡´åº¦ï¼ˆä¾¡æ ¼å¤‰åŒ–ã¨MAå¤‰åŒ–ã®æ–¹å‘ãŒä¸€è‡´ã™ã‚‹å‰²åˆï¼‰
    direction_accuracy = np.mean(np.sign(price_changes) == np.sign(ma_changes)) if len(price_changes) > 0 else 0
    
    # 3. é…å»¶åˆ†æ
    # ä¾¡æ ¼ã®è»¢æ›ç‚¹ã¨MAã®è»¢æ›ç‚¹ã®é…å»¶ã‚’è¨ˆç®—
    price_turning_points = []
    ma_turning_points = []
    
    for i in range(2, len(close_prices) - 2):
        # ä¾¡æ ¼ã®è»¢æ›ç‚¹æ¤œå‡º
        if ((close_prices[i-1] < close_prices[i] > close_prices[i+1]) or 
            (close_prices[i-1] > close_prices[i] < close_prices[i+1])):
            price_turning_points.append(i)
    
    for i in range(2, len(ma_values) - 2):
        # MAã®è»¢æ›ç‚¹æ¤œå‡º
        if ((ma_values[i-1] < ma_values[i] > ma_values[i+1]) or 
            (ma_values[i-1] > ma_values[i] < ma_values[i+1])):
            ma_turning_points.append(i)
    
    # å¹³å‡é…å»¶è¨ˆç®—
    if price_turning_points and ma_turning_points:
        delays = []
        for pt in price_turning_points:
            closest_ma_tp = min(ma_turning_points, key=lambda x: abs(x - pt))
            if closest_ma_tp > pt:  # MAãŒä¾¡æ ¼ã‚ˆã‚Šå¾Œã®å ´åˆã®ã¿
                delays.append(closest_ma_tp - pt)
        avg_delay = np.mean(delays) if delays else 0
    else:
        avg_delay = 0
    
    # 4. ãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡å·çµ±è¨ˆ
    if trend_signals is not None and len(trend_signals) > 0:
        up_signals = np.sum(trend_signals == 1)
        down_signals = np.sum(trend_signals == -1)
        range_signals = np.sum(trend_signals == 0)
        total_signals = len(trend_signals)
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰ç¶™ç¶šæ€§ï¼ˆåŒã˜ä¿¡å·ãŒé€£ç¶šã™ã‚‹å¹³å‡é•·ï¼‰
        signal_changes = np.diff(trend_signals)
        trend_continuity = len(trend_signals) / (np.sum(signal_changes != 0) + 1) if len(signal_changes) > 0 else 1
    else:
        up_signals = down_signals = range_signals = total_signals = 0
        trend_continuity = 0
    
    # 5. ä¾¡æ ¼è¿½å¾“æ€§
    # MAã¨ä¾¡æ ¼ã®ç›¸é–¢ä¿‚æ•°
    correlation = np.corrcoef(close_prices, ma_values)[0, 1] if len(close_prices) == len(ma_values) else 0
    
    # 6. å®‰å®šæ€§æŒ‡æ¨™
    # MAã®å¤‰å‹•ä¿‚æ•°ï¼ˆæ¨™æº–åå·®/å¹³å‡ï¼‰
    ma_stability = np.nanstd(ma_values) / np.nanmean(np.abs(ma_values)) if np.nanmean(np.abs(ma_values)) > 0 else 0
    
    return {
        'version': version_name,
        'noise_reduction': {
            'raw_volatility': raw_volatility,
            'filtered_volatility': filtered_volatility,
            'reduction_ratio': noise_reduction,
            'reduction_percentage': noise_reduction * 100
        },
        'trend_detection': {
            'direction_accuracy': direction_accuracy,
            'avg_delay': avg_delay,
            'trend_continuity': trend_continuity
        },
        'signal_distribution': {
            'up_signals': up_signals,
            'down_signals': down_signals,
            'range_signals': range_signals,
            'total_signals': total_signals,
            'up_ratio': up_signals / total_signals if total_signals > 0 else 0,
            'down_ratio': down_signals / total_signals if total_signals > 0 else 0,
            'range_ratio': range_signals / total_signals if total_signals > 0 else 0
        },
        'quality_metrics': {
            'correlation': correlation,
            'stability': ma_stability,
            'turning_points_price': len(price_turning_points),
            'turning_points_ma': len(ma_turning_points)
        }
    }


def run_version_comparison(data: pd.DataFrame, symbol: str) -> dict:
    """
    å„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã®è¨ˆç®—ã‚’å®Ÿè¡Œã—ã€çµæœã‚’æ¯”è¼ƒ
    
    Args:
        data: OHLCãƒ‡ãƒ¼ã‚¿
        symbol: ã‚·ãƒ³ãƒœãƒ«å
    
    Returns:
        dict: å„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®çµæœ
    """
    results = {}
    
    print(f"\nğŸ”¬ {symbol} - UltimateMA ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ¯”è¼ƒãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("="*60)
    
    # V1ãƒ†ã‚¹ãƒˆ
    print("\nğŸ“Š UltimateMA V1 ãƒ†ã‚¹ãƒˆä¸­...")
    try:
        start_time = time.time()
        uma_v1 = UltimateMA(
            super_smooth_period=10,
            zero_lag_period=21,
            realtime_window=89,
            src_type='hlc3',
            slope_index=1,
            range_threshold=0.005
        )
        v1_result = uma_v1.calculate(data)
        v1_calc_time = time.time() - start_time
        
        v1_performance = calculate_performance_metrics(
            data, 
            v1_result.values, 
            v1_result.trend_signals, 
            'V1'
        )
        v1_performance['calc_time'] = v1_calc_time
        v1_performance['current_trend'] = v1_result.current_trend
        v1_performance['result'] = v1_result
        
        results['V1'] = v1_performance
        print(f"âœ… V1 å®Œäº† (æ™‚é–“: {v1_calc_time:.3f}ç§’)")
        
    except Exception as e:
        print(f"âŒ V1 ã‚¨ãƒ©ãƒ¼: {e}")
        results['V1'] = None
    
    # V2ãƒ†ã‚¹ãƒˆ
    print("\nğŸ“Š UltimateMA V2 ãƒ†ã‚¹ãƒˆä¸­...")
    try:
        start_time = time.time()
        uma_v2 = UltimateMAV2(
            super_smooth_period=12,
            zero_lag_period=24,
            realtime_window=55,
            src_type='hlc3',
            slope_index=2,
            range_threshold=0.008
        )
        v2_result = uma_v2.calculate(data)
        v2_calc_time = time.time() - start_time
        
        v2_performance = calculate_performance_metrics(
            data, 
            v2_result.values, 
            v2_result.trend_signals, 
            'V2'
        )
        v2_performance['calc_time'] = v2_calc_time
        v2_performance['current_trend'] = v2_result.current_trend
        v2_performance['result'] = v2_result
        
        results['V2'] = v2_performance
        print(f"âœ… V2 å®Œäº† (æ™‚é–“: {v2_calc_time:.3f}ç§’)")
        
    except Exception as e:
        print(f"âŒ V2 ã‚¨ãƒ©ãƒ¼: {e}")
        results['V2'] = None
    
    # V3ãƒ†ã‚¹ãƒˆ
    print("\nğŸ“Š UltimateMA V3 ãƒ†ã‚¹ãƒˆä¸­...")
    try:
        start_time = time.time()
        uma_v3 = UltimateMAV3(
            super_smooth_period=8,
            zero_lag_period=16,
            realtime_window=34,
            quantum_window=16,
            fractal_window=16,
            entropy_window=16,
            src_type='hlc3',
            slope_index=2,
            base_threshold=0.002,
            min_confidence=0.15
        )
        v3_result = uma_v3.calculate(data)
        v3_calc_time = time.time() - start_time
        
        # V3ã¯ç‰¹åˆ¥ãªæ€§èƒ½æŒ‡æ¨™ã‚‚å«ã‚€
        v3_performance = calculate_performance_metrics(
            data, 
            v3_result.values, 
            v3_result.trend_signals, 
            'V3'
        )
        v3_performance['calc_time'] = v3_calc_time
        v3_performance['current_trend'] = v3_result.current_trend
        v3_performance['result'] = v3_result
        
        # V3ç‰¹æœ‰ã®æŒ‡æ¨™
        if hasattr(v3_result, 'trend_confidence'):
            v3_performance['v3_specific'] = {
                'avg_confidence': np.nanmean(v3_result.trend_confidence),
                'max_confidence': np.nanmax(v3_result.trend_confidence),
                'quantum_strength': np.nanmean(np.abs(v3_result.quantum_state)) if hasattr(v3_result, 'quantum_state') else 0,
                'mtf_consensus': np.nanmean(v3_result.multi_timeframe_consensus) if hasattr(v3_result, 'multi_timeframe_consensus') else 0,
                'fractal_dimension': np.nanmean(v3_result.fractal_dimension) if hasattr(v3_result, 'fractal_dimension') else 0,
                'entropy_level': np.nanmean(v3_result.entropy_level) if hasattr(v3_result, 'entropy_level') else 0
            }
        
        results['V3'] = v3_performance
        print(f"âœ… V3 å®Œäº† (æ™‚é–“: {v3_calc_time:.3f}ç§’)")
        
    except Exception as e:
        print(f"âŒ V3 ã‚¨ãƒ©ãƒ¼: {e}")
        results['V3'] = None
    
    return results


def plot_comparison_results(data: pd.DataFrame, results: dict, symbol: str):
    """
    æ¯”è¼ƒçµæœã‚’å¯è¦–åŒ–
    
    Args:
        data: å…ƒã®OHLCãƒ‡ãƒ¼ã‚¿
        results: å„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®çµæœ
        symbol: ã‚·ãƒ³ãƒœãƒ«å
    """
    print(f"\nğŸ“Š {symbol} æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆä½œæˆä¸­...")
    
    # æœ‰åŠ¹ãªçµæœã®ã¿ã‚’å–å¾—
    valid_results = {k: v for k, v in results.items() if v is not None}
    
    if len(valid_results) < 2:
        print("âŒ æ¯”è¼ƒã«ååˆ†ãªçµæœãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # å›³ã®ä½œæˆ
    fig, axes = plt.subplots(4, 2, figsize=(20, 16))
    fig.suptitle(f'ğŸš€ UltimateMA V1 vs V2 vs V3 Performance Comparison - {symbol}', 
                 fontsize=16, fontweight='bold')
    
    x_axis = data.index
    colors = {'V1': 'red', 'V2': 'blue', 'V3': 'green'}
    
    # 1. ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆã¨å„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®MA
    ax1 = axes[0, 0]
    ax1.plot(x_axis, data['close'], color='black', alpha=0.7, linewidth=1.0, label='Close Price')
    
    for version, result_data in valid_results.items():
        if 'result' in result_data:
            ma_values = result_data['result'].values
            ax1.plot(x_axis, ma_values, color=colors[version], linewidth=1.5, 
                    label=f'UltimateMA {version}', alpha=0.8)
    
    ax1.set_title('ğŸ’° Price Chart with UltimateMA Versions', fontweight='bold')
    ax1.set_ylabel('Price (USD)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. ãƒã‚¤ã‚ºé™¤å»åŠ¹æœæ¯”è¼ƒ
    ax2 = axes[0, 1]
    versions = list(valid_results.keys())
    noise_reductions = [valid_results[v]['noise_reduction']['reduction_percentage'] for v in versions]
    
    bars = ax2.bar(versions, noise_reductions, color=[colors[v] for v in versions], alpha=0.7)
    ax2.set_title('ğŸ”‡ Noise Reduction Effectiveness', fontweight='bold')
    ax2.set_ylabel('Noise Reduction (%)')
    ax2.set_ylim(0, max(noise_reductions) * 1.2 if noise_reductions else 1)
    
    # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
    for bar, value in zip(bars, noise_reductions):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                f'{value:.1f}%', ha='center', va='bottom', fontweight='bold')
    
    # 3. æ–¹å‘ç²¾åº¦æ¯”è¼ƒ
    ax3 = axes[1, 0]
    direction_accuracies = [valid_results[v]['trend_detection']['direction_accuracy'] * 100 for v in versions]
    
    bars = ax3.bar(versions, direction_accuracies, color=[colors[v] for v in versions], alpha=0.7)
    ax3.set_title('ğŸ¯ Direction Accuracy', fontweight='bold')
    ax3.set_ylabel('Accuracy (%)')
    ax3.set_ylim(0, 100)
    
    for bar, value in zip(bars, direction_accuracies):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{value:.1f}%', ha='center', va='bottom', fontweight='bold')
    
    # 4. é…å»¶æ¯”è¼ƒ
    ax4 = axes[1, 1]
    delays = [valid_results[v]['trend_detection']['avg_delay'] for v in versions]
    
    bars = ax4.bar(versions, delays, color=[colors[v] for v in versions], alpha=0.7)
    ax4.set_title('â±ï¸ Average Delay (periods)', fontweight='bold')
    ax4.set_ylabel('Delay (periods)')
    
    for bar, value in zip(bars, delays):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                f'{value:.1f}', ha='center', va='bottom', fontweight='bold')
    
    # 5. è¨ˆç®—æ™‚é–“æ¯”è¼ƒ
    ax5 = axes[2, 0]
    calc_times = [valid_results[v]['calc_time'] * 1000 for v in versions]  # ãƒŸãƒªç§’ã«å¤‰æ›
    
    bars = ax5.bar(versions, calc_times, color=[colors[v] for v in versions], alpha=0.7)
    ax5.set_title('âš¡ Calculation Time', fontweight='bold')
    ax5.set_ylabel('Time (ms)')
    
    for bar, value in zip(bars, calc_times):
        height = bar.get_height()
        ax5.text(bar.get_x() + bar.get_width()/2., height + max(calc_times) * 0.02,
                f'{value:.1f}ms', ha='center', va='bottom', fontweight='bold')
    
    # 6. ç›¸é–¢ä¿‚æ•°æ¯”è¼ƒ
    ax6 = axes[2, 1]
    correlations = [valid_results[v]['quality_metrics']['correlation'] * 100 for v in versions]
    
    bars = ax6.bar(versions, correlations, color=[colors[v] for v in versions], alpha=0.7)
    ax6.set_title('ğŸ“ˆ Price Correlation', fontweight='bold')
    ax6.set_ylabel('Correlation (%)')
    ax6.set_ylim(0, 100)
    
    for bar, value in zip(bars, correlations):
        height = bar.get_height()
        ax6.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{value:.1f}%', ha='center', va='bottom', fontweight='bold')
    
    # 7. ãƒˆãƒ¬ãƒ³ãƒ‰ç¶™ç¶šæ€§æ¯”è¼ƒ
    ax7 = axes[3, 0]
    continuities = [valid_results[v]['trend_detection']['trend_continuity'] for v in versions]
    
    bars = ax7.bar(versions, continuities, color=[colors[v] for v in versions], alpha=0.7)
    ax7.set_title('ğŸ“Š Trend Continuity', fontweight='bold')
    ax7.set_ylabel('Average Trend Length')
    
    for bar, value in zip(bars, continuities):
        height = bar.get_height()
        ax7.text(bar.get_x() + bar.get_width()/2., height + max(continuities) * 0.02,
                f'{value:.1f}', ha='center', va='bottom', fontweight='bold')
    
    # 8. ç·åˆã‚¹ã‚³ã‚¢
    ax8 = axes[3, 1]
    
    # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆå„æŒ‡æ¨™ã‚’æ­£è¦åŒ–ã—ã¦åˆè¨ˆï¼‰
    scores = {}
    for version in versions:
        result = valid_results[version]
        
        # å„æŒ‡æ¨™ã‚’0-1ã«æ­£è¦åŒ–ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰
        noise_score = min(result['noise_reduction']['reduction_percentage'] / 30, 1.0)  # 30%ã‚’æœ€å¤§ã¨ã™ã‚‹
        accuracy_score = result['trend_detection']['direction_accuracy']
        delay_score = max(0, 1.0 - result['trend_detection']['avg_delay'] / 10)  # 10æœŸé–“ã‚’æœ€å¤§é…å»¶ã¨ã™ã‚‹
        correlation_score = result['quality_metrics']['correlation']
        speed_score = max(0, 1.0 - result['calc_time'] / 1.0)  # 1ç§’ã‚’æœ€å¤§æ™‚é–“ã¨ã™ã‚‹
        
        # V3ã®ç‰¹åˆ¥ã‚¹ã‚³ã‚¢
        if version == 'V3' and 'v3_specific' in result:
            v3_specific = result['v3_specific']
            confidence_score = v3_specific['avg_confidence']
            quantum_score = min(v3_specific['quantum_strength'] / 0.1, 1.0)
            total_score = (noise_score + accuracy_score + delay_score + correlation_score + 
                          speed_score + confidence_score + quantum_score) / 7
        else:
            total_score = (noise_score + accuracy_score + delay_score + correlation_score + speed_score) / 5
        
        scores[version] = total_score * 100
    
    score_values = list(scores.values())
    bars = ax8.bar(versions, score_values, color=[colors[v] for v in versions], alpha=0.7)
    ax8.set_title('ğŸ† Overall Performance Score', fontweight='bold')
    ax8.set_ylabel('Score (%)')
    ax8.set_ylim(0, 100)
    
    for bar, value in zip(bars, score_values):
        height = bar.get_height()
        ax8.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{value:.1f}%', ha='center', va='bottom', fontweight='bold')
    
    # Xè»¸ã®æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆã®ã¿ï¼‰
    ax1.tick_params(axis='x', rotation=45)
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
    ax1.xaxis.set_major_locator(mdates.MonthLocator(interval=2))
    
    plt.tight_layout()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    filename = f"tests/ultimate_ma_comparison_{symbol.lower()}.png"
    plt.savefig(filename, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"âœ… æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆä¿å­˜å®Œäº†: {filename}")
    
    plt.show()
    plt.close()
    
    return scores


def print_detailed_comparison(results: dict, symbol: str):
    """
    è©³ç´°ãªæ¯”è¼ƒçµæœã‚’è¡¨ç¤º
    
    Args:
        results: å„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®çµæœ
        symbol: ã‚·ãƒ³ãƒœãƒ«å
    """
    print(f"\n{'='*80}")
    print(f"ğŸ† **{symbol} - UltimateMA ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ¯”è¼ƒ è©³ç´°çµæœ**")
    print("="*80)
    
    valid_results = {k: v for k, v in results.items() if v is not None}
    
    if not valid_results:
        print("âŒ æœ‰åŠ¹ãªçµæœãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # å„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®è©³ç´°çµæœ
    for version, result in valid_results.items():
        print(f"\nğŸ“Š **UltimateMA {version}**")
        print("-" * 40)
        
        # åŸºæœ¬æƒ…å ±
        print(f"ç¾åœ¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰: {result['current_trend'].upper()}")
        print(f"è¨ˆç®—æ™‚é–“: {result['calc_time']:.3f}ç§’")
        
        # ãƒã‚¤ã‚ºé™¤å»
        noise = result['noise_reduction']
        print(f"\nğŸ”‡ ãƒã‚¤ã‚ºé™¤å»åŠ¹æœ:")
        print(f"  - å…ƒã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {noise['raw_volatility']:.4f}")
        print(f"  - ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œ: {noise['filtered_volatility']:.4f}")
        print(f"  - é™¤å»ç‡: {noise['reduction_percentage']:.2f}%")
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡º
        trend = result['trend_detection']
        print(f"\nğŸ¯ ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºæ€§èƒ½:")
        print(f"  - æ–¹å‘ç²¾åº¦: {trend['direction_accuracy']*100:.2f}%")
        print(f"  - å¹³å‡é…å»¶: {trend['avg_delay']:.2f}æœŸé–“")
        print(f"  - ãƒˆãƒ¬ãƒ³ãƒ‰ç¶™ç¶šæ€§: {trend['trend_continuity']:.2f}")
        
        # ä¿¡å·åˆ†å¸ƒ
        signals = result['signal_distribution']
        print(f"\nğŸ“ˆ ä¿¡å·åˆ†å¸ƒ:")
        print(f"  - ä¸Šæ˜‡: {signals['up_signals']}å› ({signals['up_ratio']*100:.1f}%)")
        print(f"  - ä¸‹é™: {signals['down_signals']}å› ({signals['down_ratio']*100:.1f}%)")
        print(f"  - ãƒ¬ãƒ³ã‚¸: {signals['range_signals']}å› ({signals['range_ratio']*100:.1f}%)")
        
        # å“è³ªæŒ‡æ¨™
        quality = result['quality_metrics']
        print(f"\nğŸ“Š å“è³ªæŒ‡æ¨™:")
        print(f"  - ä¾¡æ ¼ç›¸é–¢: {quality['correlation']:.4f}")
        print(f"  - å®‰å®šæ€§: {quality['stability']:.4f}")
        print(f"  - è»¢æ›ç‚¹æ¤œå‡º: ä¾¡æ ¼{quality['turning_points_price']}å€‹, MA{quality['turning_points_ma']}å€‹")
        
        # V3ç‰¹æœ‰ã®æŒ‡æ¨™
        if version == 'V3' and 'v3_specific' in result:
            v3_spec = result['v3_specific']
            print(f"\nğŸŒŒ V3ç‰¹æœ‰æŒ‡æ¨™:")
            print(f"  - å¹³å‡ä¿¡é ¼åº¦: {v3_spec['avg_confidence']:.3f}")
            print(f"  - æœ€å¤§ä¿¡é ¼åº¦: {v3_spec['max_confidence']:.3f}")
            print(f"  - é‡å­å¼·åº¦: {v3_spec['quantum_strength']:.3f}")
            print(f"  - MTFåˆæ„åº¦: {v3_spec['mtf_consensus']:.3f}")
            print(f"  - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ: {v3_spec['fractal_dimension']:.3f}")
            print(f"  - ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {v3_spec['entropy_level']:.3f}")
    
    # å‹è€…åˆ¤å®š
    print(f"\nğŸ† **ç·åˆè©•ä¾¡**")
    print("="*40)
    
    # å„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã§ã®å‹è€…
    categories = {
        'ãƒã‚¤ã‚ºé™¤å»': 'noise_reduction.reduction_percentage',
        'æ–¹å‘ç²¾åº¦': 'trend_detection.direction_accuracy',
        'ä½é…å»¶': 'trend_detection.avg_delay',  # ä½ã„ã»ã©è‰¯ã„
        'è¨ˆç®—é€Ÿåº¦': 'calc_time',  # ä½ã„ã»ã©è‰¯ã„
        'ä¾¡æ ¼ç›¸é–¢': 'quality_metrics.correlation'
    }
    
    winners = {}
    for category, metric_path in categories.items():
        best_version = None
        best_value = None
        
        for version, result in valid_results.items():
            # ãƒã‚¹ãƒˆã—ãŸè¾æ›¸ã‹ã‚‰å€¤ã‚’å–å¾—
            value = result
            for key in metric_path.split('.'):
                value = value[key]
            
            if best_value is None:
                best_value = value
                best_version = version
            else:
                # é…å»¶ã¨è¨ˆç®—æ™‚é–“ã¯ä½ã„ã»ã©è‰¯ã„
                if category in ['ä½é…å»¶', 'è¨ˆç®—é€Ÿåº¦']:
                    if value < best_value:
                        best_value = value
                        best_version = version
                else:
                    if value > best_value:
                        best_value = value
                        best_version = version
        
        winners[category] = (best_version, best_value)
        print(f"{category}: {best_version} ({best_value:.3f})")
    
    # ç·åˆå‹è€…
    version_scores = {}
    for version in valid_results.keys():
        score = 0
        for category, (winner, _) in winners.items():
            if winner == version:
                score += 1
        version_scores[version] = score
    
    overall_winner = max(version_scores, key=version_scores.get)
    print(f"\nğŸ¥‡ **ç·åˆå‹è€…: UltimateMA {overall_winner}** (å‹åˆ©ã‚«ãƒ†ã‚´ãƒªãƒ¼: {version_scores[overall_winner]}/{len(categories)})")
    
    # æ¨å¥¨ç”¨é€”
    print(f"\nğŸ’¡ **æ¨å¥¨ç”¨é€”:**")
    for version in valid_results.keys():
        if version == 'V1':
            print(f"  - V1: ã‚·ãƒ³ãƒ—ãƒ«ã§é«˜é€Ÿãªå‡¦ç†ãŒå¿…è¦ãªå ´åˆ")
        elif version == 'V2':
            print(f"  - V2: ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ€§èƒ½ãŒå¿…è¦ãªå ´åˆ")
        elif version == 'V3':
            print(f"  - V3: æœ€é«˜ç²¾åº¦ã®åˆ†æã¨é«˜åº¦ãªæŒ‡æ¨™ãŒå¿…è¦ãªå ´åˆ")


def test_multiple_symbols():
    """è¤‡æ•°ã®ã‚·ãƒ³ãƒœãƒ«ã§æ¯”è¼ƒãƒ†ã‚¹ãƒˆ"""
    symbols = ['BTC', 'ETH', 'ADA']
    all_results = {}
    
    print("ğŸš€ UltimateMA V1 vs V2 vs V3 - è¤‡æ•°ã‚·ãƒ³ãƒœãƒ«æ¯”è¼ƒãƒ†ã‚¹ãƒˆ")
    print("="*80)
    
    for symbol in symbols:
        print(f"\n{'='*60}")
        print(f"ğŸ”¬ {symbol} ãƒ†ã‚¹ãƒˆé–‹å§‹")
        print("="*60)
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        data = load_binance_data(symbol=symbol, market_type='spot', timeframe='4h')
        
        if data is None:
            print(f"âŒ {symbol}ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã«å¤±æ•—")
            continue
        
        # æœ€æ–°1000ä»¶ã‚’ä½¿ç”¨
        if len(data) > 1000:
            data = data.tail(1000)
            print(f"ğŸ“Š æœ€æ–°1000ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨")
        
        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ¯”è¼ƒå®Ÿè¡Œ
        results = run_version_comparison(data, symbol)
        
        # çµæœè¡¨ç¤º
        print_detailed_comparison(results, symbol)
        
        # ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
        scores = plot_comparison_results(data, results, symbol)
        
        all_results[symbol] = {
            'results': results,
            'scores': scores
        }
        
        print(f"âœ… {symbol} ãƒ†ã‚¹ãƒˆå®Œäº†")
    
    # å…¨ä½“ã‚µãƒãƒªãƒ¼
    if all_results:
        print(f"\n{'='*80}")
        print("ğŸ† **å…¨ã‚·ãƒ³ãƒœãƒ«ç·åˆçµæœ**")
        print("="*80)
        
        version_wins = {'V1': 0, 'V2': 0, 'V3': 0}
        
        for symbol, data in all_results.items():
            if 'scores' in data:
                scores = data['scores']
                winner = max(scores, key=scores.get)
                version_wins[winner] += 1
                print(f"{symbol}: {winner} (ã‚¹ã‚³ã‚¢: {scores[winner]:.1f}%)")
        
        print(f"\nğŸ¥‡ **æœ€çµ‚å‹è€…çµ±è¨ˆ:**")
        for version, wins in version_wins.items():
            print(f"  - {version}: {wins}å‹")
        
        overall_champion = max(version_wins, key=version_wins.get)
        print(f"\nğŸ‘‘ **ç·åˆãƒãƒ£ãƒ³ãƒ”ã‚ªãƒ³: UltimateMA {overall_champion}**")


def main():
    print("ğŸš€ UltimateMA V1 vs V2 vs V3 Performance Comparison Test")
    print("å®Ÿéš›ã®Binanceãƒ‡ãƒ¼ã‚¿ã§ã®åŒ…æ‹¬çš„æ€§èƒ½æ¯”è¼ƒæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ")
    print("="*80)
    
    # è¤‡æ•°ã‚·ãƒ³ãƒœãƒ«ã§ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_multiple_symbols()
    
    print(f"\nâœ… UltimateMA ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ¯”è¼ƒãƒ†ã‚¹ãƒˆå®Œäº†")
    print("ğŸ“Š ç”Ÿæˆã•ã‚ŒãŸãƒãƒ£ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
    print("ğŸŒŸ å„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ç‰¹å¾´ã‚’ç†è§£ã—ã¦ã€ç”¨é€”ã«å¿œã˜ã¦é¸æŠã—ã¦ãã ã•ã„ï¼")


if __name__ == "__main__":
    main() 