#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†ææ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

X_ERã¨X_Hurstã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†ææ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã€
æ­£å¸¸ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚
"""

import sys
import os
import numpy as np
import pandas as pd

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from indicators.trend_filter.x_er import XER, calculate_x_er
from indicators.trend_filter.x_hurst import XHurst, calculate_x_hurst


def generate_test_data(length=200):
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    np.random.seed(42)
    
    # ãƒ™ãƒ¼ã‚¹ä¾¡æ ¼
    base_price = 100.0
    prices = [base_price]
    
    # ç•°ãªã‚‹å¸‚å ´çŠ¶æ…‹ã‚’æ¨¡æ“¬
    for i in range(1, length):
        if i < 50:  # åŠ¹ç‡çš„ãƒˆãƒ¬ãƒ³ãƒ‰ç›¸å ´
            change = 0.003 + np.random.normal(0, 0.008)
        elif i < 100:  # éåŠ¹ç‡çš„ãƒ¬ãƒ³ã‚¸ç›¸å ´
            change = np.random.normal(0, 0.012)
        elif i < 150:  # éå¸¸ã«åŠ¹ç‡çš„ãªãƒˆãƒ¬ãƒ³ãƒ‰ç›¸å ´
            change = 0.005 + np.random.normal(0, 0.006)
        else:  # ãƒ¬ãƒ³ã‚¸ç›¸å ´
            change = np.random.normal(0, 0.010)
        
        new_price = prices[-1] * (1 + change)
        prices.append(new_price)
    
    # OHLC ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
    data = []
    for i, close in enumerate(prices):
        daily_range = abs(np.random.normal(0, close * 0.01))
        
        high = close + daily_range * np.random.uniform(0.3, 1.0)
        low = close - daily_range * np.random.uniform(0.3, 1.0)
        
        if i == 0:
            open_price = close
        else:
            gap = np.random.normal(0, close * 0.005)
            open_price = prices[i-1] + gap
        
        # è«–ç†çš„æ•´åˆæ€§ã®ç¢ºä¿
        high = max(high, open_price, close)
        low = min(low, open_price, close)
        
        data.append({
            'open': open_price,
            'high': high,
            'low': low,
            'close': close,
            'volume': np.random.uniform(1000, 10000)
        })
    
    return pd.DataFrame(data)


def test_x_er_percentile_analysis():
    """X_ERã®ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†ææ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("\n=== X_ER ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æãƒ†ã‚¹ãƒˆ ===")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    df = generate_test_data(150)
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(df)}ãƒã‚¤ãƒ³ãƒˆ")
    
    # X_ERã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆï¼ˆãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†ææœ‰åŠ¹ï¼‰
    x_er = XER(
        period=14,
        midline_period=50,
        er_period=10,
        use_smoothing=True,
        use_kalman_filter=False,  # ãƒ†ã‚¹ãƒˆç”¨ã«ç„¡åŠ¹
        enable_percentile_analysis=True,
        percentile_lookback_period=30,
        percentile_low_threshold=0.3,
        percentile_high_threshold=0.7
    )
    
    # è¨ˆç®—å®Ÿè¡Œ
    result = x_er.calculate(df)
    
    # çµæœæ¤œè¨¼
    print(f"X_ERæœ‰åŠ¹å€¤æ•°: {np.sum(~np.isnan(result.values))}/{len(df)}")
    print(f"å¹³å‡X_ERå€¤: {np.nanmean(result.values):.4f}")
    
    # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æçµæœã®æ¤œè¨¼
    if result.percentiles is not None:
        valid_percentiles = result.percentiles[~np.isnan(result.percentiles)]
        print(f"ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«æœ‰åŠ¹å€¤æ•°: {len(valid_percentiles)}")
        print(f"ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ç¯„å›²: {np.min(valid_percentiles):.3f} - {np.max(valid_percentiles):.3f}")
        
        if result.trend_state is not None:
            valid_states = result.trend_state[~np.isnan(result.trend_state)]
            if len(valid_states) > 0:
                low_count = np.sum(valid_states == -1.0)
                mid_count = np.sum(valid_states == 0.0)
                high_count = np.sum(valid_states == 1.0)
                total_count = len(valid_states)
                
                print(f"ãƒˆãƒ¬ãƒ³ãƒ‰çŠ¶æ…‹åˆ†å¸ƒ:")
                print(f"  ä½ãƒˆãƒ¬ãƒ³ãƒ‰: {low_count}/{total_count} ({low_count/total_count:.1%})")
                print(f"  ä¸­ãƒˆãƒ¬ãƒ³ãƒ‰: {mid_count}/{total_count} ({mid_count/total_count:.1%})")
                print(f"  é«˜ãƒˆãƒ¬ãƒ³ãƒ‰: {high_count}/{total_count} ({high_count/total_count:.1%})")
        
        if result.trend_intensity is not None:
            valid_intensity = result.trend_intensity[~np.isnan(result.trend_intensity)]
            if len(valid_intensity) > 0:
                print(f"ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦: å¹³å‡={np.mean(valid_intensity):.3f}, ç¯„å›²={np.min(valid_intensity):.3f}-{np.max(valid_intensity):.3f}")
    
    # getterãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ†ã‚¹ãƒˆ
    percentiles = x_er.get_percentiles()
    trend_state = x_er.get_trend_state()
    trend_intensity = x_er.get_trend_intensity()
    
    print(f"getterçµæœ:")
    print(f"  ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«: {percentiles is not None}")
    print(f"  ãƒˆãƒ¬ãƒ³ãƒ‰çŠ¶æ…‹: {trend_state is not None}")
    print(f"  ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦: {trend_intensity is not None}")
    
    # ä¾¿åˆ©é–¢æ•°ã®ãƒ†ã‚¹ãƒˆ
    convenience_result = calculate_x_er(
        df, period=14, enable_percentile_analysis=True
    )
    print(f"ä¾¿åˆ©é–¢æ•°çµæœ: {np.sum(~np.isnan(convenience_result))}/{len(convenience_result)} æœ‰åŠ¹å€¤")
    
    return True


def test_x_hurst_percentile_analysis():
    """X_Hurstã®ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†ææ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("\n=== X_Hurst ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æãƒ†ã‚¹ãƒˆ ===")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    df = generate_test_data(150)
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(df)}ãƒã‚¤ãƒ³ãƒˆ")
    
    # X_Hurstã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆï¼ˆãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†ææœ‰åŠ¹ï¼‰
    x_hurst = XHurst(
        period=30,  # çŸ­ã‚ã«è¨­å®šã—ã¦ãƒ†ã‚¹ãƒˆæ™‚é–“çŸ­ç¸®
        midline_period=50,
        min_scale=4,
        max_scale=15,
        scale_steps=6,
        use_smoothing=True,
        use_dynamic_period=False,  # ãƒ†ã‚¹ãƒˆç”¨ã«ç„¡åŠ¹
        use_kalman_filter=False,   # ãƒ†ã‚¹ãƒˆç”¨ã«ç„¡åŠ¹
        enable_percentile_analysis=True,
        percentile_lookback_period=25,
        percentile_low_threshold=0.35,
        percentile_high_threshold=0.65
    )
    
    # è¨ˆç®—å®Ÿè¡Œ
    try:
        result = x_hurst.calculate(df)
        
        # çµæœæ¤œè¨¼
        print(f"X_Hurstæœ‰åŠ¹å€¤æ•°: {np.sum(~np.isnan(result.values))}/{len(df)}")
        if np.sum(~np.isnan(result.values)) > 0:
            print(f"å¹³å‡X_Hurstå€¤: {np.nanmean(result.values):.4f}")
            
            # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æçµæœã®æ¤œè¨¼
            if result.percentiles is not None:
                valid_percentiles = result.percentiles[~np.isnan(result.percentiles)]
                print(f"ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«æœ‰åŠ¹å€¤æ•°: {len(valid_percentiles)}")
                if len(valid_percentiles) > 0:
                    print(f"ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ç¯„å›²: {np.min(valid_percentiles):.3f} - {np.max(valid_percentiles):.3f}")
                
                if result.trend_state is not None:
                    valid_states = result.trend_state[~np.isnan(result.trend_state)]
                    if len(valid_states) > 0:
                        low_count = np.sum(valid_states == -1.0)
                        mid_count = np.sum(valid_states == 0.0)
                        high_count = np.sum(valid_states == 1.0)
                        total_count = len(valid_states)
                        
                        print(f"ãƒˆãƒ¬ãƒ³ãƒ‰çŠ¶æ…‹åˆ†å¸ƒ:")
                        print(f"  ä½ãƒˆãƒ¬ãƒ³ãƒ‰: {low_count}/{total_count} ({low_count/total_count:.1%})")
                        print(f"  ä¸­ãƒˆãƒ¬ãƒ³ãƒ‰: {mid_count}/{total_count} ({mid_count/total_count:.1%})")
                        print(f"  é«˜ãƒˆãƒ¬ãƒ³ãƒ‰: {high_count}/{total_count} ({high_count/total_count:.1%})")
                
                if result.trend_intensity is not None:
                    valid_intensity = result.trend_intensity[~np.isnan(result.trend_intensity)]
                    if len(valid_intensity) > 0:
                        print(f"ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦: å¹³å‡={np.mean(valid_intensity):.3f}, ç¯„å›²={np.min(valid_intensity):.3f}-{np.max(valid_intensity):.3f}")
        
        # getterãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ†ã‚¹ãƒˆ
        percentiles = x_hurst.get_percentiles()
        trend_state = x_hurst.get_trend_state()
        trend_intensity = x_hurst.get_trend_intensity()
        
        print(f"getterçµæœ:")
        print(f"  ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«: {percentiles is not None}")
        print(f"  ãƒˆãƒ¬ãƒ³ãƒ‰çŠ¶æ…‹: {trend_state is not None}")
        print(f"  ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦: {trend_intensity is not None}")
        
        # ä¾¿åˆ©é–¢æ•°ã®ãƒ†ã‚¹ãƒˆ
        convenience_result = calculate_x_hurst(
            df, period=30, enable_percentile_analysis=True,
            use_dynamic_period=False, use_kalman_filter=False
        )
        print(f"ä¾¿åˆ©é–¢æ•°çµæœ: {np.sum(~np.isnan(convenience_result))}/{len(convenience_result)} æœ‰åŠ¹å€¤")
        
        return True
        
    except Exception as e:
        print(f"X_Hurstè¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_indicator_info():
    """ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼æƒ…å ±ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n=== ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼æƒ…å ±ãƒ†ã‚¹ãƒˆ ===")
    
    # X_ERã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼æƒ…å ±
    x_er = XER(enable_percentile_analysis=True)
    er_info = x_er.get_indicator_info()
    print("X_ERæƒ…å ±:")
    for key, value in er_info.items():
        print(f"  {key}: {value}")
    
    # X_Hurstã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼æƒ…å ±
    x_hurst = XHurst(enable_percentile_analysis=True)
    hurst_info = x_hurst.get_indicator_info()
    print("\nX_Hurstæƒ…å ±:")
    for key, value in hurst_info.items():
        print(f"  {key}: {value}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†ææ©Ÿèƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    success_count = 0
    total_tests = 0
    
    # X_ERãƒ†ã‚¹ãƒˆ
    total_tests += 1
    if test_x_er_percentile_analysis():
        success_count += 1
        print("âœ“ X_ER ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æãƒ†ã‚¹ãƒˆæˆåŠŸ")
    else:
        print("âœ— X_ER ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æãƒ†ã‚¹ãƒˆå¤±æ•—")
    
    # X_Hurstãƒ†ã‚¹ãƒˆ
    total_tests += 1
    if test_x_hurst_percentile_analysis():
        success_count += 1
        print("âœ“ X_Hurst ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æãƒ†ã‚¹ãƒˆæˆåŠŸ")
    else:
        print("âœ— X_Hurst ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æãƒ†ã‚¹ãƒˆå¤±æ•—")
    
    # ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼æƒ…å ±ãƒ†ã‚¹ãƒˆ
    total_tests += 1
    try:
        test_indicator_info()
        success_count += 1
        print("âœ“ ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼æƒ…å ±ãƒ†ã‚¹ãƒˆæˆåŠŸ")
    except Exception as e:
        print(f"âœ— ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼æƒ…å ±ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
    
    # çµæœã‚µãƒãƒªãƒ¼
    print(f"\n=== ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼ ===")
    print(f"æˆåŠŸ: {success_count}/{total_tests}")
    print(f"æˆåŠŸç‡: {success_count/total_tests:.1%}")
    
    if success_count == total_tests:
        print("\nğŸ‰ å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        return True
    else:
        print(f"\nâš ï¸  {total_tests - success_count}å€‹ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)