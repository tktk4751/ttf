#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸŒŸ **Ultimate Volatility V3.0 - ç©¶æ¥µé€²åŒ–ç‰ˆ** ğŸŒŸ

ğŸ¯ **é©æ–°çš„7å±¤çµ±åˆã‚·ã‚¹ãƒ†ãƒ :**
1. **é©å¿œçš„True Range**: å¾“æ¥ATRã®TRã‚’å‹•çš„å¸‚å ´æ¡ä»¶ã«é©å¿œ
2. **ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°**: Wilder's smoothingã®é€²åŒ–ç‰ˆ
3. **é‡å­å¼·åŒ–ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›**: ç¬æ™‚æŒ¯å¹…ãƒ»ä½ç›¸ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã®è¶…ä½é…å»¶æ¤œå‡º
4. **é‡å­é©å¿œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼**: å‹•çš„ãƒã‚¤ã‚ºãƒ¢ãƒ‡ãƒªãƒ³ã‚° + é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹èª¿æ•´
5. **ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå¤šè§£åƒåº¦è§£æ**: è¤‡æ•°æ™‚é–“è»¸ã§ã®å¸‚å ´æ§‹é€ è§£æ
6. **ãƒˆãƒ¬ãƒ³ãƒ‰é©å¿œèª¿æ•´**: ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã«å¿œã˜ãŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è£œæ­£
7. **ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ çµ±åˆ**: çŸ­æœŸãƒ»ä¸­æœŸãƒ»é•·æœŸã®åŠ¹ç‡çš„çµ±åˆ

ğŸ† **Ultimate Breakout Channelã®æœ€å¼·æŠ€è¡“ã‚’çµ±åˆ:**
- **è¶…ä½é…å»¶**: ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆ + ã‚«ãƒ«ãƒãƒ³çµ±åˆã«ã‚ˆã‚‹äºˆæ¸¬çš„è£œæ­£
- **è¶…é«˜ç²¾åº¦**: é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ + ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå¤šè§£åƒåº¦è§£æ
- **è¶…è¿½å¾“æ€§**: é‡å­ã‚‚ã¤ã‚ŒåŠ¹æœ + é©å¿œçš„é‡ã¿è¨ˆç®—
- **ç•°å¸¸å€¤è€æ€§**: å¤šå±¤ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° + ä¿¡é ¼åº¦è©•ä¾¡
- **äºˆæ¸¬æ©Ÿèƒ½**: æ¬¡æœŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®è¶…é«˜ç²¾åº¦äºˆæ¸¬

ã‚·ãƒ³ãƒ—ãƒ«ãªATRåŸºç›¤ã«æœ€å…ˆç«¯ã®é‡å­é‡‘èå·¥å­¦ã‚’èåˆã—ãŸç©¶æ¥µã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚·ã‚¹ãƒ†ãƒ 
"""

from dataclasses import dataclass
from typing import Union, Tuple, Dict, Optional, NamedTuple
import numpy as np
import pandas as pd
from numba import jit, njit, prange, vectorize, float64, int64, boolean
import math
import warnings
warnings.filterwarnings('ignore')

try:
    from .indicator import Indicator
    from .price_source import PriceSource
except ImportError:
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from indicator import Indicator
    from price_source import PriceSource


@dataclass
class UltimateVolatilityResult:
    """Ultimate Volatility V3.0è¨ˆç®—çµæœ"""
    # æ ¸å¿ƒãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æˆåˆ†
    adaptive_true_range: np.ndarray         # é©å¿œçš„True Range
    ultimate_volatility: np.ndarray         # æœ€çµ‚çµ±åˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
    volatility_trend: np.ndarray            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒˆãƒ¬ãƒ³ãƒ‰
    confidence_score: np.ndarray            # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
    
    # é‡å­å¼·åŒ–æˆåˆ†
    hilbert_amplitude: np.ndarray           # ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆç¬æ™‚æŒ¯å¹…
    hilbert_phase: np.ndarray               # ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆç¬æ™‚ä½ç›¸
    quantum_coherence: np.ndarray           # é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹
    quantum_entanglement: np.ndarray        # é‡å­ã‚‚ã¤ã‚Œ
    
    # ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆæˆåˆ†
    wavelet_trend: np.ndarray               # ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†
    wavelet_cycle: np.ndarray               # ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆã‚µã‚¤ã‚¯ãƒ«æˆåˆ†
    market_regime: np.ndarray               # å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ 
    
    # äºˆæ¸¬ãƒ»åˆ†ææˆåˆ†
    volatility_forecast: np.ndarray         # æ¬¡æœŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£äºˆæ¸¬
    regime_indicator: np.ndarray            # ãƒ¬ã‚¸ãƒ¼ãƒ æŒ‡æ¨™
    efficiency_score: np.ndarray            # åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢
    
    # ç¾åœ¨çŠ¶æ…‹
    current_regime: str                     # ç¾åœ¨ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ 
    current_efficiency: float               # ç¾åœ¨ã®åŠ¹ç‡æ€§
    forecast_accuracy: float                # äºˆæ¸¬ç²¾åº¦


# === 1. é©å¿œçš„True Rangeè¨ˆç®—ï¼ˆV2.0ã‹ã‚‰ç¶™æ‰¿ï¼‰ ===

@njit(fastmath=True, parallel=True, cache=True)
def adaptive_true_range(high: np.ndarray, low: np.ndarray, close: np.ndarray) -> np.ndarray:
    """
    é©å¿œçš„True Range - å¾“æ¥TRã‚’å¸‚å ´æ¡ä»¶ã«é©å¿œã•ã›ãŸé€²åŒ–ç‰ˆ
    """
    n = len(high)
    atr_values = np.zeros(n)
    
    for i in prange(1, n):
        # æ¨™æº–True Rangeæˆåˆ†
        tr1 = high[i] - low[i]
        tr2 = abs(high[i] - close[i-1])
        tr3 = abs(low[i] - close[i-1])
        base_tr = max(tr1, tr2, tr3)
        
        # é©å¿œçš„èª¿æ•´ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼
        if i >= 10:
            recent_ranges = np.zeros(9)
            for j in range(9):
                if i-j-1 >= 0:
                    prev_tr1 = high[i-j] - low[i-j]
                    prev_tr2 = abs(high[i-j] - close[i-j-1]) if i-j-1 >= 0 else prev_tr1
                    prev_tr3 = abs(low[i-j] - close[i-j-1]) if i-j-1 >= 0 else prev_tr1
                    recent_ranges[j] = max(prev_tr1, prev_tr2, prev_tr3)
            
            recent_avg = np.mean(recent_ranges)
            if recent_avg > 1e-10:
                volatility_regime = base_tr / recent_avg
                adaptation_factor = max(min(volatility_regime, 2.0), 0.5)
                atr_values[i] = base_tr * (0.7 + 0.3 * adaptation_factor)
            else:
                atr_values[i] = base_tr
        else:
            atr_values[i] = base_tr
    
    atr_values[0] = high[0] - low[0] if n > 0 else 0.0
    return atr_values


# === 2. é‡å­å¼·åŒ–ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ› V2.0ï¼ˆUltimate Breakoutã‹ã‚‰ç§»æ¤ï¼‰ ===

@njit(fastmath=True, parallel=True, cache=True)
def quantum_enhanced_hilbert_transform(prices: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    é‡å­å¼·åŒ–ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ› V2.0 - ç©¶æ¥µè¶…ä½é…å»¶ãƒ»è¶…é«˜ç²¾åº¦è§£æ
    
    é‡å­ã‚‚ã¤ã‚ŒåŠ¹æœãƒ»å¤šé‡å…±é³´ãƒ»é©å¿œãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’çµ±åˆã—ãŸ
    äººé¡å²ä¸Šæœ€å¼·ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¸‚å ´è§£æã‚·ã‚¹ãƒ†ãƒ 
    """
    n = len(prices)
    amplitude = np.full(n, np.nan)
    phase = np.full(n, np.nan)
    trend_strength = np.full(n, np.nan)
    quantum_entanglement = np.full(n, np.nan)
    
    quantum_states = 12
    
    for i in prange(max(quantum_states, 10), n):
        # === å¤šé‡å…±é³´ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ› ===
        real_components = np.zeros(3)
        imag_components = np.zeros(3)
        
        # çŸ­æœŸå…±é³´ï¼ˆ4ç‚¹ï¼‰
        if i >= 4:
            real_components[0] = (prices[i] * 0.4 + prices[i-2] * 0.35 + prices[i-4] * 0.25)
            imag_components[0] = (prices[i-1] * 0.37 + prices[i-3] * 0.33)
        
        # ä¸­æœŸå…±é³´ï¼ˆ8ç‚¹ï¼‰
        if i >= 8:
            weights_real = np.array([0.25, 0.22, 0.18, 0.15])
            weights_imag = np.array([0.24, 0.21, 0.17, 0.14])
            
            for j in range(4):
                real_components[1] += prices[i - j*2] * weights_real[j]
                imag_components[1] += prices[i - j*2 - 1] * weights_imag[j]
        
        # é•·æœŸå…±é³´ï¼ˆ12ç‚¹ï¼‰
        if i >= 12:
            weights_real = np.array([0.20, 0.18, 0.16, 0.14, 0.12, 0.10])
            weights_imag = np.array([0.19, 0.17, 0.15, 0.13, 0.11, 0.09])
            
            for j in range(6):
                real_components[2] += prices[i - j*2] * weights_real[j]
                imag_components[2] += prices[i - j*2 - 1] * weights_imag[j]
        
        # === é‡å­ã‚‚ã¤ã‚ŒåŠ¹æœè¨ˆç®— ===
        entanglement_factor = 0.0
        if i >= 20:
            for j in range(1, min(10, i)):
                correlation = (prices[i] - prices[i-j]) * (prices[i-j] - prices[i-j-1])
                if correlation != 0:
                    entanglement_factor += math.sin(math.pi * correlation / (abs(correlation) + 1e-10))
            entanglement_factor = abs(entanglement_factor) / 9.0
            quantum_entanglement[i] = max(min(entanglement_factor, 1.0), 0.0)
        else:
            quantum_entanglement[i] = 0.5
        
        # === é©å¿œé‡ã¿è¨ˆç®— ===
        entangled_weight = quantum_entanglement[i]
        adaptive_weights = np.array([
            0.5 + 0.3 * entangled_weight,
            0.3 + 0.2 * (1 - entangled_weight),
            0.2 + 0.1 * entangled_weight
        ])
        adaptive_weights /= np.sum(adaptive_weights)
        
        # === çµ±åˆæŒ¯å¹…ãƒ»ä½ç›¸è¨ˆç®— ===
        real_part = np.sum(real_components * adaptive_weights)
        imag_part = np.sum(imag_components * adaptive_weights)
        
        raw_amplitude = math.sqrt(real_part * real_part + imag_part * imag_part)
        quantum_correction = 0.8 + 0.4 * quantum_entanglement[i]
        amplitude[i] = raw_amplitude * quantum_correction
        
        if abs(real_part) > 1e-12:
            base_phase = math.atan2(imag_part, real_part)
            phase[i] = base_phase
        else:
            phase[i] = 0.0
        
        # === é‡å­ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ ===
        if i >= 5:
            short_momentum = 0.0
            for j in range(1, min(4, i)):
                if i-j >= 0:
                    weight = math.exp(-j * 0.2)
                    short_momentum += math.sin(phase[i-j]) * weight
            if i > 1:
                short_momentum /= min(3.0, i-1)
            
            trend_strength[i] = abs(math.tanh(short_momentum * 4))
        
        amplitude[i] = max(min(amplitude[i], prices[i] * 3), 0.0)
        trend_strength[i] = max(min(trend_strength[i], 1.0), 0.0)
    
    return amplitude, phase, trend_strength, quantum_entanglement


# === 3. é‡å­é©å¿œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆUltimate Breakoutã‹ã‚‰ç§»æ¤ï¼‰ ===

@njit(fastmath=True, cache=True)
def quantum_adaptive_kalman_filter(prices: np.ndarray, amplitude: np.ndarray, 
                                  phase: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """
    é‡å­é©å¿œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ - å‹•çš„ãƒã‚¤ã‚ºãƒ¢ãƒ‡ãƒªãƒ³ã‚° + é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹èª¿æ•´
    """
    n = len(prices)
    filtered_prices = np.full(n, np.nan)
    quantum_coherence = np.full(n, np.nan)
    
    if n < 2:
        return filtered_prices, quantum_coherence
    
    state_estimate = prices[0]
    error_covariance = 1.0
    filtered_prices[0] = state_estimate
    quantum_coherence[0] = 0.5
    
    for i in range(1, n):
        # é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹è¨ˆç®—
        if not np.isnan(amplitude[i]) and not np.isnan(phase[i]):
            amplitude_mean = np.nanmean(amplitude[max(0, i-10):i+1])
            denominator = amplitude_mean + 1e-10
            if abs(denominator) > 1e-15:
                amplitude_coherence = min(amplitude[i] / denominator, 2.0) * 0.5
            else:
                amplitude_coherence = 0.5
            
            if i > 5:
                phase_coherence = 0.0
                for j in range(5):
                    if i-j > 0:
                        phase_diff = abs(phase[i] - phase[i-j])
                        phase_coherence += math.exp(-phase_diff)
                if phase_coherence > 0:
                    phase_coherence /= 5.0
                else:
                    phase_coherence = 0.5
            else:
                phase_coherence = 0.5
            
            quantum_coherence[i] = (amplitude_coherence * 0.6 + phase_coherence * 0.4)
            quantum_coherence[i] = max(min(quantum_coherence[i], 1.0), 0.0)
        else:
            quantum_coherence[i] = quantum_coherence[i-1] if i > 0 else 0.5
        
        # é©å¿œçš„ãƒã‚¤ã‚ºèª¿æ•´
        coherence = quantum_coherence[i]
        process_noise = 0.001 * (1.0 - coherence)
        observation_noise = 0.01 * (1.0 + coherence)
        
        # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ›´æ–°
        state_prediction = state_estimate
        error_prediction = error_covariance + process_noise
        
        denominator = error_prediction + observation_noise
        if abs(denominator) > 1e-10:
            kalman_gain = error_prediction / denominator
        else:
            kalman_gain = 0.5
        
        innovation = prices[i] - state_prediction
        state_estimate = state_prediction + kalman_gain * innovation
        error_covariance = (1 - kalman_gain) * error_prediction
        
        filtered_prices[i] = state_estimate
    
    return filtered_prices, quantum_coherence


# === 4. ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå¤šè§£åƒåº¦è§£æï¼ˆUltimate Breakoutã‹ã‚‰ç§»æ¤ï¼‰ ===

@njit(fastmath=True, parallel=True, cache=True)
def wavelet_multiresolution_analysis(prices: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå¤šè§£åƒåº¦è§£æ - è¤‡æ•°æ™‚é–“è»¸ã§ã®å¸‚å ´æ§‹é€ è§£æ
    """
    n = len(prices)
    trend_component = np.full(n, np.nan)
    cycle_component = np.full(n, np.nan)
    market_regime = np.full(n, np.nan)
    
    for i in prange(15, n):
        segment_size = min(16, i)
        segment = prices[i-segment_size:i]
        
        if len(segment) >= 16:
            high_freq = np.zeros(8)
            low_freq = np.zeros(8)
            
            for j in range(8):
                high_freq[j] = (segment[j*2] - segment[j*2+1]) / math.sqrt(2)
                low_freq[j] = (segment[j*2] + segment[j*2+1]) / math.sqrt(2)
            
            trend_coeffs = np.zeros(4)
            cycle_coeffs = np.zeros(4)
            
            for j in range(4):
                trend_coeffs[j] = (low_freq[j*2] + low_freq[j*2+1]) / math.sqrt(2)
                cycle_coeffs[j] = (low_freq[j*2] - low_freq[j*2+1]) / math.sqrt(2)
        else:
            variance = np.var(segment)
            mean_val = np.mean(segment)
            trend_coeffs = np.array([mean_val, mean_val/2, mean_val/4, mean_val/8])
            cycle_coeffs = np.array([variance/4, variance/8, variance/16, variance/32])
            high_freq = np.full(8, variance/8)
        
        # æˆåˆ†ã‚¨ãƒãƒ«ã‚®ãƒ¼è¨ˆç®—
        trend_energy = np.sum(trend_coeffs * trend_coeffs)
        cycle_energy = np.sum(cycle_coeffs * cycle_coeffs)
        noise_energy = np.sum(high_freq * high_freq)
        
        total_energy = trend_energy + cycle_energy + noise_energy
        
        if abs(total_energy) > 1e-10:
            trend_component[i] = trend_energy / total_energy
            cycle_component[i] = cycle_energy / total_energy
            
            if trend_energy > (cycle_energy + noise_energy) * 1.2:
                market_regime[i] = 1.0  # ãƒˆãƒ¬ãƒ³ãƒ‰ç›¸å ´
            elif cycle_energy > (trend_energy + noise_energy) * 1.2:
                market_regime[i] = -1.0  # ã‚µã‚¤ã‚¯ãƒ«ç›¸å ´
            else:
                market_regime[i] = 0.0  # ä¸­ç«‹ãƒ»ãƒ¬ãƒ³ã‚¸ç›¸å ´
        else:
            trend_component[i] = 0.33
            cycle_component[i] = 0.33
            market_regime[i] = 0.0
    
    return trend_component, cycle_component, market_regime


# === 5. ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆV2.0ã‹ã‚‰ç¶™æ‰¿ï¼‰ ===

@njit(fastmath=True, cache=True)
def intelligent_smoothing(tr_values: np.ndarray, period: int = 14) -> np.ndarray:
    """
    ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚° - Wilder's smoothingã®é€²åŒ–ç‰ˆ
    """
    n = len(tr_values)
    smoothed = np.zeros(n)
    
    if n == 0:
        return smoothed
    
    smoothed[0] = tr_values[0]
    
    for i in range(1, n):
        if i < period:
            sum_tr = 0.0
            for j in range(i + 1):
                sum_tr += tr_values[j]
            smoothed[i] = sum_tr / (i + 1)
        else:
            base_alpha = 1.0 / period
            
            recent_volatility = 0.0
            for j in range(max(0, i-5), i):
                if j > 0:
                    recent_volatility += abs(tr_values[j] - tr_values[j-1])
            recent_volatility /= min(5, i)
            
            long_term_avg = smoothed[i-1]
            
            if long_term_avg > 1e-10:
                volatility_ratio = recent_volatility / long_term_avg
                if volatility_ratio > 1.0:
                    adaptive_alpha = base_alpha * (1.0 + min(volatility_ratio - 1.0, 1.0) * 0.5)
                else:
                    adaptive_alpha = base_alpha * (0.7 + 0.3 * volatility_ratio)
            else:
                adaptive_alpha = base_alpha
            
            adaptive_alpha = max(min(adaptive_alpha, 0.5), 0.02)
            smoothed[i] = smoothed[i-1] * (1 - adaptive_alpha) + tr_values[i] * adaptive_alpha
    
    return smoothed


# === 6. ç©¶æ¥µçµ±åˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ V3.0 ===

@njit(fastmath=True, parallel=True, cache=True)
def ultimate_volatility_engine_v3(
    adaptive_tr: np.ndarray,
    hilbert_amplitude: np.ndarray,
    quantum_coherence: np.ndarray,
    wavelet_trend: np.ndarray,
    wavelet_cycle: np.ndarray,
    smoothed_vol: np.ndarray
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    ç©¶æ¥µçµ±åˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ V3.0 - å…¨æˆåˆ†ã®æœ€é©çµ±åˆ
    
    ATRåŸºç›¤ + ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆ + ã‚«ãƒ«ãƒãƒ³ + ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆã®é©æ–°çš„çµ±åˆ
    """
    n = len(smoothed_vol)
    ultimate_vol = np.zeros(n)
    confidence = np.zeros(n)
    regime = np.zeros(n)
    
    for i in prange(15, n):
        # åŸºæœ¬ATRã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆ30%ï¼‰
        base_component = smoothed_vol[i] * 0.3
        
        # ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆæŒ¯å¹…ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆ25%ï¼‰
        hilbert_component = 0.0
        if not np.isnan(hilbert_amplitude[i]):
            # æŒ¯å¹…ã‚’ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å½¢å¼ã«æ­£è¦åŒ–
            if i >= 20:
                amplitude_avg = 0.0
                valid_count = 0
                for j in range(max(0, i-20), i):
                    if not np.isnan(hilbert_amplitude[j]):
                        amplitude_avg += hilbert_amplitude[j]
                        valid_count += 1
                if valid_count > 0:
                    amplitude_avg /= valid_count
                    if amplitude_avg > 1e-10:
                        hilbert_component = (hilbert_amplitude[i] / amplitude_avg) * smoothed_vol[i] * 0.25
        
        # é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹èª¿æ•´ï¼ˆ20%ï¼‰
        coherence_component = 0.0
        if not np.isnan(quantum_coherence[i]):
            coherence_factor = 0.8 + 0.4 * quantum_coherence[i]
            coherence_component = smoothed_vol[i] * coherence_factor * 0.2
        
        # ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆæˆåˆ†ï¼ˆ25%ï¼‰
        wavelet_component = 0.0
        if not np.isnan(wavelet_trend[i]) and not np.isnan(wavelet_cycle[i]):
            # ãƒˆãƒ¬ãƒ³ãƒ‰ã¨ã‚µã‚¤ã‚¯ãƒ«ã®çµ±åˆ
            wavelet_weight = wavelet_trend[i] * 0.6 + wavelet_cycle[i] * 0.4
            wavelet_component = smoothed_vol[i] * (1.0 + wavelet_weight) * 0.25
        
        # çµ±åˆè¨ˆç®—
        total_weight = 0.0
        integrated_vol = 0.0
        
        # å„æˆåˆ†ã®é‡ã¿ä»˜ãåŠ ç®—
        integrated_vol += base_component
        total_weight += 0.3
        
        if hilbert_component > 0:
            integrated_vol += hilbert_component
            total_weight += 0.25
        
        if coherence_component > 0:
            integrated_vol += coherence_component
            total_weight += 0.2
        
        if wavelet_component > 0:
            integrated_vol += wavelet_component
            total_weight += 0.25
        
        # æ­£è¦åŒ–
        if total_weight > 0:
            ultimate_vol[i] = integrated_vol / total_weight
        else:
            ultimate_vol[i] = smoothed_vol[i]
        
        # ä¿¡é ¼åº¦è¨ˆç®—ï¼ˆæˆåˆ†ã®åˆ©ç”¨å¯èƒ½æ€§ï¼‰
        component_count = 1  # base_component always available
        if hilbert_component > 0:
            component_count += 1
        if coherence_component > 0:
            component_count += 1
        if wavelet_component > 0:
            component_count += 1
        
        confidence[i] = min(component_count / 4.0, 1.0)
        
        # ãƒ¬ã‚¸ãƒ¼ãƒ æŒ‡æ¨™
        if i >= 20:
            recent_vols = np.zeros(20)
            for j in range(20):
                recent_vols[j] = ultimate_vol[i-j]
            
            current_vol = ultimate_vol[i]
            count_below = 0
            for vol in recent_vols:
                if vol <= current_vol:
                    count_below += 1
            regime[i] = count_below / 20.0
        else:
            regime[i] = 0.5
    
    # åˆæœŸå€¤è¨­å®š
    for i in range(min(15, n)):
        ultimate_vol[i] = smoothed_vol[i] if i < len(smoothed_vol) else 0.0
        confidence[i] = 0.5
        regime[i] = 0.5
    
    return ultimate_vol, confidence, regime


class UltimateVolatility(Indicator):
    """
    ğŸŒŸ **Ultimate Volatility V3.0 - ç©¶æ¥µé€²åŒ–ç‰ˆ** ğŸŒŸ
    
    é©æ–°çš„7å±¤çµ±åˆã‚·ã‚¹ãƒ†ãƒ ï¼š
    1. é©å¿œçš„True Range - å¸‚å ´æ¡ä»¶é©å¿œå‹TRè¨ˆç®—
    2. ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚° - é€²åŒ–å‹å¹³æ»‘åŒ–
    3. é‡å­å¼·åŒ–ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ› - ç¬æ™‚æŒ¯å¹…ãƒ»ä½ç›¸ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦æ¤œå‡º
    4. é‡å­é©å¿œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ - å‹•çš„ãƒã‚¤ã‚ºãƒ¢ãƒ‡ãƒªãƒ³ã‚°
    5. ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå¤šè§£åƒåº¦è§£æ - å¤šæ™‚é–“è»¸å¸‚å ´æ§‹é€ è§£æ
    6. ãƒˆãƒ¬ãƒ³ãƒ‰é©å¿œèª¿æ•´ - å¸‚å ´çŠ¶æ³åˆ¥æœ€é©åŒ–
    7. ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ çµ±åˆ - åŠ¹ç‡çš„æ™‚é–“è»¸çµ±åˆ
    
    Ultimate Breakout Channelã®æœ€å¼·æŠ€è¡“ã‚’çµ±åˆã—ã€
    å¾“æ¥ATRã‚’é¥ã‹ã«è¶…ãˆã‚‹è¶…é«˜ç²¾åº¦ãƒ»è¶…ä½é…å»¶ãƒ»è¶…è¿½å¾“æ€§ã‚’å®Ÿç¾
    """
    
    def __init__(
        self,
        # åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        period: int = 14,
        trend_window: int = 10,
        
        # é‡å­ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        hilbert_window: int = 12,
        kalman_process_noise: float = 0.001,
        
        # ä¾¡æ ¼ã‚½ãƒ¼ã‚¹
        src_type: str = 'hlc3'
    ):
        """
        Ultimate Volatility V3.0 ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
        
        Args:
            period: åŸºæœ¬ATRè¨ˆç®—æœŸé–“
            trend_window: ãƒˆãƒ¬ãƒ³ãƒ‰é©å¿œã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            hilbert_window: ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            kalman_process_noise: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚¤ã‚º
            src_type: ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ï¼ˆè¨ˆç®—ç”¨ã€å®Ÿéš›ã¯HLCã‚’ä½¿ç”¨ï¼‰
        """
        super().__init__(f"UltimateVolatilityV3(period={period},quantum={hilbert_window})")
        
        self.period = period
        self.trend_window = trend_window
        self.hilbert_window = hilbert_window
        self.kalman_process_noise = kalman_process_noise
        self.src_type = src_type
        
        # ä¾å­˜ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.price_source = PriceSource()
        
        # çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._result_cache = {}
        self._cache_keys = []
        self._max_cache_size = 2
    
    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> UltimateVolatilityResult:
        """Ultimate Volatility V3.0è¨ˆç®—ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            data_hash = self._get_data_hash(data)
            if data_hash in self._result_cache:
                return self._result_cache[data_hash]
            
            # ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆHLCå¿…é ˆï¼‰
            if isinstance(data, pd.DataFrame):
                if 'high' not in data.columns or 'low' not in data.columns or 'close' not in data.columns:
                    raise ValueError("DataFrameã«ã¯high, low, closeåˆ—ãŒå¿…è¦ã§ã™")
                high = data['high'].values
                low = data['low'].values
                close = data['close'].values
                price_data = self.price_source.get_source(data, self.src_type)
                prices = price_data.values if hasattr(price_data, 'values') else price_data
            else:
                if data.ndim < 2 or data.shape[1] < 4:
                    raise ValueError("NumPyé…åˆ—ã¯[open, high, low, close]ã®4åˆ—ãŒå¿…è¦ã§ã™")
                high = data[:, 1]
                low = data[:, 2]
                close = data[:, 3]
                prices = close
            
            n = len(high)
            
            self.logger.info("ğŸŒŸ Ultimate Volatility V3.0è¨ˆç®—é–‹å§‹...")
            
            # === æ®µéš1: é©å¿œçš„True Rangeè¨ˆç®— ===
            adaptive_tr = adaptive_true_range(high, low, close)
            
            # === æ®µéš2: ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚° ===
            smoothed_vol = intelligent_smoothing(adaptive_tr, self.period)
            
            # === æ®µéš3: é‡å­å¼·åŒ–ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ› ===
            hilbert_amplitude, hilbert_phase, hilbert_trend_strength, quantum_entanglement = quantum_enhanced_hilbert_transform(prices)
            
            # === æ®µéš4: é‡å­é©å¿œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ ===
            filtered_prices, quantum_coherence = quantum_adaptive_kalman_filter(
                prices, hilbert_amplitude, hilbert_phase
            )
            
            # === æ®µéš5: ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå¤šè§£åƒåº¦è§£æ ===
            wavelet_trend, wavelet_cycle, market_regime = wavelet_multiresolution_analysis(prices)
            
            # === æ®µéš6: ç©¶æ¥µçµ±åˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®— ===
            ultimate_vol, confidence_score, regime_indicator = ultimate_volatility_engine_v3(
                adaptive_tr, hilbert_amplitude, quantum_coherence,
                wavelet_trend, wavelet_cycle, smoothed_vol
            )
            
            # === æ®µéš7: äºˆæ¸¬ãƒ»åˆ†æ ===
            vol_trend = self._calculate_volatility_trend(ultimate_vol)
            forecast = self._calculate_forecast(ultimate_vol)
            efficiency = self._calculate_efficiency(ultimate_vol, adaptive_tr)
            
            # === æ®µéš8: ç¾åœ¨çŠ¶æ…‹åˆ¤å®š ===
            current_regime = self._determine_current_regime(regime_indicator)
            current_efficiency = float(efficiency[-1]) if len(efficiency) > 0 and not np.isnan(efficiency[-1]) else 0.0
            forecast_accuracy = self._calculate_forecast_accuracy(ultimate_vol, forecast)
            
            # çµæœæ§‹ç¯‰
            result = UltimateVolatilityResult(
                adaptive_true_range=adaptive_tr,
                ultimate_volatility=ultimate_vol,
                volatility_trend=vol_trend,
                confidence_score=confidence_score,
                hilbert_amplitude=hilbert_amplitude,
                hilbert_phase=hilbert_phase,
                quantum_coherence=quantum_coherence,
                quantum_entanglement=quantum_entanglement,
                wavelet_trend=wavelet_trend,
                wavelet_cycle=wavelet_cycle,
                market_regime=market_regime,
                volatility_forecast=forecast,
                regime_indicator=regime_indicator,
                efficiency_score=efficiency,
                current_regime=current_regime,
                current_efficiency=current_efficiency,
                forecast_accuracy=forecast_accuracy
            )
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
            if len(self._result_cache) >= self._max_cache_size and self._cache_keys:
                oldest_key = self._cache_keys.pop(0)
                if oldest_key in self._result_cache:
                    del self._result_cache[oldest_key]
            
            self._result_cache[data_hash] = result
            self._cache_keys.append(data_hash)
            
            # çµ±è¨ˆæƒ…å ±ãƒ­ã‚°
            avg_vol = float(np.nanmean(ultimate_vol[~np.isnan(ultimate_vol)])) if np.any(~np.isnan(ultimate_vol)) else 0.0
            avg_confidence = float(np.nanmean(confidence_score[~np.isnan(confidence_score)])) if np.any(~np.isnan(confidence_score)) else 0.0
            avg_coherence = float(np.nanmean(quantum_coherence[~np.isnan(quantum_coherence)])) if np.any(~np.isnan(quantum_coherence)) else 0.0
            
            self.logger.info(f"âœ… Ultimate Volatility V3.0è¨ˆç®—å®Œäº†")
            self.logger.info(f"å¹³å‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {avg_vol:.6f}, å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.3f}")
            self.logger.info(f"é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹: {avg_coherence:.3f}, ç¾åœ¨ãƒ¬ã‚¸ãƒ¼ãƒ : {current_regime}")
            
            return result
            
        except Exception as e:
            import traceback
            self.logger.error(f"Ultimate Volatility V3.0è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.logger.error(traceback.format_exc())
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºã®çµæœã‚’è¿”ã™
            n = len(data) if hasattr(data, '__len__') else 0
            empty_array = np.full(n, np.nan)
            empty_zeros = np.zeros(n)
            return UltimateVolatilityResult(
                adaptive_true_range=empty_zeros,
                ultimate_volatility=empty_array,
                volatility_trend=empty_zeros,
                confidence_score=empty_zeros,
                hilbert_amplitude=empty_array,
                hilbert_phase=empty_array,
                quantum_coherence=empty_array,
                quantum_entanglement=empty_array,
                wavelet_trend=empty_array,
                wavelet_cycle=empty_array,
                market_regime=empty_array,
                volatility_forecast=empty_array,
                regime_indicator=empty_zeros,
                efficiency_score=empty_zeros,
                current_regime="unknown",
                current_efficiency=0.0,
                forecast_accuracy=0.0
            )
    
    def _calculate_volatility_trend(self, vol_series: np.ndarray) -> np.ndarray:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—"""
        n = len(vol_series)
        trend = np.zeros(n)
        
        for i in range(5, n):
            x_sum = 10.0
            y_sum = 0.0
            xy_sum = 0.0
            x2_sum = 30.0
            
            for j in range(5):
                y_val = vol_series[i-4+j]
                y_sum += y_val
                xy_sum += j * y_val
            
            denominator = 5 * x2_sum - x_sum * x_sum
            if abs(denominator) > 1e-10:
                slope = (5 * xy_sum - x_sum * y_sum) / denominator
                avg_vol = y_sum / 5
                if abs(avg_vol) > 1e-10:
                    trend[i] = slope / avg_vol
                    trend[i] = max(min(trend[i], 1.0), -1.0)
        
        return trend
    
    def _calculate_forecast(self, vol_series: np.ndarray) -> np.ndarray:
        """æ¬¡æœŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£äºˆæ¸¬"""
        n = len(vol_series)
        forecast = np.full(n, np.nan)
        
        for i in range(3, n):
            alpha = 0.3
            if i >= 1 and not np.isnan(vol_series[i]) and not np.isnan(vol_series[i-1]):
                if not np.isnan(forecast[i-1]):
                    forecast[i] = alpha * vol_series[i-1] + (1-alpha) * forecast[i-1]
                else:
                    forecast[i] = vol_series[i-1]
        
        return forecast
    
    def _calculate_efficiency(self, ultimate_vol: np.ndarray, adaptive_tr: np.ndarray) -> np.ndarray:
        """åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        n = len(ultimate_vol)
        efficiency = np.full(n, np.nan)
        
        for i in range(10, n):
            if adaptive_tr[i] > 1e-10:
                ratio = ultimate_vol[i] / adaptive_tr[i]
                efficiency[i] = max(0.0, 1.0 - abs(ratio - 1.0))
        
        return efficiency
    
    def _determine_current_regime(self, regime_indicator: np.ndarray) -> str:
        """ç¾åœ¨ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¤å®š"""
        if len(regime_indicator) == 0:
            return "unknown"
        
        latest_regime = regime_indicator[-1] if not np.isnan(regime_indicator[-1]) else 0.5
        
        if latest_regime <= 0.33:
            return "low_volatility"
        elif latest_regime >= 0.67:
            return "high_volatility"
        else:
            return "medium_volatility"
    
    def _calculate_forecast_accuracy(self, actual: np.ndarray, forecast: np.ndarray) -> float:
        """äºˆæ¸¬ç²¾åº¦è¨ˆç®—"""
        if len(actual) < 2 or len(forecast) < 2:
            return 0.0
        
        valid_pairs = 0
        total_error = 0.0
        
        for i in range(1, min(len(actual), len(forecast))):
            if not np.isnan(actual[i]) and not np.isnan(forecast[i-1]) and actual[i] > 1e-10:
                error = abs(actual[i] - forecast[i-1]) / actual[i]
                total_error += error
                valid_pairs += 1
        
        if valid_pairs > 0:
            mae = total_error / valid_pairs
            return max(0.0, 1.0 - mae)
        
        return 0.0
    
    def _get_data_hash(self, data) -> str:
        """ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥è¨ˆç®—"""
        try:
            if isinstance(data, pd.DataFrame):
                return f"{hash(data.values.tobytes())}_uv3_{self.period}"
            else:
                return f"{hash(data.tobytes())}_uv3_{self.period}"
        except:
            return f"{id(data)}_uv3_{self.period}"
    
    # === Getter ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤ ===
    
    def get_ultimate_volatility(self) -> Optional[np.ndarray]:
        """çµ±åˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’å–å¾—"""
        if self._cache_keys and self._cache_keys[-1] in self._result_cache:
            result = self._result_cache[self._cache_keys[-1]]
            return result.ultimate_volatility.copy()
        return None
    
    def get_quantum_components(self) -> Optional[Dict]:
        """é‡å­æˆåˆ†ã‚’å–å¾—"""
        if self._cache_keys and self._cache_keys[-1] in self._result_cache:
            result = self._result_cache[self._cache_keys[-1]]
            return {
                'hilbert_amplitude': result.hilbert_amplitude.copy(),
                'hilbert_phase': result.hilbert_phase.copy(),
                'quantum_coherence': result.quantum_coherence.copy(),
                'quantum_entanglement': result.quantum_entanglement.copy()
            }
        return None
    
    def get_wavelet_components(self) -> Optional[Dict]:
        """ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆæˆåˆ†ã‚’å–å¾—"""
        if self._cache_keys and self._cache_keys[-1] in self._result_cache:
            result = self._result_cache[self._cache_keys[-1]]
            return {
                'wavelet_trend': result.wavelet_trend.copy(),
                'wavelet_cycle': result.wavelet_cycle.copy(),
                'market_regime': result.market_regime.copy()
            }
        return None
    
    def get_intelligence_report(self) -> Dict:
        """çŸ¥èƒ½ãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—"""
        if not self._cache_keys or self._cache_keys[-1] not in self._result_cache:
            return {"status": "no_data"}
        
        result = self._result_cache[self._cache_keys[-1]]
        
        return {
            "current_regime": result.current_regime,
            "current_efficiency": result.current_efficiency,
            "forecast_accuracy": result.forecast_accuracy,
            "avg_volatility": float(np.nanmean(result.ultimate_volatility[~np.isnan(result.ultimate_volatility)])) if np.any(~np.isnan(result.ultimate_volatility)) else 0.0,
            "avg_confidence": float(np.nanmean(result.confidence_score[~np.isnan(result.confidence_score)])) if np.any(~np.isnan(result.confidence_score)) else 0.0,
            "quantum_coherence": float(np.nanmean(result.quantum_coherence[~np.isnan(result.quantum_coherence)])) if np.any(~np.isnan(result.quantum_coherence)) else 0.0,
            "quantum_entanglement": float(np.nanmean(result.quantum_entanglement[~np.isnan(result.quantum_entanglement)])) if np.any(~np.isnan(result.quantum_entanglement)) else 0.0,
            "wavelet_trend_strength": float(np.nanmean(result.wavelet_trend[~np.isnan(result.wavelet_trend)])) if np.any(~np.isnan(result.wavelet_trend)) else 0.0
        }
    
    def reset(self) -> None:
        """ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        super().reset()
        self._result_cache = {}
        self._cache_keys = []