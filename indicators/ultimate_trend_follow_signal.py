#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸš€ **Ultimate Trend Follow Signal V1.0 - äººé¡å²ä¸Šæœ€å¼·ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ•ã‚©ãƒ­ãƒ¼ã‚·ã‚°ãƒŠãƒ«** ğŸš€

ç‰©ç†å­¦ã®æ³•å‰‡ã«åŸºã¥ãé©æ–°çš„ã‚·ã‚¹ãƒ†ãƒ ï¼š
- é‡å­åŠ›å­¦ï¼ˆé‡å­ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºå™¨ï¼‰
- æµä½“åŠ›å­¦ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¨ãƒ³ã‚¸ãƒ³ï¼‰  
- ç›¸å¯¾è«–ï¼ˆè¶…ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ è§£æå™¨ï¼‰
- çµ±åˆå‰å‡¦ç†åŸºç›¤å±¤ï¼ˆNeural Supreme Kalman + Quantum Supreme Hilbert + Ultimate Cosmic Waveletï¼‰

5ã¤ã®ä¿¡å·å‡ºåŠ›ï¼š
- ãƒ­ãƒ³ã‚°ã‚·ã‚°ãƒŠãƒ«
- ãƒ­ãƒ³ã‚°ã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚°ãƒŠãƒ«
- ã‚·ãƒ§ãƒ¼ãƒˆã‚·ã‚°ãƒŠãƒ«
- ã‚·ãƒ§ãƒ¼ãƒˆã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚°ãƒŠãƒ«
- ã‚¹ãƒ†ã‚¤ã‚·ã‚°ãƒŠãƒ«

ğŸŒŸ **é©æ–°çš„ç‰¹å¾´:**
- 3æ¬¡å…ƒçŠ¶æ…‹ç©ºé–“ã«ã‚ˆã‚‹è»½é‡åŒ–
- 1æœŸé–“ã§ã®å³åº§é©å¿œå­¦ç¿’
- ç‰©ç†æ³•å‰‡ã«ã‚ˆã‚‹è‡ªå‹•èª¿æ•´
- è¶…é«˜ç²¾åº¦ãƒ»è¶…ä½é…å»¶ãƒ»è¶…è¿½å¾“æ€§ãƒ»è¶…å®‰å®šæ€§
"""

from typing import Union, Optional, Dict, Tuple, NamedTuple
import numpy as np
import pandas as pd
from numba import jit, njit
import warnings
warnings.filterwarnings('ignore')

try:
    from .indicator import Indicator
    from .price_source import PriceSource
    from .kalman_filter_unified import KalmanFilterUnified
    from .hilbert_unified import HilbertTransformUnified
    from .wavelet_unified import WaveletUnified
except ImportError:
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from indicator import Indicator
    from price_source import PriceSource
    from kalman_filter_unified import KalmanFilterUnified
    from hilbert_unified import HilbertTransformUnified
    from wavelet_unified import WaveletUnified


class TrendFollowSignalResult(NamedTuple):
    """ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ•ã‚©ãƒ­ãƒ¼ã‚·ã‚°ãƒŠãƒ«çµæœ"""
    # ãƒ¡ã‚¤ãƒ³ä¿¡å· (0-2: Stay, Long, Short)
    signals: np.ndarray
    
    # 3æ¬¡å…ƒçŠ¶æ…‹ç©ºé–“
    trend_dynamics: np.ndarray          # T(t): [ç¬æ™‚æ–¹å‘æ€§, åŠ é€Ÿåº¦, æŒç¶šåŠ›]
    volatility_state: np.ndarray        # V(t): [ãƒ¬ã‚¸ãƒ¼ãƒ å¼·åº¦, å¤‰åŒ–é€Ÿåº¦, äºˆæ¸¬å¯èƒ½æ€§]
    momentum_state: np.ndarray          # M(t): [å‹¢ã„å¼·åº¦, åæŸåº¦, ç¶™ç¶šç¢ºç‡]
    
    # å€‹åˆ¥ä¿¡å·ç¢ºç‡ (0-1)
    long_probability: np.ndarray
    short_probability: np.ndarray
    stay_probability: np.ndarray
    
    # ä¿¡é ¼åº¦ãƒ»å¼·åº¦
    signal_confidence: np.ndarray       # å…¨ä½“ä¿¡é ¼åº¦
    trend_strength: np.ndarray          # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ»è§£æç”¨
    preprocessing_results: Optional[Dict] = None


class IntegratedPreprocessingFoundation:
    """ğŸŒŸ çµ±åˆå‰å‡¦ç†åŸºç›¤å±¤ã®å®Ÿè£…"""
    
    def __init__(self):
        # ğŸ§ ğŸš€ Neural Adaptive Quantum Supreme Kalman
        self.kalman_filter = KalmanFilterUnified(
            filter_type='neural_supreme',
            base_process_noise=0.0001,
            base_measurement_noise=0.001,
            volatility_window=21
        )
        
        # ğŸŒ€ Quantum Supreme Hilbert Transform  
        self.hilbert_transform = HilbertTransformUnified(
            algorithm_type='quantum_supreme',
            min_periods=16
        )
        
        # ğŸŒŒ Ultimate Cosmic Wavelet
        self.wavelet_analyzer = WaveletUnified(
            wavelet_type='ultimate_cosmic',
            cosmic_power_level=1.0
        )
    
    def process(self, prices: Union[pd.DataFrame, np.ndarray]) -> Dict[str, np.ndarray]:
        """çµ±åˆå‰å‡¦ç†ã®å®Ÿè¡Œ"""
        
        # Phase 1: Neural Supreme Kalmanæ¿¾æ³¢
        kalman_result = self.kalman_filter.calculate(prices)
        
        # Phase 2: Quantum Supreme Hilbertè§£æ
        hilbert_result = self.hilbert_transform.calculate(kalman_result.filtered_values)
        
        # Phase 3: Ultimate Cosmic Waveletå¤‰æ›
        wavelet_result = self.wavelet_analyzer.calculate(kalman_result.filtered_values)
        
        return {
            # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœ
            'kalman_filtered': kalman_result.filtered_values,
            'neural_weights': kalman_result.trend_estimate,
            'quantum_phases_kalman': kalman_result.quantum_coherence,
            'chaos_indicators': kalman_result.uncertainty,
            'confidence_scores': kalman_result.confidence_scores,
            
            # ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›çµæœ
            'hilbert_amplitude': hilbert_result.amplitude,
            'hilbert_phase': hilbert_result.phase,
            'hilbert_frequency': hilbert_result.frequency,
            'quantum_coherence': hilbert_result.quantum_coherence,
            
            # ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆçµæœ
            'cosmic_signal': wavelet_result.values,
            'cosmic_trend': wavelet_result.trend_component,
            'cosmic_cycle': wavelet_result.cycle_component,
            'cosmic_noise': wavelet_result.noise_component,
            'market_regime': wavelet_result.market_regime
        }


@njit(fastmath=True, cache=True)
def quantum_trend_detector_core(
    kalman_filtered: np.ndarray,
    hilbert_phase: np.ndarray,
    hilbert_amplitude: np.ndarray,
    cosmic_signal: np.ndarray,
    window: int = 21
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """ğŸ”¬ é‡å­ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºå™¨ï¼ˆçµ±åˆå‰å‡¦ç†åŸºç›¤å±¤å¼·åŒ–ç‰ˆï¼‰"""
    
    n = len(kalman_filtered)
    direction = np.zeros(n)      # ç¬æ™‚æ–¹å‘æ€§
    acceleration = np.zeros(n)   # åŠ é€Ÿåº¦
    persistence = np.zeros(n)    # æŒç¶šåŠ›
    
    # é‡å­ã‚‚ã¤ã‚ŒåŠ¹æœï¼šçµ±åˆåŸºç›¤å±¤ã«ã‚ˆã‚‹å¼·åŒ–
    entanglement_matrix = np.zeros((window, window))
    for i in range(window):
        for j in range(window):
            if i != j:
                # EPRç›¸é–¢ã‚’ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆä½ç›¸ã§å¼·åŒ–
                base_correlation = np.exp(-abs(i-j) / (window/4))
                if i < len(hilbert_phase) and j < len(hilbert_phase):
                    phase_correlation = np.cos(hilbert_phase[min(i, n-1)] - hilbert_phase[min(j, n-1)])
                    entanglement_matrix[i,j] = base_correlation * (1 + phase_correlation) / 2
                else:
                    entanglement_matrix[i,j] = base_correlation
    
    for i in range(window, n):
        # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿ä¾¡æ ¼ã‚’ä½¿ç”¨
        price_window = kalman_filtered[i-window+1:i+1]
        cosmic_window = cosmic_signal[i-window+1:i+1] if i < len(cosmic_signal) else price_window
        
        # 1. é‡å­é‡ã­åˆã‚ã›çŠ¶æ…‹ã®è¨ˆç®—ï¼ˆãƒ’ãƒ«ãƒ™ãƒ«ãƒˆä½ç›¸å¼·åŒ–ç‰ˆï¼‰
        price_diffs = np.diff(price_window)
        up_probability = np.sum(price_diffs > 0) / len(price_diffs)
        down_probability = np.sum(price_diffs < 0) / len(price_diffs)
        sideways_probability = 1 - up_probability - down_probability
        
        # ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆä½ç›¸ã«ã‚ˆã‚‹é‡å­ä½ç›¸ã®ç²¾å¯†åŒ–
        hilbert_phase_current = hilbert_phase[i] if i < len(hilbert_phase) else 0
        phase_modulation = hilbert_phase_current * 0.1
        
        # æ³¢å‹•é–¢æ•°ã®è¤‡ç´ æŒ¯å¹…ï¼ˆä½ç›¸å¼·åŒ–ç‰ˆï¼‰
        psi_up = np.sqrt(up_probability) * np.exp(1j * (np.pi/4 + phase_modulation))
        psi_down = np.sqrt(down_probability) * np.exp(1j * (3*np.pi/4 + phase_modulation))
        psi_sideways = np.sqrt(sideways_probability) * np.exp(1j * (np.pi/2 + phase_modulation))
        
        # 2. è¦³æ¸¬ã«ã‚ˆã‚‹æ³¢å‹•é–¢æ•°ã®åæŸ
        current_trend = kalman_filtered[i] - kalman_filtered[i-1]
        if current_trend > 0:
            collapsed_state = psi_up
        elif current_trend < 0:
            collapsed_state = psi_down
        else:
            collapsed_state = psi_sideways
            
        direction[i] = np.real(collapsed_state)
        
        # 3. é‡å­ã‚‚ã¤ã‚Œã«ã‚ˆã‚‹éå±€æ‰€ç›¸é–¢ï¼ˆã‚³ã‚ºãƒŸãƒƒã‚¯å¼·åŒ–ç‰ˆï¼‰
        normalized_prices = (price_window - np.mean(price_window)) / (np.std(price_window) + 1e-10)
        entangled_correlation = np.dot(normalized_prices, np.dot(entanglement_matrix, normalized_prices))
        entangled_correlation /= window
        
        # ã‚³ã‚ºãƒŸãƒƒã‚¯ä¿¡å·ã«ã‚ˆã‚‹ç›¸é–¢å¼·åŒ–
        cosmic_current = cosmic_window[-1] if len(cosmic_window) > 0 else 0
        cosmic_enhanced_correlation = entangled_correlation * (1 + abs(cosmic_current))
        
        # 4. ãƒã‚¤ã‚¼ãƒ³ãƒ™ãƒ«ã‚¯ã®ä¸ç¢ºå®šæ€§åŸç†ï¼ˆæŒ¯å¹…å¼·åŒ–ç‰ˆï¼‰
        price_uncertainty = np.std(price_window[-5:])
        momentum_uncertainty = np.std(np.diff(price_window[-5:]))
        uncertainty_product = price_uncertainty * momentum_uncertainty
        
        # ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆæŒ¯å¹…ã«ã‚ˆã‚‹ä¸ç¢ºå®šæ€§è£œæ­£
        amplitude_current = hilbert_amplitude[i] if i < len(hilbert_amplitude) else 1
        amplitude_factor = 1 / (amplitude_current + 1e-10)
        
        certainty_factor = amplitude_factor / (1 + uncertainty_product)
        
        # 5. ç¬æ™‚3ç‚¹å¾®åˆ†ã«ã‚ˆã‚‹è¶…é«˜é€ŸåŠ é€Ÿåº¦æ¤œå‡ºï¼ˆã‚«ãƒ«ãƒãƒ³å¼·åŒ–ç‰ˆï¼‰
        if i >= 2:
            second_derivative = kalman_filtered[i] - 2*kalman_filtered[i-1] + kalman_filtered[i-2]
            quantum_acceleration = second_derivative * certainty_factor * cosmic_enhanced_correlation
            acceleration[i] = np.tanh(quantum_acceleration)
        
        # 6. é‡å­å¹²æ¸‰ã«ã‚ˆã‚‹æŒç¶šåŠ›è¨ˆç®—ï¼ˆçµ±åˆç‰ˆï¼‰
        if i >= window:
            past_trends = np.sign(np.diff(kalman_filtered[i-window:i]))
            current_direction = np.sign(kalman_filtered[i] - kalman_filtered[i-1])
            
            interference_pattern = 0
            for t in range(len(past_trends)):
                phase_difference = np.pi * (past_trends[t] != current_direction)
                
                # ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆä½ç›¸ã«ã‚ˆã‚‹å¹²æ¸‰å¼·åŒ–
                if i-t >= 0 and i-t < len(hilbert_phase):
                    phase_coherence = np.cos(hilbert_phase[i] - hilbert_phase[i-t])
                else:
                    phase_coherence = 1
                
                # ã‚³ã‚ºãƒŸãƒƒã‚¯æˆåˆ†ã«ã‚ˆã‚‹æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«é‡ã¿ä»˜ã‘
                if i-t >= 0 and i-t < len(cosmic_signal):
                    cosmic_weight = 1 + abs(cosmic_signal[i-t])
                else:
                    cosmic_weight = 1
                
                interference_term = (np.cos(phase_difference) * phase_coherence * 
                                   cosmic_weight * np.exp(-t/window))
                interference_pattern += interference_term
            
            persistence[i] = np.tanh(interference_pattern / len(past_trends))
    
    return direction, acceleration, persistence


@njit(fastmath=True, cache=True)
def fluid_volatility_engine_core(
    kalman_filtered: np.ndarray,
    hilbert_amplitude: np.ndarray,
    cosmic_cycle: np.ndarray,
    window: int = 21
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """ğŸ’§ æµä½“åŠ›å­¦ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆçµ±åˆå¼·åŒ–ç‰ˆï¼‰"""
    
    n = len(kalman_filtered)
    regime_strength = np.zeros(n)    # ãƒ¬ã‚¸ãƒ¼ãƒ å¼·åº¦
    change_velocity = np.zeros(n)    # å¤‰åŒ–é€Ÿåº¦
    predictability = np.zeros(n)     # äºˆæ¸¬å¯èƒ½æ€§
    
    for i in range(window, n):
        price_window = kalman_filtered[i-window+1:i+1]
        returns = np.diff(price_window)
        
        # 1. æµä½“é€Ÿåº¦å ´ã®å®šç¾©ï¼ˆãƒ’ãƒ«ãƒ™ãƒ«ãƒˆæŒ¯å¹…å¼·åŒ–ï¼‰
        velocity = returns / price_window[:-1]
        mean_velocity = np.mean(velocity)
        velocity_variance = np.var(velocity)
        
        # ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆæŒ¯å¹…ã«ã‚ˆã‚‹é€Ÿåº¦å ´è£œæ­£
        amplitude_current = hilbert_amplitude[i] if i < len(hilbert_amplitude) else 1
        amplitude_corrected_variance = velocity_variance * amplitude_current
        
        # 2. ãƒ¬ã‚¤ãƒãƒ«ã‚ºæ•°ã®è¨ˆç®—ï¼ˆãƒ¬ã‚¸ãƒ¼ãƒ å¼·åº¦ï¼‰
        characteristic_length = np.std(price_window)
        kinematic_viscosity = amplitude_corrected_variance + 1e-10
        
        reynolds = abs(mean_velocity) * characteristic_length / kinematic_viscosity
        regime_strength[i] = np.tanh(reynolds / 2300)  # æ­£è¦åŒ– (0-1)
        
        # 3. å¤‰åŒ–é€Ÿåº¦ã®è¨ˆç®—ï¼ˆã‚³ã‚ºãƒŸãƒƒã‚¯ã‚µã‚¤ã‚¯ãƒ«å¼·åŒ–ï¼‰
        if len(cosmic_cycle) > i:
            cosmic_factor = 1 + abs(cosmic_cycle[i])
        else:
            cosmic_factor = 1
            
        change_velocity[i] = abs(mean_velocity) * cosmic_factor
        
        # 4. äºˆæ¸¬å¯èƒ½æ€§ã®è¨ˆç®—ï¼ˆç²˜æ€§ä¿‚æ•°ãƒ™ãƒ¼ã‚¹ï¼‰
        turbulence_intensity = np.sqrt(amplitude_corrected_variance) / (abs(mean_velocity) + 1e-10)
        
        if reynolds > 2300:  # ä¹±æµ
            predictability[i] = 1.0 / (1.0 + turbulence_intensity)
        else:  # å±¤æµ
            predictability[i] = 0.8 + 0.2 / (1.0 + turbulence_intensity)
    
    return regime_strength, change_velocity, predictability


@njit(fastmath=True, cache=True)
def ultra_momentum_analyzer_core(
    kalman_filtered: np.ndarray,
    hilbert_frequency: np.ndarray,
    cosmic_trend: np.ndarray,
    window: int = 21
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """âš¡ è¶…ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ è§£æå™¨ï¼ˆçµ±åˆå¼·åŒ–ç‰ˆï¼‰"""
    
    n = len(kalman_filtered)
    momentum_strength = np.zeros(n)     # å‹¢ã„å¼·åº¦
    convergence = np.zeros(n)           # åæŸåº¦
    continuation_probability = np.zeros(n)  # ç¶™ç¶šç¢ºç‡
    
    # ç‰©ç†å®šæ•°
    c_market = 1.0  # å¸‚å ´ã®ã€Œå…‰é€Ÿã€
    
    for i in range(window, n):
        price_window = kalman_filtered[i-window+1:i+1]
        returns = np.diff(price_window)
        
        # 1. ç›¸å¯¾è«–çš„é‹å‹•é‡ã®è¨ˆç®—ï¼ˆå‘¨æ³¢æ•°å¼·åŒ–ç‰ˆï¼‰
        velocity = returns / price_window[:-1]
        mean_velocity = np.mean(velocity)
        
        # å…‰é€Ÿåˆ¶é™ã®é©ç”¨
        if np.abs(mean_velocity) >= c_market:
            mean_velocity = c_market * np.sign(mean_velocity) * 0.99
        
        # ãƒ­ãƒ¼ãƒ¬ãƒ³ãƒ„å› å­ï¼ˆãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå‘¨æ³¢æ•°å¼·åŒ–ï¼‰
        frequency_current = hilbert_frequency[i] if i < len(hilbert_frequency) else 0.1
        frequency_factor = 1 + frequency_current
        
        gamma = frequency_factor / np.sqrt(1 - (mean_velocity/c_market)**2)
        
        # ç›¸å¯¾è«–çš„é‹å‹•é‡
        rest_mass = np.std(price_window)
        relativistic_momentum = gamma * rest_mass * mean_velocity
        momentum_strength[i] = np.tanh(relativistic_momentum)
        
        # 2. ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¿å­˜å‰‡ï¼ˆã‚³ã‚ºãƒŸãƒƒã‚¯ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åŒ–ï¼‰
        rest_energy = rest_mass * c_market**2
        momentum_energy = (relativistic_momentum * c_market)**2
        total_energy = np.sqrt(momentum_energy + rest_energy**2)
        kinetic_energy = total_energy - rest_energy
        
        # ã‚³ã‚ºãƒŸãƒƒã‚¯ãƒˆãƒ¬ãƒ³ãƒ‰ã«ã‚ˆã‚‹ ã‚¨ãƒãƒ«ã‚®ãƒ¼å¢—å¹…
        if len(cosmic_trend) > i:
            cosmic_trend_factor = 1 + np.abs(cosmic_trend[i])
        else:
            cosmic_trend_factor = 1
            
        enhanced_kinetic_energy = kinetic_energy * cosmic_trend_factor
        
        # 3. åæŸåº¦ã®è¨ˆç®—ï¼ˆæ…£æ€§ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆãƒ™ãƒ¼ã‚¹ï¼‰
        if len(returns) >= 3:
            abs_returns = np.abs(returns)
            mass_distribution = abs_returns / (np.sum(abs_returns) + 1e-10)
            distances_squared = (returns - mean_velocity * price_window[:-1])**2
            moment_of_inertia = np.sum(mass_distribution * distances_squared)
            convergence[i] = 1.0 / (1.0 + moment_of_inertia)
        
        # 4. ç¶™ç¶šç¢ºç‡ã®è¨ˆç®—ï¼ˆæ‘©æ“¦ä¿‚æ•°ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ™ãƒ¼ã‚¹ï¼‰
        volatility = np.std(returns)
        friction_coefficient = volatility * (1 - convergence[i])  # åæŸåº¦ãŒé«˜ã„ã»ã©æ‘©æ“¦å°
        
        if enhanced_kinetic_energy > 0:
            energy_dissipation_rate = friction_coefficient / enhanced_kinetic_energy
            continuation_probability[i] = max(0, 1 - energy_dissipation_rate)
        else:
            continuation_probability[i] = 0.5
    
    return momentum_strength, convergence, continuation_probability


@njit(fastmath=True, cache=True)
def integrated_signal_generator(
    trend_dynamics: np.ndarray,      # [direction, acceleration, persistence]
    volatility_state: np.ndarray,    # [regime_strength, change_velocity, predictability]
    momentum_state: np.ndarray,      # [momentum_strength, convergence, continuation_probability]
    quantum_sensitivity: float = 1.0  # é‡å­æ„Ÿåº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """ğŸ¯ çµ±åˆä¿¡å·ç”Ÿæˆå™¨ï¼ˆç‰©ç†å­¦çš„èåˆï¼‰- 3ã‚·ã‚°ãƒŠãƒ«ç‰ˆ"""
    
    n = len(trend_dynamics)
    
    # 3ã¤ã®ä¿¡å·ç¢ºç‡
    long_prob = np.zeros(n)
    short_prob = np.zeros(n)
    stay_prob = np.zeros(n)
    
    signal_confidence = np.zeros(n)
    trend_strength = np.zeros(n)
    
    for i in range(n):
        # 3æ¬¡å…ƒçŠ¶æ…‹ã®æŠ½å‡º
        direction = trend_dynamics[i] if not np.isnan(trend_dynamics[i]) else 0
        acceleration = trend_dynamics[i] if i < len(trend_dynamics) else 0  # ç°¡ç•¥åŒ–
        persistence = trend_dynamics[i] if not np.isnan(trend_dynamics[i]) else 0
        
        regime_strength = volatility_state[i] if not np.isnan(volatility_state[i]) else 0.5
        change_velocity = volatility_state[i] if i < len(volatility_state) else 0  # ç°¡ç•¥åŒ–
        predictability = volatility_state[i] if not np.isnan(volatility_state[i]) else 0.5
        
        momentum_strength = momentum_state[i] if not np.isnan(momentum_state[i]) else 0
        convergence = momentum_state[i] if i < len(momentum_state) else 0  # ç°¡ç•¥åŒ–
        continuation_prob = momentum_state[i] if not np.isnan(momentum_state[i]) else 0.5
        
        # ç‰©ç†å­¦çš„çµ±åˆçŠ¶æ…‹æ–¹ç¨‹å¼
        # F = ma (ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ³ç¬¬2æ³•å‰‡)
        force = direction * np.abs(acceleration) * momentum_strength
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¿å­˜å‰‡
        potential_energy = persistence * predictability
        kinetic_energy = np.abs(momentum_strength) * continuation_prob
        total_energy = potential_energy + kinetic_energy
        
        # æµä½“åŠ›å­¦çš„å®‰å®šæ€§
        flow_stability = predictability * (1 - regime_strength)  # å±¤æµã»ã©å®‰å®š
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ï¼ˆçµ±åˆæŒ‡æ¨™ï¼‰
        trend_strength[i] = np.tanh(np.abs(force) + total_energy)
        
        # ä¿¡å·ç¢ºç‡è¨ˆç®—ï¼ˆå®Ÿè·µçš„ãªé–¾å€¤ã«èª¿æ•´ï¼‰
        force_magnitude = np.abs(force)
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã®å‹•çš„èª¿æ•´
        trend_signal_strength = trend_strength[i] * 5.0  # æ„Ÿåº¦ã‚’5å€ã«å¢—åŠ 
        momentum_signal = np.abs(momentum_strength) * 3.0  # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ æ„Ÿåº¦ã‚’3å€ã«
        
        # ã‚ˆã‚Šå®Ÿè·µçš„ãªæ¡ä»¶è¨­å®šï¼ˆé‡å­æ„Ÿåº¦ã‚’é©ç”¨ï¼‰
        quantum_boost = 1.0 + (quantum_sensitivity - 1.0) * 0.5
        
        if force > 0.02 / quantum_boost and trend_signal_strength > 0.3 / quantum_boost and continuation_prob > 0.4:
            # ãƒ­ãƒ³ã‚°æ¡ä»¶ï¼šã‚ˆã‚Šä½ã„é–¾å€¤ã§åå¿œ
            signal_strength = force * trend_signal_strength * (1 + momentum_signal)
            long_prob[i] = min(0.85, signal_strength * 2.0)
            
        elif force < -0.02 / quantum_boost and trend_signal_strength > 0.3 / quantum_boost and continuation_prob > 0.4:
            # ã‚·ãƒ§ãƒ¼ãƒˆæ¡ä»¶ï¼šè² ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æ•æ„Ÿã«æ¤œå‡º
            signal_strength = force_magnitude * trend_signal_strength * (1 + momentum_signal)
            short_prob[i] = min(0.85, signal_strength * 2.0)
            
        # ã‚µã‚¤ãƒ‰ã‚¦ã‚§ã‚¤ã‚º/ãƒ¬ãƒ³ã‚¸ç›¸å ´ã®æ¤œå‡º
        elif force_magnitude < 0.02 and trend_signal_strength < 0.3:
            # ã‚ˆã‚Šç©æ¥µçš„ãªãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡º
            if momentum_signal > 0.1:
                # å¾®ç´°ãªãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã‚‚æ‰ãˆã‚‹
                if force > 0:
                    long_prob[i] = min(0.6, momentum_signal * 2.0)
                else:
                    short_prob[i] = min(0.6, momentum_signal * 2.0)
            else:
                stay_prob[i] = max(0.3, 0.8 - momentum_signal)  # Stayã®ç¢ºç‡ã‚’ä¸‹ã’ã‚‹
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã‚ˆã‚Šå‹•çš„ãªåˆ¤å®š
            stay_prob[i] = max(0.2, 0.6 - trend_signal_strength - momentum_signal)
        
        # ç¢ºç‡ã®æ­£è¦åŒ–ï¼ˆå…¨ç¢ºç‡ã®åˆè¨ˆã‚’1ã«ã™ã‚‹ï¼‰
        total_prob = long_prob[i] + short_prob[i] + stay_prob[i]
        if total_prob > 1.0:
            normalization_factor = 1.0 / total_prob
            long_prob[i] *= normalization_factor
            short_prob[i] *= normalization_factor
            stay_prob[i] *= normalization_factor
        elif total_prob < 0.8:
            # ä½ã„ç¢ºç‡ã®å ´åˆã¯stayã«é‡ã¿ä»˜ã‘
            remaining = 1.0 - total_prob
            stay_prob[i] += remaining
        
        # ä¿¡é ¼åº¦ï¼ˆç‰©ç†çš„ä¸€è²«æ€§ï¼‰
        signal_confidence[i] = predictability * convergence * (1 - regime_strength * 0.5)
    
    return long_prob, short_prob, stay_prob, signal_confidence, trend_strength


class UltimateTrendFollowSignal(Indicator):
    """
    ğŸš€ Ultimate Trend Follow Signal - äººé¡å²ä¸Šæœ€å¼·ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ•ã‚©ãƒ­ãƒ¼ã‚·ã‚°ãƒŠãƒ«
    
    ç‰©ç†å­¦ã®æ³•å‰‡ã«åŸºã¥ãé©æ–°çš„ã‚·ã‚¹ãƒ†ãƒ ï¼š
    - é‡å­åŠ›å­¦ï¼šé‡å­ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºå™¨
    - æµä½“åŠ›å­¦ï¼šãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¨ãƒ³ã‚¸ãƒ³  
    - ç›¸å¯¾è«–ï¼šè¶…ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ è§£æå™¨
    - çµ±åˆå‰å‡¦ç†ï¼šNeural Supreme + Quantum Supreme + Ultimate Cosmic
    """
    
    def __init__(
        self,
        src_type: str = 'close',
        window: int = 21,
        # ç‰©ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        quantum_sensitivity: float = 1.0,
        fluid_turbulence_threshold: float = 2300.0,
        relativistic_c_market: float = 1.0,
        # ä¿¡å·ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        signal_threshold: float = 0.3,  # ã‚ˆã‚Šä½ã„é–¾å€¤ã§å®Ÿè·µçš„ã«
        confidence_threshold: float = 0.2,  # ä¿¡é ¼åº¦é–¾å€¤ã‚‚ä¸‹ã’ã‚‹
        enable_debug: bool = False
    ):
        """
        Args:
            src_type: ä¾¡æ ¼ã‚½ãƒ¼ã‚¹
            window: è§£æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            quantum_sensitivity: é‡å­æ„Ÿåº¦
            fluid_turbulence_threshold: æµä½“ä¹±æµé–¾å€¤
            relativistic_c_market: ç›¸å¯¾è«–çš„å¸‚å ´å…‰é€Ÿ
            signal_threshold: ã‚·ã‚°ãƒŠãƒ«é–¾å€¤
            confidence_threshold: ä¿¡é ¼åº¦é–¾å€¤
            enable_debug: ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
        """
        name = f"UltimateTrendFollowSignal(window={window}, src={src_type})"
        super().__init__(name)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¿å­˜
        self.src_type = src_type
        self.window = window
        self.quantum_sensitivity = quantum_sensitivity
        self.fluid_turbulence_threshold = fluid_turbulence_threshold
        self.relativistic_c_market = relativistic_c_market
        self.signal_threshold = signal_threshold
        self.confidence_threshold = confidence_threshold
        self.enable_debug = enable_debug
        
        # çµ±åˆå‰å‡¦ç†åŸºç›¤å±¤
        self.preprocessing_foundation = IntegratedPreprocessingFoundation()
        
        # çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._result: Optional[TrendFollowSignalResult] = None
        self._cache_hash: Optional[str] = None
    
    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> TrendFollowSignalResult:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ•ã‚©ãƒ­ãƒ¼ã‚·ã‚°ãƒŠãƒ«ã‚’è¨ˆç®—"""
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        current_hash = self._get_data_hash(data)
        if self._cache_hash == current_hash and self._result is not None:
            return self._result
        
        try:
            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
            src_prices = PriceSource.calculate_source(data, self.src_type)
            
            if len(src_prices) < self.window * 2:
                return self._create_empty_result(len(src_prices))
            
            # Phase 1: ğŸŒŸ çµ±åˆå‰å‡¦ç†åŸºç›¤å±¤
            preprocessing_results = self.preprocessing_foundation.process(src_prices)
            
            # Phase 2: ğŸ”¬ é‡å­ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºå™¨
            direction, acceleration, persistence = quantum_trend_detector_core(
                preprocessing_results['kalman_filtered'],
                preprocessing_results['hilbert_phase'], 
                preprocessing_results['hilbert_amplitude'],
                preprocessing_results['cosmic_signal'],
                self.window
            )
            
            # Phase 3: ğŸ’§ æµä½“åŠ›å­¦ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¨ãƒ³ã‚¸ãƒ³
            regime_strength, change_velocity, predictability = fluid_volatility_engine_core(
                preprocessing_results['kalman_filtered'],
                preprocessing_results['hilbert_amplitude'],
                preprocessing_results['cosmic_cycle'] if preprocessing_results['cosmic_cycle'] is not None else np.zeros(len(src_prices)),
                self.window
            )
            
            # Phase 4: âš¡ è¶…ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ è§£æå™¨
            momentum_strength, convergence, continuation_probability = ultra_momentum_analyzer_core(
                preprocessing_results['kalman_filtered'],
                preprocessing_results['hilbert_frequency'],
                preprocessing_results['cosmic_trend'] if preprocessing_results['cosmic_trend'] is not None else np.zeros(len(src_prices)),
                self.window
            )
            
            # Phase 5: ğŸ¯ çµ±åˆä¿¡å·ç”Ÿæˆ
            (long_prob, short_prob, stay_prob, 
             signal_confidence, trend_strength) = integrated_signal_generator(
                direction,  # ç°¡ç•¥åŒ–ï¼š3æ¬¡å…ƒã®ä»£è¡¨å€¤ã¨ã—ã¦ä½¿ç”¨
                regime_strength,  # ç°¡ç•¥åŒ–ï¼š3æ¬¡å…ƒã®ä»£è¡¨å€¤ã¨ã—ã¦ä½¿ç”¨  
                momentum_strength,  # ç°¡ç•¥åŒ–ï¼š3æ¬¡å…ƒã®ä»£è¡¨å€¤ã¨ã—ã¦ä½¿ç”¨
                self.quantum_sensitivity  # é‡å­æ„Ÿåº¦ã‚’æ¸¡ã™
            )
            
            # æœ€çµ‚ã‚·ã‚°ãƒŠãƒ«æ±ºå®š
            signals = self._determine_final_signals(
                long_prob, short_prob, stay_prob,
                signal_confidence
            )
            
            # çµæœæ§‹ç¯‰
            result = TrendFollowSignalResult(
                signals=signals,
                trend_dynamics=direction,  # ç°¡ç•¥åŒ–
                volatility_state=regime_strength,  # ç°¡ç•¥åŒ–
                momentum_state=momentum_strength,  # ç°¡ç•¥åŒ–
                long_probability=long_prob,
                short_probability=short_prob,
                stay_probability=stay_prob,
                signal_confidence=signal_confidence,
                trend_strength=trend_strength,
                preprocessing_results=preprocessing_results if self.enable_debug else None
            )
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°
            self._result = result
            self._cache_hash = current_hash
            
            return result
            
        except Exception as e:
            self.logger.error(f"Ultimate Trend Follow Signalè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return self._create_empty_result(len(data) if hasattr(data, '__len__') else 0)
    
    def _determine_final_signals(
        self,
        long_prob: np.ndarray,
        short_prob: np.ndarray,
        stay_prob: np.ndarray,
        confidence: np.ndarray
    ) -> np.ndarray:
        """æœ€çµ‚ã‚·ã‚°ãƒŠãƒ«æ±ºå®šï¼ˆ3ã‚·ã‚°ãƒŠãƒ«ç‰ˆï¼‰"""
        
        n = len(long_prob)
        signals = np.zeros(n)  # 0: Stay, 1: Long, 2: Short
        
        for i in range(n):
            # ã‚ˆã‚Šå®Ÿè·µçš„ãªåˆ¤å®šï¼šä¿¡é ¼åº¦ã®é–¾å€¤ã‚’æŸ”è»Ÿã«é©ç”¨
            base_confidence_threshold = self.confidence_threshold
            
            # å„ç¢ºç‡ã‚’é›†è¨ˆ
            probs = [stay_prob[i], long_prob[i], short_prob[i]]
            max_idx = np.argmax(probs)
            max_prob = probs[max_idx]
            
            # å‹•çš„ãªé–¾å€¤åˆ¤å®šï¼ˆä¿¡å·ã®ç¨®é¡ã«ã‚ˆã£ã¦é–¾å€¤ã‚’èª¿æ•´ï¼‰
            if max_idx == 0:  # Stay
                # Stayã«ã¯é«˜ã„é–¾å€¤ã‚’è¦æ±‚ï¼ˆã‚ˆã‚Šã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«ã™ã‚‹ï¼‰
                if max_prob >= 0.7 and confidence[i] >= base_confidence_threshold:
                    signals[i] = 0
                else:
                    # StayãŒæ¡ä»¶ã‚’æº€ãŸã•ãªã„å ´åˆã€æ¬¡ã«é«˜ã„ç¢ºç‡ã®ä¿¡å·ã‚’æ¤œè¨
                    probs[0] = 0  # Stayã‚’é™¤å¤–
                    second_idx = np.argmax(probs)
                    second_prob = probs[second_idx]
                    
                    if second_prob >= self.signal_threshold * 0.8:  # ã‚ˆã‚Šä½ã„é–¾å€¤
                        signals[i] = second_idx
                    else:
                        signals[i] = 0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§Stay
            else:
                # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ã‚°ãƒŠãƒ«ï¼ˆLong, Shortï¼‰ã®å ´åˆ
                signal_threshold = self.signal_threshold
                
                # ãƒˆãƒ¬ãƒ³ãƒ‰ã‚·ã‚°ãƒŠãƒ«ã¯ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã‚’è€ƒæ…®
                if max_idx in [1, 2]:  # Long, Short
                    # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ãŒå¼·ã„å ´åˆã¯é–¾å€¤ã‚’ä¸‹ã’ã‚‹
                    momentum_boost = min(0.3, abs(self._get_momentum_at_index(i)) * 0.5)
                    signal_threshold = max(0.15, signal_threshold - momentum_boost)
                
                if max_prob >= signal_threshold:
                    signals[i] = max_idx
                else:
                    signals[i] = 0  # Stay (é–¾å€¤æœªæº€)
        
        return signals
    
    def _get_momentum_at_index(self, i: int) -> float:
        """æŒ‡å®šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ã®ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ å€¤ã‚’å–å¾—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        if self._result and i < len(self._result.momentum_state):
            return self._result.momentum_state[i]
        return 0.0
    
    def _create_empty_result(self, length: int) -> TrendFollowSignalResult:
        """ç©ºã®çµæœã‚’ä½œæˆ"""
        return TrendFollowSignalResult(
            signals=np.zeros(length),
            trend_dynamics=np.zeros(length),
            volatility_state=np.zeros(length), 
            momentum_state=np.zeros(length),
            long_probability=np.zeros(length),
            short_probability=np.zeros(length),
            stay_probability=np.ones(length),
            signal_confidence=np.zeros(length),
            trend_strength=np.zeros(length)
        )
    
    def _get_data_hash(self, data) -> str:
        """ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—"""
        try:
            if hasattr(data, 'values'):
                return str(hash(data.values.tobytes()))
            else:
                return str(hash(data.tobytes()))
        except:
            return str(len(data))
    
    def get_signals(self) -> Optional[np.ndarray]:
        """ã‚·ã‚°ãƒŠãƒ«é…åˆ—ã‚’å–å¾—"""
        if self._result is not None:
            return self._result.signals.copy()
        return None
    
    def get_signal_probabilities(self) -> Optional[Dict[str, np.ndarray]]:
        """å„ã‚·ã‚°ãƒŠãƒ«ã®ç¢ºç‡ã‚’å–å¾—"""
        if self._result is None:
            return None
        
        return {
            'long': self._result.long_probability.copy(),
            'short': self._result.short_probability.copy(),
            'stay': self._result.stay_probability.copy()
        }
    
    def get_analysis_components(self) -> Optional[Dict[str, np.ndarray]]:
        """è§£æã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å–å¾—"""
        if self._result is None:
            return None
        
        return {
            'trend_dynamics': self._result.trend_dynamics.copy(),
            'volatility_state': self._result.volatility_state.copy(),
            'momentum_state': self._result.momentum_state.copy(),
            'signal_confidence': self._result.signal_confidence.copy(),
            'trend_strength': self._result.trend_strength.copy()
        }
    
    def get_preprocessing_results(self) -> Optional[Dict]:
        """å‰å‡¦ç†çµæœã‚’å–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿ï¼‰"""
        if self._result is not None and self._result.preprocessing_results is not None:
            return self._result.preprocessing_results.copy()
        return None
    
    def reset(self) -> None:
        """çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self._result = None
        self._cache_hash = None
        self.preprocessing_foundation = IntegratedPreprocessingFoundation()


# ã‚·ã‚°ãƒŠãƒ«å®šæ•°ï¼ˆ3ã¤ã«ã‚·ãƒ³ãƒ—ãƒ«åŒ–ï¼‰
SIGNAL_STAY = 0
SIGNAL_LONG = 1
SIGNAL_SHORT = 2

SIGNAL_NAMES = {
    SIGNAL_STAY: "Stay",
    SIGNAL_LONG: "Long", 
    SIGNAL_SHORT: "Short"
}


def example_usage():
    """ä½¿ç”¨ä¾‹"""
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    dates = pd.date_range('2023-01-01', periods=1000, freq='1H')
    np.random.seed(42)
    prices = 100 + np.cumsum(np.random.randn(1000) * 0.01)
    
    data = pd.DataFrame({
        'open': prices + np.random.randn(1000) * 0.001,
        'high': prices + abs(np.random.randn(1000) * 0.002),
        'low': prices - abs(np.random.randn(1000) * 0.002),
        'close': prices,
        'volume': np.random.randint(1000, 10000, 1000)
    }, index=dates)
    
    # ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ä½œæˆãƒ»å®Ÿè¡Œ
    indicator = UltimateTrendFollowSignal(
        window=21,
        signal_threshold=0.6,
        confidence_threshold=0.5,
        enable_debug=True
    )
    
    result = indicator.calculate(data)
    
    print("ğŸš€ Ultimate Trend Follow Signal Results:")
    print(f"Total signals: {len(result.signals)}")
    print(f"Long signals: {np.sum(result.signals == SIGNAL_LONG)}")
    print(f"Short signals: {np.sum(result.signals == SIGNAL_SHORT)}")
    print(f"Stay signals: {np.sum(result.signals == SIGNAL_STAY)}")
    print(f"Average confidence: {np.mean(result.signal_confidence):.3f}")
    print(f"Average trend strength: {np.mean(result.trend_strength):.3f}")


if __name__ == "__main__":
    example_usage() 