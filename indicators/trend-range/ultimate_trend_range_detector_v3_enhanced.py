#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union
from numba import jit, prange
import warnings
warnings.filterwarnings('ignore')


@jit(nopython=True)
def calculate_efficiency_ratio_enhanced(prices: np.ndarray, period: int) -> np.ndarray:
    """
    ğŸš€ åŠ¹ç‡æ¯”è¨ˆç®—ï¼ˆã‚¨ãƒ³ãƒãƒ³ã‚¹ç‰ˆãƒ»ä¿å®ˆçš„èª¿æ•´ï¼‰
    ã‚ˆã‚Šä¿å®ˆçš„ãªåŠ¹ç‡æ¯”æ¸¬å®šã§ç¢ºå®Ÿãªãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡º
    """
    n = len(prices)
    er = np.zeros(n)
    
    for i in range(period, n):
        # ç›´ç·šè·é›¢ï¼ˆæœŸé–“ã®æœ€åˆã‹ã‚‰æœ€å¾Œã¸ã®ä¾¡æ ¼å¤‰åŒ–ï¼‰
        change = abs(prices[i] - prices[i-period])
        
        # å®Ÿéš›ã®çµŒè·¯è·é›¢ï¼ˆä¾¡æ ¼å¤‰åŒ–ã®çµ¶å¯¾å€¤ã®åˆè¨ˆï¼‰
        volatility = 0.0
        for j in range(i-period, i):
            volatility += abs(prices[j+1] - prices[j])
        
        # åŠ¹ç‡æ¯”ã®è¨ˆç®—ï¼ˆã‚ˆã‚Šä¿å®ˆçš„ã«ï¼‰
        if volatility > 1e-12:
            er[i] = change / volatility
            # åŠ¹ç‡æ¯”ã®ãƒ–ãƒ¼ã‚¹ãƒˆã‚’æ§ãˆã‚ã«ï¼ˆå¼·ã„ãƒˆãƒ¬ãƒ³ãƒ‰ã®ã¿ã‚’ãƒ–ãƒ¼ã‚¹ãƒˆï¼‰
            if er[i] > 0.5:  # ã‚ˆã‚Šé«˜ã„é–¾å€¤ã§ãƒ–ãƒ¼ã‚¹ãƒˆ
                er[i] = min(1.0, er[i] * 1.1)  # ãƒ–ãƒ¼ã‚¹ãƒˆå€ç‡ã‚’ä¸‹ã’ã‚‹
        else:
            er[i] = 1.0
    
    return er


@jit(nopython=True)
def calculate_enhanced_momentum_consistency(prices: np.ndarray) -> np.ndarray:
    """
    ğŸ¯ ã‚¨ãƒ³ãƒãƒ³ã‚¹ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ä¸€è²«æ€§ï¼ˆä¿å®ˆçš„èª¿æ•´ç‰ˆï¼‰
    """
    n = len(prices)
    consistency = np.zeros(n)
    periods = np.array([3, 7, 14, 21, 35])
    
    for i in range(35, n):
        directions = np.zeros(len(periods))
        weights = np.array([0.25, 0.25, 0.25, 0.15, 0.1])  # ã‚ˆã‚Šå‡ç­‰ãªé‡ã¿ä»˜ã‘
        
        for j, period in enumerate(periods):
            if i >= period:
                momentum = (prices[i] - prices[i-period]) / prices[i-period]
                # ã‚ˆã‚Šå³ã—ã„é–¾å€¤ã§æ–¹å‘ã‚’åˆ¤å®šï¼ˆä¿å®ˆçš„ã«ï¼‰
                if momentum > 0.005:  # 0.5%ä»¥ä¸Šã®ä¸Šæ˜‡ï¼ˆ0.2%ã‹ã‚‰ä¸Šã’ã‚‹ï¼‰
                    directions[j] = 1.0
                elif momentum < -0.005:  # 0.5%ä»¥ä¸Šã®ä¸‹é™
                    directions[j] = -1.0
        
        # é‡ã¿ä»˜ãä¸€è‡´åº¦è¨ˆç®—
        if np.sum(np.abs(directions)) > 0:
            weighted_sum = np.sum(directions * weights)
            weight_sum = np.sum(weights[np.abs(directions) > 0])
            if weight_sum > 0:
                consistency[i] = abs(weighted_sum) / weight_sum
        else:
            consistency[i] = 0.0
    
    return consistency


@jit(nopython=True)
def enhanced_adaptive_threshold(er: np.ndarray, chop: np.ndarray, adx: np.ndarray,
                               vol_adj: np.ndarray, period: int = 30) -> np.ndarray:
    """
    ğŸ§  ã‚¨ãƒ³ãƒãƒ³ã‚¹é©å¿œçš„é–¾å€¤ï¼ˆãƒãƒ©ãƒ³ã‚¹èª¿æ•´ç‰ˆï¼‰
    """
    n = len(er)
    threshold = np.full(n, 0.40)  # ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ï¼ˆ0.45ã‹ã‚‰ä¸‹ã’ã‚‹ï¼‰
    
    for i in range(period, n):
        # éå»ã®æŒ‡æ¨™å€¤ã®çµ±è¨ˆ
        er_mean = np.mean(er[i-period+1:i+1])
        chop_mean = np.mean(chop[i-period+1:i+1])
        adx_mean = np.mean(adx[i-period+1:i+1])
        
        # ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã•ã‚ŒãŸé–¾å€¤èª¿æ•´
        base_threshold = 0.40
        
        # é«˜ADXæœŸé–“ã§ã®èª¿æ•´ï¼ˆé©åº¦ã«ï¼‰
        if adx_mean > 25:  # ä¸­é–“çš„ãªé–¾å€¤
            base_threshold -= 0.10  # é©åº¦ãªèª¿æ•´
        elif adx_mean > 18:
            base_threshold -= 0.06
        elif adx_mean < 12:
            base_threshold += 0.08
        
        # ä½ChopæœŸé–“ã§ã®èª¿æ•´ï¼ˆé©åº¦ã«ï¼‰
        if chop_mean < 45:  # ä¸­é–“çš„ãªæ¡ä»¶
            base_threshold -= 0.08  # é©åº¦ãªèª¿æ•´
        elif chop_mean > 65:  # ä¸­é–“çš„ãªæ¡ä»¶
            base_threshold += 0.12
        
        # é«˜åŠ¹ç‡æ¯”æœŸé–“ã§ã®èª¿æ•´ï¼ˆé©åº¦ã«ï¼‰
        if er_mean > 0.45:  # ä¸­é–“çš„ãªé–¾å€¤
            base_threshold -= 0.05  # é©åº¦ãªèª¿æ•´
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´ã‚‚é©åº¦ã«
        if vol_adj[i] < 0.9:
            base_threshold *= 0.92  # é©åº¦ãªèª¿æ•´
        else:
            base_threshold *= vol_adj[i]
        
        threshold[i] = max(0.20, min(0.65, base_threshold))  # ä¸­é–“çš„ãªç¯„å›²
    
    return threshold


@jit(nopython=True)
def ultimate_enhanced_ensemble_decision(
    er: np.ndarray,
    chop: np.ndarray,
    adx: np.ndarray,
    momentum_consistency: np.ndarray,
    vol_adj: np.ndarray,
    threshold: np.ndarray
) -> Tuple[np.ndarray, np.ndarray]:
    """
    ğŸ‘‘ ç©¶æ¥µã‚¨ãƒ³ãƒãƒ³ã‚¹ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ±ºå®šï¼ˆãƒãƒ©ãƒ³ã‚¹èª¿æ•´ç‰ˆï¼‰
    """
    n = len(er)
    signals = np.zeros(n, dtype=np.int32)
    confidence = np.zeros(n)
    
    for i in range(50, n):
        # å„æŒ‡æ¨™ã®ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆãƒãƒ©ãƒ³ã‚¹èª¿æ•´ï¼‰
        scores = np.zeros(4)
        
        # 1. Enhanced Efficiency Ratio Score (é‡ã¿: 35%) - ãƒãƒ©ãƒ³ã‚¹èª¿æ•´
        if er[i] > 0.55:  # ä¸­é–“çš„ãªé–¾å€¤
            scores[0] = min(1.3, (er[i] - 0.55) / 0.3 * 1.6)
        elif er[i] > 0.35:
            scores[0] = (er[i] - 0.35) / 0.2 * 0.7  # é©åº¦ãªã‚¹ã‚³ã‚¢
        elif er[i] < 0.28:
            scores[0] = -min(1.0, (0.28 - er[i]) / 0.28 * 1.1)
        else:
            scores[0] = 0.0
        
        # 2. Enhanced Choppiness Score (é‡ã¿: 30%) - ãƒãƒ©ãƒ³ã‚¹èª¿æ•´
        chop_normalized = (100.0 - chop[i]) / 100.0
        if chop_normalized > 0.58:  # ä¸­é–“çš„ãªé–¾å€¤
            scores[1] = (chop_normalized - 0.58) / 0.42 * 1.3
        elif chop_normalized < 0.42:
            scores[1] = -(0.42 - chop_normalized) / 0.42 * 1.2
        else:
            scores[1] = (chop_normalized - 0.42) / 0.16 * 0.4  # é©åº¦ãªã‚¹ã‚³ã‚¢
        
        # 3. Enhanced ADX Score (é‡ã¿: 25%) - ãƒãƒ©ãƒ³ã‚¹èª¿æ•´
        adx_normalized = adx[i] / 100.0
        if adx_normalized > 0.25:  # ä¸­é–“çš„ãªé–¾å€¤
            scores[2] = min(1.1, (adx_normalized - 0.25) / 0.25 * 1.3)
        elif adx_normalized < 0.18:
            scores[2] = -min(0.8, (0.18 - adx_normalized) / 0.18 * 0.9)
        else:
            scores[2] = (adx_normalized - 0.18) / 0.07 * 0.3  # é©åº¦ãªã‚¹ã‚³ã‚¢
        
        # 4. Enhanced Momentum Score (é‡ã¿: 10%) - ãƒãƒ©ãƒ³ã‚¹èª¿æ•´
        if momentum_consistency[i] > 0.65:  # ä¸­é–“çš„ãªé–¾å€¤
            scores[3] = (momentum_consistency[i] - 0.65) / 0.35 * 1.1
        elif momentum_consistency[i] < 0.25:
            scores[3] = -(0.25 - momentum_consistency[i]) / 0.25 * 0.7
        else:
            scores[3] = 0.0
        
        # é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚¹ã‚³ã‚¢ï¼ˆèª¿æ•´æ¸ˆã¿ï¼‰
        weights = np.array([0.35, 0.30, 0.25, 0.10])
        final_score = np.sum(scores * weights)
        
        # ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã•ã‚ŒãŸä¿¡é ¼åº¦è¨ˆç®—
        positive_indicators = np.sum(scores > 0.25)  # ä¸­é–“çš„ãªé–¾å€¤
        negative_indicators = np.sum(scores < -0.25)
        
        if positive_indicators >= 2:  # ä¸­é–“çš„ãªæ¡ä»¶
            agreement = positive_indicators / len(scores)
            confidence_boost = 1.15 if positive_indicators >= 3 else 1.05
        elif negative_indicators >= 2:
            agreement = negative_indicators / len(scores)
            confidence_boost = 1.10 if negative_indicators >= 3 else 1.0
        else:
            agreement = 0.45  # ä¸­é–“çš„ãªåŸºæœ¬ä¿¡é ¼åº¦
            confidence_boost = 0.85
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´ï¼ˆé©åº¦ã«ï¼‰
        vol_adjustment = 0.93 + (vol_adj[i] - 1.0) * 0.4
        adjusted_score = final_score * vol_adjustment
        
        # ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã•ã‚ŒãŸåˆ¤å®šåŸºæº–
        current_threshold = threshold[i]
        
        # ãƒ¡ã‚¤ãƒ³ã®åˆ¤å®šï¼ˆãƒãƒ©ãƒ³ã‚¹èª¿æ•´ï¼‰
        if abs(adjusted_score) >= current_threshold:
            signals[i] = 1 if adjusted_score > 0 else 0
            base_confidence = 0.52 + agreement * 0.28  # ä¸­é–“çš„ãªåŸºæœ¬ä¿¡é ¼åº¦
            confidence[i] = min(0.92, base_confidence * confidence_boost)
        else:
            # ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã•ã‚ŒãŸãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ¤å®š
            if positive_indicators >= 2 and abs(adjusted_score) >= current_threshold * 0.75:
                signals[i] = 1
                confidence[i] = 0.58 + (positive_indicators - 2) * 0.04
            elif negative_indicators >= 2 and abs(adjusted_score) >= current_threshold * 0.75:
                signals[i] = 0
                confidence[i] = 0.58 + (negative_indicators - 2) * 0.04
            else:
                signals[i] = 0  # ãƒ¬ãƒ³ã‚¸
                confidence[i] = 0.48  # ä¸­é–“çš„ãªä¿¡é ¼åº¦
    
    # åˆæœŸå€¤è¨­å®š
    for i in range(50):
        signals[i] = 0
        confidence[i] = 0.48
    
    return signals, confidence


@jit(nopython=True)
def enhanced_noise_filter(signals: np.ndarray, confidence: np.ndarray, 
                         window: int = 5) -> np.ndarray:
    """
    ğŸ”§ ã‚¨ãƒ³ãƒãƒ³ã‚¹ãƒã‚¤ã‚ºé™¤å»ï¼ˆã‚ˆã‚ŠæŸ”è»Ÿãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
    """
    n = len(signals)
    filtered_signals = np.zeros(n, dtype=np.int32)
    
    for i in range(n):
        if i < window:
            filtered_signals[i] = signals[i]
        else:
            # ã‚ˆã‚ŠçŸ­ã„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã®é‡ã¿ä»˜ãåˆ¤å®š
            weighted_sum = 0.0
            total_weight = 0.0
            
            for j in range(window):
                idx = i - j
                # æ–°ã—ã„ä¿¡å·ã«ã‚ˆã‚Šå¤§ããªé‡ã¿ã‚’ä¸ãˆã‚‹
                time_weight = 1.0 + j * 0.1
                confidence_weight = confidence[idx] if idx >= 0 else 0.5
                weight = confidence_weight * time_weight
                
                weighted_sum += signals[idx] * weight
                total_weight += weight
            
            if total_weight > 0:
                avg_signal = weighted_sum / total_weight
                # ã‚ˆã‚Šã‚½ãƒ•ãƒˆãªåˆ¤å®š
                filtered_signals[i] = 1 if avg_signal >= 0.45 else 0
            else:
                filtered_signals[i] = signals[i]
    
    return filtered_signals


class UltimateTrendRangeDetectorV3Enhanced:
    """
    ğŸš€ äººé¡å²ä¸Šæœ€å¼·ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ¤åˆ¥ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ V3.0 ENHANCED - BALANCED EDITION
    
    ğŸ¯ **ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ç‰ˆ:**
    - é©åº¦ãªé–¾å€¤è¨­å®šã§ãƒãƒ©ãƒ³ã‚¹åˆ¤å®š
    - ä¸­é–“çš„ãªãƒ–ãƒ¼ã‚¹ãƒˆå€ç‡
    - æŸ”è»Ÿãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ¤å®š
    - ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ãƒ¬ãƒ³ã‚¸ã®é©åˆ‡ãªåˆ†å¸ƒ
    
    ğŸ’ **V3ã‚¨ãƒ³ãƒãƒ³ã‚¹ãƒãƒ©ãƒ³ã‚¹ç‰ˆé©æ–°:**
    - å®Ÿç”¨çš„ãªãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ 
    - é©å¿œçš„å¤šæ®µéšåˆ¤å®š
    - ãƒãƒ©ãƒ³ã‚¹é‡è¦–ãƒã‚¤ã‚ºãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    - å®Ÿç”¨æ€§ã¨ç²¾åº¦ã®ä¸¡ç«‹
    
    ğŸ† **å®Ÿç”¨æ€§ãƒ»ç²¾åº¦ãƒ»ãƒãƒ©ãƒ³ã‚¹ã®ä¸‰ä½ä¸€ä½“**
    """
    
    def __init__(self, 
                 er_period: int = 20,  # ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã•ã‚ŒãŸæœŸé–“
                 chop_period: int = 14,
                 adx_period: int = 14,
                 vol_period: int = 18):  # ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã•ã‚ŒãŸæœŸé–“
        """
        ãƒãƒ©ãƒ³ã‚¹ç‰ˆã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ï¼ˆå®Ÿç”¨çš„ãªæœŸé–“è¨­å®šï¼‰
        """
        self.er_period = er_period
        self.chop_period = chop_period
        self.adx_period = adx_period
        self.vol_period = vol_period
        self.name = "UltimateTrendRangeDetectorV3EnhancedBalanced"
        self.version = "v3.0-enhanced-balanced"
    
    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> Dict[str, np.ndarray]:
        """
        ğŸ¯ V3ã‚¨ãƒ³ãƒãƒ³ã‚¹ç‰ˆ ç©¶æ¥µåˆ¤åˆ¥å®Ÿè¡Œï¼ˆ80%ç²¾åº¦ç›®æ¨™ï¼‰
        """
        # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        if isinstance(data, pd.DataFrame):
            if not all(col in data.columns for col in ['high', 'low', 'close']):
                raise ValueError("high, low, closeã‚«ãƒ©ãƒ ãŒå¿…è¦ã§ã™")
            high = data['high'].values.astype(np.float64)
            low = data['low'].values.astype(np.float64)
            close = data['close'].values.astype(np.float64)
        else:
            if data.ndim != 2 or data.shape[1] < 4:
                raise ValueError("OHLCå½¢å¼ã®4åˆ—ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™")
            high = data[:, 1].astype(np.float64)
            low = data[:, 2].astype(np.float64)
            close = data[:, 3].astype(np.float64)
        
        # HLC3ä¾¡æ ¼è¨ˆç®—
        prices = (high + low + close) / 3.0
        n = len(prices)
        
        print("ğŸ“Š ã‚¨ãƒ³ãƒãƒ³ã‚¹æŒ‡æ¨™è¨ˆç®—ä¸­...")
        
        # ã‚¨ãƒ³ãƒãƒ³ã‚¹ç‰ˆã®è¨ˆç®—ã‚’ä½¿ç”¨
        from ultimate_trend_range_detector_v3 import (
            calculate_true_range_v3, calculate_chop_index_v3, 
            calculate_adx_v3, calculate_volatility_adjustment_v3
        )
        
        # 1. ã‚¨ãƒ³ãƒãƒ³ã‚¹åŠ¹ç‡æ¯”
        er = calculate_efficiency_ratio_enhanced(prices, self.er_period)
        
        # 2. True Range
        tr = calculate_true_range_v3(high, low, close)
        
        # 3. Choppiness Index
        chop = calculate_chop_index_v3(high, low, close, tr, self.chop_period)
        
        # 4. ADX
        adx = calculate_adx_v3(high, low, close, self.adx_period)
        
        print("âš¡ ã‚¨ãƒ³ãƒãƒ³ã‚¹è£œåŠ©æŒ‡æ¨™è¨ˆç®—ä¸­...")
        
        # 5. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´
        vol_adj = calculate_volatility_adjustment_v3(prices, self.vol_period)
        
        # 6. ã‚¨ãƒ³ãƒãƒ³ã‚¹ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ä¸€è²«æ€§
        momentum_consistency = calculate_enhanced_momentum_consistency(prices)
        
        # 7. ã‚¨ãƒ³ãƒãƒ³ã‚¹é©å¿œçš„é–¾å€¤
        threshold = enhanced_adaptive_threshold(er, chop, adx, vol_adj)
        
        print("ğŸ§  ã‚¨ãƒ³ãƒãƒ³ã‚¹ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆ¤å®šå®Ÿè¡Œä¸­...")
        
        # 8. ç©¶æ¥µã‚¨ãƒ³ãƒãƒ³ã‚¹ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
        signals, confidence = ultimate_enhanced_ensemble_decision(
            er, chop, adx, momentum_consistency, vol_adj, threshold
        )
        
        # 9. ã‚¨ãƒ³ãƒãƒ³ã‚¹ãƒã‚¤ã‚ºé™¤å»
        final_signals = enhanced_noise_filter(signals, confidence)
        
        # çµæœçµ±è¨ˆ
        trend_count = int(np.sum(final_signals == 1))
        range_count = int(np.sum(final_signals == 0))
        
        print("âœ… V3ã‚¨ãƒ³ãƒãƒ³ã‚¹ç‰ˆè¨ˆç®—å®Œäº†ï¼")
        
        return {
            'signal': final_signals,
            'confidence': confidence,
            'efficiency_ratio': er,
            'choppiness_index': chop,
            'adx': adx,
            'volatility_adjustment': vol_adj,
            'momentum_consistency': momentum_consistency,
            'adaptive_threshold': threshold,
            'labels': np.array(['ãƒ¬ãƒ³ã‚¸', 'ãƒˆãƒ¬ãƒ³ãƒ‰'])[final_signals],
            'summary': {
                'total_bars': n,
                'trend_bars': trend_count,
                'range_bars': range_count,
                'trend_ratio': float(trend_count / n),
                'avg_confidence': float(np.mean(confidence)),
                'high_confidence_ratio': float(np.mean(confidence >= 0.8)),
                'er_avg': float(np.mean(er[er > 0])),
                'chop_avg': float(np.mean(chop[chop > 0])),
                'adx_avg': float(np.mean(adx[adx > 0]))
            }
        } 