#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import yaml
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List
from ultimate_trend_range_detector_v3_enhanced import UltimateTrendRangeDetectorV3Enhanced
import time
import warnings
warnings.filterwarnings('ignore')

# ãƒ‡ãƒ¼ã‚¿å–å¾—ã®ãŸã‚ã®ä¾å­˜é–¢ä¿‚
from data.data_loader import DataLoader, CSVDataSource
from data.data_processor import DataProcessor
from data.binance_data_source import BinanceDataSource

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
plt.rcParams['font.family'] = 'DejaVu Sans'
sns.set_style("whitegrid")


def load_data_from_config(config_path: str) -> pd.DataFrame:
    """
    è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        å‡¦ç†æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
        
    # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    binance_config = config.get('binance_data', {})
    data_dir = binance_config.get('data_dir', 'data/binance')
    binance_data_source = BinanceDataSource(data_dir)
    
    # CSVãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã¯ãƒ€ãƒŸãƒ¼ã¨ã—ã¦æ¸¡ã™ï¼ˆBinanceãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®ã¿ã‚’ä½¿ç”¨ï¼‰
    dummy_csv_source = CSVDataSource("dummy")
    data_loader = DataLoader(
        data_source=dummy_csv_source,
        binance_data_source=binance_data_source
    )
    data_processor = DataProcessor()
    
    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‡¦ç†
    print("\nğŸ“Š å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ãƒ»å‡¦ç†ä¸­...")
    raw_data = data_loader.load_data_from_config(config)
    processed_data = {
        symbol: data_processor.process(df)
        for symbol, df in raw_data.items()
    }
    
    # æœ€åˆã®ã‚·ãƒ³ãƒœãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    first_symbol = next(iter(processed_data))
    data = processed_data[first_symbol]
    
    print(f"âœ… å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {first_symbol}")
    print(f"ğŸ“… æœŸé–“: {data.index.min()} â†’ {data.index.max()}")
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ•°: {len(data)}")
    
    return data


def generate_enhanced_market_data(n_samples: int = 2000) -> pd.DataFrame:
    """
    V3ã‚¨ãƒ³ãƒãƒ³ã‚¹ç”¨ã®å¸‚å ´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    """
    np.random.seed(42)
    
    data = []
    current_price = 100.0
    market_state = 'range'
    state_duration = 0
    volatility_regime = 'normal'
    
    for i in range(n_samples):
        # å¸‚å ´çŠ¶æ…‹ã®ç®¡ç†
        if state_duration <= 0:
            # æ–°ã—ã„çŠ¶æ…‹ã‚’æ±ºå®š
            if market_state == 'range':
                market_state = np.random.choice(['trend_up', 'trend_down', 'range'], 
                                               p=[0.35, 0.35, 0.30])
            else:
                market_state = np.random.choice(['range', 'trend_up', 'trend_down'], 
                                               p=[0.50, 0.25, 0.25])
            
            # çŠ¶æ…‹ã®æŒç¶šæœŸé–“
            if 'trend' in market_state:
                state_duration = np.random.randint(60, 201)  # 60-200æœŸé–“ã®é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰
            else:
                state_duration = np.random.randint(30, 121)  # 30-120æœŸé–“ã®ãƒ¬ãƒ³ã‚¸
            
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ ã®å¤‰æ›´
            volatility_regime = np.random.choice(['low', 'normal', 'high'], 
                                                p=[0.3, 0.5, 0.2])
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ ã«å¿œã˜ãŸåŸºæœ¬å¤‰å‹•
        if volatility_regime == 'low':
            base_vol = 0.008
        elif volatility_regime == 'normal':
            base_vol = 0.015
        else:  # high
            base_vol = 0.025
        
        # å¸‚å ´çŠ¶æ…‹ã«å¿œã˜ãŸä¾¡æ ¼ç”Ÿæˆ
        if market_state == 'trend_up':
            # ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰
            trend_strength = np.random.uniform(0.0015, 0.005)
            noise_factor = 0.6  # ãƒˆãƒ¬ãƒ³ãƒ‰æ™‚ã¯ãƒã‚¤ã‚ºã‚’æŠ‘åˆ¶
            price_change = (trend_strength * current_price + 
                           np.random.normal(0, current_price * base_vol * noise_factor))
            true_regime = 1
            
        elif market_state == 'trend_down':
            # ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰
            trend_strength = np.random.uniform(-0.005, -0.0015)
            noise_factor = 0.6
            price_change = (trend_strength * current_price + 
                           np.random.normal(0, current_price * base_vol * noise_factor))
            true_regime = 1
            
        else:  # range
            # ãƒ¬ãƒ³ã‚¸ç›¸å ´ï¼ˆå¹³å‡å›å¸°ç‰¹æ€§ï¼‰
            if i >= 30:
                recent_mean = np.mean([d['close'] for d in data[-30:]])
                mean_reversion_force = (recent_mean - current_price) * 0.08
            else:
                mean_reversion_force = 0
            
            noise_factor = 1.2  # ãƒ¬ãƒ³ã‚¸æ™‚ã¯ãƒã‚¤ã‚ºã‚’å¢—åŠ 
            price_change = (mean_reversion_force + 
                           np.random.normal(0, current_price * base_vol * noise_factor))
            true_regime = 0
        
        # ä¾¡æ ¼æ›´æ–°
        current_price += price_change
        current_price = max(current_price, 10.0)
        
        # OHLCç”Ÿæˆï¼ˆã‚ˆã‚Šç¾å®Ÿçš„ãªæ—¥å†…å¤‰å‹•ï¼‰
        intraday_vol = current_price * base_vol * 0.8
        high_bias = np.random.uniform(0.2, 1.5)
        low_bias = np.random.uniform(0.2, 1.5)
        
        high = current_price + intraday_vol * high_bias
        low = current_price - intraday_vol * low_bias
        
        # Openä¾¡æ ¼ã¯å‰ã®çµ‚å€¤ã«è¿‘ã„å€¤
        if i > 0:
            prev_close = data[-1]['close']
            gap = np.random.normal(0, current_price * 0.005)  # å°ã•ãªã‚®ãƒ£ãƒƒãƒ—
            open_price = prev_close + gap
        else:
            open_price = current_price
        
        data.append({
            'open': open_price,
            'high': high,
            'low': low,
            'close': current_price,
            'true_regime': true_regime,
            'market_state': market_state,
            'volatility_regime': volatility_regime
        })
        
        state_duration -= 1
    
    return pd.DataFrame(data)


def evaluate_performance_enhanced(predicted: np.ndarray, actual: np.ndarray) -> dict:
    """
    ã‚¨ãƒ³ãƒãƒ³ã‚¹ç‰ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
    """
    # åŸºæœ¬çµ±è¨ˆ
    correct = np.sum(predicted == actual)
    total = len(predicted)
    accuracy = correct / total
    
    # æ··åŒè¡Œåˆ—
    tp = np.sum((predicted == 1) & (actual == 1))  # True Positive (ãƒˆãƒ¬ãƒ³ãƒ‰æ­£è§£)
    tn = np.sum((predicted == 0) & (actual == 0))  # True Negative (ãƒ¬ãƒ³ã‚¸æ­£è§£)
    fp = np.sum((predicted == 1) & (actual == 0))  # False Positive (ãƒ¬ãƒ³ã‚¸ã‚’ãƒˆãƒ¬ãƒ³ãƒ‰ã¨èª¤åˆ¤å®š)
    fn = np.sum((predicted == 0) & (actual == 1))  # False Negative (ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ãƒ¬ãƒ³ã‚¸ã¨èª¤åˆ¤å®š)
    
    # è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    precision_trend = tp / (tp + fp) if (tp + fp) > 0 else 0
    precision_range = tn / (tn + fn) if (tn + fn) > 0 else 0
    recall_trend = tp / (tp + fn) if (tp + fn) > 0 else 0
    recall_range = tn / (tn + fp) if (tn + fp) > 0 else 0
    
    f1_trend = 2 * (precision_trend * recall_trend) / (precision_trend + recall_trend) if (precision_trend + recall_trend) > 0 else 0
    f1_range = 2 * (precision_range * recall_range) / (precision_range + recall_range) if (precision_range + recall_range) > 0 else 0
    
    # ãƒãƒ©ãƒ³ã‚¹ç²¾åº¦
    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    balanced_accuracy = (sensitivity + specificity) / 2
    
    # Matthewsç›¸é–¢ä¿‚æ•°ï¼ˆMCCï¼‰
    mcc_denominator = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))
    mcc = ((tp * tn) - (fp * fn)) / mcc_denominator if mcc_denominator > 0 else 0
    
    return {
        'accuracy': accuracy,
        'balanced_accuracy': balanced_accuracy,
        'precision_trend': precision_trend,
        'precision_range': precision_range,
        'recall_trend': recall_trend,
        'recall_range': recall_range,
        'f1_trend': f1_trend,
        'f1_range': f1_range,
        'sensitivity': sensitivity,
        'specificity': specificity,
        'mcc': mcc,
        'confusion_matrix': {
            'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn
        }
    }


def plot_results_enhanced_with_real_data(data: pd.DataFrame, results: dict, 
                                        actual_signals: Optional[np.ndarray] = None,
                                        save_path: str = None):
    """
    å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ç”¨ã®é«˜åº¦ãªçµæœå¯è¦–åŒ–ï¼ˆèƒŒæ™¯è‰²ä»˜ãï¼‰
    """
    fig, axes = plt.subplots(5, 1, figsize=(18, 14))
    
    # 1. ä¾¡æ ¼ã¨ã‚·ã‚°ãƒŠãƒ«
    ax1 = axes[0]
    ax1.plot(data.index, data['close'], label='Close Price', alpha=0.8, linewidth=1.5, color='black')
    
    # äºˆæ¸¬çµæœã‚’èƒŒæ™¯è‰²ã§è¡¨ç¤ºï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ç”¨ï¼‰
    trend_mask_pred = results['signal'] == 1
    range_mask_pred = results['signal'] == 0
    
    # èƒŒæ™¯è‰²ã‚’è¿½åŠ 
    ax1.fill_between(data.index, data['close'].min(), data['close'].max(), 
                     where=trend_mask_pred, alpha=0.1, color='green', 
                     label='Predicted Trend Periods', interpolate=True)
    ax1.fill_between(data.index, data['close'].min(), data['close'].max(), 
                     where=range_mask_pred, alpha=0.1, color='red', 
                     label='Predicted Range Periods', interpolate=True)
    
    # V3ã‚¨ãƒ³ãƒãƒ³ã‚¹äºˆæ¸¬ä¿¡å·ã‚’ãƒãƒ¼ã‚«ãƒ¼ã§è¡¨ç¤º
    trend_pred_idx = np.where(results['signal'] == 1)[0]
    range_pred_idx = np.where(results['signal'] == 0)[0]
    
    if len(trend_pred_idx) > 0:
        ax1.scatter(data.index[trend_pred_idx], data['close'].iloc[trend_pred_idx], 
                   c='darkgreen', marker='^', s=20, alpha=0.8, label='V3 Enhanced Trend Signals')
    if len(range_pred_idx) > 0:
        ax1.scatter(data.index[range_pred_idx], data['close'].iloc[range_pred_idx], 
                   c='darkred', marker='v', s=20, alpha=0.8, label='V3 Enhanced Range Signals')
    
    ax1.set_title('ğŸš€ V3.0 Enhanced - Real Market Data Analysis with Predicted Backgrounds', 
                  fontsize=14, fontweight='bold')
    ax1.set_ylabel('Price', fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. ä¸»è¦æŒ‡æ¨™ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
    ax2 = axes[1]
    ax2.plot(data.index, results['efficiency_ratio'], label='Enhanced Efficiency Ratio', color='blue', alpha=0.8)
    ax2.plot(data.index, results['choppiness_index']/100, label='Choppiness Index (normalized)', color='red', alpha=0.8)
    ax2.plot(data.index, results['adx']/100, label='ADX (normalized)', color='purple', alpha=0.8)
    
    # èƒŒæ™¯è‰²ã‚’æŒ‡æ¨™ãƒãƒ£ãƒ¼ãƒˆã«ã‚‚è¿½åŠ 
    ax2.fill_between(data.index, 0, 1, where=trend_mask_pred, alpha=0.05, color='green', interpolate=True)
    ax2.fill_between(data.index, 0, 1, where=range_mask_pred, alpha=0.05, color='red', interpolate=True)
    
    ax2.axhline(y=0.618, color='green', linestyle='--', alpha=0.5, label='Golden Ratio')
    ax2.axhline(y=0.382, color='orange', linestyle='--', alpha=0.5, label='Silver Ratio')
    ax2.set_title('ğŸ“Š Enhanced Core Indicators Dashboard', fontweight='bold')
    ax2.set_ylabel('Indicator Values', fontweight='bold')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. ä¿¡é ¼åº¦ã¨é©å¿œçš„é–¾å€¤
    ax3 = axes[2]
    ax3.plot(data.index, results['confidence'], label='V3 Enhanced Confidence Score', color='darkblue', linewidth=2)
    ax3.plot(data.index, results['adaptive_threshold'], label='Dynamic Adaptive Threshold', color='purple', 
             linestyle='--', alpha=0.8)
    
    # èƒŒæ™¯è‰²ã‚’ä¿¡é ¼åº¦ãƒãƒ£ãƒ¼ãƒˆã«ã‚‚è¿½åŠ 
    ax3.fill_between(data.index, 0, 1, where=trend_mask_pred, alpha=0.05, color='green', interpolate=True)
    ax3.fill_between(data.index, 0, 1, where=range_mask_pred, alpha=0.05, color='red', interpolate=True)
    
    ax3.axhline(y=0.8, color='green', linestyle=':', alpha=0.7, label='High Confidence Level')
    ax3.fill_between(data.index, 0, results['confidence'], alpha=0.2, color='blue')
    ax3.set_title('ğŸ§  Enhanced Confidence & Dynamic Intelligence', fontweight='bold')
    ax3.set_ylabel('Score', fontweight='bold')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. ã‚¨ãƒ³ãƒãƒ³ã‚¹è£œåŠ©æŒ‡æ¨™
    ax4 = axes[3]
    ax4.plot(data.index, results['momentum_consistency'], label='Enhanced Momentum Consistency', 
             color='darkgreen', alpha=0.8)
    ax4.plot(data.index, results['volatility_adjustment'], label='Volatility Adjustment', 
             color='orange', alpha=0.8)
    
    # èƒŒæ™¯è‰²ã‚’è£œåŠ©æŒ‡æ¨™ãƒãƒ£ãƒ¼ãƒˆã«ã‚‚è¿½åŠ 
    ax4.fill_between(data.index, 0, 2, where=trend_mask_pred, alpha=0.05, color='green', interpolate=True)
    ax4.fill_between(data.index, 0, 2, where=range_mask_pred, alpha=0.05, color='red', interpolate=True)
    
    ax4.axhline(y=1.0, color='black', linestyle='-', alpha=0.3)
    ax4.axhline(y=0.7, color='green', linestyle='--', alpha=0.5, label='Strong Momentum')
    ax4.set_title('ğŸ¯ Enhanced Market Analysis', fontweight='bold')
    ax4.set_ylabel('Factor Values', fontweight='bold')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    # 5. ã‚·ã‚°ãƒŠãƒ«åˆ†å¸ƒã¨çµ±è¨ˆ
    ax5 = axes[4]
    
    # ã‚·ã‚°ãƒŠãƒ«ã®æ™‚ç³»åˆ—è¡¨ç¤º
    signal_colors = ['red' if s == 0 else 'green' for s in results['signal']]
    ax5.scatter(data.index, results['signal'], c=signal_colors, alpha=0.6, s=10)
    ax5.set_ylim(-0.5, 1.5)
    ax5.set_yticks([0, 1])
    ax5.set_yticklabels(['Range', 'Trend'])
    
    # èƒŒæ™¯è‰²ã‚’ã‚·ã‚°ãƒŠãƒ«ãƒãƒ£ãƒ¼ãƒˆã«ã‚‚è¿½åŠ 
    ax5.fill_between(data.index, -0.5, 1.5, where=trend_mask_pred, alpha=0.1, color='green', 
                     interpolate=True, label='Trend Periods')
    ax5.fill_between(data.index, -0.5, 1.5, where=range_mask_pred, alpha=0.1, color='red', 
                     interpolate=True, label='Range Periods')
    
    # ä¿¡é ¼åº¦ã«ã‚ˆã‚‹è‰²åˆ†ã‘
    high_conf_mask = results['confidence'] >= 0.8
    med_conf_mask = (results['confidence'] >= 0.6) & (results['confidence'] < 0.8)
    
    if np.sum(high_conf_mask) > 0:
        ax5.scatter(data.index[high_conf_mask], results['signal'][high_conf_mask], 
                   c='gold', marker='*', s=30, alpha=0.8, label='High Confidence')
    
    ax5.set_title('ğŸ“ˆ Signal Distribution & Confidence Analysis with Background', fontweight='bold')
    ax5.set_ylabel('Signal', fontweight='bold')
    ax5.set_xlabel('Time', fontweight='bold')
    ax5.legend()
    ax5.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        print(f"ğŸ“Š ãƒãƒ£ãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_path}")
    plt.show()


def analyze_real_market_performance(data: pd.DataFrame, results: dict) -> dict:
    """
    å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
    """
    analysis = {}
    
    # ã‚·ã‚°ãƒŠãƒ«çµ±è¨ˆ
    total_signals = len(results['signal'])
    trend_signals = np.sum(results['signal'] == 1)
    range_signals = np.sum(results['signal'] == 0)
    
    analysis['signal_distribution'] = {
        'total': total_signals,
        'trend_count': trend_signals,
        'range_count': range_signals,
        'trend_ratio': trend_signals / total_signals,
        'range_ratio': range_signals / total_signals
    }
    
    # ä¿¡é ¼åº¦åˆ†æ
    high_conf_count = np.sum(results['confidence'] >= 0.8)
    med_conf_count = np.sum((results['confidence'] >= 0.6) & (results['confidence'] < 0.8))
    low_conf_count = np.sum(results['confidence'] < 0.6)
    
    analysis['confidence_distribution'] = {
        'high_confidence': high_conf_count,
        'medium_confidence': med_conf_count,
        'low_confidence': low_conf_count,
        'high_conf_ratio': high_conf_count / total_signals,
        'avg_confidence': np.mean(results['confidence'])
    }
    
    # æŒ‡æ¨™çµ±è¨ˆ
    analysis['indicator_stats'] = {
        'er_mean': np.mean(results['efficiency_ratio'][results['efficiency_ratio'] > 0]),
        'er_std': np.std(results['efficiency_ratio'][results['efficiency_ratio'] > 0]),
        'chop_mean': np.mean(results['choppiness_index'][results['choppiness_index'] > 0]),
        'chop_std': np.std(results['choppiness_index'][results['choppiness_index'] > 0]),
        'adx_mean': np.mean(results['adx'][results['adx'] > 0]),
        'adx_std': np.std(results['adx'][results['adx'] > 0])
    }
    
    # ã‚·ã‚°ãƒŠãƒ«é·ç§»åˆ†æ
    signal_changes = np.diff(results['signal'])
    trend_to_range = np.sum(signal_changes == -1)
    range_to_trend = np.sum(signal_changes == 1)
    
    analysis['signal_transitions'] = {
        'trend_to_range': trend_to_range,
        'range_to_trend': range_to_trend,
        'total_transitions': trend_to_range + range_to_trend,
        'avg_signal_duration': total_signals / (trend_to_range + range_to_trend) if (trend_to_range + range_to_trend) > 0 else 0
    }
    
    return analysis


def plot_results_v3(data: pd.DataFrame, results: dict, save_path: str = None):
    """
    V3ç‰ˆã®é«˜åº¦ãªçµæœå¯è¦–åŒ–
    """
    fig, axes = plt.subplots(6, 1, figsize=(18, 16))
    
    # 1. ä¾¡æ ¼ã¨ã‚·ã‚°ãƒŠãƒ«æ¯”è¼ƒ
    ax1 = axes[0]
    ax1.plot(data['close'], label='Close Price', alpha=0.8, linewidth=1.5, color='black')
    
    # çœŸã®å¸‚å ´çŠ¶æ…‹ã‚’èƒŒæ™¯è‰²ã§è¡¨ç¤º
    trend_mask_true = data['true_regime'] == 1
    range_mask_true = data['true_regime'] == 0
    
    ax1.fill_between(range(len(data)), data['close'].min(), data['close'].max(), 
                     where=trend_mask_true, alpha=0.1, color='green', label='True Trend Periods')
    ax1.fill_between(range(len(data)), data['close'].min(), data['close'].max(), 
                     where=range_mask_true, alpha=0.1, color='red', label='True Range Periods')
    
    # V3äºˆæ¸¬ä¿¡å·ã‚’ãƒãƒ¼ã‚«ãƒ¼ã§è¡¨ç¤º
    trend_pred_idx = np.where(results['signal'] == 1)[0]
    range_pred_idx = np.where(results['signal'] == 0)[0]
    
    if len(trend_pred_idx) > 0:
        ax1.scatter(trend_pred_idx, data['close'].iloc[trend_pred_idx], 
                   c='darkgreen', marker='^', s=15, alpha=0.7, label='V3 Trend Signals')
    if len(range_pred_idx) > 0:
        ax1.scatter(range_pred_idx, data['close'].iloc[range_pred_idx], 
                   c='darkred', marker='v', s=15, alpha=0.7, label='V3 Range Signals')
    
    ax1.set_title('ğŸš€ V3.0 Ultimate - Price & Revolutionary Signal Detection', fontsize=14, fontweight='bold')
    ax1.set_ylabel('Price', fontweight='bold')
    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax1.grid(True, alpha=0.3)
    
    # 2. ä¸»è¦æŒ‡æ¨™ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
    ax2 = axes[1]
    ax2.plot(results['efficiency_ratio'], label='Efficiency Ratio', color='blue', alpha=0.8)
    ax2.plot(results['choppiness_index']/100, label='Choppiness Index (normalized)', color='red', alpha=0.8)
    ax2.plot(results['adx']/100, label='ADX (normalized)', color='purple', alpha=0.8)
    ax2.axhline(y=0.618, color='green', linestyle='--', alpha=0.5, label='Golden Ratio')
    ax2.axhline(y=0.382, color='orange', linestyle='--', alpha=0.5, label='Silver Ratio')
    ax2.set_title('ğŸ“Š Core Indicators Dashboard', fontweight='bold')
    ax2.set_ylabel('Indicator Values', fontweight='bold')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. ä¿¡é ¼åº¦ã¨é©å¿œçš„é–¾å€¤
    ax3 = axes[2]
    ax3.plot(results['confidence'], label='V3 Confidence Score', color='darkblue', linewidth=2)
    ax3.plot(results['adaptive_threshold'], label='Adaptive Threshold', color='purple', 
             linestyle='--', alpha=0.8)
    ax3.axhline(y=0.8, color='green', linestyle=':', alpha=0.7, label='High Confidence Level')
    ax3.fill_between(range(len(results['confidence'])), 0, results['confidence'], 
                     alpha=0.2, color='blue')
    ax3.set_title('ğŸ§  Confidence & Adaptive Intelligence', fontweight='bold')
    ax3.set_ylabel('Score', fontweight='bold')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ä¸€è²«æ€§ã¨ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´
    ax4 = axes[3]
    ax4.plot(results['momentum_consistency'], label='Momentum Consistency', 
             color='darkgreen', alpha=0.8)
    ax4.plot(results['volatility_adjustment'], label='Volatility Adjustment', 
             color='orange', alpha=0.8)
    ax4.axhline(y=1.0, color='black', linestyle='-', alpha=0.3)
    ax4.set_title('ğŸ¯ Advanced Market Analysis', fontweight='bold')
    ax4.set_ylabel('Factor Values', fontweight='bold')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    # 5. åˆ¤å®šç²¾åº¦ã®æ™‚ç³»åˆ—åˆ†æ
    ax5 = axes[4]
    # ç§»å‹•å¹³å‡ç²¾åº¦ã‚’è¨ˆç®—
    window = 100
    rolling_accuracy = []
    for i in range(window, len(data)):
        pred_window = results['signal'][i-window:i]
        actual_window = data['true_regime'].values[i-window:i]
        acc = np.sum(pred_window == actual_window) / window
        rolling_accuracy.append(acc)
    
    # ãƒ—ãƒ­ãƒƒãƒˆã®èª¿æ•´
    x_rolling = range(window, len(data))
    ax5.plot(x_rolling, rolling_accuracy, color='red', linewidth=2, 
             label=f'Rolling Accuracy ({window}-period)')
    ax5.axhline(y=0.8, color='green', linestyle='--', alpha=0.7, label='80% Target')
    ax5.axhline(y=np.mean(rolling_accuracy), color='blue', linestyle=':', 
               alpha=0.7, label=f'Average: {np.mean(rolling_accuracy):.3f}')
    ax5.fill_between(x_rolling, 0.8, rolling_accuracy, 
                     where=np.array(rolling_accuracy) >= 0.8, 
                     alpha=0.3, color='green', label='Above Target')
    ax5.set_title('ğŸ“ˆ Real-time Accuracy Performance', fontweight='bold')
    ax5.set_ylabel('Accuracy', fontweight='bold')
    ax5.legend()
    ax5.grid(True, alpha=0.3)
    
    # 6. ã‚¨ãƒ©ãƒ¼åˆ†æ
    ax6 = axes[5]
    errors = (results['signal'] != data['true_regime'].values).astype(int)
    cumulative_error_rate = np.cumsum(errors) / np.arange(1, len(errors) + 1)
    
    ax6.plot(cumulative_error_rate, color='red', linewidth=2, label='Cumulative Error Rate')
    ax6.axhline(y=0.2, color='green', linestyle='--', alpha=0.7, label='20% Error Target')
    ax6.fill_between(range(len(cumulative_error_rate)), 0, errors, 
                     alpha=0.2, color='red', label='Individual Errors')
    ax6.set_title('ğŸ” Error Analysis & Learning Curve', fontweight='bold')
    ax6.set_ylabel('Error Rate', fontweight='bold')
    ax6.set_xlabel('Time', fontweight='bold')
    ax6.legend()
    ax6.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.show()


def main():
    """
    V3ã‚¨ãƒ³ãƒãƒ³ã‚¹ç‰ˆãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ - ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ç‰ˆ
    """
    print("ğŸš€ äººé¡å²ä¸Šæœ€å¼·ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ¤åˆ¥ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ V3.0 ENHANCED - BALANCED EDITION")
    print("=" * 120)
    print("ğŸ¯ ç›®æ¨™: å®Ÿç”¨çš„ã§é«˜ç²¾åº¦ãªãƒãƒ©ãƒ³ã‚¹åˆ¤åˆ¥")
    print("ğŸ’ ãƒãƒ©ãƒ³ã‚¹æŠ€è¡“: é©åº¦é–¾å€¤ + å®Ÿç”¨ER + æŸ”è»Ÿåˆ¤å®š + å®Ÿç”¨æ€§é‡è¦–")
    print("ğŸ“Š æ–°æ©Ÿèƒ½: å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆå¯¾å¿œ")
    print("=" * 120)
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®å‡¦ç†
    import argparse
    parser = argparse.ArgumentParser(description='V3ã‚¨ãƒ³ãƒãƒ³ã‚¹ç‰ˆ ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ¤åˆ¥ãƒ†ã‚¹ãƒˆï¼ˆãƒãƒ©ãƒ³ã‚¹èª¿æ•´ç‰ˆï¼‰')
    parser.add_argument('--config', '-c', type=str, default='config.yaml', help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--real-data', '-r', action='store_true', help='å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨')
    parser.add_argument('--synthetic', '-s', action='store_true', help='åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰')
    parser.add_argument('--output', '-o', type=str, help='çµæœç”»åƒã®ä¿å­˜ãƒ‘ã‚¹')
    args = parser.parse_args()
    
    # ãƒ‡ãƒ¼ã‚¿ã®é¸æŠ
    if args.real_data:
        print("\nğŸ“Š å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ")
        try:
            data = load_data_from_config(args.config)
            data_type = "å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿"
            
            # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã«ã¯çœŸã®å¸‚å ´çŠ¶æ…‹ãŒãªã„ãŸã‚ã€ãƒ€ãƒŸãƒ¼ã‚’ä½œæˆ
            print("âš ï¸  æ³¨æ„: å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ã§ã¯çœŸã®å¸‚å ´çŠ¶æ…‹ãŒä¸æ˜ã®ãŸã‚ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ã¯å‚è€ƒå€¤ã§ã™")
            
        except Exception as e:
            print(f"âŒ å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
            print("ğŸ”„ åˆæˆãƒ‡ãƒ¼ã‚¿ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™...")
            data = generate_enhanced_market_data(2500)
            data_type = "åˆæˆãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"
    else:
        print("\nğŸ“Š åˆæˆãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ")
        data = generate_enhanced_market_data(2500)
        data_type = "é«˜åº¦ãªåˆæˆãƒ‡ãƒ¼ã‚¿"
    
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: {data_type}")
    print(f"   ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿æ•°: {len(data)}ä»¶")
    
    # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã®è¡¨ç¤º
    if 'true_regime' in data.columns:
        actual_trend_count = sum(data['true_regime'])
        actual_range_count = len(data) - actual_trend_count
        print(f"   ğŸ“ˆ çœŸã®ãƒˆãƒ¬ãƒ³ãƒ‰æœŸé–“: {actual_trend_count}ä»¶ ({actual_trend_count/len(data)*100:.1f}%)")
        print(f"   ğŸ“‰ çœŸã®ãƒ¬ãƒ³ã‚¸æœŸé–“: {actual_range_count}ä»¶ ({actual_range_count/len(data)*100:.1f}%)")
        
        if 'market_state' in data.columns:
            state_dist = data['market_state'].value_counts()
            print(f"   ğŸ”„ å¸‚å ´çŠ¶æ…‹åˆ†å¸ƒ: {dict(state_dist)}")
    else:
        print("   ğŸ“Š å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ - ä¾¡æ ¼ç¯„å›²:")
        print(f"      æœ€é«˜å€¤: {data['high'].max():.2f}")
        print(f"      æœ€å®‰å€¤: {data['low'].min():.2f}")
        print(f"      çµ‚å€¤ç¯„å›²: {data['close'].min():.2f} - {data['close'].max():.2f}")
    
    # 2. V3ã‚¨ãƒ³ãƒãƒ³ã‚¹ãƒãƒ©ãƒ³ã‚¹ç‰ˆåˆæœŸåŒ–
    print("\nğŸ”§ Ultimate V3 Enhanced Balanced åˆæœŸåŒ–ä¸­...")
    detector_enhanced = UltimateTrendRangeDetectorV3Enhanced(
        er_period=20,      # ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã•ã‚ŒãŸæœŸé–“
        chop_period=14,    # æ¨™æº–æœŸé–“
        adx_period=14,     # æ¨™æº–æœŸé–“
        vol_period=18      # ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã•ã‚ŒãŸæœŸé–“
    )
    print("âœ… V3ã‚¨ãƒ³ãƒãƒ³ã‚¹ãƒãƒ©ãƒ³ã‚¹ç‰ˆåˆæœŸåŒ–å®Œäº†")
    print("   ğŸ§  ãƒãƒ©ãƒ³ã‚¹æ§‹æˆ: ER(35%) + Chop(30%) + ADX(25%) + Momentum(10%)")
    print("   âš¡ ãƒãƒ©ãƒ³ã‚¹æ©Ÿèƒ½: é©åº¦é–¾å€¤ + å®Ÿç”¨åˆ¤å®š + æŸ”è»Ÿãƒ•ã‚£ãƒ«ã‚¿ + å®Ÿç”¨æ€§é‡è¦–")
    
    # 3. è¨ˆç®—å®Ÿè¡Œ
    print(f"\nâš¡ V3ã‚¨ãƒ³ãƒãƒ³ã‚¹ãƒãƒ©ãƒ³ã‚¹ç‰ˆ {data_type}è§£æå®Ÿè¡Œä¸­...")
    start_time = time.time()
    
    results = detector_enhanced.calculate(data)
    
    end_time = time.time()
    calculation_time = end_time - start_time
    
    print(f"âœ… è¨ˆç®—å®Œäº† (å‡¦ç†æ™‚é–“: {calculation_time:.2f}ç§’)")
    print(f"   âš¡ å‡¦ç†é€Ÿåº¦: {len(data)/calculation_time:.0f} ãƒ‡ãƒ¼ã‚¿/ç§’")
    
    # 4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ï¼ˆåˆæˆãƒ‡ãƒ¼ã‚¿ã®å ´åˆã®ã¿ï¼‰
    if 'true_regime' in data.columns:
        print("\nğŸ“ˆ V3ã‚¨ãƒ³ãƒãƒ³ã‚¹ãƒãƒ©ãƒ³ã‚¹ç‰ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ä¸­...")
        
        # åˆæœŸæœŸé–“ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦è©•ä¾¡
        skip_initial = 50
        predicted_signals = results['signal'][skip_initial:]
        actual_signals = data['true_regime'].values[skip_initial:]
        
        performance = evaluate_performance_enhanced(predicted_signals, actual_signals)
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœè¡¨ç¤º
        print("\n" + "="*90)
        print("ğŸ† **V3.0 ENHANCED BALANCED PERFORMANCE RESULTS**")
        print("="*90)
        print(f"ğŸ“Š ç·åˆç²¾åº¦: {performance['accuracy']:.4f} ({performance['accuracy']*100:.2f}%)")
        print(f"âš–ï¸  ãƒãƒ©ãƒ³ã‚¹ç²¾åº¦: {performance['balanced_accuracy']:.4f} ({performance['balanced_accuracy']*100:.2f}%)")
        print(f"ğŸ’ MCCï¼ˆå“è³ªæŒ‡æ¨™ï¼‰: {performance['mcc']:.4f}")
        
        # è©•ä¾¡åˆ¤å®š
        if performance['accuracy'] >= 0.75:
            print(f"ğŸ‰ğŸ† **ãƒãƒ©ãƒ³ã‚¹è¨­å®šã§75%ä»¥ä¸Šé”æˆï¼å®Ÿç”¨æ€§ã¨ç²¾åº¦ã®å®Œç’§ãªä¸¡ç«‹ï¼** ğŸ†ğŸ‰")
            achievement_status = "BALANCED SUCCESS"
        elif performance['accuracy'] >= 0.70:
            print(f"â­ğŸ”¥ **70%çªç ´ï¼ãƒãƒ©ãƒ³ã‚¹å–ã‚ŒãŸé«˜æ€§èƒ½ï¼** ğŸ”¥â­")
            achievement_status = "PRACTICAL ACHIEVEMENT"
        else:
            print(f"ğŸ“ˆğŸ’« **ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã«ã‚ˆã‚Šå®Ÿç”¨æ€§å‘ä¸Šä¸­...** ğŸ’«ğŸ“ˆ")
            achievement_status = "PRACTICAL PROGRESS"
        
        print(f"\nğŸ“ˆ **ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤åˆ¥è©³ç´°**")
        print(f"   - ç²¾åº¦ (Precision): {performance['precision_trend']:.4f} ({performance['precision_trend']*100:.1f}%)")
        print(f"   - å†ç¾ç‡ (Recall): {performance['recall_trend']:.4f} ({performance['recall_trend']*100:.1f}%)")
        print(f"   - F1ã‚¹ã‚³ã‚¢: {performance['f1_trend']:.4f}")
        
        print(f"\nğŸ“‰ **ãƒ¬ãƒ³ã‚¸åˆ¤åˆ¥è©³ç´°**")
        print(f"   - ç²¾åº¦ (Precision): {performance['precision_range']:.4f} ({performance['precision_range']*100:.1f}%)")
        print(f"   - å†ç¾ç‡ (Recall): {performance['recall_range']:.4f} ({performance['recall_range']*100:.1f}%)")
        print(f"   - F1ã‚¹ã‚³ã‚¢: {performance['f1_range']:.4f}")
    
    # 5. å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿åˆ†æ
    print("\nğŸ“Š å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿åˆ†æå®Ÿè¡Œä¸­...")
    market_analysis = analyze_real_market_performance(data, results)
    
    # 6. æŠ€è¡“çµ±è¨ˆ
    print("\n" + "="*90)
    print("ğŸ”¬ **V3ã‚¨ãƒ³ãƒãƒ³ã‚¹ãƒãƒ©ãƒ³ã‚¹ç‰ˆæŠ€è¡“çµ±è¨ˆ**")
    print("="*90)
    summary = results['summary']
    print(f"ğŸ“Š äºˆæ¸¬çµ±è¨ˆ:")
    print(f"   - ãƒˆãƒ¬ãƒ³ãƒ‰æœŸé–“: {summary['trend_bars']}ä»¶ ({summary['trend_ratio']*100:.1f}%)")
    print(f"   - ãƒ¬ãƒ³ã‚¸æœŸé–“: {summary['range_bars']}ä»¶ ({(1-summary['trend_ratio'])*100:.1f}%)")
    print(f"   - å¹³å‡ä¿¡é ¼åº¦: {summary['avg_confidence']:.4f}")
    print(f"   - é«˜ä¿¡é ¼åº¦æ¯”ç‡: {summary['high_confidence_ratio']*100:.1f}%")
    
    print(f"\nğŸ¯ ãƒãƒ©ãƒ³ã‚¹æŒ‡æ¨™çµ±è¨ˆ:")
    stats = market_analysis['indicator_stats']
    print(f"   - ãƒãƒ©ãƒ³ã‚¹åŠ¹ç‡æ¯”: å¹³å‡ {stats['er_mean']:.4f} Â± {stats['er_std']:.4f}")
    print(f"   - Choppiness Index: å¹³å‡ {stats['chop_mean']:.2f} Â± {stats['chop_std']:.2f}")
    print(f"   - ADX: å¹³å‡ {stats['adx_mean']:.2f} Â± {stats['adx_std']:.2f}")
    
    # 7. ã‚·ã‚°ãƒŠãƒ«åˆ†æ
    signal_dist = market_analysis['signal_distribution']
    conf_dist = market_analysis['confidence_distribution']
    transitions = market_analysis['signal_transitions']
    
    print(f"\nğŸ”„ **ã‚·ã‚°ãƒŠãƒ«åˆ†æ:**")
    print(f"   ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰ã‚·ã‚°ãƒŠãƒ«: {signal_dist['trend_count']}ä»¶ ({signal_dist['trend_ratio']*100:.1f}%)")
    print(f"   ğŸ“‰ ãƒ¬ãƒ³ã‚¸ã‚·ã‚°ãƒŠãƒ«: {signal_dist['range_count']}ä»¶ ({signal_dist['range_ratio']*100:.1f}%)")
    print(f"   ğŸ”„ ã‚·ã‚°ãƒŠãƒ«é·ç§»: {transitions['total_transitions']}å›")
    print(f"   â±ï¸  å¹³å‡ã‚·ã‚°ãƒŠãƒ«æŒç¶š: {transitions['avg_signal_duration']:.1f}æœŸé–“")
    
    # ã‚·ã‚°ãƒŠãƒ«åˆ†å¸ƒã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
    trend_ratio = signal_dist['trend_ratio']
    if 0.4 <= trend_ratio <= 0.65:
        print(f"   âœ… ã‚·ã‚°ãƒŠãƒ«åˆ†å¸ƒãƒãƒ©ãƒ³ã‚¹: è‰¯å¥½ (ãƒˆãƒ¬ãƒ³ãƒ‰{trend_ratio*100:.1f}%)")
    elif trend_ratio > 0.7:
        print(f"   âš ï¸  ã‚·ã‚°ãƒŠãƒ«åˆ†å¸ƒ: ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šå¤šã‚ (ãƒˆãƒ¬ãƒ³ãƒ‰{trend_ratio*100:.1f}%)")
    elif trend_ratio < 0.35:
        print(f"   âš ï¸  ã‚·ã‚°ãƒŠãƒ«åˆ†å¸ƒ: ãƒ¬ãƒ³ã‚¸åˆ¤å®šå¤šã‚ (ãƒˆãƒ¬ãƒ³ãƒ‰{trend_ratio*100:.1f}%)")
    else:
        print(f"   âš ï¸  ã‚·ã‚°ãƒŠãƒ«åˆ†å¸ƒ: ã‚„ã‚„åã‚Šæœ‰ã‚Š (ãƒˆãƒ¬ãƒ³ãƒ‰{trend_ratio*100:.1f}%)")
    
    print(f"\nğŸ’ **ä¿¡é ¼åº¦åˆ†æ:**")
    print(f"   - é«˜ä¿¡é ¼åº¦(â‰¥80%): {conf_dist['high_confidence']}ä»¶ ({conf_dist['high_conf_ratio']*100:.1f}%)")
    print(f"   - ä¸­ä¿¡é ¼åº¦(60-80%): {conf_dist['medium_confidence']}ä»¶")
    print(f"   - ä½ä¿¡é ¼åº¦(<60%): {conf_dist['low_confidence']}ä»¶")
    print(f"   - å¹³å‡ä¿¡é ¼åº¦: {conf_dist['avg_confidence']:.4f}")
    
    # 8. å¯è¦–åŒ–
    print(f"\nğŸ“Š V3ã‚¨ãƒ³ãƒãƒ³ã‚¹ãƒãƒ©ãƒ³ã‚¹ç‰ˆ {data_type}çµæœå¯è¦–åŒ–ä¸­...")
    output_path = args.output or f'ultimate_trend_range_v3_enhanced_balanced_{data_type.replace(" ", "_").lower()}_results.png'
    
    if 'true_regime' in data.columns:
        plot_results_v3(data, results, output_path)
    else:
        plot_results_enhanced_with_real_data(data, results, save_path=output_path)
    
    print(f"âœ… å¯è¦–åŒ–å®Œäº† ({output_path})")
    
    # 9. æœ€çµ‚è©•ä¾¡
    print("\n" + "="*100)
    print("ğŸ† **V3.0 ENHANCED BALANCED FINAL EVALUATION**")
    print("="*100)
    
    if 'true_regime' in data.columns:
        final_score = performance['accuracy']
        print(f"ğŸ–ï¸  æœ€çµ‚è©•ä¾¡: {achievement_status}")
        print(f"ğŸ“Š ç·åˆç²¾åº¦: {final_score*100:.2f}%")
        print(f"ğŸ“Š ãƒãƒ©ãƒ³ã‚¹ç²¾åº¦: {performance['balanced_accuracy']*100:.2f}%")
        print(f"ğŸ’ å“è³ªæŒ‡æ¨™(MCC): {performance['mcc']:.4f}")
        
        if final_score >= 0.75:
            print(f"\nğŸ‰ğŸ† **ãƒãƒ©ãƒ³ã‚¹è¨­å®šã§75%ä»¥ä¸Šé”æˆï¼å®Ÿç”¨æ€§ãƒ»ç²¾åº¦ãƒ»ãƒãƒ©ãƒ³ã‚¹ã®ä¸‰ä½ä¸€ä½“ï¼** ğŸ†ğŸ‰")
        elif final_score >= 0.70:
            print(f"\nâ­ğŸ”¥ **å®Ÿç”¨çš„ãª70%ä»¥ä¸Šã®ç²¾åº¦ã‚’å®Ÿç¾ï¼** ğŸ”¥â­")
        else:
            print(f"\nğŸ“ˆğŸ’« **ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã«ã‚ˆã‚Šå®Ÿç”¨æ€§ã‚’é‡è¦–ã—ãŸå®‰å®šé‹ç”¨ï¼** ğŸ’«ğŸ“ˆ")
    else:
        print(f"ğŸ–ï¸  å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿è§£æå®Œäº†")
        print(f"ğŸ“Š è§£æãƒ‡ãƒ¼ã‚¿: {data_type}")
        print(f"ğŸ“Š ç·ã‚·ã‚°ãƒŠãƒ«æ•°: {signal_dist['total']}")
        print(f"ğŸ“Š å¹³å‡ä¿¡é ¼åº¦: {conf_dist['avg_confidence']:.4f}")
        print(f"ğŸ’ é«˜ä¿¡é ¼åº¦æ¯”ç‡: {conf_dist['high_conf_ratio']*100:.1f}%")
        
        print(f"\nğŸš€ **ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ç‰ˆã«ã‚ˆã‚‹å®Ÿç”¨çš„ãªç›¸å ´è§£æå®Œäº†ï¼**")
        print("ğŸ’ V3ã‚¨ãƒ³ãƒãƒ³ã‚¹ãƒãƒ©ãƒ³ã‚¹ç‰ˆã«ã‚ˆã‚Šã€å®Ÿç”¨æ€§ã¨ç²¾åº¦ã‚’ä¸¡ç«‹ã—ãŸåˆ¤åˆ¥ã‚’å®Ÿç¾ï¼")
    
    print(f"\nğŸŒŸ **ãƒãƒ©ãƒ³ã‚¹æŠ€è¡“:**")
    print("   ğŸš€ é©åº¦é–¾å€¤ã‚·ã‚¹ãƒ†ãƒ : åŸºæœ¬0.40ã€ç¯„å›²0.20-0.65ã®å®Ÿç”¨è¨­å®š")
    print("   ğŸ’ å®Ÿç”¨åŠ¹ç‡æ¯”: ä¸­ç¨‹åº¦ãƒˆãƒ¬ãƒ³ãƒ‰ã‚‚é©åº¦ã«ãƒ–ãƒ¼ã‚¹ãƒˆã§å®Ÿç”¨æ¤œå‡º")
    print("   ğŸ¯ æŸ”è»Ÿãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ä¸€è²«æ€§: ãƒãƒ©ãƒ³ã‚¹é‡ã¿ä»˜ãã€0.5%é–¾å€¤ã§å®Ÿç”¨æ¤œå‡º")
    print("   ğŸ§  å®Ÿç”¨å¤šæ®µéšåˆ¤å®š: 2æŒ‡æ¨™ä»¥ä¸Šä¸€è‡´ã®æŸ”è»Ÿã‚·ã‚¹ãƒ†ãƒ ")
    print("   ğŸ”§ ãƒãƒ©ãƒ³ã‚¹ãƒã‚¤ã‚ºãƒ•ã‚£ãƒ«ã‚¿: å®Ÿç”¨æ€§é‡è¦–ã®ãƒãƒ©ãƒ³ã‚¹ãƒ•ã‚£ãƒ«ã‚¿")
    
    print("\nV3.0 ENHANCED BALANCED EDITION COMPLETE")
    print("="*100)


if __name__ == "__main__":
    main() 