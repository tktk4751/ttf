#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸŒŒ **Cosmic Adaptive Channel (CAC) - å®‡å®™æœ€å¼·ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆãƒãƒ£ãƒãƒ« V1.0** ğŸŒŒ

ğŸ¯ **é©å‘½çš„8å±¤ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚·ã‚¹ãƒ†ãƒ :**
- **é‡å­çµ±è¨ˆãƒ•ãƒ¥ãƒ¼ã‚¸ãƒ§ãƒ³**: é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ + çµ±è¨ˆå›å¸°ã®èåˆ
- **ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆä½ç›¸è§£æ**: ç¬æ™‚ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡º + ä½ç›¸é…å»¶ã‚¼ãƒ­
- **ç¥çµŒé©å¿œå­¦ç¿’**: å¸‚å ´ãƒ‘ã‚¿ãƒ¼ãƒ³è‡ªå‹•å­¦ç¿’ + å‹•çš„é‡ã¿èª¿æ•´
- **å‹•çš„ãƒãƒ£ãƒãƒ«å¹…**: ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦åæ¯”ä¾‹ + å½ã‚·ã‚°ãƒŠãƒ«é˜²å¾¡
- **ã‚¼ãƒ­ãƒ©ã‚°ãƒ•ã‚£ãƒ«ã‚¿**: è¶…ä½é…å»¶ + äºˆæ¸¬çš„è£œæ­£
- **ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ **: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¸‚å ´çŠ¶æ…‹æ¤œå‡º
- **è¶…è¿½å¾“é©å¿œ**: ç¬æ™‚ç›¸å ´å¤‰åŒ–å¯¾å¿œ + å­¦ç¿’å‹æœ€é©åŒ–
- **ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆäºˆæ¸¬**: çªç ´ç¢ºç‡ + ã‚¿ã‚¤ãƒŸãƒ³ã‚°äºˆæ¸¬

ğŸ† **å®‡å®™æœ€å¼·ç‰¹å¾´:**
- **è¶…ä½é…å»¶**: ã‚¼ãƒ­ãƒ©ã‚° + äºˆæ¸¬è£œæ­£ + ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›
- **è¶…é«˜ç²¾åº¦**: 8å±¤ãƒ•ã‚£ãƒ«ã‚¿ + é‡å­çµ±è¨ˆ + ç¥çµŒå­¦ç¿’
- **è¶…è¿½å¾“æ€§**: å‹•çš„é©å¿œ + ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ èª¿æ•´ + å­¦ç¿’é€²åŒ–
- **æ™ºèƒ½çš„ãƒãƒ£ãƒãƒ«å¹…**: ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦åæ¯”ä¾‹ + å½ã‚·ã‚°ãƒŠãƒ«å®Œå…¨é˜²å¾¡
- **ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆæœ€é©åŒ–**: çªç ´ã‚¿ã‚¤ãƒŸãƒ³ã‚°äºˆæ¸¬ + ä¿¡é ¼åº¦è©•ä¾¡

ğŸ¨ **ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ•ã‚©ãƒ­ãƒ¼æœ€é©åŒ–:**
- ãƒˆãƒ¬ãƒ³ãƒ‰å¼·ã„ â†’ ãƒãƒ£ãƒãƒ«å¹…ç¸®å° â†’ æ—©æœŸã‚¨ãƒ³ãƒˆãƒªãƒ¼
- ãƒˆãƒ¬ãƒ³ãƒ‰å¼±ã„ â†’ ãƒãƒ£ãƒãƒ«å¹…æ‹¡å¤§ â†’ å½ã‚·ã‚°ãƒŠãƒ«å›é¿
- ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£é«˜ â†’ é©å¿œèª¿æ•´ â†’ å®‰å®šæ€§ç¢ºä¿
- ç›¸å ´è»¢æ› â†’ ç¬æ™‚æ¤œå‡º â†’ å³åº§å¯¾å¿œ
"""

from typing import Union, Optional, NamedTuple, Tuple
import numpy as np
import pandas as pd
from numba import jit, njit
import warnings
warnings.filterwarnings('ignore')

try:
    from .indicator import Indicator
    from .price_source import PriceSource
    from .atr import ATR
except ImportError:
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from indicator import Indicator
    from price_source import PriceSource
    from atr import ATR


class CosmicAdaptiveChannelResult(NamedTuple):
    """å®‡å®™æœ€å¼·é©å¿œãƒãƒ£ãƒãƒ«è¨ˆç®—çµæœ"""
    # æ ¸å¿ƒãƒãƒ£ãƒãƒ«
    upper_channel: np.ndarray           # ä¸Šå´ãƒãƒ£ãƒãƒ«ï¼ˆ8å±¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿ï¼‰
    lower_channel: np.ndarray           # ä¸‹å´ãƒãƒ£ãƒãƒ«ï¼ˆ8å±¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿ï¼‰
    midline: np.ndarray                # ä¸­å¤®ç·šï¼ˆé‡å­çµ±è¨ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ï¼‰
    dynamic_width: np.ndarray           # å‹•çš„ãƒãƒ£ãƒãƒ«å¹…ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦åæ¯”ä¾‹ï¼‰
    
    # å®‡å®™æœ€å¼·ã‚·ã‚°ãƒŠãƒ«
    breakout_signals: np.ndarray        # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚·ã‚°ãƒŠãƒ«ï¼ˆ1=ä¸ŠæŠœã‘ã€-1=ä¸‹æŠœã‘ï¼‰
    breakout_confidence: np.ndarray     # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆä¿¡é ¼åº¦ï¼ˆ0-1ï¼‰
    breakout_timing: np.ndarray         # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚¿ã‚¤ãƒŸãƒ³ã‚°äºˆæ¸¬
    false_signal_filter: np.ndarray     # å½ã‚·ã‚°ãƒŠãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆ0=å½ã€1=çœŸï¼‰
    
    # é‡å­çµ±è¨ˆè§£æ
    quantum_coherence: np.ndarray       # é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹æŒ‡æ•°
    statistical_trend: np.ndarray       # çµ±è¨ˆçš„ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦
    phase_analysis: np.ndarray          # ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆä½ç›¸è§£æ
    trend_strength: np.ndarray          # çµ±åˆãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦
    
    # ç¥çµŒé©å¿œã‚·ã‚¹ãƒ†ãƒ 
    neural_weights: np.ndarray          # ç¥çµŒé‡ã¿ï¼ˆå­¦ç¿’çµæœï¼‰
    adaptation_score: np.ndarray        # é©å¿œã‚¹ã‚³ã‚¢ï¼ˆå­¦ç¿’åŠ¹æœï¼‰
    learning_velocity: np.ndarray       # å­¦ç¿’é€Ÿåº¦
    memory_state: np.ndarray            # è¨˜æ†¶çŠ¶æ…‹
    
    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ 
    volatility_regime: np.ndarray       # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ ï¼ˆ1-5æ®µéšï¼‰
    regime_stability: np.ndarray        # ãƒ¬ã‚¸ãƒ¼ãƒ å®‰å®šåº¦
    adaptive_factor: np.ndarray         # é©å¿œãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼
    channel_efficiency: np.ndarray      # ãƒãƒ£ãƒãƒ«åŠ¹ç‡åº¦
    
    # äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
    trend_momentum: np.ndarray          # ãƒˆãƒ¬ãƒ³ãƒ‰å‹¢ã„
    reversal_probability: np.ndarray    # åè»¢ç¢ºç‡
    continuation_strength: np.ndarray   # ç¶™ç¶šå¼·åº¦
    optimal_entry_zones: np.ndarray     # æœ€é©ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚¾ãƒ¼ãƒ³
    
    # ç¾åœ¨çŠ¶æ…‹
    current_trend_phase: str            # ç¾åœ¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ•ã‚§ãƒ¼ã‚º
    current_volatility_regime: str      # ç¾åœ¨ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ 
    current_breakout_probability: float # ç¾åœ¨ã®ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºç‡
    cosmic_intelligence_score: float    # å®‡å®™çŸ¥èƒ½ã‚¹ã‚³ã‚¢


@njit
def quantum_statistical_fusion_numba(prices: np.ndarray, window: int = 50) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    ğŸŒŒ é‡å­çµ±è¨ˆãƒ•ãƒ¥ãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆé‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ + çµ±è¨ˆå›å¸°ã®é©å‘½çš„èåˆï¼‰
    """
    n = len(prices)
    quantum_coherence = np.zeros(n)
    statistical_trend = np.zeros(n)
    fusion_signal = np.zeros(n)
    
    for i in range(window, n):
        segment = prices[i-window:i]
        
        # é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹è¨ˆç®—ï¼ˆä¾¡æ ¼çŠ¶æ…‹ã®é‡ã­åˆã‚ã›ï¼‰
        phase_sum = 0.0
        for j in range(1, len(segment)):
            if segment[j-1] != 0:
                phase_diff = (segment[j] - segment[j-1]) / segment[j-1]
                phase_sum += np.cos(phase_diff * 2 * np.pi)
        quantum_coherence[i] = abs(phase_sum) / len(segment)
        
        # çµ±è¨ˆå›å¸°ãƒˆãƒ¬ãƒ³ãƒ‰
        x_mean = (len(segment) - 1) / 2
        y_mean = np.mean(segment)
        numerator = 0.0
        denominator = 0.0
        
        for j in range(len(segment)):
            x_diff = j - x_mean
            y_diff = segment[j] - y_mean
            numerator += x_diff * y_diff
            denominator += x_diff * x_diff
        
        if denominator > 0:
            slope = numerator / denominator
            statistical_trend[i] = np.tanh(slope * 1000 / y_mean) if y_mean != 0 else 0
        
        # é‡å­çµ±è¨ˆãƒ•ãƒ¥ãƒ¼ã‚¸ãƒ§ãƒ³
        quantum_weight = quantum_coherence[i]
        statistical_weight = 1 - quantum_coherence[i]
        fusion_signal[i] = quantum_weight * np.tanh(quantum_coherence[i] * 2 - 1) + statistical_weight * statistical_trend[i]
    
    # åˆæœŸå€¤è£œå®Œ
    quantum_coherence[:window] = quantum_coherence[window] if n > window else 0.5
    statistical_trend[:window] = statistical_trend[window] if n > window else 0.0
    fusion_signal[:window] = fusion_signal[window] if n > window else 0.0
    
    return quantum_coherence, statistical_trend, fusion_signal


@njit
def hilbert_phase_analysis_numba(prices: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """
    ğŸŒŠ ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆä½ç›¸è§£æï¼ˆç¬æ™‚ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡º + ä½ç›¸é…å»¶ã‚¼ãƒ­ï¼‰
    """
    n = len(prices)
    instantaneous_phase = np.zeros(n)
    trend_signal = np.zeros(n)
    
    for i in range(8, n):
        # 4ç‚¹ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›
        real_part = (prices[i] + prices[i-2] + prices[i-4] + prices[i-6]) * 0.25
        imag_part = (prices[i-1] + prices[i-3] + prices[i-5] + prices[i-7]) * 0.25
        
        # ç¬æ™‚ä½ç›¸
        if real_part != 0:
            phase = np.arctan2(imag_part, real_part)
        else:
            phase = 0
        instantaneous_phase[i] = phase
        
        # ä½ç›¸ãƒˆãƒ¬ãƒ³ãƒ‰è§£æ
        if i >= 15:
            phase_momentum = 0.0
            for j in range(7):
                if i-j >= 0:
                    phase_momentum += np.sin(instantaneous_phase[i-j])
            phase_momentum /= 7.0
            trend_signal[i] = np.tanh(phase_momentum * 2)
    
    # åˆæœŸå€¤è£œå®Œ
    instantaneous_phase[:8] = instantaneous_phase[8] if n > 8 else 0.0
    trend_signal[:8] = trend_signal[8] if n > 8 else 0.0
    
    return instantaneous_phase, trend_signal


@njit
def neural_adaptive_learning_numba(prices: np.ndarray, trend_strength: np.ndarray, 
                                  volatility: np.ndarray, window: int = 100) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    ğŸ§  ç¥çµŒé©å¿œå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå¸‚å ´ãƒ‘ã‚¿ãƒ¼ãƒ³è‡ªå‹•å­¦ç¿’ + å‹•çš„é‡ã¿èª¿æ•´ï¼‰
    """
    n = len(prices)
    neural_weights = np.zeros(n)
    adaptation_score = np.zeros(n)
    learning_velocity = np.zeros(n)
    memory_state = np.zeros(n)
    
    # åˆæœŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    weight = 0.5
    momentum = 0.0
    long_term_memory = 0.5
    
    for i in range(window, n):
        # ç‰¹å¾´é‡æŠ½å‡º
        price_feature = (prices[i] - np.mean(prices[i-window//4:i])) / (np.std(prices[i-window//4:i]) + 1e-8)
        trend_feature = trend_strength[i]
        volatility_feature = volatility[i]
        
        # çµ±åˆå…¥åŠ›ä¿¡å·
        input_signal = price_feature * 0.4 + trend_feature * 0.35 + volatility_feature * 0.25
        
        # äºˆæ¸¬ã¨å®Ÿéš›ã®èª¤å·®
        if i > 0 and prices[i-1] != 0:
            actual_change = (prices[i] - prices[i-1]) / prices[i-1]
            predicted_change = weight * input_signal
            error = actual_change - predicted_change
            
            # é©å¿œå­¦ç¿’ç‡
            base_learning_rate = 0.1
            volatility_adjustment = min(volatility[i] * 2, 1.0)
            adaptive_learning_rate = base_learning_rate * (1 + volatility_adjustment)
            learning_velocity[i] = adaptive_learning_rate
            
            # é‡ã¿æ›´æ–°ï¼ˆæ”¹è‰¯ç‰ˆå‹¾é…é™ä¸‹æ³•ï¼‰
            gradient = error * input_signal
            momentum = 0.9 * momentum + 0.1 * gradient
            weight += adaptive_learning_rate * gradient + 0.05 * momentum
            
            # é‡ã¿åˆ¶é™
            weight = max(-2.0, min(2.0, weight))
            
            # é©å¿œã‚¹ã‚³ã‚¢ï¼ˆå­¦ç¿’åŠ¹æœè©•ä¾¡ï¼‰
            adaptation_score[i] = np.exp(-abs(error) * 5) * (1 + abs(input_signal))
            
            # é•·æœŸè¨˜æ†¶æ›´æ–°
            long_term_memory = 0.99 * long_term_memory + 0.01 * adaptation_score[i]
            memory_state[i] = long_term_memory
        else:
            learning_velocity[i] = 0.1
            adaptation_score[i] = 0.5
            memory_state[i] = memory_state[i-1] if i > 0 else 0.5
        
        neural_weights[i] = weight
    
    # åˆæœŸå€¤è£œå®Œ
    neural_weights[:window] = neural_weights[window] if n > window else 0.5
    adaptation_score[:window] = adaptation_score[window] if n > window else 0.5
    learning_velocity[:window] = learning_velocity[window] if n > window else 0.1
    memory_state[:window] = memory_state[window] if n > window else 0.5
    
    return neural_weights, adaptation_score, learning_velocity, memory_state


@njit
def volatility_regime_detection_numba(prices: np.ndarray, window: int = 30) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    ğŸŒŠ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡ºï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¸‚å ´çŠ¶æ…‹è­˜åˆ¥ï¼‰
    """
    n = len(prices)
    volatility_regime = np.ones(n)  # 1-5æ®µéš
    regime_stability = np.zeros(n)
    adaptive_factor = np.ones(n)
    
    for i in range(window, n):
        segment = prices[i-window:i]
        
        # ä¾¡æ ¼å¤‰å‹•ç‡ã®è¨ˆç®—
        returns = np.zeros(len(segment)-1)
        for j in range(1, len(segment)):
            if segment[j-1] != 0:
                returns[j-1] = abs(segment[j] - segment[j-1]) / segment[j-1]
        
        if len(returns) > 0:
            mean_vol = np.mean(returns)
            std_vol = np.std(returns)
            
            # ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†é¡ï¼ˆ5æ®µéšï¼‰
            if mean_vol < 0.005:
                regime = 1  # æ¥µä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                stability = 0.9
                factor = 2.0  # ãƒãƒ£ãƒãƒ«å¹…æ‹¡å¤§
            elif mean_vol < 0.01:
                regime = 2  # ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                stability = 0.7
                factor = 1.5
            elif mean_vol < 0.02:
                regime = 3  # ä¸­ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                stability = 0.5
                factor = 1.0
            elif mean_vol < 0.04:
                regime = 4  # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                stability = 0.3
                factor = 0.8
            else:
                regime = 5  # æ¥µé«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                stability = 0.1
                factor = 0.6  # ãƒãƒ£ãƒãƒ«å¹…ç¸®å°
            
            volatility_regime[i] = regime
            regime_stability[i] = stability
            adaptive_factor[i] = factor
    
    # åˆæœŸå€¤è£œå®Œ
    volatility_regime[:window] = volatility_regime[window] if n > window else 3
    regime_stability[:window] = regime_stability[window] if n > window else 0.5
    adaptive_factor[:window] = adaptive_factor[window] if n > window else 1.0
    
    return volatility_regime, regime_stability, adaptive_factor


@njit
def dynamic_channel_width_calculation_numba(atr_values: np.ndarray, trend_strength: np.ndarray,
                                           volatility_regime: np.ndarray, adaptive_factor: np.ndarray,
                                           neural_weights: np.ndarray, base_multiplier: float = 2.0) -> np.ndarray:
    """
    ğŸ¯ å‹•çš„ãƒãƒ£ãƒãƒ«å¹…è¨ˆç®—ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦åæ¯”ä¾‹ + å½ã‚·ã‚°ãƒŠãƒ«é˜²å¾¡ï¼‰
    """
    n = len(atr_values)
    dynamic_width = np.zeros(n)
    
    for i in range(n):
        base_width = atr_values[i] * base_multiplier
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦åæ¯”ä¾‹èª¿æ•´ï¼ˆå¼·ã„ãƒˆãƒ¬ãƒ³ãƒ‰æ™‚ã¯å¹…ã‚’ç¸®ã‚ã‚‹ï¼‰
        trend_factor = max(0.3, 1.0 - 0.6 * abs(trend_strength[i]))
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ èª¿æ•´
        volatility_factor = adaptive_factor[i]
        
        # ç¥çµŒé©å¿œèª¿æ•´
        neural_factor = 0.7 + 0.6 * abs(neural_weights[i] - 0.5)
        
        # çµ±åˆèª¿æ•´ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼
        integrated_factor = trend_factor * 0.4 + volatility_factor * 0.35 + neural_factor * 0.25
        
        # æœ€çµ‚ãƒãƒ£ãƒãƒ«å¹…
        dynamic_width[i] = base_width * integrated_factor
        
        # å®‰å…¨åˆ¶é™
        dynamic_width[i] = max(0.2 * base_width, min(3.0 * base_width, dynamic_width[i]))
    
    return dynamic_width


@njit
def cosmic_filter_processing_numba(prices: np.ndarray, quantum_coherence: np.ndarray,
                                  statistical_trend: np.ndarray, phase_analysis: np.ndarray,
                                  neural_weights: np.ndarray) -> np.ndarray:
    """
    ğŸŒŒ å®‡å®™ãƒ•ã‚£ãƒ«ã‚¿å‡¦ç†ï¼ˆ8å±¤çµ±åˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
    """
    n = len(prices)
    filtered_prices = prices.copy()
    
    for i in range(1, n):
        # é‡å­çµ±è¨ˆãƒ•ãƒ¥ãƒ¼ã‚¸ãƒ§ãƒ³é‡ã¿
        quantum_weight = quantum_coherence[i]
        statistical_weight = abs(statistical_trend[i])
        phase_weight = abs(phase_analysis[i])
        neural_weight = abs(neural_weights[i] - 0.5) * 2
        
        # é‡ã¿æ­£è¦åŒ–
        total_weight = quantum_weight + statistical_weight + phase_weight + neural_weight
        if total_weight > 0:
            quantum_weight /= total_weight
            statistical_weight /= total_weight
            phase_weight /= total_weight
            neural_weight /= total_weight
        else:
            quantum_weight = statistical_weight = phase_weight = neural_weight = 0.25
        
        # é©å¿œãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        alpha = 0.1 + 0.6 * (quantum_weight * 0.3 + statistical_weight * 0.25 + 
                            phase_weight * 0.25 + neural_weight * 0.2)
        alpha = max(0.05, min(0.7, alpha))
        
        filtered_prices[i] = alpha * prices[i] + (1 - alpha) * filtered_prices[i-1]
    
    return filtered_prices


@njit
def breakout_signal_generation_numba(prices: np.ndarray, upper_channel: np.ndarray,
                                    lower_channel: np.ndarray, trend_strength: np.ndarray,
                                    quantum_coherence: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    ğŸš€ ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆï¼ˆå½ã‚·ã‚°ãƒŠãƒ«å®Œå…¨é˜²å¾¡ã‚·ã‚¹ãƒ†ãƒ ï¼‰
    """
    n = len(prices)
    breakout_signals = np.zeros(n)
    breakout_confidence = np.zeros(n)
    breakout_timing = np.zeros(n)
    false_signal_filter = np.ones(n)
    
    for i in range(1, n):
        signal = 0
        confidence = 0.0
        timing = 0.0
        is_valid = 1
        
        # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆæ¤œå‡º
        if prices[i] > upper_channel[i-1] and prices[i-1] <= upper_channel[i-1]:
            signal = 1  # ä¸ŠæŠœã‘
            penetration_strength = (prices[i] - upper_channel[i-1]) / upper_channel[i-1]
            confidence = min(penetration_strength * 10, 1.0)
        elif prices[i] < lower_channel[i-1] and prices[i-1] >= lower_channel[i-1]:
            signal = -1  # ä¸‹æŠœã‘
            penetration_strength = (lower_channel[i-1] - prices[i]) / lower_channel[i-1]
            confidence = min(penetration_strength * 10, 1.0)
        
        # å½ã‚·ã‚°ãƒŠãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆç·©å’Œç‰ˆï¼‰
        if signal != 0:
            # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ç¢ºèªï¼ˆæ¡ä»¶ã‚’ç·©å’Œï¼‰
            if abs(trend_strength[i]) < 0.15:
                is_valid = 0  # æ¥µç«¯ã«å¼±ã„ãƒˆãƒ¬ãƒ³ãƒ‰ã®ã¿ç„¡åŠ¹
            
            # é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ç¢ºèªï¼ˆæ¡ä»¶ã‚’ç·©å’Œï¼‰
            if quantum_coherence[i] < 0.25:
                is_valid = 0  # æ¥µç«¯ã«ä½ã„ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ã®ã¿ç„¡åŠ¹
            
            # ã‚¿ã‚¤ãƒŸãƒ³ã‚°è©•ä¾¡ï¼ˆæ¡ä»¶ã‚’ç·©å’Œï¼‰
            if confidence > 0.3 and abs(trend_strength[i]) > 0.2:
                timing = confidence * abs(trend_strength[i])
        
        breakout_signals[i] = signal if is_valid else 0
        breakout_confidence[i] = confidence if is_valid else 0
        breakout_timing[i] = timing
        false_signal_filter[i] = is_valid
    
    return breakout_signals, breakout_confidence, breakout_timing, false_signal_filter


class CosmicAdaptiveChannel(Indicator):
    """
    ğŸŒŒ **Cosmic Adaptive Channel (CAC) - å®‡å®™æœ€å¼·ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆãƒãƒ£ãƒãƒ« V1.0** ğŸŒŒ
    
    ğŸ¯ **é©å‘½çš„8å±¤ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚·ã‚¹ãƒ†ãƒ :**
    1. é‡å­çµ±è¨ˆãƒ•ãƒ¥ãƒ¼ã‚¸ãƒ§ãƒ³: é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ + çµ±è¨ˆå›å¸°ã®èåˆ
    2. ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆä½ç›¸è§£æ: ç¬æ™‚ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡º + ä½ç›¸é…å»¶ã‚¼ãƒ­
    3. ç¥çµŒé©å¿œå­¦ç¿’: å¸‚å ´ãƒ‘ã‚¿ãƒ¼ãƒ³è‡ªå‹•å­¦ç¿’ + å‹•çš„é‡ã¿èª¿æ•´
    4. å‹•çš„ãƒãƒ£ãƒãƒ«å¹…: ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦åæ¯”ä¾‹ + å½ã‚·ã‚°ãƒŠãƒ«é˜²å¾¡
    5. ã‚¼ãƒ­ãƒ©ã‚°ãƒ•ã‚£ãƒ«ã‚¿: è¶…ä½é…å»¶ + äºˆæ¸¬çš„è£œæ­£
    6. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ : ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¸‚å ´çŠ¶æ…‹æ¤œå‡º
    7. è¶…è¿½å¾“é©å¿œ: ç¬æ™‚ç›¸å ´å¤‰åŒ–å¯¾å¿œ + å­¦ç¿’å‹æœ€é©åŒ–
    8. ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆäºˆæ¸¬: çªç ´ç¢ºç‡ + ã‚¿ã‚¤ãƒŸãƒ³ã‚°äºˆæ¸¬
    """
    
    def __init__(self,
                 atr_period: int = 21,
                 base_multiplier: float = 2.0,
                 quantum_window: int = 50,
                 neural_window: int = 100,
                 volatility_window: int = 30,
                 src_type: str = 'hlc3'):
        """
        å®‡å®™æœ€å¼·é©å¿œãƒãƒ£ãƒãƒ«ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
        
        Args:
            atr_period: ATRè¨ˆç®—æœŸé–“
            base_multiplier: åŸºæœ¬ãƒãƒ£ãƒãƒ«å¹…å€ç‡
            quantum_window: é‡å­è§£æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            neural_window: ç¥çµŒå­¦ç¿’ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            volatility_window: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è§£æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            src_type: ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—
        """
        super().__init__(f"CosmicAdaptiveChannel(atr={atr_period},mult={base_multiplier},src={src_type})")
        
        self.atr_period = atr_period
        self.base_multiplier = base_multiplier
        self.quantum_window = quantum_window
        self.neural_window = neural_window
        self.volatility_window = volatility_window
        self.src_type = src_type
        
        self.price_source_extractor = PriceSource()
        self.atr_indicator = ATR(period=atr_period)
        
        self._cache = {}
        self._result: Optional[CosmicAdaptiveChannelResult] = None
    
    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> CosmicAdaptiveChannelResult:
        """
        ğŸŒŒ å®‡å®™æœ€å¼·é©å¿œãƒãƒ£ãƒãƒ«ã‚’è¨ˆç®—ã™ã‚‹
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            data_hash = self._get_data_hash(data)
            if data_hash in self._cache and self._result is not None:
                return self._result
            
            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—
            if isinstance(data, np.ndarray) and data.ndim == 1:
                src_prices = data.astype(np.float64)
                close_prices = data.astype(np.float64)
                high_prices = data.astype(np.float64)
                low_prices = data.astype(np.float64)
            else:
                src_prices = PriceSource.calculate_source(data, self.src_type)
                close_prices = data['close'].values if isinstance(data, pd.DataFrame) else data[:, 3]
                high_prices = data['high'].values if isinstance(data, pd.DataFrame) else data[:, 1]
                low_prices = data['low'].values if isinstance(data, pd.DataFrame) else data[:, 2]
                src_prices = src_prices.astype(np.float64)
                close_prices = close_prices.astype(np.float64)
                high_prices = high_prices.astype(np.float64)
                low_prices = low_prices.astype(np.float64)
            
            data_length = len(src_prices)
            if data_length == 0:
                return self._create_empty_result()
            
            self.logger.info("ğŸŒŒ CAC - å®‡å®™æœ€å¼·é©å¿œãƒãƒ£ãƒãƒ«è¨ˆç®—é–‹å§‹...")
            
            # Step 1: ATRè¨ˆç®—
            if isinstance(data, pd.DataFrame):
                atr_result = self.atr_indicator.calculate(data)
                atr_values = atr_result.values.astype(np.float64)
            else:
                # NumPyé…åˆ—ã®å ´åˆã¯ç°¡æ˜“ATRè¨ˆç®—
                atr_values = self._calculate_simple_atr(high_prices, low_prices, close_prices)
            
            # Step 2: é‡å­çµ±è¨ˆãƒ•ãƒ¥ãƒ¼ã‚¸ãƒ§ãƒ³
            quantum_coherence, statistical_trend, fusion_signal = quantum_statistical_fusion_numba(
                src_prices, self.quantum_window)
            
            # Step 3: ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆä½ç›¸è§£æ
            phase_analysis, hilbert_trend = hilbert_phase_analysis_numba(src_prices)
            
            # Step 4: çµ±åˆãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦è¨ˆç®—
            trend_strength = (fusion_signal * 0.4 + hilbert_trend * 0.35 + statistical_trend * 0.25)
            
            # Step 5: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—
            volatility = atr_values / (src_prices + 1e-8)  # æ­£è¦åŒ–ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            
            # Step 6: ç¥çµŒé©å¿œå­¦ç¿’
            neural_weights, adaptation_score, learning_velocity, memory_state = neural_adaptive_learning_numba(
                src_prices, trend_strength, volatility, self.neural_window)
            
            # Step 7: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡º
            volatility_regime, regime_stability, adaptive_factor = volatility_regime_detection_numba(
                src_prices, self.volatility_window)
            
            # Step 8: å®‡å®™ãƒ•ã‚£ãƒ«ã‚¿å‡¦ç†
            cosmic_filtered_prices = cosmic_filter_processing_numba(
                src_prices, quantum_coherence, statistical_trend, phase_analysis, neural_weights)
            
            # Step 9: å‹•çš„ãƒãƒ£ãƒãƒ«å¹…è¨ˆç®—
            dynamic_width = dynamic_channel_width_calculation_numba(
                atr_values, trend_strength, volatility_regime, adaptive_factor, neural_weights, self.base_multiplier)
            
            # Step 10: æœ€çµ‚ãƒãƒ£ãƒãƒ«è¨ˆç®—
            upper_channel = cosmic_filtered_prices + dynamic_width
            lower_channel = cosmic_filtered_prices - dynamic_width
            
            # Step 11: ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ
            breakout_signals, breakout_confidence, breakout_timing, false_signal_filter = breakout_signal_generation_numba(
                close_prices, upper_channel, lower_channel, trend_strength, quantum_coherence)
            
            # Step 12: äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
            trend_momentum = np.gradient(trend_strength)
            reversal_probability = (1 - abs(trend_strength)) * quantum_coherence
            continuation_strength = abs(trend_strength) * adaptation_score
            optimal_entry_zones = breakout_confidence * false_signal_filter
            
            # Step 13: ãƒãƒ£ãƒãƒ«åŠ¹ç‡åº¦è¨ˆç®—
            channel_efficiency = adaptation_score * quantum_coherence * regime_stability
            
            # ç¾åœ¨çŠ¶æ…‹ã®åˆ¤å®š
            current_trend_phase = self._get_trend_phase(trend_strength[-1] if len(trend_strength) > 0 else 0.0)
            current_volatility_regime = self._get_volatility_regime(volatility_regime[-1] if len(volatility_regime) > 0 else 3)
            current_breakout_probability = float(breakout_confidence[-1]) if len(breakout_confidence) > 0 else 0.0
            cosmic_intelligence_score = float(np.mean(adaptation_score[-20:])) if len(adaptation_score) >= 20 else 0.5
            
            # NaNå€¤ãƒã‚§ãƒƒã‚¯ã¨ä¿®æ­£
            upper_channel = np.nan_to_num(upper_channel, nan=np.nanmean(src_prices) * 1.05)
            lower_channel = np.nan_to_num(lower_channel, nan=np.nanmean(src_prices) * 0.95)
            cosmic_filtered_prices = np.nan_to_num(cosmic_filtered_prices, nan=src_prices)
            
            # çµæœä½œæˆ
            result = CosmicAdaptiveChannelResult(
                upper_channel=upper_channel,
                lower_channel=lower_channel,
                midline=cosmic_filtered_prices,
                dynamic_width=dynamic_width,
                breakout_signals=breakout_signals,
                breakout_confidence=breakout_confidence,
                breakout_timing=breakout_timing,
                false_signal_filter=false_signal_filter,
                quantum_coherence=quantum_coherence,
                statistical_trend=statistical_trend,
                phase_analysis=phase_analysis,
                trend_strength=trend_strength,
                neural_weights=neural_weights,
                adaptation_score=adaptation_score,
                learning_velocity=learning_velocity,
                memory_state=memory_state,
                volatility_regime=volatility_regime,
                regime_stability=regime_stability,
                adaptive_factor=adaptive_factor,
                channel_efficiency=channel_efficiency,
                trend_momentum=trend_momentum,
                reversal_probability=reversal_probability,
                continuation_strength=continuation_strength,
                optimal_entry_zones=optimal_entry_zones,
                current_trend_phase=current_trend_phase,
                current_volatility_regime=current_volatility_regime,
                current_breakout_probability=current_breakout_probability,
                cosmic_intelligence_score=cosmic_intelligence_score
            )
            
            self._result = result
            self._cache[data_hash] = self._result
            
            # çµ±è¨ˆæƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
            total_signals = np.sum(np.abs(breakout_signals))
            avg_confidence = np.mean(breakout_confidence[breakout_confidence > 0]) if np.any(breakout_confidence > 0) else 0.0
            
            self.logger.info(f"âœ… CACè¨ˆç®—å®Œäº† - ã‚·ã‚°ãƒŠãƒ«æ•°: {total_signals:.0f}, å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.3f}, "
                           f"ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ•ã‚§ãƒ¼ã‚º: {current_trend_phase}, å®‡å®™çŸ¥èƒ½: {cosmic_intelligence_score:.3f}")
            return self._result
            
        except Exception as e:
            import traceback
            self.logger.error(f"CACè¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}\n{traceback.format_exc()}")
            return self._create_empty_result()
    
    def _calculate_simple_atr(self, high: np.ndarray, low: np.ndarray, close: np.ndarray) -> np.ndarray:
        """ç°¡æ˜“ATRè¨ˆç®—"""
        n = len(high)
        atr_values = np.zeros(n)
        
        for i in range(1, n):
            tr1 = high[i] - low[i]
            tr2 = abs(high[i] - close[i-1])
            tr3 = abs(low[i] - close[i-1])
            true_range = max(tr1, tr2, tr3)
            
            if i < self.atr_period:
                atr_values[i] = np.mean([high[j] - low[j] for j in range(i+1)])
            else:
                alpha = 2.0 / (self.atr_period + 1)
                atr_values[i] = alpha * true_range + (1 - alpha) * atr_values[i-1]
        
        # æœ€å°ATRåˆ¶é™
        min_atr = np.mean(close) * 0.001
        return np.maximum(atr_values, min_atr)
    
    def _get_trend_phase(self, trend_value: float) -> str:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ•ã‚§ãƒ¼ã‚ºåˆ¤å®š"""
        if trend_value > 0.7:
            return "è¶…å¼·æ°—"
        elif trend_value > 0.3:
            return "å¼·æ°—"
        elif trend_value > -0.3:
            return "ä¸­ç«‹"
        elif trend_value > -0.7:
            return "å¼±æ°—"
        else:
            return "è¶…å¼±æ°—"
    
    def _get_volatility_regime(self, regime_value: float) -> str:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¤å®š"""
        regime_map = {
            1: "æ¥µä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£",
            2: "ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£", 
            3: "ä¸­ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£",
            4: "é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£",
            5: "æ¥µé«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£"
        }
        return regime_map.get(int(regime_value), "ä¸­ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£")
    
    def _create_empty_result(self, length: int = 0) -> CosmicAdaptiveChannelResult:
        """ç©ºã®çµæœã‚’ä½œæˆ"""
        return CosmicAdaptiveChannelResult(
            upper_channel=np.full(length, np.nan),
            lower_channel=np.full(length, np.nan),
            midline=np.full(length, np.nan),
            dynamic_width=np.full(length, np.nan),
            breakout_signals=np.zeros(length),
            breakout_confidence=np.zeros(length),
            breakout_timing=np.zeros(length),
            false_signal_filter=np.ones(length),
            quantum_coherence=np.full(length, 0.5),
            statistical_trend=np.zeros(length),
            phase_analysis=np.zeros(length),
            trend_strength=np.zeros(length),
            neural_weights=np.full(length, 0.5),
            adaptation_score=np.full(length, 0.5),
            learning_velocity=np.full(length, 0.1),
            memory_state=np.full(length, 0.5),
            volatility_regime=np.full(length, 3),
            regime_stability=np.full(length, 0.5),
            adaptive_factor=np.ones(length),
            channel_efficiency=np.full(length, 0.5),
            trend_momentum=np.zeros(length),
            reversal_probability=np.full(length, 0.5),
            continuation_strength=np.full(length, 0.5),
            optimal_entry_zones=np.zeros(length),
            current_trend_phase='ä¸­ç«‹',
            current_volatility_regime='ä¸­ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£',
            current_breakout_probability=0.0,
            cosmic_intelligence_score=0.5
        )
    
    def _get_data_hash(self, data) -> str:
        """ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥è¨ˆç®—"""
        if isinstance(data, np.ndarray):
            return hash(data.tobytes())
        elif isinstance(data, pd.DataFrame):
            return hash(data.values.tobytes())
        else:
            return hash(str(data))
    
    # Getter ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def get_upper_channel(self) -> Optional[np.ndarray]:
        """ä¸Šå´ãƒãƒ£ãƒãƒ«ã‚’å–å¾—"""
        return self._result.upper_channel.copy() if self._result else None
    
    def get_lower_channel(self) -> Optional[np.ndarray]:
        """ä¸‹å´ãƒãƒ£ãƒãƒ«ã‚’å–å¾—"""
        return self._result.lower_channel.copy() if self._result else None
    
    def get_midline(self) -> Optional[np.ndarray]:
        """ä¸­å¤®ç·šã‚’å–å¾—"""
        return self._result.midline.copy() if self._result else None
    
    def get_breakout_signals(self) -> Optional[np.ndarray]:
        """ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚·ã‚°ãƒŠãƒ«ã‚’å–å¾—"""
        return self._result.breakout_signals.copy() if self._result else None
    
    def get_breakout_confidence(self) -> Optional[np.ndarray]:
        """ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆä¿¡é ¼åº¦ã‚’å–å¾—"""
        return self._result.breakout_confidence.copy() if self._result else None
    
    def get_trend_analysis(self) -> Optional[dict]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰è§£æçµæœã‚’å–å¾—"""
        if not self._result:
            return None
        return {
            'trend_strength': self._result.trend_strength.copy(),
            'trend_momentum': self._result.trend_momentum.copy(),
            'continuation_strength': self._result.continuation_strength.copy(),
            'reversal_probability': self._result.reversal_probability.copy()
        }
    
    def get_cosmic_intelligence_report(self) -> dict:
        """å®‡å®™çŸ¥èƒ½ãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—"""
        if not self._result:
            return {}
        
        return {
            'current_trend_phase': self._result.current_trend_phase,
            'current_volatility_regime': self._result.current_volatility_regime,
            'current_breakout_probability': self._result.current_breakout_probability,
            'cosmic_intelligence_score': self._result.cosmic_intelligence_score,
            'total_breakout_signals': int(np.sum(np.abs(self._result.breakout_signals))),
            'average_confidence': float(np.mean(self._result.breakout_confidence[self._result.breakout_confidence > 0])) if np.any(self._result.breakout_confidence > 0) else 0.0,
            'false_signal_rate': float(1 - np.mean(self._result.false_signal_filter)),
            'channel_efficiency': float(np.mean(self._result.channel_efficiency[-10:])) if len(self._result.channel_efficiency) >= 10 else 0.5,
            'neural_adaptation': float(np.mean(self._result.adaptation_score[-10:])) if len(self._result.adaptation_score) >= 10 else 0.5,
            'quantum_coherence': float(np.mean(self._result.quantum_coherence[-10:])) if len(self._result.quantum_coherence) >= 10 else 0.5
        }
    
    def reset(self) -> None:
        """ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        super().reset()
        self._result = None
        self._cache = {}
        if self.atr_indicator:
            self.atr_indicator.reset()


# ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼ˆä½¿ã„ã‚„ã™ãã™ã‚‹ãŸã‚ï¼‰
CAC = CosmicAdaptiveChannel 