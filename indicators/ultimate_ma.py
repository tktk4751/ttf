#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from typing import Union, Optional, NamedTuple, Tuple
import numpy as np
import pandas as pd
from numba import jit

# ã‚¤ãƒ³ãƒãƒ¼ãƒˆå‡¦ç†
try:
    from .indicator import Indicator
    from .price_source import PriceSource
    from .smoother.ultimate_smoother import UltimateSmoother  # ã‚¢ãƒ«ãƒ†ã‚£ãƒ¡ãƒƒãƒˆã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼
except ImportError:
    # ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œæ™‚ã®å¯¾å¿œ
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from indicator import Indicator
    from price_source import PriceSource
    from indicators.smoother.ultimate_smoother import UltimateSmoother  # ã‚¢ãƒ«ãƒ†ã‚£ãƒ¡ãƒƒãƒˆã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼

# EhlersUnifiedDCã¯å‹•çš„ã«æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆå®Ÿè¡Œæ™‚ã«ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³å†…ã§å‡¦ç†ï¼‰


class UltimateMAResult(NamedTuple):
    """UltimateMAè¨ˆç®—çµæœ"""
    values: np.ndarray              # æœ€çµ‚ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿ä¾¡æ ¼
    raw_values: np.ndarray          # å…ƒã®ä¾¡æ ¼
    ukf_values: np.ndarray          # hlc3ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œ
    kalman_values: np.ndarray       # é©å¿œçš„ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œ
    kalman_gains: np.ndarray        # ã‚«ãƒ«ãƒãƒ³ã‚²ã‚¤ãƒ³
    kalman_innovations: np.ndarray  # ã‚«ãƒ«ãƒãƒ³ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³
    kalman_confidence: np.ndarray   # ã‚«ãƒ«ãƒãƒ³ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
    ultimate_smooth_values: np.ndarray # ã‚¢ãƒ«ãƒ†ã‚£ãƒ¡ãƒƒãƒˆã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼å¾Œ
    zero_lag_values: np.ndarray     # ã‚¼ãƒ­ãƒ©ã‚°EMAå¾Œ
    amplitude: np.ndarray           # ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›æŒ¯å¹…
    phase: np.ndarray              # ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ä½ç›¸
    realtime_trends: np.ndarray     # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒˆãƒ¬ãƒ³ãƒ‰
    trend_signals: np.ndarray       # 1=up, -1=down, 0=range
    current_trend: str              # 'up', 'down', 'range'
    current_trend_value: int        # 1, -1, 0


# é©å¿œçš„ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¨ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯å‰Šé™¤
# hlc3ã¨UltimateSmoother ã‚’ä½¿ç”¨


@jit(nopython=True)
def zero_lag_ema_numba(prices: np.ndarray, period: int = 21) -> np.ndarray:
    """
    âš¡ ã‚¼ãƒ­ãƒ©ã‚°EMAï¼ˆé…å»¶ã‚¼ãƒ­æŒ‡æ•°ç§»å‹•å¹³å‡ï¼‰
    é…å»¶ã‚’å®Œå…¨ã«é™¤å»ã—ãŸé©æ–°çš„EMA
    """
    n = len(prices)
    zero_lag = np.zeros(n)
    
    if n < 2:
        return prices.copy()
    
    alpha = 2.0 / (period + 1.0)
    zero_lag[0] = prices[0]
    
    for i in range(1, n):
        # æ¨™æº–EMA
        ema = alpha * prices[i] + (1 - alpha) * zero_lag[i-1]
        
        # ã‚¼ãƒ­ãƒ©ã‚°è£œæ­£ï¼ˆäºˆæ¸¬çš„è£œæ­£ï¼‰
        if i >= 2:
            # ä¾¡æ ¼å¤‰åŒ–ã®å‹¢ã„ã‚’è¨ˆç®—
            momentum = prices[i] - prices[i-1]
            # ãƒ©ã‚°è£œæ­£ä¿‚æ•°
            lag_correction = alpha * momentum
            zero_lag[i] = ema + lag_correction
        else:
            zero_lag[i] = ema
    
    return zero_lag


@jit(nopython=True)
def alma_numba(prices: np.ndarray, period: int = 21, offset: float = 0.85, sigma: float = 6.0) -> np.ndarray:
    """
    ğŸ¯ ALMA (Arnaud Legoux Moving Average)
    é©å¿œçš„ãªé‡ã¿ä»˜ã‘ã«ã‚ˆã‚‹é«˜ç²¾åº¦ç§»å‹•å¹³å‡
    """
    n = len(prices)
    alma = np.zeros(n)
    
    if n < period:
        return prices.copy()
    
    # é‡ã¿ä¿‚æ•°ã®äº‹å‰è¨ˆç®—
    weights = np.zeros(period)
    m = offset * (period - 1)
    s = period / sigma
    
    for i in range(period):
        weights[i] = np.exp(-((i - m) ** 2) / (2 * s * s))
    
    # é‡ã¿ã®æ­£è¦åŒ–
    weight_sum = np.sum(weights)
    if weight_sum > 0:
        weights = weights / weight_sum
    
    # åˆæœŸå€¤è¨­å®š
    for i in range(period - 1):
        alma[i] = prices[i]
    
    # ALMAè¨ˆç®—
    for i in range(period - 1, n):
        value = 0.0
        for j in range(period):
            value += weights[j] * prices[i - period + 1 + j]
        alma[i] = value
    
    return alma


@jit(nopython=True)
def hma_numba(prices: np.ndarray, period: int = 21) -> np.ndarray:
    """
    ğŸš€ HMA (Hull Moving Average)
    ãƒ©ã‚°ã‚’æœ€å°åŒ–ã—ãŸé«˜å¿œç­”æ€§ç§»å‹•å¹³å‡
    """
    n = len(prices)
    hma = np.zeros(n)
    
    if n < period:
        return prices.copy()
    
    # WMAè¨ˆç®—ç”¨ã®é–¢æ•°ï¼ˆå†…éƒ¨é–¢æ•°ã¨ã—ã¦å®šç¾©ï¼‰
    def weighted_ma(data, length, start_idx):
        if length <= 0 or start_idx + length > len(data):
            return data[start_idx] if start_idx < len(data) else 0.0
        
        weight_sum = 0.0
        value_sum = 0.0
        
        for i in range(length):
            weight = length - i
            value_sum += data[start_idx + i] * weight
            weight_sum += weight
        
        return value_sum / weight_sum if weight_sum > 0 else 0.0
    
    half_period = max(1, period // 2)
    sqrt_period = max(1, int(np.sqrt(period)))
    
    # åˆæœŸå€¤è¨­å®š
    for i in range(period - 1):
        hma[i] = prices[i]
    
    # HMAè¨ˆç®—
    raw_hma = np.zeros(n)
    
    for i in range(period - 1, n):
        # WMA(period/2) * 2 - WMA(period)
        wma_half = weighted_ma(prices, half_period, i - half_period + 1)
        wma_full = weighted_ma(prices, period, i - period + 1)
        raw_hma[i] = 2.0 * wma_half - wma_full
    
    # æœ€çµ‚çš„ãªWMA(sqrt(period))
    for i in range(period - 1 + sqrt_period - 1, n):
        hma[i] = weighted_ma(raw_hma, sqrt_period, i - sqrt_period + 1)
    
    return hma


@jit(nopython=True)
def kama_numba(prices: np.ndarray, period: int = 21, fast_sc: float = 2.0, slow_sc: float = 30.0) -> np.ndarray:
    """
    ğŸ“ˆ KAMA (Kaufman's Adaptive Moving Average)
    ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã«é©å¿œã™ã‚‹å‹•çš„ç§»å‹•å¹³å‡
    """
    n = len(prices)
    kama = np.zeros(n)
    
    if n < period + 1:
        return prices.copy()
    
    # å¹³æ»‘åŒ–å®šæ•°
    fast_alpha = 2.0 / (fast_sc + 1.0)
    slow_alpha = 2.0 / (slow_sc + 1.0)
    
    # åˆæœŸå€¤è¨­å®š
    kama[0] = prices[0]
    for i in range(1, period):
        kama[i] = prices[i]
    
    # KAMAè¨ˆç®—
    for i in range(period, n):
        # å¤‰åŒ–é‡ã®è¨ˆç®—
        change = abs(prices[i] - prices[i - period])
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®è¨ˆç®—
        volatility = 0.0
        for j in range(period):
            volatility += abs(prices[i - j] - prices[i - j - 1])
        
        # åŠ¹ç‡æ¯”ã®è¨ˆç®—
        if volatility > 0:
            efficiency_ratio = change / volatility
        else:
            efficiency_ratio = 0.0
        
        # å¹³æ»‘åŒ–å®šæ•°ã®è¨ˆç®—
        smooth_constant = (efficiency_ratio * (fast_alpha - slow_alpha) + slow_alpha) ** 2
        
        # KAMAè¨ˆç®—
        kama[i] = kama[i - 1] + smooth_constant * (prices[i] - kama[i - 1])
    
    return kama


@jit(nopython=True)
def hilbert_transform_filter_numba(prices: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """
    ğŸŒ€ ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆä½ç›¸é…å»¶ã‚¼ãƒ­ï¼‰
    ç¬æ™‚æŒ¯å¹…ã¨ç¬æ™‚ä½ç›¸ã‚’è¨ˆç®—ã—ã€ãƒã‚¤ã‚ºã¨ä¿¡å·ã‚’åˆ†é›¢
    """
    n = len(prices)
    amplitude = np.zeros(n)
    phase = np.zeros(n)
    
    if n < 8:
        return prices.copy(), np.zeros(n)
    
    # ç°¡æ˜“ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ï¼ˆFIRãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¿‘ä¼¼ï¼‰
    for i in range(4, n-4):
        # å®Ÿéƒ¨ï¼ˆå…ƒä¿¡å·ï¼‰
        real_part = prices[i]
        
        # è™šéƒ¨ï¼ˆãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ï¼‰- 90åº¦ä½ç›¸ã‚·ãƒ•ãƒˆ
        imag_part = (prices[i-3] - prices[i+3] + 
                    3 * (prices[i+1] - prices[i-1])) / 8.0
        
        # ç¬æ™‚æŒ¯å¹…
        amplitude[i] = np.sqrt(real_part**2 + imag_part**2)
        
        # ç¬æ™‚ä½ç›¸
        if real_part != 0:
            phase[i] = np.arctan2(imag_part, real_part)
    
    # å¢ƒç•Œå€¤ã®å‡¦ç†
    for i in range(4):
        amplitude[i] = amplitude[4] if n > 4 else 0.0
        phase[i] = phase[4] if n > 4 else 0.0
    for i in range(n-4, n):
        amplitude[i] = amplitude[n-5] if n > 4 else 0.0
        phase[i] = phase[n-5] if n > 4 else 0.0
    
    return amplitude, phase


@jit(nopython=True)
def adaptive_noise_reduction_numba(prices: np.ndarray, amplitude: np.ndarray) -> np.ndarray:
    """
    ğŸ”‡ é©å¿œçš„ãƒã‚¤ã‚ºé™¤å»ï¼ˆAIé¢¨å­¦ç¿’å‹ï¼‰
    æŒ¯å¹…æƒ…å ±ã‚’ä½¿ç”¨ã—ã¦ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã‚’å‹•çš„ã«èª¿æ•´
    """
    n = len(prices)
    denoised = np.zeros(n)
    
    if n < 5:
        return prices.copy()
    
    # åˆæœŸå€¤
    denoised[0] = prices[0]
    
    for i in range(1, n):
        # ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã®æ¨å®š
        if i >= 10:
            # æœ€è¿‘ã®æŒ¯å¹…å¤‰å‹•ã‹ã‚‰ãƒã‚¤ã‚ºã‚’æ¨å®š
            recent_amp_std = np.std(amplitude[i-10:i])
            noise_threshold = recent_amp_std * 0.3
        else:
            noise_threshold = 0.1
        
        # ä¾¡æ ¼å¤‰åŒ–ã®å¤§ãã•
        price_change = abs(prices[i] - prices[i-1])
        
        # ãƒã‚¤ã‚ºåˆ¤å®šã¨é™¤å»
        if price_change < noise_threshold:
            # å°ã•ãªå¤‰åŒ–ã¯ãƒã‚¤ã‚ºã¨ã—ã¦é™¤å»ï¼ˆã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼‰
            if i >= 3:
                denoised[i] = (denoised[i-1] * 0.7 + 
                              prices[i] * 0.2 + 
                              denoised[i-2] * 0.1)
            else:
                denoised[i] = denoised[i-1] * 0.8 + prices[i] * 0.2
        else:
            # å¤§ããªå¤‰åŒ–ã¯ä¿¡å·ã¨ã—ã¦ä¿æŒ
            denoised[i] = prices[i] * 0.8 + denoised[i-1] * 0.2
    
    return denoised


@jit(nopython=True)
def real_time_trend_detector_numba(prices: np.ndarray, window: int = 5) -> np.ndarray:
    """
    ğŸ¯ **å®Ÿè·µçš„é«˜ç²¾åº¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºå™¨ V2.1**
    
    æœ¬è³ªçš„ãªãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºã«ç‰¹åŒ–ã—ãŸã‚·ãƒ³ãƒ—ãƒ«æœ€å¼·ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ :
    - **é©å¿œçš„ãƒã‚¤ã‚ºãƒ•ã‚£ãƒ«ã‚¿**: å¸‚å ´ãƒã‚¤ã‚ºã®å‹•çš„é™¤å»
    - **é‡ã¿ä»˜ããƒˆãƒ¬ãƒ³ãƒ‰**: è¤‡æ•°æœŸé–“ã®æœ€é©çµåˆ
    - **æœ¬è³ªæŠ½å‡º**: çœŸã®ãƒˆãƒ¬ãƒ³ãƒ‰ã®ã¿ã‚’æ¤œå‡º
    - **è¶…ä½é…å»¶**: æœ€å°3æœŸé–“ã‹ã‚‰å‡¦ç†é–‹å§‹
    """
    n = len(prices)
    trend_signals = np.zeros(n)
    
    if n < 3:  # æœ€å°3æœŸé–“ã§é–‹å§‹
        return trend_signals
    
    # é©å¿œçš„å¹³æ»‘åŒ–ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
    smoothed = np.zeros(n)
    smoothed[0] = prices[0]
    alpha = 0.3  # å¹³æ»‘åŒ–ä¿‚æ•°
    
    for i in range(1, n):
        if np.isnan(prices[i]):
            smoothed[i] = smoothed[i-1]
            continue
        
        # é©å¿œçš„å¹³æ»‘åŒ–ï¼ˆãƒã‚¤ã‚ºé™¤å»ï¼‰
        smoothed[i] = alpha * prices[i] + (1 - alpha) * smoothed[i-1]
    
    # ãƒ¡ã‚¤ãƒ³ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºãƒ«ãƒ¼ãƒ—
    for i in range(3, n):
        if np.isnan(prices[i]):
            trend_signals[i] = 0.0
            continue
        
        # ğŸ¯ 1. è¤‡æ•°æœŸé–“ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆé‡ã¿ä»˜ãï¼‰
        trend_1 = smoothed[i] - smoothed[i-1]           # ç¬é–“ï¼ˆé‡ã¿40%ï¼‰
        trend_2 = (smoothed[i] - smoothed[i-2]) / 2.0   # çŸ­æœŸï¼ˆé‡ã¿35%ï¼‰ 
        trend_3 = (smoothed[i] - smoothed[i-3]) / 3.0   # ä¸­æœŸï¼ˆé‡ã¿25%ï¼‰
        
        # é‡ã¿ä»˜ãçµ±åˆãƒˆãƒ¬ãƒ³ãƒ‰
        combined_trend = trend_1 * 0.4 + trend_2 * 0.35 + trend_3 * 0.25
        
        # ğŸ›¡ï¸ 2. å‹•çš„ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«åˆ¤å®šï¼ˆè¶…è»½é‡ï¼‰
        noise_threshold = 0.0
        if i >= 5:
            # ç›´è¿‘ã®ä¾¡æ ¼å¤‰å‹•ã‹ã‚‰ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã‚’æ¨å®š
            recent_noise = abs(prices[i-1] - prices[i-2]) + abs(prices[i-2] - prices[i-3])
            avg_noise = recent_noise / 2.0
            noise_threshold = avg_noise * 0.5  # ãƒã‚¤ã‚ºé–¾å€¤
        
        # ğŸ”¥ 3. æœ¬è³ªçš„ãƒˆãƒ¬ãƒ³ãƒ‰æŠ½å‡º
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
        consistency = 0.0
        if abs(trend_1) > 0 and abs(trend_2) > 0 and abs(trend_3) > 0:
            # 3ã¤ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã®æ–¹å‘ä¸€è‡´åº¦
            direction_1 = 1 if trend_1 > 0 else -1
            direction_2 = 1 if trend_2 > 0 else -1  
            direction_3 = 1 if trend_3 > 0 else -1
            
            main_direction = 1 if combined_trend > 0 else -1
            matches = 0
            if direction_1 == main_direction: matches += 1
            if direction_2 == main_direction: matches += 1
            if direction_3 == main_direction: matches += 1
            
            consistency = matches / 3.0
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã®è¨ˆç®—
        trend_strength = abs(combined_trend)
        
        # âš¡ 4. å®Ÿè·µçš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        
        # ãƒã‚¤ã‚ºãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if trend_strength <= noise_threshold:
            trend_signals[i] = 0.0  # ãƒã‚¤ã‚ºã¨ã—ã¦é™¤å»
            continue
        
        # ä¸€è²«æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if consistency < 0.6:  # 60%æœªæº€ã®ä¸€è²«æ€§ã¯å¼±ã„ä¿¡å·
            trend_strength *= 0.5  # ä¿¡å·ã‚’å¼±ã‚ã‚‹
        
        # ã‚ˆã‚Šé•·æœŸé–“ã®ãƒˆãƒ¬ãƒ³ãƒ‰ç¢ºèªï¼ˆå¯èƒ½ãªå ´åˆï¼‰
        long_term_boost = 1.0
        if i >= min(window, 8):
            long_trend = (smoothed[i] - smoothed[i-min(window, 8)]) / min(window, 8)
            
            # é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã¨ä¸€è‡´ã™ã‚‹å ´åˆã¯å¼·åŒ–
            if (combined_trend > 0 and long_trend > 0) or (combined_trend < 0 and long_trend < 0):
                long_term_boost = 1.3  # 30%å¼·åŒ–
        
        # ğŸ¯ 5. æœ€çµ‚ä¿¡å·ç”Ÿæˆï¼ˆæœ¬è³ªçš„ãƒˆãƒ¬ãƒ³ãƒ‰ã®ã¿ï¼‰
        
        final_strength = trend_strength * long_term_boost
        
        # æœ€å°å¼·åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆãƒã‚¤ã‚ºå®Œå…¨é™¤å»ï¼‰
        min_strength = max(noise_threshold * 2.0, abs(combined_trend) * 0.1)
        
        if final_strength > min_strength:
            # ç¬¦å·ä»˜ãå¼·åº¦ã§å‡ºåŠ›
            trend_signals[i] = final_strength * (1 if combined_trend > 0 else -1)
        else:
            trend_signals[i] = 0.0  # æœ¬è³ªçš„ã§ãªã„ãƒˆãƒ¬ãƒ³ãƒ‰ã¯é™¤å»
    
    return trend_signals


@jit(nopython=True)
def calculate_trend_signals_with_range_numba(values: np.ndarray, slope_index: int, range_threshold: float = 0.005) -> np.ndarray:
    """
    ğŸš€ **è¶…é«˜ç²¾åº¦AIé¢¨ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  V3.0** ğŸš€
    
    æœ€æ–°ã®é‡‘èå·¥å­¦æŠ€è¡“ã‚’çµ±åˆã—ãŸæ¬¡ä¸–ä»£åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ :
    - **é©å¿œçš„æŒ‡æ•°é‡ã¿ä»˜ã‘çµ±è¨ˆ**: æœ€æ–°ãƒ‡ãƒ¼ã‚¿é‡è¦–ã®å‹•çš„é–¾å€¤
    - **å¤šæ™‚é–“è»¸ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ åˆ†æ**: 1æœŸãƒ»2æœŸãƒ»3æœŸãƒ»5æœŸã®è¤‡åˆè§£æ
    - **AIé¢¨å‹•çš„ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢**: 4æŒ‡æ¨™ã®é‡ã¿ä»˜ãç·åˆè©•ä¾¡
    - **é«˜ç²¾åº¦ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ**: å¸‚å ´çŠ¶æ³ã®è‡ªå‹•åˆ¤å®šãƒ»é©å¿œ
    - **äºˆæ¸¬çš„åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ **: å…ˆèª­ã¿æ©Ÿèƒ½ã«ã‚ˆã‚‹æ—©æœŸæ¤œå‡º
    - **ç·Šæ€¥äº‹æ…‹æ¤œå‡º**: æ¥µç«¯å¤‰åŒ–ã¸ã®ç¬æ™‚å¯¾å¿œ
    
    Args:
        values: ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼å€¤ã®é…åˆ—
        slope_index: ã‚¹ãƒ­ãƒ¼ãƒ—åˆ¤å®šæœŸé–“
        range_threshold: rangeåˆ¤å®šã®åŸºæœ¬é–¾å€¤
    
    Returns:
        trend_signals: 1=up, -1=down, 0=range ã®NumPyé…åˆ—
    """
    length = len(values)
    trend_signals = np.zeros(length, dtype=np.int8)
    
    # è¶…ä½é…å»¶çµ±è¨ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆæœ€å°é™ã«çŸ­ç¸®ï¼‰
    stats_window = max(13, slope_index * 2)  # å¤§å¹…çŸ­ç¸®
    confirmation_window = 5  # å›ºå®š2æœŸé–“ã§å³å¿œæ€§é‡è¦–
    
    for i in range(stats_window, length):
        if np.isnan(values[i]):
            trend_signals[i] = 0
            continue
        
        current = values[i]
        previous = values[i - slope_index]
        
        if np.isnan(previous):
            trend_signals[i] = 0
            continue
        
        # åŸºæœ¬çš„ãªå¤‰åŒ–é‡
        change = current - previous
        base_value = max(abs(current), abs(previous), 1e-10)
        relative_change = change / base_value
        abs_relative_change = abs(relative_change)
        
        # ğŸ”¥ 1. é©å¿œçš„æŒ‡æ•°é‡ã¿ä»˜ã‘çµ±è¨ˆï¼ˆæœ€æ–°ãƒ‡ãƒ¼ã‚¿é‡è¦–ï¼‰
        start_idx = max(slope_index, i - stats_window + 1)
        
        # æŒ‡æ•°é‡ã¿ä»˜ã‘ã«ã‚ˆã‚‹é«˜ç²¾åº¦é–¾å€¤è¨ˆç®—
        weighted_changes = 0.0
        weighted_sum = 0.0
        weighted_variance = 0.0
        
        for j in range(start_idx + slope_index, i):
            if not np.isnan(values[j]) and not np.isnan(values[j - slope_index]):
                hist_current = values[j]
                hist_previous = values[j - slope_index]
                hist_base = max(abs(hist_current), abs(hist_previous), 1e-10)
                hist_change = abs(hist_current - hist_previous) / hist_base
                
                # æŒ‡æ•°é‡ã¿ï¼ˆæœ€æ–°ãƒ‡ãƒ¼ã‚¿ã»ã©é‡è¦ï¼‰
                age = i - j
                weight = np.exp(-age * 0.15)  # æŒ‡æ•°æ¸›è¡°
                
                weighted_changes += hist_change * weight
                weighted_sum += weight
        
        if weighted_sum > 0:
            weighted_mean = weighted_changes / weighted_sum
            
            # é‡ã¿ä»˜ãåˆ†æ•£ã®è¨ˆç®—
            for j in range(start_idx + slope_index, i):
                if not np.isnan(values[j]) and not np.isnan(values[j - slope_index]):
                    hist_current = values[j]
                    hist_previous = values[j - slope_index]
                    hist_base = max(abs(hist_current), abs(hist_previous), 1e-10)
                    hist_change = abs(hist_current - hist_previous) / hist_base
                    
                    age = i - j
                    weight = np.exp(-age * 0.15)
                    weighted_variance += weight * (hist_change - weighted_mean) ** 2
            
            weighted_std = np.sqrt(weighted_variance / weighted_sum) if weighted_sum > 0 else 0.0
            
            # å‹•çš„é©å¿œé–¾å€¤ï¼ˆæœ€æ–°ãƒ‡ãƒ¼ã‚¿é‡è¦–ï¼‰
            adaptive_threshold = weighted_mean + weighted_std * 1.0
            effective_threshold = max(range_threshold, adaptive_threshold)
        else:
            effective_threshold = range_threshold
        
        # ğŸš€ 2. å¤šæ™‚é–“è»¸ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ åˆ†æï¼ˆäºˆæ¸¬çš„ç¶™ç¶šæ€§ï¼‰
        momentum_score = 0.0
        consistency_score = 0.0
        
        if i >= confirmation_window:
            # è¤‡æ•°æ™‚é–“è»¸ã§ã®ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ è¨ˆç®—
            momentum_1 = change  # ç¾åœ¨ã®å¤‰åŒ–
            momentum_2 = (values[i] - values[i-2]) / 2.0 if i >= 2 and not np.isnan(values[i-2]) else 0.0
            momentum_3 = (values[i] - values[i-3]) / 3.0 if i >= 3 and not np.isnan(values[i-3]) else 0.0
            momentum_5 = (values[i] - values[i-5]) / 5.0 if i >= 5 and not np.isnan(values[i-5]) else 0.0
            
            # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ å¼·åº¦ï¼ˆåŠ é‡å¹³å‡ï¼‰
            momentum_weights = np.array([0.4, 0.3, 0.2, 0.1])
            momentums = np.array([momentum_1, momentum_2, momentum_3, momentum_5])
            
            # æ­£è¦åŒ–ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã‚¹ã‚³ã‚¢
            momentum_score = np.sum(momentums * momentum_weights)
            
            # æ–¹å‘ä¸€è‡´æ€§ã‚¹ã‚³ã‚¢ï¼ˆNumbaå¯¾å¿œç‰ˆï¼‰
            directions = np.zeros(4, dtype=np.int8)
            direction_count = 0
            
            if momentum_1 != 0: 
                directions[direction_count] = 1 if momentum_1 > 0 else -1
                direction_count += 1
            if momentum_2 != 0: 
                directions[direction_count] = 1 if momentum_2 > 0 else -1
                direction_count += 1
            if momentum_3 != 0: 
                directions[direction_count] = 1 if momentum_3 > 0 else -1
                direction_count += 1
            if momentum_5 != 0: 
                directions[direction_count] = 1 if momentum_5 > 0 else -1
                direction_count += 1
            
            if direction_count > 0:
                main_direction = 1 if change > 0 else -1
                consistent_count = 0
                for k in range(direction_count):
                    if directions[k] == main_direction:
                        consistent_count += 1
                consistency_score = consistent_count / direction_count
            else:
                consistency_score = 0.0
        
        # ğŸ¯ 3. é«˜ç²¾åº¦ãƒã‚¤ã‚ºãƒ»ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ
        volatility_factor = 1.0
        signal_strength = 0.0
        
        if i >= 8:
            
            # çŸ­æœŸå¤‰åŒ–ã®è¨ˆç®—ï¼ˆNumbaå¯¾å¿œï¼‰
            short_changes = np.zeros(4)
            short_count = 0
            for j in range(max(1, i-4), i):
                if not np.isnan(values[j]) and not np.isnan(values[j-1]) and short_count < 4:
                    short_changes[short_count] = abs(values[j] - values[j-1])
                    short_count += 1
            
            # ä¸­æœŸå¤‰åŒ–ã®è¨ˆç®—ï¼ˆNumbaå¯¾å¿œï¼‰
            mid_changes = np.zeros(4)
            mid_count = 0
            for j in range(max(2, i-8), i, 2):
                if not np.isnan(values[j]) and not np.isnan(values[j-2]) and mid_count < 4:
                    mid_changes[mid_count] = abs(values[j] - values[j-2])
                    mid_count += 1
            
            if short_count >= 2 and mid_count >= 2:
                # å¹³å‡è¨ˆç®—ï¼ˆNumbaå¯¾å¿œï¼‰
                short_vol = np.sum(short_changes[:short_count]) / short_count
                mid_vol = np.sum(mid_changes[:mid_count]) / mid_count
                
                # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æ¯”ç‡ï¼ˆå¸‚å ´çŠ¶æ³ã®åˆ¤å®šï¼‰
                vol_ratio = short_vol / (mid_vol + 1e-10)
                
                # ä¿¡å·å¼·åº¦ã®è¨ˆç®—
                signal_strength = abs(change) / (short_vol + 1e-10)
                
                # å‹•çš„ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è£œæ­£
                if vol_ratio > 1.5:  # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç’°å¢ƒ
                    volatility_factor = 1.3
                elif vol_ratio < 0.7:  # ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç’°å¢ƒ
                    volatility_factor = 0.8
                else:  # é€šå¸¸ç’°å¢ƒ
                    volatility_factor = 1.0
        
        final_threshold = effective_threshold * volatility_factor
        
        # ğŸ¯ 4. AIé¢¨å‹•çš„ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
        
        # è¤‡æ•°æŒ‡æ¨™ã®ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        change_score = min(abs_relative_change / final_threshold, 2.0)  # å¤‰åŒ–é‡ã‚¹ã‚³ã‚¢ï¼ˆæœ€å¤§2.0ï¼‰
        momentum_strength = min(abs(momentum_score) / (effective_threshold + 1e-10), 2.0)  # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã‚¹ã‚³ã‚¢
        consistency_weight = consistency_score  # ä¸€è²«æ€§é‡ã¿
        signal_quality = min(signal_strength, 3.0)  # ä¿¡å·å“è³ªï¼ˆæœ€å¤§3.0ï¼‰
        
        # ç·åˆä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ï¼ˆé‡ã¿ä»˜ãåˆæˆï¼‰
        confidence_score = (change_score * 0.35 +           # å¤‰åŒ–é‡ã®é‡è¦åº¦
                           momentum_strength * 0.25 +       # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã®é‡è¦åº¦  
                           consistency_weight * 0.25 +      # ä¸€è²«æ€§ã®é‡è¦åº¦
                           signal_quality * 0.15)           # ä¿¡å·å“è³ªã®é‡è¦åº¦
        
        # ğŸ”¥ 5. äºˆæ¸¬çš„åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ ï¼ˆå…ˆèª­ã¿æ©Ÿèƒ½ï¼‰
        
        # åŸºæœ¬ã—ãã„å€¤ãƒã‚§ãƒƒã‚¯
        base_threshold = 0.8  # åŸºæº–ä¿¡é ¼åº¦
        high_threshold = 1.3  # é«˜ä¿¡é ¼åº¦
        
        # æœ€å°å¤‰åŒ–é‡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        min_change_filter = abs_relative_change > range_threshold * 0.2
        
        if min_change_filter and confidence_score > 0.3:  # æœ€ä½ä¿¡é ¼åº¦30%
            if confidence_score > high_threshold:
                # é«˜ä¿¡é ¼åº¦ï¼šå³åº§ã«ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š
                trend_signals[i] = 1 if relative_change > 0 else -1
            elif confidence_score > base_threshold:
                # ä¸­ä¿¡é ¼åº¦ï¼šä¸€è²«æ€§ã‚‚ç¢ºèª
                if consistency_score >= 0.6:  # 60%ä»¥ä¸Šã®ä¸€è²«æ€§
                    trend_signals[i] = 1 if relative_change > 0 else -1
                else:
                    trend_signals[i] = 0  # ãƒ¬ãƒ³ã‚¸
            else:
                # ä½ä¿¡é ¼åº¦ï¼šå³æ ¼ãªæ¡ä»¶ã§ã®ã¿åˆ¤å®š
                if (consistency_score >= 0.8 and  # 80%ä»¥ä¸Šã®é«˜ä¸€è²«æ€§
                    signal_quality > 1.5 and      # é«˜å“è³ªä¿¡å·
                    change_score > 1.0):           # ååˆ†ãªå¤‰åŒ–é‡
                    trend_signals[i] = 1 if relative_change > 0 else -1
                else:
                    trend_signals[i] = 0  # ãƒ¬ãƒ³ã‚¸
        else:
            trend_signals[i] = 0  # ãƒ¬ãƒ³ã‚¸
        
        # ğŸ”¥ 6. æ¥µç«¯å¤‰åŒ–ãƒ»ç·Šæ€¥äº‹æ…‹æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ 
        extreme_threshold = final_threshold * 2.5
        if abs_relative_change > extreme_threshold:
            # æ¥µç«¯ãªå¤‰åŒ–ã®å ´åˆã€ç·Šæ€¥åˆ¤å®šãƒ¢ãƒ¼ãƒ‰
            emergency_confidence = change_score + signal_quality
            
            if emergency_confidence > 2.0:  # ç·Šæ€¥äº‹æ…‹ãƒ¬ãƒ™ãƒ«
                # æ–¹å‘ç¢ºèªã®ã¿ã§å³åº§ã«åˆ¤å®š
                if i >= 1 and not np.isnan(values[i-1]):
                    prev_change = values[i] - values[i-1]
                    same_direction = (relative_change > 0) == (prev_change > 0)
                    
                    if same_direction or emergency_confidence > 3.0:
                        trend_signals[i] = 1 if relative_change > 0 else -1
                else:
                    # å‰æœŸãƒ‡ãƒ¼ã‚¿ãªã—ã§ã‚‚è¶…æ¥µç«¯ãªå ´åˆã¯åˆ¤å®š
                    if abs_relative_change > extreme_threshold * 2.0:
                        trend_signals[i] = 1 if relative_change > 0 else -1
    
    return trend_signals


@jit(nopython=True)
def calculate_current_trend_with_range_numba(trend_signals: np.ndarray) -> tuple:
    """
    ç¾åœ¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰çŠ¶æ…‹ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆrangeå¯¾å¿œç‰ˆï¼‰(Numba JIT)
    
    Args:
        trend_signals: ãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡å·é…åˆ— (1=up, -1=down, 0=range)
    
    Returns:
        tuple: (current_trend_index, current_trend_value)
               current_trend_index: 0=range, 1=up, 2=down (trend_namesç”¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)
               current_trend_value: 0=range, 1=up, -1=down (å®Ÿéš›ã®ãƒˆãƒ¬ãƒ³ãƒ‰å€¤)
    """
    length = len(trend_signals)
    if length == 0:
        return 0, 0  # range
    
    # æœ€æ–°ã®å€¤ã‚’å–å¾—
    latest_trend = trend_signals[-1]
    
    if latest_trend == 1:  # up
        return 1, 1   # up
    elif latest_trend == -1:  # down
        return 2, -1   # down
    else:  # range
        return 0, 0  # range


@jit(nopython=True)
def zero_lag_ema_adaptive_numba(prices: np.ndarray, periods: np.ndarray) -> np.ndarray:
    """
    âš¡ å‹•çš„é©å¿œã‚¼ãƒ­ãƒ©ã‚°EMAï¼ˆæœŸé–“ãŒå‹•çš„ã«å¤‰åŒ–ï¼‰
    é…å»¶ã‚’å®Œå…¨ã«é™¤å»ã—ãŸé©æ–°çš„EMAï¼ˆé©å¿œçš„æœŸé–“å¯¾å¿œï¼‰
    """
    n = len(prices)
    zero_lag = np.zeros(n)
    
    if n < 2:
        return prices.copy()
    
    zero_lag[0] = prices[0]
    
    for i in range(1, n):
        # å‹•çš„æœŸé–“ã‹ã‚‰ã‚¢ãƒ«ãƒ•ã‚¡ã‚’è¨ˆç®—
        period = max(2.0, periods[i])  # æœ€å°æœŸé–“2
        alpha = 2.0 / (period + 1.0)
        
        # æ¨™æº–EMA
        ema = alpha * prices[i] + (1 - alpha) * zero_lag[i-1]
        
        # ã‚¼ãƒ­ãƒ©ã‚°è£œæ­£ï¼ˆäºˆæ¸¬çš„è£œæ­£ï¼‰
        if i >= 2:
            # ä¾¡æ ¼å¤‰åŒ–ã®å‹¢ã„ã‚’è¨ˆç®—
            momentum = prices[i] - prices[i-1]
            # ãƒ©ã‚°è£œæ­£ä¿‚æ•°
            lag_correction = alpha * momentum
            zero_lag[i] = ema + lag_correction
        else:
            zero_lag[i] = ema
    
    return zero_lag


@jit(nopython=True)
def real_time_trend_detector_adaptive_numba(prices: np.ndarray, windows: np.ndarray) -> np.ndarray:
    """
    ğŸ¯ **å‹•çš„é©å¿œå®Ÿè·µçš„é«˜ç²¾åº¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºå™¨ V2.1**
    
    æœ¬è³ªçš„ãªãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºã«ç‰¹åŒ–ã—ãŸã‚·ãƒ³ãƒ—ãƒ«æœ€å¼·ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆå‹•çš„æœŸé–“å¯¾å¿œï¼‰:
    - **å‹•çš„é©å¿œãƒã‚¤ã‚ºãƒ•ã‚£ãƒ«ã‚¿**: æœŸé–“ã«å¿œã˜ãŸå¸‚å ´ãƒã‚¤ã‚ºã®å‹•çš„é™¤å»
    - **é‡ã¿ä»˜ããƒˆãƒ¬ãƒ³ãƒ‰**: è¤‡æ•°æœŸé–“ã®æœ€é©çµåˆï¼ˆå‹•çš„èª¿æ•´ï¼‰
    - **æœ¬è³ªæŠ½å‡º**: çœŸã®ãƒˆãƒ¬ãƒ³ãƒ‰ã®ã¿ã‚’æ¤œå‡º
    - **è¶…ä½é…å»¶**: æœ€å°3æœŸé–“ã‹ã‚‰å‡¦ç†é–‹å§‹ï¼ˆå‹•çš„æœŸé–“å¯¾å¿œï¼‰
    """
    n = len(prices)
    trend_signals = np.zeros(n)
    
    if n < 3:  # æœ€å°3æœŸé–“ã§é–‹å§‹
        return trend_signals
    
    # é©å¿œçš„å¹³æ»‘åŒ–ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆå‹•çš„ç‰ˆï¼‰
    smoothed = np.zeros(n)
    smoothed[0] = prices[0]
    
    for i in range(1, n):
        if np.isnan(prices[i]):
            smoothed[i] = smoothed[i-1]
            continue
        
        # å‹•çš„é©å¿œå¹³æ»‘åŒ–ä¿‚æ•°ï¼ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã«å¿œã˜ã¦èª¿æ•´ï¼‰
        current_window = max(3, min(int(windows[i]), i))
        alpha = 2.0 / (current_window + 1.0)  # å‹•çš„alpha
        alpha = max(0.1, min(0.5, alpha))  # ç¯„å›²åˆ¶é™
        
        # é©å¿œçš„å¹³æ»‘åŒ–ï¼ˆãƒã‚¤ã‚ºé™¤å»ï¼‰
        smoothed[i] = alpha * prices[i] + (1 - alpha) * smoothed[i-1]
    
    # ãƒ¡ã‚¤ãƒ³ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºãƒ«ãƒ¼ãƒ—
    for i in range(3, n):
        if np.isnan(prices[i]):
            trend_signals[i] = 0.0
            continue
        
        # å‹•çš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
        current_window = max(3, min(int(windows[i]), i))
        
        # ğŸ¯ 1. å‹•çš„è¤‡æ•°æœŸé–“ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆé‡ã¿ä»˜ãï¼‰
        
        # åŸºæœ¬æœŸé–“ã®è¨­å®šï¼ˆå‹•çš„èª¿æ•´ï¼‰
        period_1 = 1
        period_2 = min(2, current_window // 3)
        period_3 = min(3, current_window // 2)
        
        # å„æœŸé–“ã®ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—
        trend_1 = smoothed[i] - smoothed[i-period_1]                    # ç¬é–“
        trend_2 = (smoothed[i] - smoothed[i-period_2]) / period_2       # çŸ­æœŸ
        trend_3 = (smoothed[i] - smoothed[i-period_3]) / period_3       # ä¸­æœŸ
        
        # å‹•çš„é‡ã¿ä»˜ãçµ±åˆï¼ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã«å¿œã˜ã¦èª¿æ•´ï¼‰
        if current_window <= 5:
            # çŸ­æœŸé–“ã®å ´åˆï¼šç¬é–“é‡è¦–
            combined_trend = trend_1 * 0.5 + trend_2 * 0.35 + trend_3 * 0.15
        elif current_window <= 15:
            # ä¸­æœŸé–“ã®å ´åˆï¼šãƒãƒ©ãƒ³ã‚¹é‡è¦–
            combined_trend = trend_1 * 0.4 + trend_2 * 0.35 + trend_3 * 0.25
        else:
            # é•·æœŸé–“ã®å ´åˆï¼šå®‰å®šæ€§é‡è¦–
            combined_trend = trend_1 * 0.3 + trend_2 * 0.35 + trend_3 * 0.35
        
        # ğŸ›¡ï¸ 2. å‹•çš„ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«åˆ¤å®šï¼ˆè¶…è»½é‡ï¼‰
        noise_threshold = 0.0
        if i >= 5:
            # ç›´è¿‘ã®ä¾¡æ ¼å¤‰å‹•ã‹ã‚‰ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã‚’æ¨å®šï¼ˆå‹•çš„èª¿æ•´ï¼‰
            lookback = min(5, current_window // 2)
            recent_noise = 0.0
            for j in range(1, lookback + 1):
                if i >= j + 1:
                    recent_noise += abs(prices[i-j] - prices[i-j-1])
            
            avg_noise = recent_noise / lookback if lookback > 0 else 0.0
            
            # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã«å¿œã˜ãŸãƒã‚¤ã‚ºé–¾å€¤èª¿æ•´
            noise_multiplier = 0.3 if current_window <= 10 else 0.5
            noise_threshold = avg_noise * noise_multiplier
        
        # ğŸ”¥ 3. æœ¬è³ªçš„ãƒˆãƒ¬ãƒ³ãƒ‰æŠ½å‡ºï¼ˆå‹•çš„ç‰ˆï¼‰
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
        consistency = 0.0
        if abs(trend_1) > 0 and abs(trend_2) > 0 and abs(trend_3) > 0:
            # 3ã¤ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã®æ–¹å‘ä¸€è‡´åº¦
            direction_1 = 1 if trend_1 > 0 else -1
            direction_2 = 1 if trend_2 > 0 else -1  
            direction_3 = 1 if trend_3 > 0 else -1
            
            main_direction = 1 if combined_trend > 0 else -1
            matches = 0
            if direction_1 == main_direction: matches += 1
            if direction_2 == main_direction: matches += 1
            if direction_3 == main_direction: matches += 1
            
            consistency = matches / 3.0
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã®è¨ˆç®—
        trend_strength = abs(combined_trend)
        
        # âš¡ 4. å‹•çš„å®Ÿè·µçš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        
        # ãƒã‚¤ã‚ºãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if trend_strength <= noise_threshold:
            trend_signals[i] = 0.0  # ãƒã‚¤ã‚ºã¨ã—ã¦é™¤å»
            continue
        
        # å‹•çš„ä¸€è²«æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã«å¿œã˜ã¦èª¿æ•´ï¼‰
        consistency_threshold = 0.5 if current_window <= 10 else 0.6
        if consistency < consistency_threshold:
            trend_strength *= 0.5  # ä¿¡å·ã‚’å¼±ã‚ã‚‹
        
        # ã‚ˆã‚Šé•·æœŸé–“ã®ãƒˆãƒ¬ãƒ³ãƒ‰ç¢ºèªï¼ˆå‹•çš„èª¿æ•´ï¼‰
        long_term_boost = 1.0
        long_period = min(current_window, 8)
        if i >= long_period:
            long_trend = (smoothed[i] - smoothed[i-long_period]) / long_period
            
            # é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã¨ä¸€è‡´ã™ã‚‹å ´åˆã¯å¼·åŒ–ï¼ˆå‹•çš„èª¿æ•´ï¼‰
            if (combined_trend > 0 and long_trend > 0) or (combined_trend < 0 and long_trend < 0):
                boost_factor = 1.2 if current_window <= 10 else 1.3  # å‹•çš„å¼·åŒ–
                long_term_boost = boost_factor
        
        # ğŸ¯ 5. æœ€çµ‚ä¿¡å·ç”Ÿæˆï¼ˆæœ¬è³ªçš„ãƒˆãƒ¬ãƒ³ãƒ‰ã®ã¿ãƒ»å‹•çš„ç‰ˆï¼‰
        
        final_strength = trend_strength * long_term_boost
        
        # å‹•çš„æœ€å°å¼·åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆãƒã‚¤ã‚ºå®Œå…¨é™¤å»ï¼‰
        min_strength_base = max(noise_threshold * 2.0, abs(combined_trend) * 0.1)
        
        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã«å¿œã˜ãŸæœ€å°å¼·åº¦èª¿æ•´
        window_factor = 0.8 if current_window <= 10 else 1.0
        min_strength = min_strength_base * window_factor
        
        if final_strength > min_strength:
            # ç¬¦å·ä»˜ãå¼·åº¦ã§å‡ºåŠ›
            trend_signals[i] = final_strength * (1 if combined_trend > 0 else -1)
        else:
            trend_signals[i] = 0.0  # æœ¬è³ªçš„ã§ãªã„ãƒˆãƒ¬ãƒ³ãƒ‰ã¯é™¤å»
    
    return trend_signals


@jit(nopython=True)
def adaptive_kalman_filter_numba(prices: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    ğŸ¯ é©å¿œçš„ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆè¶…ä½é…å»¶ãƒã‚¤ã‚ºé™¤å»ï¼‰
    å‹•çš„ã«ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã‚’æ¨å®šã—ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒã‚¤ã‚ºé™¤å»
    """
    n = len(prices)
    filtered_prices = np.zeros(n)
    kalman_gains = np.zeros(n)
    innovations = np.zeros(n)
    confidence_scores = np.zeros(n)
    
    if n < 2:
        return prices.copy(), kalman_gains, innovations, np.ones(n)
    
    # åˆæœŸåŒ–
    filtered_prices[0] = prices[0]
    kalman_gains[0] = 0.5
    innovations[0] = 0.0
    confidence_scores[0] = 1.0
    
    # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆé©å¿œçš„ï¼‰
    process_variance = 1e-5
    measurement_variance = 0.01
    
    # çŠ¶æ…‹æ¨å®š
    x_est = prices[0]
    p_est = 1.0
    
    for i in range(1, n):
        # äºˆæ¸¬ã‚¹ãƒ†ãƒƒãƒ—
        x_pred = x_est
        p_pred = p_est + process_variance
        
        # é©å¿œçš„æ¸¬å®šãƒã‚¤ã‚ºæ¨å®š
        if i >= 5:
            recent_volatility = np.std(prices[i-5:i])
            measurement_variance = max(0.001, min(0.1, recent_volatility * 0.1))
        
        # ã‚«ãƒ«ãƒãƒ³ã‚²ã‚¤ãƒ³
        kalman_gain = p_pred / (p_pred + measurement_variance)
        
        # æ›´æ–°ã‚¹ãƒ†ãƒƒãƒ—
        innovation = prices[i] - x_pred
        x_est = x_pred + kalman_gain * innovation
        p_est = (1 - kalman_gain) * p_pred
        
        filtered_prices[i] = x_est
        kalman_gains[i] = kalman_gain
        innovations[i] = innovation
        confidence_scores[i] = 1.0 / (1.0 + p_est)
    
    return filtered_prices, kalman_gains, innovations, confidence_scores


class UltimateMA(Indicator):
    """
    ğŸš€ **Ultimate Moving Average - V5.2 DYNAMIC ADAPTIVE QUANTUM NEURAL SUPREMACY EDITION**
    
    ğŸ¯ **6æ®µéšé©æ–°çš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ  + å‹•çš„é©å¿œæ©Ÿèƒ½:**
    1. **hlc3ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼**: ç„¡é¦™æ–™ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ»é«˜ç²¾åº¦çŠ¶æ…‹æ¨å®š
    2. **ã‚¢ãƒ«ãƒ†ã‚£ãƒ¡ãƒƒãƒˆã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼**: John Ehlers Ultimate Smootherãƒ»ã‚¼ãƒ­é…å»¶è¨­è¨ˆ
    3. **ã‚¼ãƒ­ãƒ©ã‚°EMA**: é…å»¶å®Œå…¨é™¤å»ãƒ»äºˆæ¸¬çš„è£œæ­£ï¼ˆå‹•çš„é©å¿œå¯¾å¿œï¼‰
    4. **ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼**: ä½ç›¸é…å»¶ã‚¼ãƒ­ãƒ»ç¬æ™‚æŒ¯å¹…/ä½ç›¸
    5. **é©å¿œçš„ãƒã‚¤ã‚ºé™¤å»**: AIé¢¨å­¦ç¿’å‹ãƒ»æŒ¯å¹…é€£å‹•èª¿æ•´
    6. **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡º**: è¶…ä½é…å»¶ãƒ»å³åº§åå¿œï¼ˆå‹•çš„é©å¿œå¯¾å¿œï¼‰
    
    ğŸ† **é©æ–°çš„ç‰¹å¾´:**
    - **ãƒã‚¤ã‚ºé™¤å»**: 6æ®µéšé©æ–°çš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    - **è¶…ä½é…å»¶**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†æœ€é©åŒ–
    - **ä½ç›¸é…å»¶ã‚¼ãƒ­**: ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›é©ç”¨
    - **é©å¿œçš„å­¦ç¿’**: AIé¢¨ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«æ¨å®š
    - **å‹•çš„é©å¿œ**: Ehlersã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºã«ã‚ˆã‚‹æœŸé–“è‡ªå‹•èª¿æ•´
    - **80%è¶…é«˜ä¿¡é ¼åº¦**: é‡å­ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æŠ€è¡“
    - **å®Œå…¨çµ±åˆå‡¦ç†**: å„æ®µéšã®çµæœã‚‚å–å¾—å¯èƒ½
    """
    
    def __init__(self, 
                 ultimate_smoother_period: float = 5.0,
                 zero_lag_period: int = 21,
                 realtime_window: int = 89,
                 src_type: str = 'hlc3',
                 slope_index: int = 1,
                 range_threshold: float = 0.005,
                 # é©å¿œçš„ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                 use_adaptive_kalman: bool = True,  # é©å¿œçš„ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ã‹
                 kalman_process_variance: float = 1e-5,  # ãƒ—ãƒ­ã‚»ã‚¹åˆ†æ•£
                 kalman_measurement_variance: float = 0.01,  # æ¸¬å®šåˆ†æ•£
                 kalman_volatility_window: int = 5,  # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
                 # å‹•çš„é©å¿œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                 zero_lag_period_mode: str = 'dynamic', # dynamic or fixed
                 realtime_window_mode: str = 'dynamic', # dynamic or fixed
                 # ã‚¼ãƒ­ãƒ©ã‚°ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                 zl_cycle_detector_type: str = 'absolute_ultimate',
                 zl_cycle_detector_cycle_part: float = 1.0,
                 zl_cycle_detector_max_cycle: int = 120,
                 zl_cycle_detector_min_cycle: int = 5,
                 zl_cycle_period_multiplier: float = 1.0,
                 # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                 rt_cycle_detector_type: str = 'absolute_ultimate',
                 rt_cycle_detector_cycle_part: float = 0.5,
                 rt_cycle_detector_max_cycle: int = 120,
                 rt_cycle_detector_min_cycle: int = 5,
                 rt_cycle_period_multiplier: float = 0.5,
                 # period_rangeãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆabsolute_ultimateã€ultra_supreme_stabilityç”¨ï¼‰
                 zl_cycle_detector_period_range: Tuple[int, int] = (5, 120),
                 rt_cycle_detector_period_range: Tuple[int, int] = (5, 120)):
        """
        ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
        
        Args:
            ultimate_smoother_period: ã‚¢ãƒ«ãƒ†ã‚£ãƒ¡ãƒƒãƒˆã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 13.0ï¼‰
            zero_lag_period: ã‚¼ãƒ­ãƒ©ã‚°EMAæœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 21ï¼‰
            realtime_window: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 89ï¼‰
            src_type: ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ ('close', 'hlc3', etc.)
            slope_index: ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šæœŸé–“ (1ä»¥ä¸Šã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1)
            range_threshold: rangeåˆ¤å®šã®åŸºæœ¬é–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.005 = 0.5%ï¼‰
            
            # é©å¿œçš„ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            use_adaptive_kalman: é©å¿œçš„ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰
            kalman_process_variance: ãƒ—ãƒ­ã‚»ã‚¹åˆ†æ•£ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1e-5ï¼‰
            kalman_measurement_variance: æ¸¬å®šåˆ†æ•£ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.01ï¼‰
            kalman_volatility_window: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰
            
            # UKFãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            ukf_alpha: UKFã®alphaå€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.001ï¼‰
            ukf_beta: UKFã®betaå€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2.0ï¼‰
            ukf_kappa: UKFã®kappaå€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.0ï¼‰
            ukf_process_noise_scale: ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚¤ã‚ºã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.001ï¼‰
            ukf_volatility_window: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ï¼‰
            ukf_adaptive_noise: é©å¿œãƒã‚¤ã‚ºã®ä½¿ç”¨ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰
            
            # å‹•çš„é©å¿œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            zero_lag_period_mode: ã‚¼ãƒ­ãƒ©ã‚°æœŸé–“ãƒ¢ãƒ¼ãƒ‰ ('fixed' or 'dynamic')
            realtime_window_mode: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãƒ¢ãƒ¼ãƒ‰ ('fixed' or 'dynamic')
            
            # ã‚¼ãƒ­ãƒ©ã‚°ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            zl_cycle_detector_type: ã‚¼ãƒ­ãƒ©ã‚°ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã‚¿ã‚¤ãƒ— ('hody', 'phac', 'dudi', etc.)
            zl_cycle_detector_cycle_part: ã‚¼ãƒ­ãƒ©ã‚°ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®ã‚µã‚¤ã‚¯ãƒ«éƒ¨åˆ†å€ç‡ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1.0ï¼‰
            zl_cycle_detector_max_cycle: ã‚¼ãƒ­ãƒ©ã‚°ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®æœ€å¤§ã‚µã‚¤ã‚¯ãƒ«æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 120ï¼‰
            zl_cycle_detector_min_cycle: ã‚¼ãƒ­ãƒ©ã‚°ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®æœ€å°ã‚µã‚¤ã‚¯ãƒ«æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰
            zl_cycle_period_multiplier: ã‚¼ãƒ­ãƒ©ã‚°ç”¨ã‚µã‚¤ã‚¯ãƒ«æœŸé–“ã®ä¹—æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1.0ï¼‰
            
            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            rt_cycle_detector_type: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã‚¿ã‚¤ãƒ— ('hody', 'phac', 'dudi', etc.)
            rt_cycle_detector_cycle_part: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®ã‚µã‚¤ã‚¯ãƒ«éƒ¨åˆ†å€ç‡ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.5ï¼‰
            rt_cycle_detector_max_cycle: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®æœ€å¤§ã‚µã‚¤ã‚¯ãƒ«æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50ï¼‰
            rt_cycle_detector_min_cycle: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®æœ€å°ã‚µã‚¤ã‚¯ãƒ«æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 6ï¼‰
            rt_cycle_period_multiplier: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ã‚µã‚¤ã‚¯ãƒ«æœŸé–“ã®ä¹—æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.33ï¼‰
            zl_cycle_detector_period_range: ã‚¼ãƒ­ãƒ©ã‚°ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®å‘¨æœŸç¯„å›²ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: (5, 120)ï¼‰
            rt_cycle_detector_period_range: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®å‘¨æœŸç¯„å›²ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: (5, 120)ï¼‰
        """
        kalman_info = f"KF:{'ON' if use_adaptive_kalman else 'OFF'}"
        super().__init__(f"UltimateMA({kalman_info},us={ultimate_smoother_period},zl={zero_lag_period}({zero_lag_period_mode}),rt={realtime_window}({realtime_window_mode}),src={src_type},slope={slope_index},range_th={range_threshold:.3f},zl_cycle={zl_cycle_detector_type},rt_cycle={rt_cycle_detector_type})")
        
        self.ultimate_smoother_period = ultimate_smoother_period
        self.zero_lag_period = zero_lag_period
        self.realtime_window = realtime_window
        self.src_type = src_type
        self.slope_index = slope_index
        self.range_threshold = range_threshold
        
        # é©å¿œçš„ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.use_adaptive_kalman = use_adaptive_kalman
        self.kalman_process_variance = kalman_process_variance
        self.kalman_measurement_variance = kalman_measurement_variance
        self.kalman_volatility_window = kalman_volatility_window
        
        # å‹•çš„é©å¿œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.zero_lag_period_mode = zero_lag_period_mode.lower()
        self.realtime_window_mode = realtime_window_mode.lower()
        
        # ã‚¼ãƒ­ãƒ©ã‚°ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.zl_cycle_detector_type = zl_cycle_detector_type
        self.zl_cycle_detector_cycle_part = zl_cycle_detector_cycle_part
        self.zl_cycle_detector_max_cycle = zl_cycle_detector_max_cycle
        self.zl_cycle_detector_min_cycle = zl_cycle_detector_min_cycle
        self.zl_cycle_period_multiplier = zl_cycle_period_multiplier
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.rt_cycle_detector_type = rt_cycle_detector_type
        self.rt_cycle_detector_cycle_part = rt_cycle_detector_cycle_part
        self.rt_cycle_detector_max_cycle = rt_cycle_detector_max_cycle
        self.rt_cycle_detector_min_cycle = rt_cycle_detector_min_cycle
        self.rt_cycle_period_multiplier = rt_cycle_period_multiplier
        self.zl_cycle_detector_period_range = zl_cycle_detector_period_range
        self.rt_cycle_detector_period_range = rt_cycle_detector_period_range
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼
        if self.zero_lag_period_mode not in ['fixed', 'dynamic']:
            raise ValueError(f"ç„¡åŠ¹ãªzero_lag_period_mode: {self.zero_lag_period_mode}. 'fixed' ã¾ãŸã¯ 'dynamic' ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        
        if self.realtime_window_mode not in ['fixed', 'dynamic']:
            raise ValueError(f"ç„¡åŠ¹ãªrealtime_window_mode: {self.realtime_window_mode}. 'fixed' ã¾ãŸã¯ 'dynamic' ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        
        self.price_source_extractor = PriceSource()
        
        # å‹•çš„é©å¿œãŒå¿…è¦ãªå ´åˆã®ã¿EhlersUnifiedDCã‚’åˆæœŸåŒ–
        self.zl_cycle_detector = None
        self.rt_cycle_detector = None
        
        # ã‚¼ãƒ­ãƒ©ã‚°ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®åˆæœŸåŒ–
        if self.zero_lag_period_mode == 'dynamic':
            # EhlersUnifiedDCã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆãƒ‡ãƒãƒƒã‚°ä»˜ãï¼‰
            EhlersUnifiedDC = None
            import_success = False
            
            try:
                # ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ
                from .cycle.ehlers_unified_dc import EhlersUnifiedDC
                import_success = True
                self.logger.debug("UltimateMA: EhlersUnifiedDC ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
            except ImportError as e1:
                self.logger.debug(f"UltimateMA: EhlersUnifiedDC ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•—: {e1}")
                try:
                    # çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œï¼ˆãƒ‘ã‚¹èª¿æ•´ä»˜ãï¼‰
                    import sys
                    import os
                    current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
                    if current_dir not in sys.path:
                        sys.path.insert(0, current_dir)
                    
                    from indicators.cycle.ehlers_unified_dc import EhlersUnifiedDC
                    import_success = True
                    self.logger.debug("UltimateMA: EhlersUnifiedDC çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
                except ImportError as e2:
                    self.logger.error(f"UltimateMA: EhlersUnifiedDC ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•— - ç›¸å¯¾: {e1}, çµ¶å¯¾: {e2}")
                    import_success = False
            
            if import_success and EhlersUnifiedDC is not None:
                try:
                    self.zl_cycle_detector = EhlersUnifiedDC(
                        detector_type=self.zl_cycle_detector_type,
                        cycle_part=self.zl_cycle_detector_cycle_part,
                        max_cycle=self.zl_cycle_detector_max_cycle,
                        min_cycle=self.zl_cycle_detector_min_cycle,
                        src_type=self.src_type,
                        period_range=self.zl_cycle_detector_period_range
                    )
                    self.logger.info(f"UltimateMA: ã‚¼ãƒ­ãƒ©ã‚°ç”¨å‹•çš„é©å¿œã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã‚’åˆæœŸåŒ–: {self.zl_cycle_detector_type}")
                except Exception as e:
                    self.logger.error(f"UltimateMA: ã‚¼ãƒ­ãƒ©ã‚°ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦å›ºå®šãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›´
                    self.zero_lag_period_mode = 'fixed'
                    self.logger.warning("UltimateMA: ã‚¼ãƒ­ãƒ©ã‚°å‹•çš„é©å¿œãƒ¢ãƒ¼ãƒ‰ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ãŸãŸã‚ã€å›ºå®šãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã—ãŸã€‚")
            else:
                self.logger.error("UltimateMA: EhlersUnifiedDCã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆã‚¼ãƒ­ãƒ©ã‚°ç”¨ï¼‰")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦å›ºå®šãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›´
                self.zero_lag_period_mode = 'fixed'
                self.logger.warning("UltimateMA: EhlersUnifiedDCã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•—ã®ãŸã‚ã€ã‚¼ãƒ­ãƒ©ã‚°å›ºå®šãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã—ãŸã€‚")
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®åˆæœŸåŒ–
        if self.realtime_window_mode == 'dynamic':
            # EhlersUnifiedDCã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆãƒ‡ãƒãƒƒã‚°ä»˜ãï¼‰
            EhlersUnifiedDC = None
            import_success = False
            
            try:
                # ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ
                from .cycle.ehlers_unified_dc import EhlersUnifiedDC
                import_success = True
                self.logger.debug("UltimateMA: EhlersUnifiedDC ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸï¼ˆRTç”¨ï¼‰")
            except ImportError as e1:
                self.logger.debug(f"UltimateMA: EhlersUnifiedDC ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•—ï¼ˆRTç”¨ï¼‰: {e1}")
                try:
                    # çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œï¼ˆãƒ‘ã‚¹èª¿æ•´ä»˜ãï¼‰
                    import sys
                    import os
                    current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
                    if current_dir not in sys.path:
                        sys.path.insert(0, current_dir)
                    
                    from indicators.cycle.ehlers_unified_dc import EhlersUnifiedDC
                    import_success = True
                    self.logger.debug("UltimateMA: EhlersUnifiedDC çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸï¼ˆRTç”¨ï¼‰")
                except ImportError as e2:
                    self.logger.error(f"UltimateMA: EhlersUnifiedDC ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•—ï¼ˆRTç”¨ï¼‰ - ç›¸å¯¾: {e1}, çµ¶å¯¾: {e2}")
                    import_success = False
            
            if import_success and EhlersUnifiedDC is not None:
                try:
                    self.rt_cycle_detector = EhlersUnifiedDC(
                        detector_type=self.rt_cycle_detector_type,
                        cycle_part=self.rt_cycle_detector_cycle_part,
                        max_cycle=self.rt_cycle_detector_max_cycle,
                        min_cycle=self.rt_cycle_detector_min_cycle,
                        src_type=self.src_type,
                        period_range=self.rt_cycle_detector_period_range
                    )
                    self.logger.info(f"UltimateMA: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨å‹•çš„é©å¿œã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã‚’åˆæœŸåŒ–: {self.rt_cycle_detector_type}")
                except Exception as e:
                    self.logger.error(f"UltimateMA: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦å›ºå®šãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›´
                    self.realtime_window_mode = 'fixed'
                    self.logger.warning("UltimateMA: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹•çš„é©å¿œãƒ¢ãƒ¼ãƒ‰ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ãŸãŸã‚ã€å›ºå®šãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã—ãŸã€‚")
            else:
                self.logger.error("UltimateMA: EhlersUnifiedDCã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ï¼‰")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦å›ºå®šãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›´
                self.realtime_window_mode = 'fixed'
                self.logger.warning("UltimateMA: EhlersUnifiedDCã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•—ã®ãŸã‚ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å›ºå®šãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã—ãŸã€‚")
        
        self._cache = {}
        self._result: Optional[UltimateMAResult] = None

    def _get_dynamic_periods(self, data: Union[pd.DataFrame, np.ndarray]) -> Tuple[np.ndarray, np.ndarray]:
        """
        å‹•çš„é©å¿œæœŸé–“ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆå€‹åˆ¥ã®ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã‚’ä½¿ç”¨ï¼‰
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            Tuple[np.ndarray, np.ndarray]: (zero_lag_periods, realtime_windows)
        """
        data_length = len(data) if hasattr(data, '__len__') else 0
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§åˆæœŸåŒ–
        zero_lag_periods = np.full(data_length, self.zero_lag_period, dtype=np.float64)
        realtime_windows = np.full(data_length, self.realtime_window, dtype=np.float64)
        
        # ã‚¼ãƒ­ãƒ©ã‚°æœŸé–“ã®å‹•çš„é©å¿œ
        if self.zero_lag_period_mode == 'dynamic' and self.zl_cycle_detector is not None:
            try:
                # ã‚¼ãƒ­ãƒ©ã‚°ç”¨ãƒ‰ãƒŸãƒŠãƒ³ãƒˆã‚µã‚¤ã‚¯ãƒ«ã‚’è¨ˆç®—
                zl_dominant_cycles = self.zl_cycle_detector.calculate(data)
                
                if zl_dominant_cycles is not None and len(zl_dominant_cycles) == data_length:
                    # ã‚µã‚¤ã‚¯ãƒ«æœŸé–“ã«ä¹—æ•°ã‚’é©ç”¨
                    adjusted_zl_cycles = zl_dominant_cycles * self.zl_cycle_period_multiplier
                    
                    # ã‚µã‚¤ã‚¯ãƒ«æœŸé–“ã‚’é©åˆ‡ãªç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—
                    zero_lag_periods = np.clip(adjusted_zl_cycles, 
                                             self.zl_cycle_detector_min_cycle, 
                                             self.zl_cycle_detector_max_cycle)
                    
                    self.logger.debug(f"ã‚¼ãƒ­ãƒ©ã‚°å‹•çš„æœŸé–“è¨ˆç®—å®Œäº† - æœŸé–“ç¯„å›²: [{np.min(zero_lag_periods):.1f}-{np.max(zero_lag_periods):.1f}]")
                else:
                    self.logger.warning("ã‚¼ãƒ­ãƒ©ã‚°ç”¨ãƒ‰ãƒŸãƒŠãƒ³ãƒˆã‚µã‚¤ã‚¯ãƒ«ã®è¨ˆç®—çµæœãŒç„¡åŠ¹ã§ã™ã€‚å›ºå®šæœŸé–“ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                    
            except Exception as e:
                self.logger.error(f"ã‚¼ãƒ­ãƒ©ã‚°å‹•çš„æœŸé–“è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å›ºå®šæœŸé–“ã‚’ä½¿ç”¨
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®å‹•çš„é©å¿œ
        if self.realtime_window_mode == 'dynamic' and self.rt_cycle_detector is not None:
            try:
                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ãƒ‰ãƒŸãƒŠãƒ³ãƒˆã‚µã‚¤ã‚¯ãƒ«ã‚’è¨ˆç®—
                rt_dominant_cycles = self.rt_cycle_detector.calculate(data)
                
                if rt_dominant_cycles is not None and len(rt_dominant_cycles) == data_length:
                    # ã‚µã‚¤ã‚¯ãƒ«æœŸé–“ã«ä¹—æ•°ã‚’é©ç”¨
                    adjusted_rt_cycles = rt_dominant_cycles * self.rt_cycle_period_multiplier
                    
                    # ã‚µã‚¤ã‚¯ãƒ«æœŸé–“ã‚’é©åˆ‡ãªç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—
                    realtime_windows = np.clip(adjusted_rt_cycles, 
                                             2.0,  # æœ€å°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
                                             25.0)  # æœ€å¤§ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
                    
                    self.logger.debug(f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹•çš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨ˆç®—å®Œäº† - ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç¯„å›²: [{np.min(realtime_windows):.1f}-{np.max(realtime_windows):.1f}]")
                else:
                    self.logger.warning("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ãƒ‰ãƒŸãƒŠãƒ³ãƒˆã‚µã‚¤ã‚¯ãƒ«ã®è¨ˆç®—çµæœãŒç„¡åŠ¹ã§ã™ã€‚å›ºå®šã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                    
            except Exception as e:
                self.logger.error(f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹•çš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å›ºå®šã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ä½¿ç”¨
        
        return zero_lag_periods, realtime_windows

    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> UltimateMAResult:
        """
        ğŸš€ Ultimate Moving Average ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆ6æ®µéšé©æ–°çš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° + å‹•çš„é©å¿œï¼‰
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆDataFrameã¾ãŸã¯NumPyé…åˆ—ï¼‰ã¾ãŸã¯ç›´æ¥ä¾¡æ ¼ã®é…åˆ—
        
        Returns:
            UltimateMAResult: å…¨æ®µéšã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœã¨ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’å«ã‚€çµæœ
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯ - 1æ¬¡å…ƒé…åˆ—ãŒç›´æ¥æ¸¡ã•ã‚ŒãŸå ´åˆã¯ä½¿ç”¨ã§ããªã„ï¼ˆhlc3ã«ã¯OHLCãŒå¿…è¦ï¼‰
            if isinstance(data, np.ndarray) and data.ndim == 1:
                raise ValueError("1æ¬¡å…ƒé…åˆ—ã¯ç›´æ¥ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚hlc3ã«ã¯OHLCãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚")
            else:
                # é€šå¸¸ã®ãƒãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
                data_hash = self._get_data_hash(data)
                if data_hash in self._cache and self._result is not None:
                    return self._result

                # hlc3ã‚’ä½¿ç”¨ã—ã¦ä¾¡æ ¼ã‚’å–å¾—
                ukf_prices = PriceSource.calculate_source(data, 'hlc3')
                ukf_prices = ukf_prices.astype(np.float64)  # æ˜ç¤ºçš„ã«float64ã«å¤‰æ›
                data_hash_key = data_hash

            # ãƒ‡ãƒ¼ã‚¿é•·ã®æ¤œè¨¼
            data_length = len(ukf_prices)
            if data_length == 0:
                self.logger.warning("ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚ç©ºã®é…åˆ—ã‚’è¿”ã—ã¾ã™ã€‚")
                empty_result = UltimateMAResult(
                    values=np.array([], dtype=np.float64),
                    raw_values=np.array([], dtype=np.float64),
                    ukf_values=np.array([], dtype=np.float64),
                    kalman_values=np.array([], dtype=np.float64),
                    kalman_gains=np.array([], dtype=np.float64),
                    kalman_innovations=np.array([], dtype=np.float64),
                    kalman_confidence=np.array([], dtype=np.float64),
                    ultimate_smooth_values=np.array([], dtype=np.float64),
                    zero_lag_values=np.array([], dtype=np.float64),
                    amplitude=np.array([], dtype=np.float64),
                    phase=np.array([], dtype=np.float64),
                    realtime_trends=np.array([], dtype=np.float64),
                    trend_signals=np.array([], dtype=np.int8),
                    current_trend='range',
                    current_trend_value=0
                )
                self._result = empty_result
                self._cache[data_hash_key] = self._result
                return empty_result

            # ğŸš€ å‹•çš„é©å¿œæœŸé–“ã®è¨ˆç®—
            if self.zero_lag_period_mode == 'dynamic' or self.realtime_window_mode == 'dynamic':
                self.logger.debug("å‹•çš„é©å¿œæœŸé–“ã‚’è¨ˆç®—ä¸­...")
                zero_lag_periods, realtime_windows = self._get_dynamic_periods(data)
            else:
                # å›ºå®šæœŸé–“ã®å ´åˆ
                zero_lag_periods = np.full(data_length, self.zero_lag_period, dtype=np.float64)
                realtime_windows = np.full(data_length, self.realtime_window, dtype=np.float64)

            # ğŸš€ 7æ®µéšé©æ–°çš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†
            self.logger.info("ğŸš€ Ultimate MA - 7æ®µéšé©æ–°çš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œä¸­...")
            
            # â‘ å…ƒã®ä¾¡æ ¼ï¼ˆæ¯”è¼ƒç”¨ï¼‰
            src_prices = PriceSource.calculate_source(data, self.src_type)
            src_prices = src_prices.astype(np.float64)
            
            # â‘¡é©å¿œçš„ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆæ–°è¦è¿½åŠ ï¼‰
            if self.use_adaptive_kalman:
                self.logger.debug("ğŸ¯ é©å¿œçš„ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ä¸­...")
                kalman_filtered, kalman_gains, kalman_innovations, kalman_confidence = adaptive_kalman_filter_numba(ukf_prices)
            else:
                self.logger.debug("ğŸ¯ é©å¿œçš„ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ä¸­...")
                kalman_filtered = ukf_prices.copy()
                kalman_gains = np.zeros(len(ukf_prices))
                kalman_innovations = np.zeros(len(ukf_prices))
                kalman_confidence = np.ones(len(ukf_prices))
            
            # â‘¢ã‚¢ãƒ«ãƒ†ã‚£ãƒ¡ãƒƒãƒˆã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
            self.logger.debug("ğŸŒŠ ã‚¢ãƒ«ãƒ†ã‚£ãƒ¡ãƒƒãƒˆã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ä¸­...")
            # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒ«ãƒ†ã‚£ãƒ¡ãƒƒãƒˆã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã«æ¸¡ã™
            ultimate_smoother = UltimateSmoother(period=self.ultimate_smoother_period, src_type='hlc3')
            ultimate_smooth_result = ultimate_smoother.calculate(data)
            ultimate_smoothed = ultimate_smooth_result.values
            
            # â‘¢ã‚¼ãƒ­ãƒ©ã‚°EMAï¼ˆå‹•çš„é©å¿œå¯¾å¿œï¼‰
            if self.zero_lag_period_mode == 'dynamic':
                self.logger.debug("âš¡ å‹•çš„é©å¿œã‚¼ãƒ­ãƒ©ã‚°EMAå‡¦ç†ä¸­...")
                zero_lag_prices = zero_lag_ema_adaptive_numba(ultimate_smoothed, zero_lag_periods)
            else:
                self.logger.debug("âš¡ å›ºå®šã‚¼ãƒ­ãƒ©ã‚°EMAå‡¦ç†ä¸­...")
                zero_lag_prices = zero_lag_ema_numba(ultimate_smoothed, self.zero_lag_period)
            
            # â‘£ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            self.logger.debug("ğŸŒ€ ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ä¸­...")
            amplitude, phase = hilbert_transform_filter_numba(zero_lag_prices)
            
            # â‘¤é©å¿œçš„ãƒã‚¤ã‚ºé™¤å»
            self.logger.debug("ğŸ”‡ é©å¿œçš„ãƒã‚¤ã‚ºé™¤å»å®Ÿè¡Œä¸­...")
            denoised_prices = adaptive_noise_reduction_numba(zero_lag_prices, amplitude)
            
            # â‘¥ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºï¼ˆå‹•çš„é©å¿œå¯¾å¿œï¼‰
            if self.realtime_window_mode == 'dynamic':
                self.logger.debug("âš¡ å‹•çš„é©å¿œãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºä¸­...")
                realtime_trends = real_time_trend_detector_adaptive_numba(denoised_prices, realtime_windows)
            else:
                self.logger.debug("âš¡ å›ºå®šãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºä¸­...")
                realtime_trends = real_time_trend_detector_numba(denoised_prices, self.realtime_window)
            
            # æœ€çµ‚çš„ãªå‡¦ç†æ¸ˆã¿ä¾¡æ ¼ç³»åˆ—
            final_values = denoised_prices
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š
            trend_signals = calculate_trend_signals_with_range_numba(final_values, self.slope_index, self.range_threshold)
            trend_index, trend_value = calculate_current_trend_with_range_numba(trend_signals)
            trend_names = ['range', 'up', 'down']
            current_trend = trend_names[trend_index]

            result = UltimateMAResult(
                values=final_values,
                raw_values=src_prices,
                ukf_values=ukf_prices,
                kalman_values=kalman_filtered,
                kalman_gains=kalman_gains,
                kalman_innovations=kalman_innovations,
                kalman_confidence=kalman_confidence,
                ultimate_smooth_values=ultimate_smoothed,
                zero_lag_values=zero_lag_prices,
                amplitude=amplitude,
                phase=phase,
                realtime_trends=realtime_trends,
                trend_signals=trend_signals,
                current_trend=current_trend,
                current_trend_value=trend_value
            )

            self._result = result
            self._cache[data_hash_key] = self._result
            
            mode_info = f"ZL:{self.zero_lag_period_mode}, RT:{self.realtime_window_mode}"
            if self.zero_lag_period_mode == 'dynamic':
                mode_info += f", ZLã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨:{self.zl_cycle_detector_type}"
            if self.realtime_window_mode == 'dynamic':
                mode_info += f", RTã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨:{self.rt_cycle_detector_type}"
            
            self.logger.info(f"âœ… Ultimate MA è¨ˆç®—å®Œäº† - ãƒˆãƒ¬ãƒ³ãƒ‰: {current_trend}, ãƒ¢ãƒ¼ãƒ‰: {mode_info}")
            return self._result

        except Exception as e:
            import traceback
            error_msg = str(e)
            stack_trace = traceback.format_exc()
            self.logger.error(f"{self.name} è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {error_msg}\n{stack_trace}")
            data_len = len(data) if hasattr(data, '__len__') else 0
            self._result = None # ã‚¨ãƒ©ãƒ¼æ™‚ã¯çµæœã‚’ã‚¯ãƒªã‚¢
            error_result = UltimateMAResult(
                values=np.full(data_len, np.nan, dtype=np.float64),
                raw_values=np.full(data_len, np.nan, dtype=np.float64),
                ukf_values=np.full(data_len, np.nan, dtype=np.float64),
                kalman_values=np.full(data_len, np.nan, dtype=np.float64),
                kalman_gains=np.full(data_len, np.nan, dtype=np.float64),
                kalman_innovations=np.full(data_len, np.nan, dtype=np.float64),
                kalman_confidence=np.full(data_len, np.nan, dtype=np.float64),
                ultimate_smooth_values=np.full(data_len, np.nan, dtype=np.float64),
                zero_lag_values=np.full(data_len, np.nan, dtype=np.float64),
                amplitude=np.full(data_len, np.nan, dtype=np.float64),
                phase=np.full(data_len, np.nan, dtype=np.float64),
                realtime_trends=np.full(data_len, np.nan, dtype=np.float64),
                trend_signals=np.zeros(data_len, dtype=np.int8),
                current_trend='range',
                current_trend_value=0
            )
            return error_result

    def get_values(self) -> Optional[np.ndarray]:
        """æœ€çµ‚ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿å€¤ã®ã¿ã‚’å–å¾—ã™ã‚‹ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰"""
        if self._result is not None:
            return self._result.values.copy()
        return None

    def get_raw_values(self) -> Optional[np.ndarray]:
        """å…ƒã®ä¾¡æ ¼å€¤ã‚’å–å¾—ã™ã‚‹"""
        if self._result is not None:
            return self._result.raw_values.copy()
        return None

    def get_ukf_values(self) -> Optional[np.ndarray]:
        """hlc3ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®å€¤ã‚’å–å¾—ã™ã‚‹"""
        if self._result is not None:
            return self._result.ukf_values.copy()
        return None

    def get_kalman_values(self) -> Optional[np.ndarray]:
        """é©å¿œçš„ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®å€¤ã‚’å–å¾—ã™ã‚‹"""
        if self._result is not None:
            return self._result.kalman_values.copy()
        return None

    def get_kalman_gains(self) -> Optional[np.ndarray]:
        """ã‚«ãƒ«ãƒãƒ³ã‚²ã‚¤ãƒ³ã‚’å–å¾—ã™ã‚‹"""
        if self._result is not None:
            return self._result.kalman_gains.copy()
        return None

    def get_kalman_innovations(self) -> Optional[np.ndarray]:
        """ã‚«ãƒ«ãƒãƒ³ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å–å¾—ã™ã‚‹"""
        if self._result is not None:
            return self._result.kalman_innovations.copy()
        return None

    def get_kalman_confidence(self) -> Optional[np.ndarray]:
        """ã‚«ãƒ«ãƒãƒ³ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’å–å¾—ã™ã‚‹"""
        if self._result is not None:
            return self._result.kalman_confidence.copy()
        return None

    def get_ultimate_smooth_values(self) -> Optional[np.ndarray]:
        """ã‚¢ãƒ«ãƒ†ã‚£ãƒ¡ãƒƒãƒˆã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®å€¤ã‚’å–å¾—ã™ã‚‹"""
        if self._result is not None:
            return self._result.ultimate_smooth_values.copy()
        return None

    def get_zero_lag_values(self) -> Optional[np.ndarray]:
        """ã‚¼ãƒ­ãƒ©ã‚°EMAå¾Œã®å€¤ã‚’å–å¾—ã™ã‚‹"""
        if self._result is not None:
            return self._result.zero_lag_values.copy()
        return None

    def get_amplitude(self) -> Optional[np.ndarray]:
        """ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›æŒ¯å¹…ã‚’å–å¾—ã™ã‚‹"""
        if self._result is not None:
            return self._result.amplitude.copy()
        return None

    def get_phase(self) -> Optional[np.ndarray]:
        """ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ä½ç›¸ã‚’å–å¾—ã™ã‚‹"""
        if self._result is not None:
            return self._result.phase.copy()
        return None

    def get_realtime_trends(self) -> Optional[np.ndarray]:
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡å·ã‚’å–å¾—ã™ã‚‹"""
        if self._result is not None:
            return self._result.realtime_trends.copy()
        return None

    def get_trend_signals(self) -> Optional[np.ndarray]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡å·ã‚’å–å¾—ã™ã‚‹"""
        if self._result is not None:
            return self._result.trend_signals.copy()
        return None

    def get_current_trend(self) -> str:
        """ç¾åœ¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰çŠ¶æ…‹ã‚’å–å¾—ã™ã‚‹"""
        if self._result is not None:
            return self._result.current_trend
        return 'range'

    def get_current_trend_value(self) -> int:
        """ç¾åœ¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰å€¤ã‚’å–å¾—ã™ã‚‹"""
        if self._result is not None:
            return self._result.current_trend_value
        return 0

    def get_noise_reduction_stats(self) -> dict:
        """ãƒã‚¤ã‚ºé™¤å»çµ±è¨ˆã‚’å–å¾—ã™ã‚‹"""
        if self._result is None:
            return {}
        
        raw_std = np.nanstd(self._result.raw_values)
        final_std = np.nanstd(self._result.values)
        noise_reduction_ratio = (raw_std - final_std) / raw_std if raw_std > 0 else 0.0
        
        return {
            'raw_volatility': raw_std,
            'filtered_volatility': final_std,
            'noise_reduction_ratio': noise_reduction_ratio,
            'noise_reduction_percentage': noise_reduction_ratio * 100,
            'smoothing_effectiveness': min(noise_reduction_ratio * 100, 100.0)
        }

    def get_dynamic_periods_info(self) -> dict:
        """å‹•çš„é©å¿œæœŸé–“ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹"""
        info = {
            'zero_lag_period_mode': self.zero_lag_period_mode,
            'realtime_window_mode': self.realtime_window_mode,
            'zl_cycle_detector_available': self.zl_cycle_detector is not None,
            'rt_cycle_detector_available': self.rt_cycle_detector is not None
        }
        
        # ã‚¼ãƒ­ãƒ©ã‚°ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®æƒ…å ±
        if self.zl_cycle_detector is not None:
            info.update({
                'zl_cycle_detector_type': self.zl_cycle_detector_type,
                'zl_cycle_detector_cycle_part': self.zl_cycle_detector_cycle_part,
                'zl_cycle_detector_max_cycle': self.zl_cycle_detector_max_cycle,
                'zl_cycle_detector_min_cycle': self.zl_cycle_detector_min_cycle,
                'zl_cycle_period_multiplier': self.zl_cycle_period_multiplier
            })
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®æƒ…å ±
        if self.rt_cycle_detector is not None:
            info.update({
                'rt_cycle_detector_type': self.rt_cycle_detector_type,
                'rt_cycle_detector_cycle_part': self.rt_cycle_detector_cycle_part,
                'rt_cycle_detector_max_cycle': self.rt_cycle_detector_max_cycle,
                'rt_cycle_detector_min_cycle': self.rt_cycle_detector_min_cycle,
                'rt_cycle_period_multiplier': self.rt_cycle_period_multiplier
            })
        
        return info

    def reset(self) -> None:
        """ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹"""
        super().reset()
        self._result = None
        self._cache = {}
        if self.zl_cycle_detector is not None:
            self.zl_cycle_detector.reset()
        if self.rt_cycle_detector is not None:
            self.rt_cycle_detector.reset()

    def _get_data_hash(self, data: Union[pd.DataFrame, np.ndarray]) -> str:
        """ãƒ‡ãƒ¼ã‚¿ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—ã™ã‚‹"""
        # src_typeã«åŸºã¥ã„ã¦å¿…è¦ãªã‚«ãƒ©ãƒ ã‚’æ±ºå®š
        required_cols = set()
        if self.src_type == 'open':
            required_cols.add('open')
        elif self.src_type == 'high':
            required_cols.add('high')
        elif self.src_type == 'low':
            required_cols.add('low')
        elif self.src_type == 'close':
            required_cols.add('close')
        elif self.src_type == 'hl2':
            required_cols.update(['high', 'low'])
        elif self.src_type == 'hlc3':
            required_cols.update(['high', 'low', 'close'])
        elif self.src_type == 'ohlc4':
            required_cols.update(['open', 'high', 'low', 'close'])
        elif self.src_type == 'hlcc4':
            required_cols.update(['high', 'low', 'close'])
        elif self.src_type == 'weighted_close':
            required_cols.update(['high', 'low', 'close'])
        else:
            required_cols.add('close') # Default

        if isinstance(data, pd.DataFrame):
            relevant_cols = [col for col in data.columns if col.lower() in required_cols]
            present_cols = [col for col in relevant_cols if col in data.columns]
            if not present_cols:
                try:
                    shape_tuple = data.shape
                    first_row = tuple(data.iloc[0]) if len(data) > 0 else ()
                    last_row = tuple(data.iloc[-1]) if len(data) > 0 else ()
                    data_repr_tuple = (shape_tuple, first_row, last_row)
                    data_hash_val = hash(data_repr_tuple)
                except Exception:
                    data_hash_val = hash(str(data))
            else:
                data_values = data[present_cols].values
                data_hash_val = hash(data_values.tobytes())

        elif isinstance(data, np.ndarray):
            col_indices = []
            if 'open' in required_cols: col_indices.append(0)
            if 'high' in required_cols: col_indices.append(1)
            if 'low' in required_cols: col_indices.append(2)
            if 'close' in required_cols: col_indices.append(3)
            col_indices = sorted(list(set(col_indices)))
            if data.ndim == 2 and data.shape[1] > max(col_indices if col_indices else [-1]):
                data_values = data[:, col_indices]
                data_hash_val = hash(data_values.tobytes())
            else:
                data_hash_val = hash(data.tobytes())
        else:
            data_hash_val = hash(str(data))

        param_str = (f"kf={self.use_adaptive_kalman}_kf_pv={self.kalman_process_variance}_kf_mv={self.kalman_measurement_variance}_kf_vw={self.kalman_volatility_window}"
                    f"_us={self.ultimate_smoother_period}_zl={self.zero_lag_period}({self.zero_lag_period_mode})"
                    f"_rt={self.realtime_window}({self.realtime_window_mode})"
                    f"_src={self.src_type}_slope={self.slope_index}_range_th={self.range_threshold}"
                    f"_zl_cycle={self.zl_cycle_detector_type}_zl_cycle_part={self.zl_cycle_detector_cycle_part}"
                    f"_zl_cycle_max={self.zl_cycle_detector_max_cycle}_zl_cycle_min={self.zl_cycle_detector_min_cycle}"
                    f"_zl_cycle_mult={self.zl_cycle_period_multiplier}"
                    f"_rt_cycle={self.rt_cycle_detector_type}_rt_cycle_part={self.rt_cycle_detector_cycle_part}"
                    f"_rt_cycle_max={self.rt_cycle_detector_max_cycle}_rt_cycle_min={self.rt_cycle_detector_min_cycle}"
                    f"_rt_cycle_mult={self.rt_cycle_period_multiplier}"
                    f"_zl_cycle_period_range={self.zl_cycle_detector_period_range}_rt_cycle_period_range={self.rt_cycle_detector_period_range}")
        return f"{data_hash_val}_{param_str}" 