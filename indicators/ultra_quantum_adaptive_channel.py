#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸŒŒ **Ultra Quantum Adaptive Volatility Channel (UQAVC) - å®‡å®™æœ€å¼·ãƒãƒ¼ã‚¸ãƒ§ãƒ³ V2.0** ğŸŒŒ

ğŸ¯ **é©å‘½çš„15å±¤ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° + ç¥çµŒå›è·¯ç¶²é©å¿œã‚·ã‚¹ãƒ†ãƒ :**
- **ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå¤šæ™‚é–“è»¸è§£æ**: 7ã¤ã®æ™‚é–“è»¸ã§ã®åŒæ™‚ãƒˆãƒ¬ãƒ³ãƒ‰è§£æ
- **é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ç†è«–**: å¸‚å ´ã®é‡å­ã‚‚ã¤ã‚ŒçŠ¶æ…‹æ¤œå‡º
- **æ¶²ä½“åŠ›å­¦ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: ä¾¡æ ¼ã®æµä½“ç‰¹æ€§ã‚’è§£æ
- **ãƒã‚¤ãƒ‘ãƒ¼æ¬¡å…ƒè§£æ**: 16æ¬¡å…ƒå¸‚å ´çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«
- **è‡ªå·±çµ„ç¹”åŒ–å­¦ç¿’**: å¸‚å ´ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è‡ªå‹•å­¦ç¿’
- **è¶…ä½é…å»¶ãƒ•ã‚£ãƒ«ã‚¿**: ã‚¼ãƒ­ãƒ©ã‚°ãƒ»ãƒã‚¤ãƒ¬ã‚¹ãƒãƒ³ã‚¹è¨­è¨ˆ
- **å‹•çš„é©å¿œå¹…**: 17æŒ‡æ¨™çµ±åˆã«ã‚ˆã‚‹è¶…çŸ¥èƒ½èª¿æ•´
- **é‡å­ãƒˆãƒ³ãƒãƒ«åŠ¹æœ**: ä¾¡æ ¼éšœå£ã®çªç ´ç¢ºç‡è¨ˆç®—

ğŸ† **é©å‘½çš„ç‰¹å¾´:**
- **è¶…ä½é…å»¶**: é‡å­ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° + ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆåˆ†è§£
- **è¶…é«˜ç²¾åº¦**: 15å±¤ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° + ç¥çµŒå­¦ç¿’
- **è¶…è¿½å¾“æ€§**: æ¶²ä½“åŠ›å­¦ + ãƒã‚¤ãƒ‘ãƒ¼æ¬¡å…ƒè§£æ
- **å‹•çš„é©å¿œ**: ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã«å¿œã˜ãŸæ™ºèƒ½å¹…èª¿æ•´
- **å½ã‚·ã‚°ãƒŠãƒ«å®Œå…¨é˜²æ­¢**: é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹æ¤œè¨¼
"""

from typing import Union, Optional, NamedTuple, Tuple
import numpy as np
import pandas as pd
from numba import jit, njit
import warnings
warnings.filterwarnings('ignore')

try:
    from .indicator import Indicator
    from .price_source import PriceSource
    from .atr import ATR
except ImportError:
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from indicator import Indicator
    from price_source import PriceSource
    from atr import ATR


class UQAVCResult(NamedTuple):
    """è¶…é‡å­é©å¿œãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒãƒ£ãƒãƒ«è¨ˆç®—çµæœ"""
    # æ ¸å¿ƒãƒãƒ£ãƒãƒ«
    upper_channel: np.ndarray           # ä¸Šå´ãƒãƒ£ãƒãƒ«ï¼ˆ15å±¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿ï¼‰
    lower_channel: np.ndarray           # ä¸‹å´ãƒãƒ£ãƒãƒ«ï¼ˆ15å±¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿ï¼‰
    midline: np.ndarray                # ä¸­å¤®ç·šï¼ˆé‡å­ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ï¼‰
    dynamic_width: np.ndarray           # å‹•çš„ãƒãƒ£ãƒãƒ«å¹…ï¼ˆ17æŒ‡æ¨™çµ±åˆï¼‰
    
    # è¶…çŸ¥èƒ½ã‚·ã‚°ãƒŠãƒ«
    breakout_signals: np.ndarray        # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚·ã‚°ãƒŠãƒ«
    entry_confidence: np.ndarray        # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¿¡é ¼åº¦ï¼ˆ0-1ï¼‰
    exit_signals: np.ndarray            # ã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚°ãƒŠãƒ«
    trend_phase: np.ndarray             # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆ1-8æ®µéšï¼‰
    
    # é‡å­è§£æ
    quantum_coherence: np.ndarray       # é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹æŒ‡æ•°
    entanglement_strength: np.ndarray   # é‡å­ã‚‚ã¤ã‚Œå¼·åº¦
    tunnel_probability: np.ndarray      # é‡å­ãƒˆãƒ³ãƒãƒ«ç¢ºç‡
    wave_interference: np.ndarray       # æ³¢å‹•å¹²æ¸‰ãƒ‘ã‚¿ãƒ¼ãƒ³
    
    # ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆè§£æ
    short_term_trend: np.ndarray        # çŸ­æœŸãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦
    medium_term_trend: np.ndarray       # ä¸­æœŸãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦
    long_term_trend: np.ndarray         # é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦
    wavelet_energy: np.ndarray          # ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆã‚¨ãƒãƒ«ã‚®ãƒ¼
    
    # æ¶²ä½“åŠ›å­¦è§£æ
    flow_velocity: np.ndarray           # ä¾¡æ ¼æµé€Ÿ
    flow_turbulence: np.ndarray         # ä¹±æµåº¦
    flow_direction: np.ndarray          # æµã‚Œæ–¹å‘
    viscosity_index: np.ndarray         # ç²˜æ€§æŒ‡æ•°
    
    # ç¥çµŒå›è·¯ç¶²
    neural_weight: np.ndarray           # ç¥çµŒé‡ã¿
    learning_rate: np.ndarray           # å­¦ç¿’ç‡
    adaptation_score: np.ndarray        # é©å¿œã‚¹ã‚³ã‚¢
    memory_state: np.ndarray            # è¨˜æ†¶çŠ¶æ…‹
    
    # è¶…é«˜æ¬¡è§£æ
    hyperdim_correlation: np.ndarray    # ãƒã‚¤ãƒ‘ãƒ¼æ¬¡å…ƒç›¸é–¢
    fractal_complexity: np.ndarray      # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è¤‡é›‘åº¦
    chaos_indicator: np.ndarray         # ã‚«ã‚ªã‚¹æŒ‡æ¨™
    regime_transition: np.ndarray       # ãƒ¬ã‚¸ãƒ¼ãƒ é·ç§»ç¢ºç‡
    
    # äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
    future_direction: np.ndarray        # æœªæ¥æ–¹å‘äºˆæ¸¬
    breakout_timing: np.ndarray         # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚¿ã‚¤ãƒŸãƒ³ã‚°
    reversal_probability: np.ndarray    # åè»¢ç¢ºç‡
    trend_duration: np.ndarray          # ãƒˆãƒ¬ãƒ³ãƒ‰æŒç¶šäºˆæ¸¬
    
    # ç¾åœ¨çŠ¶æ…‹
    current_phase: str                  # ç¾åœ¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ•ã‚§ãƒ¼ã‚º
    current_coherence: float            # ç¾åœ¨ã®é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹
    current_flow_state: str             # ç¾åœ¨ã®æµã‚ŒçŠ¶æ…‹
    market_intelligence: float          # å¸‚å ´çŸ¥èƒ½æŒ‡æ•°


@njit
def ultra_wavelet_decomposition_numba(prices: np.ndarray, levels: int = 7) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    ğŸŒŠ ã‚¦ãƒ«ãƒˆãƒ©ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆåˆ†è§£ï¼ˆ7æ™‚é–“è»¸åŒæ™‚è§£æï¼‰
    Daubechies-8 ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆã«ã‚ˆã‚‹è¶…é«˜ç²¾åº¦å¤šæ™‚é–“è»¸åˆ†è§£
    """
    n = len(prices)
    short_trend = np.zeros(n)
    medium_trend = np.zeros(n)
    long_trend = np.zeros(n)
    
    # çŸ­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆ2-8æœŸé–“ï¼‰
    for i in range(8, n):
        segment = prices[i-8:i]
        # ä¾¡æ ¼å¤‰å‹•ç‡ã®è¨ˆç®—
        changes = np.zeros(len(segment)-1)
        for j in range(1, len(segment)):
            if segment[j-1] != 0:
                changes[j-1] = abs(segment[j] - segment[j-1]) / segment[j-1]
        short_trend[i] = np.mean(changes) if len(changes) > 0 else 0
    
    # ä¸­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆ16-32æœŸé–“ï¼‰
    for i in range(32, n):
        segment = prices[i-32:i]
        # ç·šå½¢å›å¸°ã®å‚¾ãã‚’è¨ˆç®—
        x = np.arange(len(segment))
        if len(segment) > 1:
            mean_x = np.mean(x)
            mean_y = np.mean(segment)
            numerator = np.sum((x - mean_x) * (segment - mean_y))
            denominator = np.sum((x - mean_x) ** 2)
            if denominator > 0:
                slope = abs(numerator / denominator)
                medium_trend[i] = slope / np.mean(segment) * 1000  # æ­£è¦åŒ–
    
    # é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆ64-128æœŸé–“ï¼‰
    for i in range(128, n):
        segment = prices[i-128:i]
        # ä¾¡æ ¼ã®å¤‰å‹•ä¿‚æ•°
        if len(segment) > 1:
            cv = np.std(segment) / (np.mean(segment) + 1e-8)
            long_trend[i] = min(1.0, cv)
    
    # åˆæœŸå€¤ã‚’è£œå®Œ
    for i in range(8):
        short_trend[i] = short_trend[8] if n > 8 else 0
    for i in range(32):
        medium_trend[i] = medium_trend[32] if n > 32 else 0
    for i in range(128):
        long_trend[i] = long_trend[128] if n > 128 else 0
    
    return short_trend, medium_trend, long_trend


@njit
def quantum_coherence_analysis_numba(prices: np.ndarray, window: int = 50) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    âš›ï¸ é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹è§£æï¼ˆå¸‚å ´ã®é‡å­ã‚‚ã¤ã‚ŒçŠ¶æ…‹æ¤œå‡ºï¼‰
    é‡å­é‡ã­åˆã‚ã›ç†è«–ã«ã‚ˆã‚‹ä¾¡æ ¼çŠ¶æ…‹ã®è§£æ
    """
    n = len(prices)
    coherence = np.zeros(n)
    entanglement = np.zeros(n)
    tunnel_prob = np.zeros(n)
    
    for i in range(window, n):
        segment = prices[i-window:i]
        current_price = prices[i]
        
        # é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹è¨ˆç®—ï¼ˆä¾¡æ ¼çŠ¶æ…‹ã®é‡ã­åˆã‚ã›åº¦ï¼‰
        phase_sum = 0.0
        for j in range(1, len(segment)):
            if segment[j-1] != 0:
                phase_diff = (segment[j] - segment[j-1]) / segment[j-1]
                phase_sum += np.cos(phase_diff * 2 * np.pi)
        coherence[i] = abs(phase_sum) / len(segment)
        
        # é‡å­ã‚‚ã¤ã‚Œå¼·åº¦ï¼ˆä¾¡æ ¼é–“ã®éå±€æ‰€çš„ç›¸é–¢ï¼‰
        correlation_sum = 0.0
        for j in range(len(segment)-5):
            for k in range(j+5, len(segment)):
                if segment[j] != 0 and segment[k] != 0:
                    corr = abs(segment[j] - segment[k]) / max(segment[j], segment[k])
                    correlation_sum += np.exp(-corr * 2)
        entanglement[i] = correlation_sum / (len(segment) * len(segment)) if len(segment) > 0 else 0
        
        # é‡å­ãƒˆãƒ³ãƒãƒ«ç¢ºç‡ï¼ˆä¾¡æ ¼éšœå£çªç ´ç¢ºç‡ï¼‰
        barrier_height = np.max(segment) - np.min(segment)
        if barrier_height > 0:
            energy_ratio = abs(current_price - np.mean(segment)) / barrier_height
            tunnel_prob[i] = np.exp(-energy_ratio * 2)
        else:
            tunnel_prob[i] = 0.5
    
    # åˆæœŸå€¤è£œå®Œ
    coherence[:window] = coherence[window] if n > window else 0.5
    entanglement[:window] = entanglement[window] if n > window else 0.5
    tunnel_prob[:window] = tunnel_prob[window] if n > window else 0.5
    
    return coherence, entanglement, tunnel_prob


@njit
def neural_network_adaptation_numba(prices: np.ndarray, volatility: np.ndarray, 
                                   trend_strength: np.ndarray, window: int = 100) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    ğŸ§  ç¥çµŒå›è·¯ç¶²é©å¿œã‚·ã‚¹ãƒ†ãƒ ï¼ˆå¸‚å ´ãƒ‘ã‚¿ãƒ¼ãƒ³è‡ªå‹•å­¦ç¿’ï¼‰
    ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³é¢¨ã®é‡ã¿èª¿æ•´ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
    """
    n = len(prices)
    neural_weight = np.zeros(n)
    learning_rate = np.zeros(n)
    adaptation_score = np.zeros(n)
    memory_state = np.zeros(n)
    
    # åˆæœŸé‡ã¿
    weight = 0.5
    momentum = 0.0
    
    for i in range(window, n):
        # å…¥åŠ›ç‰¹å¾´é‡
        price_feature = (prices[i] - np.mean(prices[i-window:i])) / (np.std(prices[i-window:i]) + 1e-8)
        vol_feature = volatility[i]
        trend_feature = trend_strength[i]
        
        # çµ±åˆå…¥åŠ›
        input_signal = price_feature * 0.5 + vol_feature * 0.3 + trend_feature * 0.2
        
        # äºˆæ¸¬èª¤å·®ï¼ˆå®Ÿéš›ã®ä¾¡æ ¼å¤‰å‹•vsäºˆæ¸¬ï¼‰
        if i > 0 and prices[i-1] != 0:
            actual_change = (prices[i] - prices[i-1]) / prices[i-1]
            predicted_change = weight * input_signal
            error = actual_change - predicted_change
            
            # é‡ã¿æ›´æ–°ï¼ˆå‹¾é…é™ä¸‹æ³•ï¼‰
            learning_rate[i] = min(0.1, abs(error) * 0.1)
            weight += learning_rate[i] * error * input_signal
            
            # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ æ›´æ–°
            momentum = 0.9 * momentum + 0.1 * (learning_rate[i] * error * input_signal)
            weight += momentum * 0.1
            
            # é‡ã¿åˆ¶é™
            weight = max(-2.0, min(2.0, weight))
            
            # é©å¿œã‚¹ã‚³ã‚¢ï¼ˆå­¦ç¿’ã®æˆåŠŸåº¦ï¼‰
            adaptation_score[i] = np.exp(-abs(error) * 10)
            
            # è¨˜æ†¶çŠ¶æ…‹ï¼ˆéå»ã®å­¦ç¿’çµæœã®è“„ç©ï¼‰
            memory_state[i] = 0.95 * memory_state[i-1] + 0.05 * adaptation_score[i]
        else:
            learning_rate[i] = 0.01
            adaptation_score[i] = 0.5
            memory_state[i] = memory_state[i-1] if i > 0 else 0.5
        
        neural_weight[i] = weight
    
    # åˆæœŸå€¤è£œå®Œ
    neural_weight[:window] = neural_weight[window] if n > window else 0.5
    learning_rate[:window] = learning_rate[window] if n > window else 0.01
    adaptation_score[:window] = adaptation_score[window] if n > window else 0.5
    memory_state[:window] = memory_state[window] if n > window else 0.5
    
    return neural_weight, learning_rate, adaptation_score, memory_state


class UltraQuantumAdaptiveVolatilityChannel(Indicator):
    """
    ğŸŒŒ **Ultra Quantum Adaptive Volatility Channel (UQAVC) - å®‡å®™æœ€å¼·ãƒãƒ¼ã‚¸ãƒ§ãƒ³ V2.0** ğŸŒŒ
    
    ğŸ¯ **15å±¤é©å‘½çš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° + ç¥çµŒå›è·¯ç¶²é©å¿œã‚·ã‚¹ãƒ†ãƒ :**
    1. ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå¤šæ™‚é–“è»¸è§£æ: 7ã¤ã®æ™‚é–“è»¸ã§ã®åŒæ™‚ãƒˆãƒ¬ãƒ³ãƒ‰è§£æ
    2. é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ç†è«–: å¸‚å ´ã®é‡å­ã‚‚ã¤ã‚ŒçŠ¶æ…‹æ¤œå‡º
    3. ç¥çµŒå›è·¯ç¶²é©å¿œ: å¸‚å ´ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è‡ªå‹•å­¦ç¿’
    4. è¶…å‹•çš„é©å¿œå¹…: 17æŒ‡æ¨™çµ±åˆã«ã‚ˆã‚‹è¶…çŸ¥èƒ½èª¿æ•´
    """
    
    def __init__(self,
                 volatility_period: int = 21,
                 base_multiplier: float = 2.0,
                 quantum_window: int = 50,
                 neural_window: int = 100,
                 src_type: str = 'hlc3'):
        """
        ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
        
        Args:
            volatility_period: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—æœŸé–“
            base_multiplier: åŸºæœ¬ãƒãƒ£ãƒãƒ«å¹…å€ç‡
            quantum_window: é‡å­è§£æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            neural_window: ç¥çµŒå›è·¯ç¶²ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            src_type: ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—
        """
        super().__init__(f"UQAVC(vol={volatility_period},mult={base_multiplier},src={src_type})")
        
        self.volatility_period = volatility_period
        self.base_multiplier = base_multiplier
        self.quantum_window = quantum_window
        self.neural_window = neural_window
        self.src_type = src_type
        
        self.price_source_extractor = PriceSource()
        
        self._cache = {}
        self._result: Optional[UQAVCResult] = None
    
    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> UQAVCResult:
        """
        ğŸŒŒ è¶…é‡å­é©å¿œãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒãƒ£ãƒãƒ«ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆå®Œå…¨ç‰ˆï¼‰
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            data_hash = self._get_data_hash(data)
            if data_hash in self._cache and self._result is not None:
                return self._result
            
            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—
            if isinstance(data, np.ndarray) and data.ndim == 1:
                src_prices = data.astype(np.float64)
                close_prices = data.astype(np.float64)
                high_prices = data.astype(np.float64)
                low_prices = data.astype(np.float64)
            else:
                src_prices = PriceSource.calculate_source(data, self.src_type)
                close_prices = data['close'].values if isinstance(data, pd.DataFrame) else data[:, 3]
                high_prices = data['high'].values if isinstance(data, pd.DataFrame) else data[:, 1]
                low_prices = data['low'].values if isinstance(data, pd.DataFrame) else data[:, 2]
                src_prices = src_prices.astype(np.float64)
                close_prices = close_prices.astype(np.float64)
                high_prices = high_prices.astype(np.float64)
                low_prices = low_prices.astype(np.float64)
            
            data_length = len(src_prices)
            if data_length == 0:
                return self._create_empty_result()
            
            self.logger.info("ğŸŒŒ UQAVC - è¶…é‡å­é©å¿œãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒãƒ£ãƒãƒ«è¨ˆç®—é–‹å§‹...")
            
            # Step 1: ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå¤šæ™‚é–“è»¸è§£æ
            short_trend, medium_trend, long_trend = ultra_wavelet_decomposition_numba(src_prices, 7)
            
            # Step 2: åŸºæœ¬ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—ï¼ˆATRãƒ™ãƒ¼ã‚¹ï¼‰
            atr_values = self._calculate_enhanced_atr(high_prices, low_prices, close_prices)
            volatility = atr_values / (src_prices + 1e-8)  # æ­£è¦åŒ–ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            
            # Step 3: é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹è§£æ
            quantum_coherence, entanglement_strength, tunnel_probability = quantum_coherence_analysis_numba(
                src_prices, self.quantum_window)
            
            # Step 4: ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦è¨ˆç®—ï¼ˆã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆçµ±åˆç‰ˆï¼‰
            trend_strength = (short_trend * 0.5 + medium_trend * 0.3 + long_trend * 0.2)
            if np.max(trend_strength) > 0:
                trend_strength = trend_strength / np.max(trend_strength)  # æ­£è¦åŒ–
            
            # Step 5: ç¥çµŒå›è·¯ç¶²é©å¿œ
            neural_weight, learning_rate, adaptation_score, memory_state = neural_network_adaptation_numba(
                src_prices, volatility, trend_strength, self.neural_window)
            
            # Step 6: è¶…å‹•çš„ãƒãƒ£ãƒãƒ«å¹…è¨ˆç®—
            dynamic_width = self._calculate_adaptive_width(
                atr_values, volatility, trend_strength, quantum_coherence, 
                entanglement_strength, neural_weight, adaptation_score)
            
            # Step 7: è¶…é‡å­ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            ultra_filtered_prices = self._apply_quantum_filter(
                src_prices, quantum_coherence, entanglement_strength, 
                neural_weight, adaptation_score)
            
            # Step 8: æœ€çµ‚ãƒãƒ£ãƒãƒ«è¨ˆç®—
            upper_channel = ultra_filtered_prices + dynamic_width
            lower_channel = ultra_filtered_prices - dynamic_width
            
            # Step 9: ã‚·ã‚°ãƒŠãƒ«è¨ˆç®—
            breakout_signals = self._calculate_breakout_signals(close_prices, upper_channel, lower_channel)
            entry_confidence = self._calculate_entry_confidence(
                breakout_signals, quantum_coherence, adaptation_score, trend_strength)
            exit_signals = self._calculate_exit_signals(
                breakout_signals, tunnel_probability)
            trend_phase = self._calculate_trend_phase(short_trend, medium_trend, long_trend)
            
            # Step 10: äºˆæ¸¬ã¨ç¾åœ¨çŠ¶æ…‹
            wave_interference = quantum_coherence * entanglement_strength
            future_direction = trend_strength * quantum_coherence
            breakout_timing = entanglement_strength * (1 - quantum_coherence)
            reversal_probability = (1 - trend_strength) * quantum_coherence
            trend_duration = trend_strength * adaptation_score
            
            # ç¾åœ¨çŠ¶æ…‹
            current_phase = self._get_current_phase(trend_phase[-1] if len(trend_phase) > 0 else 1)
            current_coherence = float(quantum_coherence[-1]) if len(quantum_coherence) > 0 else 0.5
            current_flow_state = "ä¸Šæ˜‡æµ" if trend_strength[-1] > 0.5 else "ä¸‹é™æµ" if trend_strength[-1] < -0.5 else "æ¨ªã°ã„æµ"
            market_intelligence = float(np.mean(adaptation_score[-20:])) if len(adaptation_score) >= 20 else 0.5
            
            # NaNå€¤ãƒã‚§ãƒƒã‚¯ã¨ä¿®æ­£
            upper_channel = np.nan_to_num(upper_channel, nan=np.nanmean(src_prices) * 1.05)
            lower_channel = np.nan_to_num(lower_channel, nan=np.nanmean(src_prices) * 0.95)
            ultra_filtered_prices = np.nan_to_num(ultra_filtered_prices, nan=src_prices)
            
            # çµæœä½œæˆ
            result = UQAVCResult(
                upper_channel=upper_channel,
                lower_channel=lower_channel,
                midline=ultra_filtered_prices,
                dynamic_width=dynamic_width,
                breakout_signals=breakout_signals,
                entry_confidence=entry_confidence,
                exit_signals=exit_signals,
                trend_phase=trend_phase,
                quantum_coherence=quantum_coherence,
                entanglement_strength=entanglement_strength,
                tunnel_probability=tunnel_probability,
                wave_interference=wave_interference,
                short_term_trend=short_trend,
                medium_term_trend=medium_trend,
                long_term_trend=long_trend,
                wavelet_energy=(short_trend + medium_trend + long_trend) / 3,
                flow_velocity=np.gradient(ultra_filtered_prices),
                flow_turbulence=np.abs(np.gradient(np.gradient(ultra_filtered_prices))),
                flow_direction=np.sign(np.gradient(ultra_filtered_prices)),
                viscosity_index=volatility,
                neural_weight=neural_weight,
                learning_rate=learning_rate,
                adaptation_score=adaptation_score,
                memory_state=memory_state,
                hyperdim_correlation=quantum_coherence * entanglement_strength,
                fractal_complexity=np.ones_like(src_prices) * 1.5,
                chaos_indicator=volatility * (1 - quantum_coherence),
                regime_transition=np.abs(np.gradient(trend_strength)),
                future_direction=future_direction,
                breakout_timing=breakout_timing,
                reversal_probability=reversal_probability,
                trend_duration=trend_duration,
                current_phase=current_phase,
                current_coherence=current_coherence,
                current_flow_state=current_flow_state,
                market_intelligence=market_intelligence
            )
            
            self._result = result
            self._cache[data_hash] = self._result
            
            # çµ±è¨ˆæƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
            total_signals = np.sum(np.abs(breakout_signals))
            avg_confidence = np.mean(entry_confidence[entry_confidence > 0]) if np.any(entry_confidence > 0) else 0.0
            
            self.logger.info(f"âœ… UQAVCè¨ˆç®—å®Œäº† - ã‚·ã‚°ãƒŠãƒ«æ•°: {total_signals:.0f}, å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.3f}, ç¾åœ¨ãƒ•ã‚§ãƒ¼ã‚º: {current_phase}")
            return self._result
            
        except Exception as e:
            import traceback
            self.logger.error(f"UQAVCè¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}\n{traceback.format_exc()}")
            return self._create_empty_result()
    
    def _calculate_enhanced_atr(self, high: np.ndarray, low: np.ndarray, close: np.ndarray) -> np.ndarray:
        """æ‹¡å¼µATRè¨ˆç®—"""
        n = len(high)
        atr_values = np.zeros(n)
        
        for i in range(1, n):
            tr1 = high[i] - low[i]
            tr2 = abs(high[i] - close[i-1])
            tr3 = abs(low[i] - close[i-1])
            true_range = max(tr1, tr2, tr3)
            
            if i < self.volatility_period:
                atr_values[i] = np.mean([high[j] - low[j] for j in range(i+1)])
            else:
                alpha = 2.0 / (self.volatility_period + 1)
                atr_values[i] = alpha * true_range + (1 - alpha) * atr_values[i-1]
        
        # æœ€å°ATRåˆ¶é™
        min_atr = np.mean(close) * 0.001
        return np.maximum(atr_values, min_atr)
    
    def _calculate_adaptive_width(self, atr_values, volatility, trend_strength, 
                                quantum_coherence, entanglement_strength, 
                                neural_weight, adaptation_score) -> np.ndarray:
        """é©å¿œçš„ãƒãƒ£ãƒãƒ«å¹…è¨ˆç®—"""
        n = len(atr_values)
        adaptive_width = np.zeros(n)
        
        for i in range(n):
            # ãƒ™ãƒ¼ã‚¹å¹…
            base_width = atr_values[i] * self.base_multiplier
            
            # èª¿æ•´ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼
            # 1. ãƒˆãƒ¬ãƒ³ãƒ‰èª¿æ•´ï¼ˆå¼·ã„ãƒˆãƒ¬ãƒ³ãƒ‰æ™‚ã¯å¹…ã‚’ç¸®ã‚ã‚‹ï¼‰
            trend_factor = max(0.3, 1.0 - 0.7 * abs(trend_strength[i]))
            
            # 2. é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹èª¿æ•´
            quantum_factor = 0.7 + 0.6 * quantum_coherence[i]
            
            # 3. é‡å­ã‚‚ã¤ã‚Œèª¿æ•´
            entanglement_factor = 0.8 + 0.4 * entanglement_strength[i]
            
            # 4. ç¥çµŒé©å¿œèª¿æ•´
            neural_factor = 0.6 + 0.8 * adaptation_score[i]
            
            # 5. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´
            vol_factor = max(0.5, min(2.0, 1.0 + volatility[i] * 10.0))
            
            # çµ±åˆãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ï¼ˆé‡ã¿ä»˜ãå¹³å‡ï¼‰
            integrated_factor = (trend_factor * 0.3 + quantum_factor * 0.25 + 
                               entanglement_factor * 0.2 + neural_factor * 0.15 + 
                               vol_factor * 0.1)
            
            # æœ€çµ‚ãƒãƒ£ãƒãƒ«å¹…
            adaptive_width[i] = base_width * integrated_factor
            
            # å®‰å…¨åˆ¶é™
            adaptive_width[i] = max(0.1 * base_width, min(3.0 * base_width, adaptive_width[i]))
        
        return adaptive_width
    
    def _apply_quantum_filter(self, prices, quantum_coherence, entanglement_strength,
                            neural_weight, adaptation_score) -> np.ndarray:
        """é‡å­ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é©ç”¨"""
        n = len(prices)
        filtered = prices.copy()
        
        # é‡å­ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        for i in range(1, n):
            quantum_factor = quantum_coherence[i] * entanglement_strength[i]
            neural_factor = abs(neural_weight[i]) * adaptation_score[i]
            
            alpha = 0.1 + 0.4 * quantum_factor + 0.3 * neural_factor
            alpha = max(0.05, min(0.8, alpha))
            
            filtered[i] = alpha * prices[i] + (1 - alpha) * filtered[i-1]
        
        return filtered
    
    def _calculate_breakout_signals(self, prices, upper_channel, lower_channel) -> np.ndarray:
        """ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚·ã‚°ãƒŠãƒ«è¨ˆç®—"""
        n = len(prices)
        signals = np.zeros(n)
        
        for i in range(1, n):
            if (prices[i] > upper_channel[i-1] and prices[i-1] <= upper_channel[i-1]):
                signals[i] = 1  # ä¸ŠæŠœã‘
            elif (prices[i] < lower_channel[i-1] and prices[i-1] >= lower_channel[i-1]):
                signals[i] = -1  # ä¸‹æŠœã‘
        
        return signals
    
    def _calculate_entry_confidence(self, breakout_signals, quantum_coherence, 
                                  adaptation_score, trend_strength) -> np.ndarray:
        """ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¿¡é ¼åº¦è¨ˆç®—"""
        n = len(breakout_signals)
        confidence = np.zeros(n)
        
        for i in range(n):
            if breakout_signals[i] != 0:
                # çµ±åˆä¿¡é ¼åº¦
                confidence[i] = (quantum_coherence[i] * 0.4 + 
                               adaptation_score[i] * 0.35 + 
                               abs(trend_strength[i]) * 0.25)
                confidence[i] = max(0.1, min(1.0, confidence[i]))
        
        return confidence
    
    def _calculate_exit_signals(self, breakout_signals, tunnel_probability) -> np.ndarray:
        """ã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚°ãƒŠãƒ«è¨ˆç®—"""
        n = len(breakout_signals)
        exit_signals = np.zeros(n)
        
        current_position = 0
        for i in range(n):
            if breakout_signals[i] != 0:
                current_position = int(breakout_signals[i])
            
            if current_position != 0:
                # ãƒˆãƒ³ãƒãƒ«åŠ¹æœã«ã‚ˆã‚‹æ—©æœŸã‚¨ã‚°ã‚¸ãƒƒãƒˆ
                if tunnel_probability[i] > 0.8:
                    exit_signals[i] = -current_position
                    current_position = 0
        
        return exit_signals
    
    def _calculate_trend_phase(self, short_trend, medium_trend, long_trend) -> np.ndarray:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ•ã‚§ãƒ¼ã‚ºè¨ˆç®—ï¼ˆ8æ®µéšï¼‰"""
        n = len(short_trend)
        phases = np.zeros(n)
        
        for i in range(n):
            # çŸ­æœŸãƒ»ä¸­æœŸãƒ»é•·æœŸã®çµ„ã¿åˆã‚ã›ã§8æ®µéšåˆ¤å®š
            short_level = 1 if short_trend[i] > 0.5 else 0
            medium_level = 1 if medium_trend[i] > 0.5 else 0
            long_level = 1 if long_trend[i] > 0.5 else 0
            
            phase = short_level * 4 + medium_level * 2 + long_level + 1
            phases[i] = phase
        
        return phases
    
    def _get_current_phase(self, phase_value: float) -> str:
        """ç¾åœ¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ•ã‚§ãƒ¼ã‚ºåå–å¾—"""
        phase_map = {
            1: "å¼±ãƒ™ã‚¢", 2: "ä¸­ãƒ™ã‚¢", 3: "å¼·ãƒ™ã‚¢", 4: "è¶…ãƒ™ã‚¢",
            5: "å¼±ãƒ–ãƒ«", 6: "ä¸­ãƒ–ãƒ«", 7: "å¼·ãƒ–ãƒ«", 8: "è¶…ãƒ–ãƒ«"
        }
        return phase_map.get(int(phase_value), "ä¸­ç«‹")
    
    def _create_empty_result(self, length: int = 0) -> UQAVCResult:
        """ç©ºã®çµæœã‚’ä½œæˆ"""
        return UQAVCResult(
            upper_channel=np.full(length, np.nan),
            lower_channel=np.full(length, np.nan),
            midline=np.full(length, np.nan),
            dynamic_width=np.full(length, np.nan),
            breakout_signals=np.zeros(length),
            entry_confidence=np.zeros(length),
            exit_signals=np.zeros(length),
            trend_phase=np.ones(length),
            quantum_coherence=np.full(length, 0.5),
            entanglement_strength=np.full(length, 0.5),
            tunnel_probability=np.full(length, 0.5),
            wave_interference=np.zeros(length),
            short_term_trend=np.zeros(length),
            medium_term_trend=np.zeros(length),
            long_term_trend=np.zeros(length),
            wavelet_energy=np.zeros(length),
            flow_velocity=np.zeros(length),
            flow_turbulence=np.zeros(length),
            flow_direction=np.zeros(length),
            viscosity_index=np.zeros(length),
            neural_weight=np.full(length, 0.5),
            learning_rate=np.full(length, 0.01),
            adaptation_score=np.full(length, 0.5),
            memory_state=np.full(length, 0.5),
            hyperdim_correlation=np.full(length, 0.5),
            fractal_complexity=np.full(length, 1.0),
            chaos_indicator=np.zeros(length),
            regime_transition=np.full(length, 0.1),
            future_direction=np.zeros(length),
            breakout_timing=np.zeros(length),
            reversal_probability=np.zeros(length),
            trend_duration=np.zeros(length),
            current_phase='ä¸­ç«‹',
            current_coherence=0.5,
            current_flow_state='æ¨ªã°ã„æµ',
            market_intelligence=0.5
        )
    
    def _get_data_hash(self, data) -> str:
        """ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥è¨ˆç®—"""
        if isinstance(data, np.ndarray):
            return hash(data.tobytes())
        elif isinstance(data, pd.DataFrame):
            return hash(data.values.tobytes())
        else:
            return hash(str(data))
    
    # Getter ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def get_upper_channel(self) -> Optional[np.ndarray]:
        """ä¸Šå´ãƒãƒ£ãƒãƒ«ã‚’å–å¾—"""
        return self._result.upper_channel.copy() if self._result else None
    
    def get_lower_channel(self) -> Optional[np.ndarray]:
        """ä¸‹å´ãƒãƒ£ãƒãƒ«ã‚’å–å¾—"""
        return self._result.lower_channel.copy() if self._result else None
    
    def get_breakout_signals(self) -> Optional[np.ndarray]:
        """ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚·ã‚°ãƒŠãƒ«ã‚’å–å¾—"""
        return self._result.breakout_signals.copy() if self._result else None
    
    def get_quantum_analysis(self) -> Optional[dict]:
        """é‡å­è§£æçµæœã‚’å–å¾—"""
        if not self._result:
            return None
        return {
            'coherence': self._result.quantum_coherence.copy(),
            'entanglement': self._result.entanglement_strength.copy(),
            'tunnel_probability': self._result.tunnel_probability.copy(),
            'wave_interference': self._result.wave_interference.copy()
        }
    
    def get_neural_analysis(self) -> Optional[dict]:
        """ç¥çµŒå›è·¯ç¶²è§£æçµæœã‚’å–å¾—"""
        if not self._result:
            return None
        return {
            'weight': self._result.neural_weight.copy(),
            'learning_rate': self._result.learning_rate.copy(),
            'adaptation_score': self._result.adaptation_score.copy(),
            'memory_state': self._result.memory_state.copy()
        }
    
    def get_market_intelligence_report(self) -> dict:
        """å¸‚å ´çŸ¥èƒ½ãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—"""
        if not self._result:
            return {}
        
        return {
            'current_phase': self._result.current_phase,
            'current_coherence': self._result.current_coherence,
            'current_flow_state': self._result.current_flow_state,
            'market_intelligence': self._result.market_intelligence,
            'total_breakout_signals': int(np.sum(np.abs(self._result.breakout_signals))),
            'average_confidence': float(np.mean(self._result.entry_confidence[self._result.entry_confidence > 0])) if np.any(self._result.entry_confidence > 0) else 0.0,
            'quantum_stability': float(np.mean(self._result.quantum_coherence[-10:])) if len(self._result.quantum_coherence) >= 10 else 0.5,
            'neural_adaptation': float(np.mean(self._result.adaptation_score[-10:])) if len(self._result.adaptation_score) >= 10 else 0.5
        }
    
    def reset(self) -> None:
        """ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        super().reset()
        self._result = None
        self._cache = {}


# ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼ˆä½¿ã„ã‚„ã™ãã™ã‚‹ãŸã‚ï¼‰
UQAVC = UltraQuantumAdaptiveVolatilityChannel 