#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ultra Quantum Adaptive Trend-Range Discriminator (UQATRD)
===========================================================

John Ehlersã®å“²å­¦ã«åŸºã¥ãé©æ–°çš„ãªãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ¤åˆ¥ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼

4ã¤ã®æ ¸å¿ƒé‡å­ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼š
1. é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹æ–¹å‘æ€§æ¸¬å®šå™¨ (Quantum Coherence Directional Analyzer)
2. é‡å­ã‚¨ãƒ³ã‚¿ãƒ³ã‚°ãƒ«ãƒ¡ãƒ³ãƒˆæŒç¶šæ€§ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ (Quantum Entanglement Persistence Analyzer)
3. é‡å­åŠ¹ç‡ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ è¨ˆç®—æ©Ÿ (Quantum Efficiency Spectrum Calculator)
4. é‡å­ä¸ç¢ºå®šæ€§ãƒ¬ãƒ³ã‚¸æ¤œå‡ºå™¨ (Quantum Uncertainty Range Detector)

ç‰¹å¾´ï¼š
- è¶…é«˜ç²¾åº¦ï¼šè¤‡ç´ æ•°å¹³é¢ã§ã®å¤šæ¬¡å…ƒè§£æ
- è¶…é©å¿œæ€§ï¼šå‹•çš„ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºã«ã‚ˆã‚‹è‡ªå‹•èª¿æ•´
- è¶…ä½é…å»¶ï¼šã‚¼ãƒ­ãƒ©ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¨äºˆæ¸¬çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
- é‡å­çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼šç¢ºç‡çš„åˆ¤å®šã«ã‚ˆã‚‹æŸ”è»Ÿæ€§
"""

from dataclasses import dataclass
from typing import Union, Tuple, Dict, Optional, List, NamedTuple
import numpy as np
import pandas as pd
from numba import jit, njit, prange, float64, complex128
import traceback
import math

try:
    from .indicator import Indicator
    from .price_source import PriceSource
except ImportError:
    # ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œæ™‚ã®å¯¾å¿œ
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from indicator import Indicator
    from price_source import PriceSource


@dataclass
class UQATRDResult:
    """UQATRDè¨ˆç®—çµæœ"""
    # ãƒ¡ã‚¤ãƒ³åˆ¤å®šçµæœ
    trend_range_signal: np.ndarray      # æœ€çµ‚çš„ãªãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ¤å®š (0=ãƒ¬ãƒ³ã‚¸ to 1=ãƒˆãƒ¬ãƒ³ãƒ‰)
    signal_strength: np.ndarray         # ä¿¡å·å¼·åº¦ (0 to 1)
    
    # 4ã¤ã®æ ¸å¿ƒã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ çµæœ
    quantum_coherence: np.ndarray       # é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ (0 to 1)
    trend_persistence: np.ndarray       # ãƒˆãƒ¬ãƒ³ãƒ‰æŒç¶šæ€§ (0=ãƒ¬ãƒ³ã‚¸ to 1=ãƒˆãƒ¬ãƒ³ãƒ‰ã€æ–¹å‘æ€§ç„¡é–¢ä¿‚)
    efficiency_spectrum: np.ndarray     # åŠ¹ç‡ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ  (0 to 1)
    uncertainty_range: np.ndarray       # ä¸ç¢ºå®šæ€§ãƒ¬ãƒ³ã‚¸ (0 to 1)
    
    # å‹•çš„é©å¿œé–¾å€¤
    adaptive_threshold: np.ndarray      # å‹•çš„é©å¿œé–¾å€¤ (0.4 to 0.6)
    
    # è£œåŠ©æƒ…å ±
    confidence_score: np.ndarray        # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ (0 to 1)
    cycle_adaptive_factor: np.ndarray   # ã‚µã‚¤ã‚¯ãƒ«é©å¿œå› å­


# ================== é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹æ–¹å‘æ€§æ¸¬å®šå™¨ ==================

@njit(fastmath=True, cache=True)
def quantum_coherence_trend_analyzer(
    prices: np.ndarray,
    window: int = 21
) -> Tuple[np.ndarray, np.ndarray]:
    """
    ğŸŒ€ é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰æ¸¬å®šå™¨
    
    å¾“æ¥ã®ADXã‚’é‡å­çš„ã«å†æ§‹ç¯‰ï¼ˆæ–¹å‘æ€§ç„¡é–¢ä¿‚ç‰ˆï¼‰ï¼š
    - è¤‡ç´ æ•°å¹³é¢ã§ã®å¤‰å‹•ã®ä¸€è²«æ€§ã‚’æ¸¬å®š
    - ä½ç›¸ã®å®‰å®šæ€§ã‹ã‚‰ãƒˆãƒ¬ãƒ³ãƒ‰ã®å¼·ã•ã‚’æŠ½å‡ºï¼ˆæ–¹å‘æ€§ç„¡é–¢ä¿‚ï¼‰
    - é‡å­å¹²æ¸‰ã«ã‚ˆã‚‹å¤‰å‹•ã®ç´”åº¦æ¸¬å®š
    
    Args:
        prices: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿é…åˆ—
        window: åˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
        
    Returns:
        Tuple[coherence, trend_strength]: (ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹, ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦)
    """
    n = len(prices)
    coherence = np.zeros(n)
    trend_strength = np.zeros(n)
    
    if n < window:
        return coherence, trend_strength
    
    for i in range(window, n):
        # ä¾¡æ ¼å¤‰å‹•ã®è¤‡ç´ æ•°è¡¨ç¾ï¼ˆæ–¹å‘æ€§ç„¡é–¢ä¿‚ï¼‰
        complex_movements = np.zeros(window-1, dtype=np.complex128)
        
        for j in range(window-1):
            price_change = prices[i-window+j+1] - prices[i-window+j]
            # æŒ¯å¹…ã®ã¿ä½¿ç”¨ï¼ˆæ–¹å‘æ€§ã‚’é™¤å»ï¼‰
            amplitude = abs(price_change)
            # ä½ç›¸ã¯å¤‰å‹•ã®ä¸€è²«æ€§æ¸¬å®šã®ãŸã‚ã®ã¿ä½¿ç”¨
            angle = math.atan2(price_change, abs(price_change) + 1e-10)
            complex_movements[j] = amplitude * (math.cos(angle) + 1j * math.sin(angle))
        
        # é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ã®è¨ˆç®—
        # ä½ç›¸ã®åˆ†æ•£ã‚’æ¸¬å®šï¼ˆä½ç›¸ãŒæƒã£ã¦ã„ã‚‹ã»ã©é«˜ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ï¼‰
        phases = np.angle(complex_movements)
        
        # ä½ç›¸ã®å††å½¢çµ±è¨ˆé‡ï¼ˆvon Misesçµ±è¨ˆï¼‰
        cos_sum = np.sum(np.cos(phases))
        sin_sum = np.sum(np.sin(phases))
        
        # çµåˆãƒ™ã‚¯ãƒˆãƒ«ã®é•·ã•ï¼ˆã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹åº¦ï¼‰
        coherence_raw = math.sqrt(cos_sum**2 + sin_sum**2) / len(phases)
        coherence[i] = coherence_raw
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã®è¨ˆç®—ï¼ˆæ–¹å‘æ€§ç„¡é–¢ä¿‚ï¼‰
        # æŒ¯å¹…ã®å¹³å‡ã‚’ä½¿ç”¨ï¼ˆæ–¹å‘æ€§ã‚’é™¤å»ï¼‰
        amplitude_mean = np.mean(np.abs(complex_movements))
        
        # å¤‰å‹•ã®ä¸€è²«æ€§ï¼ˆã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ï¼‰ã¨ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã®çµåˆ
        trend_strength[i] = coherence_raw * amplitude_mean
    
    # å¢ƒç•Œå€¤ã®è£œé–“
    for i in range(window):
        coherence[i] = coherence[window] if n > window else 0.0
        trend_strength[i] = trend_strength[window] if n > window else 0.0
    
    return coherence, trend_strength


# ================== é‡å­ã‚¨ãƒ³ã‚¿ãƒ³ã‚°ãƒ«ãƒ¡ãƒ³ãƒˆæŒç¶šæ€§ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ ==================

@njit(fastmath=True, cache=True)
def quantum_entanglement_trend_analyzer(
    prices: np.ndarray,
    window: int = 34
) -> Tuple[np.ndarray, np.ndarray]:
    """
    ğŸ”— é‡å­ã‚¨ãƒ³ã‚¿ãƒ³ã‚°ãƒ«ãƒ¡ãƒ³ãƒˆãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æå™¨
    
    ãƒãƒ¼ã‚¹ãƒˆæŒ‡æ•°ã‚’é‡å­ã‚‚ã¤ã‚Œç†è«–ã§å†å®Ÿè£…ï¼ˆæ–¹å‘æ€§ç„¡é–¢ä¿‚ç‰ˆï¼‰ï¼š
    - éå»ã¨æœªæ¥ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿é–“ã®éå±€æ‰€ç›¸é–¢ã‚’æ¸¬å®š
    - EPRç›¸é–¢ã«ã‚ˆã‚‹æŒç¶šæ€§ã®é‡å­çš„è©•ä¾¡ï¼ˆæ–¹å‘æ€§ç„¡é–¢ä¿‚ï¼‰
    - æ™‚é–“è»¸ã‚’è¶…ãˆãŸç›¸é–¢ã®æ¸¬å®š
    
    Args:
        prices: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿é…åˆ—
        window: åˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
        
    Returns:
        Tuple[entanglement, trend_persistence]: (ã‚¨ãƒ³ã‚¿ãƒ³ã‚°ãƒ«ãƒ¡ãƒ³ãƒˆåº¦, ãƒˆãƒ¬ãƒ³ãƒ‰æŒç¶šæ€§)
    """
    n = len(prices)
    entanglement = np.zeros(n)
    trend_persistence = np.zeros(n)
    
    if n < window * 2:
        return entanglement, trend_persistence
    
    for i in range(window, n):
        # éå»ã®ãƒ‡ãƒ¼ã‚¿ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
        past_segment = prices[i-window:i]
        
        # é‡å­ã‚‚ã¤ã‚Œç›¸é–¢ã®è¨ˆç®—
        # R/Sçµ±è¨ˆã®é‡å­ç‰ˆï¼šã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰æ€§ã®æ¸¬å®š
        
        # 1. å¹³å‡é™¤å»ï¼ˆé‡å­çŠ¶æ…‹ã®ä¸­å¿ƒåŒ–ï¼‰
        mean_price = np.mean(past_segment)
        centered_prices = past_segment - mean_price
        
        # 2. ç´¯ç©åå·®ï¼ˆé‡å­ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ï¼‰
        cumulative_deviations = np.cumsum(centered_prices)
        
        # 3. ãƒ¬ãƒ³ã‚¸è¨ˆç®—ï¼ˆé‡å­çŠ¶æ…‹ã®åºƒãŒã‚Šï¼‰
        range_val = np.max(cumulative_deviations) - np.min(cumulative_deviations)
        
        # 4. æ¨™æº–åå·®ï¼ˆé‡å­ä¸ç¢ºå®šæ€§ï¼‰
        std_dev = np.std(past_segment)
        
        # 5. R/Sæ¯”ï¼ˆé‡å­ã‚‚ã¤ã‚ŒæŒ‡æ•°ï¼‰
        if std_dev > 1e-10:
            rs_ratio = range_val / std_dev
            # ãƒãƒ¼ã‚¹ãƒˆæŒ‡æ•°ã®è¿‘ä¼¼
            hurst_approx = math.log(rs_ratio) / math.log(window)
            
            # é‡å­ã‚‚ã¤ã‚Œåº¦ï¼ˆ0.5ã‹ã‚‰ã®åå·®ï¼‰
            entanglement[i] = abs(hurst_approx - 0.5) * 2.0
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰æŒç¶šæ€§ï¼ˆæ–¹å‘æ€§ç„¡é–¢ä¿‚ï¼‰
            # 0.5ã‹ã‚‰ã®åå·®ã®çµ¶å¯¾å€¤ã‚’ä½¿ç”¨ï¼š0.5ä»¥ä¸Šã§ãƒˆãƒ¬ãƒ³ãƒ‰ã€0.5ä»¥ä¸‹ã§ãƒ¬ãƒ³ã‚¸
            # 0ï¼ˆãƒ¬ãƒ³ã‚¸ï¼‰ã‹ã‚‰1ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰ã®ç¯„å›²ã«æ­£è¦åŒ–
            if hurst_approx > 0.5:
                trend_persistence[i] = (hurst_approx - 0.5) * 2.0
            else:
                trend_persistence[i] = (0.5 - hurst_approx) * 2.0
        else:
            entanglement[i] = 0.0
            trend_persistence[i] = 0.0
    
    # å¢ƒç•Œå€¤ã®è£œé–“
    for i in range(window):
        entanglement[i] = entanglement[window] if n > window else 0.0
        trend_persistence[i] = trend_persistence[window] if n > window else 0.0
    
    # å€¤ã®æ­£è¦åŒ–ï¼ˆæ‰‹å‹•ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ï¼‰
    for i in range(n):
        if entanglement[i] < 0.0:
            entanglement[i] = 0.0
        elif entanglement[i] > 1.0:
            entanglement[i] = 1.0
        
        if trend_persistence[i] < 0.0:
            trend_persistence[i] = 0.0
        elif trend_persistence[i] > 1.0:
            trend_persistence[i] = 1.0
    
    return entanglement, trend_persistence


# ================== é‡å­åŠ¹ç‡ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ è¨ˆç®—æ©Ÿ ==================

@njit(fastmath=True, cache=True)
def quantum_efficiency_spectrum_calculator(
    prices: np.ndarray,
    window: int = 21
) -> Tuple[np.ndarray, np.ndarray]:
    """
    ğŸ“Š é‡å­åŠ¹ç‡ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ è¨ˆç®—æ©Ÿ
    
    åŠ¹ç‡æ¯”ã‚’å‘¨æ³¢æ•°ãƒ‰ãƒ¡ã‚¤ãƒ³ã§æ‹¡å¼µï¼š
    - è¤‡æ•°æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ã§ã®åŠ¹ç‡æ€§ã‚’åŒæ™‚æ¸¬å®š
    - ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ã«ã‚ˆã‚‹åŠ¹ç‡æ€§ã®å‘¨æ³¢æ•°åˆ†è§£
    - é‡å­èª¿å’ŒæŒ¯å‹•å­ã«ã‚ˆã‚‹åŠ¹ç‡æ€§è©•ä¾¡
    
    Args:
        prices: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿é…åˆ—
        window: åˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
        
    Returns:
        Tuple[efficiency_spectrum, spectral_power]: (åŠ¹ç‡ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ , ã‚¹ãƒšã‚¯ãƒˆãƒ«å¼·åº¦)
    """
    n = len(prices)
    efficiency_spectrum = np.zeros(n)
    spectral_power = np.zeros(n)
    
    if n < window:
        return efficiency_spectrum, spectral_power
    
    for i in range(window, n):
        price_segment = prices[i-window:i]
        
        # 1. ç›´ç·šçš„å¤‰åŒ–ï¼ˆç†æƒ³çš„ãªåŠ¹ç‡ï¼‰
        linear_change = price_segment[-1] - price_segment[0]
        
        # 2. å®Ÿéš›ã®ä¾¡æ ¼å¤‰å‹•ã®ç·å’Œ
        actual_changes = np.sum(np.abs(np.diff(price_segment)))
        
        # 3. åŸºæœ¬åŠ¹ç‡æ¯”
        if actual_changes > 1e-10:
            basic_efficiency = abs(linear_change) / actual_changes
        else:
            basic_efficiency = 0.0
        
        # 4. é‡å­èª¿å’Œè§£æã«ã‚ˆã‚‹åŠ¹ç‡ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ 
        # è¤‡æ•°ã®èª¿å’Œæˆåˆ†ã§ã®åŠ¹ç‡æ€§ã‚’æ¸¬å®š
        harmonic_efficiencies = np.zeros(5)  # 5ã¤ã®èª¿å’Œæˆåˆ†
        
        for h in range(1, 6):  # 1æ¬¡ã‹ã‚‰5æ¬¡èª¿å’Œ
            # èª¿å’ŒæŒ¯å‹•å­ã®å‘¨æ³¢æ•°
            omega = 2 * math.pi * h / window
            
            # è¤‡ç´ æŒ‡æ•°ã«ã‚ˆã‚‹å¤‰æ›
            complex_sum = 0.0 + 0.0j
            for j in range(window):
                angle = omega * j
                complex_sum += price_segment[j] * (math.cos(angle) + 1j * math.sin(angle))
            
            # èª¿å’Œæˆåˆ†ã®æŒ¯å¹…
            harmonic_amplitude = abs(complex_sum) / window
            
            # èª¿å’Œæˆåˆ†ã§ã®åŠ¹ç‡æ€§
            if harmonic_amplitude > 1e-10:
                harmonic_efficiencies[h-1] = basic_efficiency * harmonic_amplitude
            else:
                harmonic_efficiencies[h-1] = 0.0
        
        # 5. åŠ¹ç‡ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ ã®çµ±åˆ
        # é»„é‡‘æ¯”ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘
        golden_weights = np.array([1.0, 0.618, 0.382, 0.236, 0.146])
        golden_weights /= np.sum(golden_weights)
        
        efficiency_spectrum[i] = np.sum(harmonic_efficiencies * golden_weights)
        spectral_power[i] = np.sum(harmonic_efficiencies)
    
    # å¢ƒç•Œå€¤ã®è£œé–“
    for i in range(window):
        efficiency_spectrum[i] = efficiency_spectrum[window] if n > window else 0.0
        spectral_power[i] = spectral_power[window] if n > window else 0.0
    
    # å€¤ã®æ­£è¦åŒ–ï¼ˆæ‰‹å‹•ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ï¼‰
    for i in range(n):
        if efficiency_spectrum[i] < 0.0:
            efficiency_spectrum[i] = 0.0
        elif efficiency_spectrum[i] > 1.0:
            efficiency_spectrum[i] = 1.0
    
    return efficiency_spectrum, spectral_power


# ================== é‡å­ä¸ç¢ºå®šæ€§ãƒ¬ãƒ³ã‚¸æ¤œå‡ºå™¨ ==================

@njit(fastmath=True, cache=True)
def quantum_uncertainty_range_detector(
    prices: np.ndarray,
    window: int = 14
) -> Tuple[np.ndarray, np.ndarray]:
    """
    ğŸ¯ é‡å­ä¸ç¢ºå®šæ€§ãƒ¬ãƒ³ã‚¸æ¤œå‡ºå™¨
    
    ä¸ç¢ºå®šæ€§åŸç†ã«ã‚ˆã‚‹ã€Œä½ç½®Ã—é‹å‹•é‡ã€ã®æ¸¬å®šï¼š
    - ä¾¡æ ¼ã®ä½ç½®ï¼ˆç¾åœ¨å€¤ï¼‰ã¨é‹å‹•é‡ï¼ˆå¤‰åŒ–ç‡ï¼‰ã®ç©
    - ä¸ç¢ºå®šæ€§ãŒé«˜ã„ = ãƒ¬ãƒ³ã‚¸ã€ä½ã„ = ãƒˆãƒ¬ãƒ³ãƒ‰
    - ãƒã‚¤ã‚¼ãƒ³ãƒ™ãƒ«ã‚¯ã®ä¸ç¢ºå®šæ€§åŸç†ã®é‡‘èå¿œç”¨
    
    Args:
        prices: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿é…åˆ—
        window: åˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
        
    Returns:
        Tuple[uncertainty_range, momentum_dispersion]: (ä¸ç¢ºå®šæ€§ãƒ¬ãƒ³ã‚¸, é‹å‹•é‡åˆ†æ•£)
    """
    n = len(prices)
    uncertainty_range = np.zeros(n)
    momentum_dispersion = np.zeros(n)
    
    if n < window:
        return uncertainty_range, momentum_dispersion
    
    for i in range(window, n):
        price_segment = prices[i-window:i]
        
        # 1. ä½ç½®ã®ä¸ç¢ºå®šæ€§ï¼ˆä¾¡æ ¼ã®åˆ†æ•£ï¼‰
        position_variance = np.var(price_segment)
        position_uncertainty = math.sqrt(position_variance)
        
        # 2. é‹å‹•é‡ã®ä¸ç¢ºå®šæ€§ï¼ˆä¾¡æ ¼å¤‰åŒ–ç‡ã®åˆ†æ•£ï¼‰
        momentum_changes = np.diff(price_segment)
        if len(momentum_changes) > 0:
            momentum_variance = np.var(momentum_changes)
            momentum_uncertainty = math.sqrt(momentum_variance)
        else:
            momentum_uncertainty = 0.0
        
        # 3. ä¸ç¢ºå®šæ€§åŸç†ã®é©ç”¨
        # Î”xÎ”p â‰¥ â„/2 (é‡å­åŠ›å­¦) â†’ ä¾¡æ ¼ç‰ˆ
        uncertainty_product = position_uncertainty * momentum_uncertainty
        
        # 4. æ­£è¦åŒ–ã•ã‚ŒãŸä¸ç¢ºå®šæ€§
        # é«˜ã„ä¸ç¢ºå®šæ€§ = ãƒ¬ãƒ³ã‚¸ç›¸å ´
        # ä½ã„ä¸ç¢ºå®šæ€§ = ãƒˆãƒ¬ãƒ³ãƒ‰ç›¸å ´
        
        # ä¾¡æ ¼ãƒ¬ãƒ³ã‚¸ã§ã®æ­£è¦åŒ–
        price_range = np.max(price_segment) - np.min(price_segment)
        if price_range > 1e-10:
            normalized_uncertainty = uncertainty_product / price_range
        else:
            normalized_uncertainty = 0.0
        
        uncertainty_range[i] = normalized_uncertainty
        momentum_dispersion[i] = momentum_uncertainty
        
        # 5. é‡å­ã‚‚ã¤ã‚Œè£œæ­£
        # è¿‘éš£ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã¨ã®ç›¸é–¢ã‚’è€ƒæ…®
        if i >= window + 5:
            past_uncertainties = uncertainty_range[i-5:i]
            correlation_factor = np.corrcoef(past_uncertainties, 
                                           np.arange(len(past_uncertainties)))[0, 1]
            if not np.isnan(correlation_factor):
                uncertainty_range[i] *= (1.0 + abs(correlation_factor) * 0.2)
    
    # å¢ƒç•Œå€¤ã®è£œé–“
    for i in range(window):
        uncertainty_range[i] = uncertainty_range[window] if n > window else 0.0
        momentum_dispersion[i] = momentum_dispersion[window] if n > window else 0.0
    
    # å€¤ã®æ­£è¦åŒ–
    max_uncertainty = np.max(uncertainty_range) if len(uncertainty_range) > 0 else 1.0
    if max_uncertainty > 1e-10:
        uncertainty_range = uncertainty_range / max_uncertainty
    
    return uncertainty_range, momentum_dispersion


# ================== å‹•çš„é©å¿œé–¾å€¤è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ ==================

@njit(fastmath=True, cache=True)
def calculate_adaptive_threshold(
    prices: np.ndarray,
    coherence: np.ndarray,
    trend_persistence: np.ndarray,
    efficiency_spectrum: np.ndarray,
    uncertainty_range: np.ndarray,
    str_values: np.ndarray,
    window: int = 21
) -> np.ndarray:
    """
    ğŸ¯ é‡å­é©å¿œå­¦ç¿’é–¾å€¤ã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ç‰ˆï¼‰
    
    4ã¤ã®é©å¿œè¦ç´ ã‚’çµ±åˆã—ãŸå‹•çš„é–¾å€¤è¨ˆç®—ï¼š
    1. STRãƒ™ãƒ¼ã‚¹ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£é©å¿œï¼ˆãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒ¬ãƒ³ã‚¸ï¼‰
    2. é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹é©å¿œï¼ˆæ‹¡å¼µå¤‰å‹•ï¼‰
    3. ã‚µã‚¤ã‚¯ãƒ«é©å¿œï¼ˆåå·®å¼·èª¿ï¼‰
    4. é©å¿œå­¦ç¿’æ©Ÿæ§‹ï¼ˆå¢—å¹…èª¿æ•´ï¼‰
    
    Args:
        prices: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿é…åˆ—
        coherence: é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹é…åˆ—
        trend_persistence: ãƒˆãƒ¬ãƒ³ãƒ‰æŒç¶šæ€§é…åˆ—
        efficiency_spectrum: åŠ¹ç‡ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ é…åˆ—
        uncertainty_range: ä¸ç¢ºå®šæ€§ãƒ¬ãƒ³ã‚¸é…åˆ—
        str_values: STRï¼ˆSmooth True Rangeï¼‰å€¤é…åˆ—
        window: é©å¿œã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
        
    Returns:
        np.ndarray: å‹•çš„é©å¿œé–¾å€¤é…åˆ—
    """
    n = len(prices)
    adaptive_threshold = np.zeros(n)
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé–¾å€¤ï¼ˆä¸­å¤®å€¤ã«è¨­å®šï¼‰
    base_threshold = 0.5
    
    if n < window:
        for i in range(n):
            adaptive_threshold[i] = base_threshold
        return adaptive_threshold
    
    for i in range(window, n):
        # 1. STRãƒ™ãƒ¼ã‚¹ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£é©å¿œè¨ˆç®—
        if i < len(str_values):
            # STRã®ç§»å‹•å¹³å‡ã‚’è¨ˆç®—ã—ã¦ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã™ã‚‹
            str_window = str_values[max(0, i-window):i]
            if len(str_window) > 0:
                str_mean = np.mean(str_window)
                str_current = str_values[i]
                
                # STRã‚’ä¾¡æ ¼ã§æ­£è¦åŒ–ï¼ˆç›¸å¯¾çš„ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼‰
                current_price = prices[i]
                if current_price > 1e-10:
                    relative_str = str_current / current_price
                else:
                    relative_str = 0.0
                
                # 0-1ç¯„å›²ã«æ­£è¦åŒ–
                # é€šå¸¸ã®STR/ä¾¡æ ¼æ¯”ç‡ã¯0.01-0.05ç¨‹åº¦ãªã®ã§ã€20å€ã—ã¦0-1ã«è¿‘ã¥ã‘ã‚‹
                normalized_volatility = min(1.0, relative_str * 20.0)
                
                # ä¸‹é™ã‚’è¨­å®šï¼ˆæ¥µç«¯ã«ä½ã„ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’é˜²ãï¼‰
                normalized_volatility = max(0.1, normalized_volatility)
            else:
                normalized_volatility = 0.5
        else:
            normalized_volatility = 0.5
        
        # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ â†’ é–¾å€¤ã‚’é«˜ãï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šã‚’å³ã—ãï¼‰
        # ã•ã‚‰ã«ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªå¤‰å‹•ã®ãŸã‚ã«ä¿‚æ•°ã‚’å¤§å¹…æ‹¡å¤§
        volatility_adjustment = 0.4 + normalized_volatility * 1.2  # 0.4-1.6ã®ç¯„å›²
        
        # 2. é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹é©å¿œ
        # é«˜ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ â†’ é–¾å€¤ã‚’ä½ãï¼ˆæ˜ç¢ºãªä¿¡å·ï¼‰
        coherence_current = coherence[i] if i < len(coherence) else 0.5
        coherence_adjustment = 1.4 - coherence_current * 0.8      # 0.6-1.4ã®ç¯„å›²
        
        # 3. ã‚µã‚¤ã‚¯ãƒ«é©å¿œï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰æŒç¶šæ€§ãƒ™ãƒ¼ã‚¹ï¼‰
        # é«˜æŒç¶šæ€§ â†’ é–¾å€¤ã‚’ä½ãï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ãŒç¶šãã‚„ã™ã„ï¼‰
        persistence_current = trend_persistence[i] if i < len(trend_persistence) else 0.5
        cycle_adjustment = 1.4 - persistence_current * 0.8        # 0.6-1.4ã®ç¯„å›²
        
        # 4. åŠ¹ç‡æ€§é©å¿œ
        # é«˜åŠ¹ç‡æ€§ â†’ é–¾å€¤ã‚’ä½ãï¼ˆåŠ¹ç‡çš„ãªå‹•ãï¼‰
        efficiency_current = efficiency_spectrum[i] if i < len(efficiency_spectrum) else 0.5
        efficiency_adjustment = 1.4 - efficiency_current * 0.8    # 0.6-1.4ã®ç¯„å›²
        
        # 5. ä¸ç¢ºå®šæ€§é©å¿œ
        # é«˜ä¸ç¢ºå®šæ€§ â†’ é–¾å€¤ã‚’é«˜ãï¼ˆãƒ¬ãƒ³ã‚¸åˆ¤å®šã—ã‚„ã™ãï¼‰
        uncertainty_current = uncertainty_range[i] if i < len(uncertainty_range) else 0.5
        uncertainty_adjustment = 0.4 + uncertainty_current * 1.2  # 0.4-1.6ã®ç¯„å›²
        
        # 6. é©å¿œå­¦ç¿’æ©Ÿæ§‹ï¼ˆéå»ã®ç²¾åº¦ã«åŸºã¥ãèª¿æ•´ï¼‰
        learning_adjustment = 1.0
        
        if i >= window * 2:
            # éå»ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
            past_signals = []
            past_thresholds = []
            
            for j in range(max(0, i-window), i):
                if j < len(coherence) and j < len(adaptive_threshold):
                    # éå»ã®ä¿¡å·ã¨é–¾å€¤ã‚’è¨˜éŒ²
                    past_signal = (coherence[j] + trend_persistence[j] + 
                                  efficiency_spectrum[j] + (1.0 - uncertainty_range[j])) / 4.0
                    past_signals.append(past_signal)
                    past_thresholds.append(adaptive_threshold[j] if j > 0 else base_threshold)
            
            if len(past_signals) > 10:
                # é–¾å€¤ã®å®‰å®šæ€§ã‚’è©•ä¾¡
                threshold_variance = np.var(np.array(past_thresholds))
                
                # ã‚ˆã‚Šãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªå­¦ç¿’èª¿æ•´
                if threshold_variance < 0.01:
                    learning_adjustment = 0.85  # ã‚ˆã‚Šå¤§ããªå¤‰å‹•ã‚’ä¿ƒã™
                else:
                    learning_adjustment = 1.25  # ã•ã‚‰ã«å¤§ããªèª¿æ•´
        
        # 7. çµ±åˆé©å¿œé–¾å€¤è¨ˆç®—ï¼ˆã‚ˆã‚Šãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªæ–¹å¼ï¼‰
        adjustments = np.array([
            volatility_adjustment,
            coherence_adjustment,
            cycle_adjustment,
            efficiency_adjustment,
            uncertainty_adjustment
        ])
        
        # ã‚ˆã‚Šå¤‰å‹•ã®å¤§ãã„çµ±åˆæ–¹å¼ï¼šé‡ã¿ä»˜ãå¹³å‡ã§ã¯ãªãåå·®ã‚’å¼·èª¿
        weights = np.array([0.25, 0.2, 0.2, 0.15, 0.2])
        weighted_adjustments = adjustments * weights
        
        # å¹³å‡ã‹ã‚‰ã®åå·®ã‚’å¼·èª¿ã—ã¦å¤‰å‹•ã‚’æ‹¡å¤§
        mean_adjustment = np.sum(weighted_adjustments)
        deviation_from_base = mean_adjustment - 1.0  # 1.0ã‚’åŸºæº–ã¨ã—ãŸåå·®
        
        # åå·®ã‚’å¤§å¹…æ‹¡å¤§ã—ã¦å¤‰å‹•ã‚’ã‚ˆã‚Šãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ã«
        amplified_deviation = deviation_from_base * 3.5 * learning_adjustment
        
        # æœ€çµ‚é–¾å€¤è¨ˆç®—ï¼ˆåŠ ç®—ãƒ™ãƒ¼ã‚¹ï¼‰- ä¿‚æ•°ã‚’å¤§å¹…æ‹¡å¤§
        final_threshold = base_threshold + amplified_deviation * 0.35  # å¤§ããªå¤‰å‹•ã®ãŸã‚ä¿‚æ•°ã‚’å¤§å¹…æ‹¡å¤§
        
        # é–¾å€¤ã®åˆ¶é™ï¼ˆå®Ÿè·µçš„ç¯„å›²: 0.4-0.6ï¼‰
        if final_threshold < 0.45:
            final_threshold = 0.45
        elif final_threshold > 0.65:
            final_threshold = 0.65
        
        adaptive_threshold[i] = final_threshold
    
    # å¢ƒç•Œå€¤ã®è£œé–“ï¼ˆã‚ˆã‚Šãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªåˆæœŸå€¤ï¼‰
    for i in range(window):
        if n > window:
            adaptive_threshold[i] = adaptive_threshold[window]
        else:
            # åˆæœŸå€¤ã«ã‚ˆã‚Šå¤§ããªå¤‰å‹•ã‚’æŒãŸã›ã‚‹
            variation = (i / window - 0.5) * 0.2  # -0.1 to +0.1ã®å¤‰å‹•
            adaptive_threshold[i] = base_threshold + variation  # 0.4-0.6ã®ç¯„å›²
    
    return adaptive_threshold


# ================== çµ±åˆè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ ==================

@njit(fastmath=True, cache=True)
def calculate_uqatrd_core(
    prices: np.ndarray,
    str_values: np.ndarray,
    coherence_window: int = 21,
    entanglement_window: int = 34,
    efficiency_window: int = 21,
    uncertainty_window: int = 14
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    ğŸš€ UQATRDçµ±åˆè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³
    
    4ã¤ã®é‡å­ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’çµ±åˆã—ã¦ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ¤å®šã‚’å®Ÿè¡Œ
    å‡ºåŠ›ï¼š0ï¼ˆãƒ¬ãƒ³ã‚¸ï¼‰ã‹ã‚‰1ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰ã®ç¯„å›²ã€æ–¹å‘æ€§ç„¡é–¢ä¿‚
    """
    n = len(prices)
    
    # 1. é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰æ¸¬å®š
    coherence, trend_strength = quantum_coherence_trend_analyzer(
        prices, coherence_window
    )
    
    # 2. é‡å­ã‚¨ãƒ³ã‚¿ãƒ³ã‚°ãƒ«ãƒ¡ãƒ³ãƒˆãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    entanglement, trend_persistence = quantum_entanglement_trend_analyzer(
        prices, entanglement_window
    )
    
    # 3. é‡å­åŠ¹ç‡ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ è¨ˆç®—
    efficiency_spectrum, spectral_power = quantum_efficiency_spectrum_calculator(
        prices, efficiency_window
    )
    
    # 4. é‡å­ä¸ç¢ºå®šæ€§ãƒ¬ãƒ³ã‚¸æ¤œå‡º
    uncertainty_range, momentum_dispersion = quantum_uncertainty_range_detector(
        prices, uncertainty_window
    )
    
    # 5. çµ±åˆä¿¡å·ã®è¨ˆç®—ï¼ˆæ–¹å‘æ€§ç„¡é–¢ä¿‚ï¼‰
    trend_range_signal = np.zeros(n)
    signal_strength = np.zeros(n)
    
    for i in range(n):
        # å„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‹ã‚‰ã®ä¿¡å·ã‚’çµ±åˆï¼ˆå…¨ã¦0-1ã®ç¯„å›²ï¼‰
        # ãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡å·ï¼ˆ1 ã«è¿‘ã„ã»ã©å¼·ã„ãƒˆãƒ¬ãƒ³ãƒ‰ã€0 ã«è¿‘ã„ã»ã©å¼·ã„ãƒ¬ãƒ³ã‚¸ï¼‰
        trend_signals = np.array([
            coherence[i],                    # é«˜ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ = ãƒˆãƒ¬ãƒ³ãƒ‰
            trend_persistence[i],            # é«˜æŒç¶šæ€§ = ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæ–¹å‘æ€§ç„¡é–¢ä¿‚ï¼‰
            efficiency_spectrum[i],          # é«˜åŠ¹ç‡ = ãƒˆãƒ¬ãƒ³ãƒ‰
            (1.0 - uncertainty_range[i])     # ä½ä¸ç¢ºå®šæ€§ = ãƒˆãƒ¬ãƒ³ãƒ‰
        ])
        
        # é‡å­é‡ã­åˆã‚ã›ã«ã‚ˆã‚‹çµ±åˆ
        # å„ä¿¡å·ã®é‡ã¿ï¼ˆé»„é‡‘æ¯”ãƒ™ãƒ¼ã‚¹ï¼‰
        weights = np.array([0.382, 0.236, 0.236, 0.146])
        
        # é‡ã¿ä»˜ãå¹³å‡
        weighted_signal = np.sum(trend_signals * weights)
        
        # æœ€çµ‚çš„ãªãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ¤å®š
        # 0 (ãƒ¬ãƒ³ã‚¸) ã‹ã‚‰ 1 (ãƒˆãƒ¬ãƒ³ãƒ‰) ã®ç¯„å›²
        if weighted_signal < 0.0:
            trend_range_signal[i] = 0.0
        elif weighted_signal > 1.0:
            trend_range_signal[i] = 1.0
        else:
            trend_range_signal[i] = weighted_signal
        
        # ä¿¡å·å¼·åº¦ï¼ˆç¢ºä¿¡åº¦ï¼‰
        signal_variance = np.var(trend_signals)
        signal_strength[i] = 1.0 / (1.0 + signal_variance * 10.0)
    
    # å€¤ã®æ­£è¦åŒ–ï¼ˆæ‰‹å‹•ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ï¼‰
    for i in range(n):
        if trend_range_signal[i] < 0.0:
            trend_range_signal[i] = 0.0
        elif trend_range_signal[i] > 1.0:
            trend_range_signal[i] = 1.0
        
        if signal_strength[i] < 0.0:
            signal_strength[i] = 0.0
        elif signal_strength[i] > 1.0:
            signal_strength[i] = 1.0
    
    # 6. å‹•çš„é©å¿œé–¾å€¤ã®è¨ˆç®—ï¼ˆSTRãƒ™ãƒ¼ã‚¹ï¼‰
    adaptive_threshold = calculate_adaptive_threshold(
        prices, coherence, trend_persistence, 
        efficiency_spectrum, uncertainty_range, str_values,
        window=21
    )
    
    return (trend_range_signal, signal_strength, coherence, 
            trend_persistence, efficiency_spectrum, uncertainty_range, adaptive_threshold)


class UltraQuantumAdaptiveTrendRangeDiscriminator(Indicator):
    """
    ğŸŒŸ Ultra Quantum Adaptive Trend-Range Discriminator (UQATRD)
    
    John Ehlersã®å“²å­¦ã«åŸºã¥ãé©æ–°çš„ãªãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ¤åˆ¥ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
    
    4ã¤ã®æ ¸å¿ƒé‡å­ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼š
    1. é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹æ–¹å‘æ€§æ¸¬å®šå™¨
    2. é‡å­ã‚¨ãƒ³ã‚¿ãƒ³ã‚°ãƒ«ãƒ¡ãƒ³ãƒˆæŒç¶šæ€§ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼
    3. é‡å­åŠ¹ç‡ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ è¨ˆç®—æ©Ÿ
    4. é‡å­ä¸ç¢ºå®šæ€§ãƒ¬ãƒ³ã‚¸æ¤œå‡ºå™¨
    
    ç‰¹å¾´ï¼š
    - è¶…é«˜ç²¾åº¦ï¼šè¤‡ç´ æ•°å¹³é¢ã§ã®å¤šæ¬¡å…ƒè§£æ
    - è¶…é©å¿œæ€§ï¼šå‹•çš„ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºã«ã‚ˆã‚‹è‡ªå‹•èª¿æ•´
    - è¶…ä½é…å»¶ï¼šã‚¼ãƒ­ãƒ©ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¨äºˆæ¸¬çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
    - é‡å­çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼šç¢ºç‡çš„åˆ¤å®šã«ã‚ˆã‚‹æŸ”è»Ÿæ€§
    """
    
    def __init__(
        self,
        # å„é‡å­ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        coherence_window: int = 21,      # é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹åˆ†æçª“
        entanglement_window: int = 34,   # é‡å­ã‚¨ãƒ³ã‚¿ãƒ³ã‚°ãƒ«ãƒ¡ãƒ³ãƒˆåˆ†æçª“
        efficiency_window: int = 21,     # é‡å­åŠ¹ç‡ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ åˆ†æçª“
        uncertainty_window: int = 14,    # é‡å­ä¸ç¢ºå®šæ€§åˆ†æçª“
        
        # ä¸€èˆ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        src_type: str = 'ukf_hlc3',          # ä¾¡æ ¼ã‚½ãƒ¼ã‚¹
        adaptive_mode: bool = True,      # é©å¿œãƒ¢ãƒ¼ãƒ‰
        sensitivity: float = 1.0,        # æ„Ÿåº¦èª¿æ•´
        
        # STRãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        str_period: float = 20.0,        # STRæœŸé–“ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—ç”¨ï¼‰
        
        # å“è³ªç®¡ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        min_data_points: int = 50,       # æœ€å°ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°
        confidence_threshold: float = 0.7 # ä¿¡é ¼åº¦é–¾å€¤
    ):
        """
        ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
        
        Args:
            coherence_window: é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹åˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            entanglement_window: é‡å­ã‚¨ãƒ³ã‚¿ãƒ³ã‚°ãƒ«ãƒ¡ãƒ³ãƒˆåˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            efficiency_window: é‡å­åŠ¹ç‡ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ åˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            uncertainty_window: é‡å­ä¸ç¢ºå®šæ€§åˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            src_type: ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—
            adaptive_mode: é©å¿œãƒ¢ãƒ¼ãƒ‰ï¼ˆå°†æ¥ã®æ©Ÿèƒ½æ‹¡å¼µç”¨ï¼‰
            sensitivity: æ„Ÿåº¦èª¿æ•´å€ç‡
            str_period: STRæœŸé–“ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—ç”¨ï¼‰
            min_data_points: æœ€å°ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°
            confidence_threshold: ä¿¡é ¼åº¦é–¾å€¤
        """
        super().__init__(f"UQATRD(C:{coherence_window},E:{entanglement_window},"
                        f"Ef:{efficiency_window},U:{uncertainty_window})")
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¿å­˜
        self.coherence_window = coherence_window
        self.entanglement_window = entanglement_window
        self.efficiency_window = efficiency_window
        self.uncertainty_window = uncertainty_window
        
        self.src_type = src_type.lower()
        self.adaptive_mode = adaptive_mode
        self.sensitivity = sensitivity
        self.str_period = str_period
        self.min_data_points = min_data_points
        self.confidence_threshold = confidence_threshold
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼
        if self.coherence_window < 5:
            raise ValueError("coherence_windowã¯5ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        if self.entanglement_window < 10:
            raise ValueError("entanglement_windowã¯10ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        if self.efficiency_window < 5:
            raise ValueError("efficiency_windowã¯5ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        if self.uncertainty_window < 5:
            raise ValueError("uncertainty_windowã¯5ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        
        # ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã®æ¤œè¨¼
        available_sources = PriceSource.get_available_sources()
        if self.src_type not in available_sources:
            valid_sources = ', '.join(available_sources.keys())
            raise ValueError(f"ç„¡åŠ¹ãªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã§ã™: {src_type}ã€‚"
                           f"æœ‰åŠ¹ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³: {valid_sources}")
        
        # STRã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—ç”¨ï¼‰
        try:
            from .str import STR
            self._str_indicator = STR(period=self.str_period, src_type='hlc3')
            self.logger.info(f"STRã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–å®Œäº†: period={self.str_period}")
        except ImportError:
            try:
                from str import STR
                self._str_indicator = STR(period=self.str_period, src_type='hlc3')
                self.logger.info(f"STRã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–å®Œäº†: period={self.str_period}")
            except ImportError:
                self.logger.warning("STRã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç°¡æ˜“ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                self._str_indicator = None
        
        # çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._result_cache = {}
        self._max_cache_size = 10
        self._cache_keys = []
    
    def _get_data_hash(self, data: Union[pd.DataFrame, np.ndarray]) -> str:
        """ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—"""
        try:
            if isinstance(data, pd.DataFrame):
                length = len(data)
                first_val = float(data.iloc[0].get('close', data.iloc[0, -1])) if length > 0 else 0.0
                last_val = float(data.iloc[-1].get('close', data.iloc[-1, -1])) if length > 0 else 0.0
            else:
                length = len(data)
                if length > 0:
                    if data.ndim > 1:
                        first_val = float(data[0, -1])
                        last_val = float(data[-1, -1])
                    else:
                        first_val = float(data[0])
                        last_val = float(data[-1])
                else:
                    first_val = last_val = 0.0
            
            params_sig = (f"{self.coherence_window}_{self.entanglement_window}_"
                         f"{self.efficiency_window}_{self.uncertainty_window}_"
                         f"{self.src_type}_{self.sensitivity}")
            data_sig = (length, first_val, last_val)
            return f"{hash(data_sig)}_{hash(params_sig)}"
            
        except Exception:
            return f"{id(data)}_{self.coherence_window}_{self.entanglement_window}"
    
    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> UQATRDResult:
        """
        UQATRDè¨ˆç®—ãƒ¡ã‚¤ãƒ³é–¢æ•°
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆDataFrameã¾ãŸã¯NumPyé…åˆ—ï¼‰
                
        Returns:
            UQATRDResult: è¨ˆç®—çµæœ
        """
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            data_hash = self._get_data_hash(data)
            
            if data_hash in self._result_cache:
                if data_hash in self._cache_keys:
                    self._cache_keys.remove(data_hash)
                self._cache_keys.append(data_hash)
                return self._result_cache[data_hash]
            
            # ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ã®è¨ˆç®—
            price_source = PriceSource.calculate_source(data, self.src_type)
            price_source = np.asarray(price_source, dtype=np.float64)
            
            # ãƒ‡ãƒ¼ã‚¿é•·ã®æ¤œè¨¼
            data_length = len(price_source)
            if data_length == 0:
                raise ValueError("å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            
            if data_length < self.min_data_points:
                self.logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãŒçŸ­ã™ãã¾ã™ï¼ˆ{data_length}ç‚¹ï¼‰ã€‚"
                                  f"æœ€ä½{self.min_data_points}ç‚¹ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
            
            # æ„Ÿåº¦èª¿æ•´
            if self.sensitivity != 1.0:
                # ä¾¡æ ¼å¤‰å‹•ã‚’æ„Ÿåº¦å€ç‡ã§èª¿æ•´
                mean_price = np.mean(price_source)
                price_deviations = price_source - mean_price
                price_source = mean_price + price_deviations * self.sensitivity
            
            # STRè¨ˆç®—ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç”¨ï¼‰
            str_values = np.zeros(data_length)
            if self._str_indicator is not None:
                try:
                    str_result = self._str_indicator.calculate(data)
                    str_values = str_result.values.copy()
                    self.logger.debug(f"STRè¨ˆç®—å®Œäº†: å¹³å‡STR={np.mean(str_values):.6f}")
                except Exception as e:
                    self.logger.warning(f"STRè¨ˆç®—ã«å¤±æ•—: {e}. ç°¡æ˜“è¨ˆç®—ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                    # ç°¡æ˜“STRè¨ˆç®—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                    for i in range(1, data_length):
                        str_values[i] = abs(price_source[i] - price_source[i-1])
            else:
                # ç°¡æ˜“STRè¨ˆç®—
                for i in range(1, data_length):
                    str_values[i] = abs(price_source[i] - price_source[i-1])
                self.logger.debug("ç°¡æ˜“STRè¨ˆç®—ã‚’ä½¿ç”¨ã—ã¾ã—ãŸ")
            
            # æ ¸å¿ƒè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè¡Œ
            (trend_range_signal, signal_strength, coherence, 
             trend_persistence, efficiency_spectrum, uncertainty_range, adaptive_threshold) = calculate_uqatrd_core(
                price_source,
                str_values,
                self.coherence_window,
                self.entanglement_window,
                self.efficiency_window,
                self.uncertainty_window
            )
            
            # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
            confidence_score = np.zeros(data_length)
            cycle_adaptive_factor = np.ones(data_length)
            
            for i in range(data_length):
                # 4ã¤ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åˆæ„åº¦ã‚’ä¿¡é ¼åº¦ã¨ã™ã‚‹ï¼ˆå…¨ã¦0-1ã®ç¯„å›²ï¼‰
                algorithm_values = np.array([
                    coherence[i],
                    trend_persistence[i],       # æ—¢ã«0~1ã®ç¯„å›²
                    efficiency_spectrum[i],
                    (1.0 - uncertainty_range[i])
                ])
                
                # åˆæ„åº¦ã®è¨ˆç®—ï¼ˆåˆ†æ•£ã®é€†æ•°ï¼‰
                agreement = 1.0 - np.var(algorithm_values)
                confidence_score[i] = max(0.0, min(1.0, agreement))
                
                # é©å¿œå› å­ï¼ˆå°†æ¥ã®æ©Ÿèƒ½æ‹¡å¼µç”¨ï¼‰
                if self.adaptive_mode:
                    cycle_adaptive_factor[i] = 1.0 + coherence[i] * 0.2
            
            # çµæœã®ä¿å­˜
            result = UQATRDResult(
                trend_range_signal=trend_range_signal.copy(),
                signal_strength=signal_strength.copy(),
                quantum_coherence=coherence.copy(),
                trend_persistence=trend_persistence.copy(),
                efficiency_spectrum=efficiency_spectrum.copy(),
                uncertainty_range=uncertainty_range.copy(),
                adaptive_threshold=adaptive_threshold.copy(),
                confidence_score=confidence_score.copy(),
                cycle_adaptive_factor=cycle_adaptive_factor.copy()
            )
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
            if len(self._result_cache) >= self._max_cache_size and self._cache_keys:
                oldest_key = self._cache_keys.pop(0)
                if oldest_key in self._result_cache:
                    del self._result_cache[oldest_key]
            
            self._result_cache[data_hash] = result
            self._cache_keys.append(data_hash)
            
            self._values = trend_range_signal  # åŸºåº•ã‚¯ãƒ©ã‚¹ã®è¦ä»¶
            
            self.logger.info(f"UQATRDè¨ˆç®—å®Œäº† - ãƒ‡ãƒ¼ã‚¿é•·: {data_length}, "
                           f"å¹³å‡ä¿¡é ¼åº¦: {np.mean(confidence_score):.3f}")
            
            return result
            
        except Exception as e:
            error_msg = str(e)
            stack_trace = traceback.format_exc()
            self.logger.error(f"UQATRDè¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {error_msg}\n{stack_trace}")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºã®çµæœã‚’è¿”ã™
            return UQATRDResult(
                trend_range_signal=np.array([]),
                signal_strength=np.array([]),
                quantum_coherence=np.array([]),
                trend_persistence=np.array([]),
                efficiency_spectrum=np.array([]),
                uncertainty_range=np.array([]),
                adaptive_threshold=np.array([]),
                confidence_score=np.array([]),
                cycle_adaptive_factor=np.array([])
            )
    
    def get_trend_range_signal(self) -> Optional[np.ndarray]:
        """ãƒ¡ã‚¤ãƒ³ã®ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ¤å®šä¿¡å·ã‚’å–å¾—"""
        if not self._result_cache or not self._cache_keys:
            return None
        
        result = self._result_cache[self._cache_keys[-1]]
        return result.trend_range_signal.copy()
    
    def get_signal_strength(self) -> Optional[np.ndarray]:
        """ä¿¡å·å¼·åº¦ã‚’å–å¾—"""
        if not self._result_cache or not self._cache_keys:
            return None
        
        result = self._result_cache[self._cache_keys[-1]]
        return result.signal_strength.copy()
    
    def get_confidence_score(self) -> Optional[np.ndarray]:
        """ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’å–å¾—"""
        if not self._result_cache or not self._cache_keys:
            return None
        
        result = self._result_cache[self._cache_keys[-1]]
        return result.confidence_score.copy()
    
    def get_algorithm_breakdown(self) -> Optional[Dict[str, np.ndarray]]:
        """å„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®è©³ç´°çµæœã‚’å–å¾—"""
        if not self._result_cache or not self._cache_keys:
            return None
        
        result = self._result_cache[self._cache_keys[-1]]
        return {
            'quantum_coherence': result.quantum_coherence.copy(),
            'trend_persistence': result.trend_persistence.copy(),
            'efficiency_spectrum': result.efficiency_spectrum.copy(),
            'uncertainty_range': result.uncertainty_range.copy()
        }
    
    def get_adaptive_threshold(self) -> Optional[np.ndarray]:
        """
        å‹•çš„é©å¿œé–¾å€¤ã‚’å–å¾—ã™ã‚‹
        
        Returns:
            np.ndarray: å‹•çš„é©å¿œé–¾å€¤é…åˆ— (0.4 to 0.6)
        """
        if not self._result_cache or not self._cache_keys:
            return None
        
        result = self._result_cache[self._cache_keys[-1]]
        return result.adaptive_threshold.copy()
    
    def get_trend_range_classification(self) -> Optional[np.ndarray]:
        """
        å‹•çš„é–¾å€¤ã‚’ä½¿ç”¨ã—ãŸãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ†é¡ã‚’å–å¾—ã™ã‚‹
        
        Returns:
            np.ndarray: åˆ†é¡çµæœ (0=ãƒ¬ãƒ³ã‚¸, 1=ãƒˆãƒ¬ãƒ³ãƒ‰)
        """
        if not self._result_cache or not self._cache_keys:
            return None
        
        result = self._result_cache[self._cache_keys[-1]]
        
        # å‹•çš„é–¾å€¤ã‚’ä½¿ç”¨ã—ã¦åˆ†é¡
        classification = np.zeros_like(result.trend_range_signal)
        
        for i in range(len(result.trend_range_signal)):
            if result.trend_range_signal[i] >= result.adaptive_threshold[i]:
                classification[i] = 1.0  # ãƒˆãƒ¬ãƒ³ãƒ‰
            else:
                classification[i] = 0.0  # ãƒ¬ãƒ³ã‚¸
                
        return classification
    
    def get_threshold_info(self) -> Optional[Dict[str, any]]:
        """
        å‹•çš„é–¾å€¤ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã™ã‚‹
        
        Returns:
            Dict: é–¾å€¤ã®çµ±è¨ˆæƒ…å ±
        """
        if not self._result_cache or not self._cache_keys:
            return None
        
        result = self._result_cache[self._cache_keys[-1]]
        threshold = result.adaptive_threshold
        
        return {
            'mean_threshold': float(np.mean(threshold)),
            'std_threshold': float(np.std(threshold)),
            'min_threshold': float(np.min(threshold)),
            'max_threshold': float(np.max(threshold)),
            'median_threshold': float(np.median(threshold)),
            'current_threshold': float(threshold[-1]) if len(threshold) > 0 else None
        }
    
    def reset(self) -> None:
        """ã‚¤ãƒ³ãƒ‡ã‚£ã‚±ãƒ¼ã‚¿ãƒ¼ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        super().reset()
        self._result_cache = {}
        self._cache_keys = []
        if self._str_indicator is not None:
            self._str_indicator.reset() 