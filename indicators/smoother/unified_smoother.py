#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ¯ **Unified Smoother - çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼** ğŸ¯

ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚’çµ±åˆã—ãŸçµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼š
- è¤‡æ•°ã®ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æ‰‹æ³•ã‚’é¸æŠå¯èƒ½
- ä¸€è²«ã—ãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§åˆ©ç”¨
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½
- ãƒ—ãƒ©ã‚¤ã‚¹ã‚½ãƒ¼ã‚¹å¯¾å¿œ

ğŸŒŸ **å¯¾å¿œã‚¹ãƒ ãƒ¼ã‚µãƒ¼:**
1. **FRAMA**: Fractal Adaptive Moving Average
2. **Super Smoother**: ã‚¨ãƒ¼ãƒ©ãƒ¼ã‚ºãƒ»ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¹ãƒ ãƒ¼ã‚µãƒ¼
3. **Ultimate Smoother**: ç©¶æ¥µã‚¹ãƒ ãƒ¼ã‚µãƒ¼  
4. **Zero Lag EMA**: ã‚¼ãƒ­ãƒ©ã‚°æŒ‡æ•°ç§»å‹•å¹³å‡

ğŸ“Š **ä½¿ç”¨ä¾‹:**
```python
smoother = UnifiedSmoother(smoother_type='frama', period=21)
result = smoother.calculate(data)
```
"""

from dataclasses import dataclass
from typing import Union, Optional, Dict, Any
import numpy as np
import pandas as pd
import traceback

try:
    from ..indicator import Indicator
    from ..price_source import PriceSource
    # ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from .frama import FRAMA
    from .super_smoother import SuperSmoother
    from .ultimate_smoother import UltimateSmoother
    from .zero_lag_ema import ZeroLagEMA
    from .laguerre_filter import LaguerreFilter
    from .alma import ALMA
    from .hma import HMA
    # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from ..kalman.unified_kalman import UnifiedKalman
    
    # Ultimate MA ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    try:
        from .ultimate_ma import UltimateMA
    except ImportError:
        UltimateMA = None
        print("Warning: Ultimate MA ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        
except ImportError:
    # Fallback for direct execution
    import sys
    import os
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    sys.path.insert(0, project_root)
    
    from indicators.indicator import Indicator
    from indicators.price_source import PriceSource
    # ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from indicators.smoother.frama import FRAMA
    from indicators.smoother.super_smoother import SuperSmoother
    from indicators.smoother.ultimate_smoother import UltimateSmoother
    from indicators.smoother.zero_lag_ema import ZeroLagEMA
    from indicators.smoother.laguerre_filter import LaguerreFilter
    from indicators.smoother.alma import ALMA
    from indicators.smoother.hma import HMA
    # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from indicators.kalman.unified_kalman import UnifiedKalman
    
    # Ultimate MA ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    try:
        from indicators.smoother.ultimate_ma import UltimateMA
    except ImportError:
        UltimateMA = None
        print("Warning: Ultimate MA ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")


@dataclass
class UnifiedSmootherResult:
    """çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®è¨ˆç®—çµæœ"""
    values: np.ndarray           # ã‚¹ãƒ ãƒ¼ã‚¹ã•ã‚ŒãŸå€¤
    raw_values: np.ndarray       # å…ƒã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
    kalman_filtered_values: Optional[np.ndarray]  # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®å€¤ï¼ˆä½¿ç”¨æ™‚ã®ã¿ï¼‰
    smoother_type: str           # ä½¿ç”¨ã•ã‚ŒãŸã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¿ã‚¤ãƒ—
    kalman_type: Optional[str]   # ä½¿ç”¨ã•ã‚ŒãŸã‚«ãƒ«ãƒãƒ³ã‚¿ã‚¤ãƒ—ï¼ˆä½¿ç”¨æ™‚ã®ã¿ï¼‰
    parameters: Dict[str, Any]   # ä½¿ç”¨ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    kalman_parameters: Dict[str, Any]  # ã‚«ãƒ«ãƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä½¿ç”¨æ™‚ã®ã¿ï¼‰
    additional_data: Dict[str, np.ndarray]  # ã‚¹ãƒ ãƒ¼ã‚µãƒ¼å›ºæœ‰ã®è¿½åŠ ãƒ‡ãƒ¼ã‚¿


class UnifiedSmoother(Indicator):
    """
    çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼
    
    ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚’çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§åˆ©ç”¨ï¼š
    - è¤‡æ•°ã®ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æ‰‹æ³•ã‚’é¸æŠå¯èƒ½
    - ä¸€è²«ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    - ãƒ—ãƒ©ã‚¤ã‚¹ã‚½ãƒ¼ã‚¹å¯¾å¿œ
    - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
    """
    
    # åˆ©ç”¨å¯èƒ½ãªã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã®å®šç¾©
    _SMOOTHERS = {
        'frama': FRAMA,
        'super_smoother': SuperSmoother,
        'ultimate_smoother': UltimateSmoother,
        'zero_lag_ema': ZeroLagEMA,
        'zlema': ZeroLagEMA,  # ã‚¨ã‚¤ãƒªã‚¢ã‚¹
        'laguerre_filter': LaguerreFilter,
        'laguerre': LaguerreFilter,  # ã‚¨ã‚¤ãƒªã‚¢ã‚¹
        'alma': ALMA,
        'hma': HMA,
    }
    
    # æ¡ä»¶ä»˜ãã§ Ultimate MA ã‚’è¿½åŠ 
    if UltimateMA is not None:
        _SMOOTHERS['ultimate_ma'] = UltimateMA
    
    # ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®èª¬æ˜
    _SMOOTHER_DESCRIPTIONS = {
        'frama': 'FRAMAï¼ˆãƒ•ãƒ©ã‚¯ã‚¿ãƒ«é©å¿œç§»å‹•å¹³å‡ï¼‰',
        'super_smoother': 'ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ï¼ˆã‚¨ãƒ¼ãƒ©ãƒ¼ã‚º2æ¥µãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼‰',
        'ultimate_smoother': 'ç©¶æ¥µã‚¹ãƒ ãƒ¼ã‚µãƒ¼ï¼ˆé«˜åº¦é©å¿œãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼‰',
        'zero_lag_ema': 'ã‚¼ãƒ­ãƒ©ã‚°EMAï¼ˆé…å»¶é™¤å»æŒ‡æ•°ç§»å‹•å¹³å‡ï¼‰',
        'zlema': 'ã‚¼ãƒ­ãƒ©ã‚°EMAï¼ˆé…å»¶é™¤å»æŒ‡æ•°ç§»å‹•å¹³å‡ï¼‰',
        'laguerre_filter': 'ãƒ©ã‚²ãƒ¼ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆæ™‚é–“è»¸æ­ªã¿ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ï¼‰',
        'laguerre': 'ãƒ©ã‚²ãƒ¼ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆæ™‚é–“è»¸æ­ªã¿ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ï¼‰',
        'alma': 'ALMAï¼ˆArnaud Legouxç§»å‹•å¹³å‡ï¼‰',
        'hma': 'HMAï¼ˆHullç§»å‹•å¹³å‡ï¼‰',
    }
    
    # æ¡ä»¶ä»˜ãã§ Ultimate MA ã®èª¬æ˜ã‚’è¿½åŠ 
    if UltimateMA is not None:
        _SMOOTHER_DESCRIPTIONS['ultimate_ma'] = 'Ultimate MAï¼ˆ6æ®µéšé©æ–°çš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ï¼‰'
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    _DEFAULT_PARAMS = {
        'frama': {'period': 10, 'fc': 1, 'sc': 198},
        'super_smoother': {'length': 5, 'num_poles': 2},
        'ultimate_smoother': {'period': 20.0, 'src_type': 'close'},
        'zero_lag_ema': {'period': 21, 'fast_mode': False},
        'zlema': {'period': 21, 'fast_mode': False},
        'laguerre_filter': {'gamma': 0.5, 'order': 4, 'period': 4},
        'laguerre': {'gamma': 0.8, 'order': 4, 'period': 4},
        'alma': {'length': 9, 'offset': 0.85, 'sigma': 6.0},
        'hma': {'length': 14},
    }
    
    # æ¡ä»¶ä»˜ãã§ Ultimate MA ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    if UltimateMA is not None:
        _DEFAULT_PARAMS['ultimate_ma'] = {
            'ultimate_smoother_period': 5.0,
            'zero_lag_period': 21,
            'realtime_window': 89,
            'src_type': 'hlc3',
            'slope_index': 1,
            'range_threshold': 0.005,
            'use_adaptive_kalman': True,
            'zero_lag_period_mode': 'fixed',
            'realtime_window_mode': 'fixed'
        }
    
    def __init__(
        self,
        smoother_type: str = 'frama',
        src_type: str = 'close',
        period_mode: str = 'fixed',
        enable_kalman: bool = False,
        kalman_type: str = 'simple',
        **kwargs
    ):
        """
        ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
        
        Args:
            smoother_type: ä½¿ç”¨ã™ã‚‹ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¿ã‚¤ãƒ—
            src_type: ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ ('close', 'hlc3', 'hl2', 'ohlc4', etc.)
            period_mode: æœŸé–“ãƒ¢ãƒ¼ãƒ‰ ('fixed' ã¾ãŸã¯ 'dynamic', ultimate_smootherã®ã¿å¯¾å¿œ)
            enable_kalman: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹
            kalman_type: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¿ã‚¤ãƒ— ('simple', 'adaptive', 'quantum_adaptive', etc.)
            **kwargs: ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ãƒ»ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å›ºæœ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        """
        # ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¿ã‚¤ãƒ—ã®æ­£è¦åŒ–
        smoother_type = smoother_type.lower()
        
        # ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¿ã‚¤ãƒ—ã®æ¤œè¨¼
        if smoother_type not in self._SMOOTHERS:
            raise ValueError(
                f"ç„¡åŠ¹ãªã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¿ã‚¤ãƒ—: {smoother_type}ã€‚"
                f"æœ‰åŠ¹ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³: {', '.join(self._SMOOTHERS.keys())}"
            )
        
        # ã‚¤ãƒ³ãƒ‡ã‚£ã‚±ãƒ¼ã‚¿ãƒ¼åã®è¨­å®š
        kalman_suffix = f"+{kalman_type}" if enable_kalman else ""
        indicator_name = f"UnifiedSmoother({smoother_type}{kalman_suffix}, src={src_type})"
        super().__init__(indicator_name)
        
        self.smoother_type = smoother_type
        self.src_type = src_type.lower()
        self.period_mode = period_mode.lower()
        self.enable_kalman = enable_kalman
        self.kalman_type = kalman_type.lower() if enable_kalman else None
        
        # ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã®æ¤œè¨¼
        valid_sources = ['close', 'hlc3', 'hl2', 'ohlc4', 'high', 'low', 'open']
        if self.src_type not in valid_sources:
            raise ValueError(f"ç„¡åŠ¹ãªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—: {src_type}")
        
        # æœŸé–“ãƒ¢ãƒ¼ãƒ‰ã®æ¤œè¨¼
        if self.period_mode not in ['fixed', 'dynamic']:
            raise ValueError(f"ç„¡åŠ¹ãªæœŸé–“ãƒ¢ãƒ¼ãƒ‰: {period_mode}")
        
        # å‹•çš„æœŸé–“å¯¾å¿œã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®ãƒã‚§ãƒƒã‚¯
        dynamic_supported_smoothers = ['ultimate_smoother', 'frama', 'super_smoother', 'zero_lag_ema', 'zlema', 'laguerre_filter', 'laguerre', 'alma', 'hma']
        if self.period_mode == 'dynamic' and smoother_type not in dynamic_supported_smoothers:
            self.logger.warning(
                f"{smoother_type}ã¯å‹•çš„æœŸé–“ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚å›ºå®šæœŸé–“ãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›´ã—ã¾ã™ã€‚"
            )
            self.period_mode = 'fixed'
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆ†é›¢
        smoother_params = {}
        kalman_params = {}
        
        for key, value in kwargs.items():
            if key.startswith('kalman_'):
                kalman_params[key[7:]] = value  # 'kalman_' ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»
            else:
                smoother_params[key] = value
        
        # ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
        self.parameters = self._DEFAULT_PARAMS[smoother_type].copy()
        self.parameters.update(smoother_params)
        
        # ã‚«ãƒ«ãƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
        self.kalman_parameters = kalman_params
        
        # å‹•çš„æœŸé–“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¿½åŠ ï¼ˆultimate_smootherã®ã¿ï¼‰
        if self.period_mode == 'dynamic' and smoother_type == 'ultimate_smoother':
            self.parameters['period_mode'] = 'dynamic'
        
        # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ä½œæˆï¼ˆå¿…è¦æ™‚ï¼‰
        self.kalman_filter = None
        if self.enable_kalman:
            self.kalman_filter = self._create_kalman_instance()
        
        # ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ä½œæˆ
        self.smoother = self._create_smoother_instance()
        
        # çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._result_cache = {}
        self._max_cache_size = 10
        self._cache_keys = []
    
    def _create_kalman_instance(self):
        """ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ"""
        try:
            return UnifiedKalman(
                filter_type=self.kalman_type,
                src_type=self.src_type,
                **self.kalman_parameters
            )
        except Exception as e:
            self.logger.error(f"ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼ ({self.kalman_type}): {e}")
            raise
    
    def _create_smoother_instance(self):
        """ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ"""
        smoother_class = self._SMOOTHERS[self.smoother_type]
        
        try:
            # å„ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã«å¿œã˜ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´
            if self.smoother_type == 'frama':
                if self.period_mode == 'dynamic':
                    return smoother_class(
                        period=self.parameters.get('period', 16),
                        fc=self.parameters.get('fc', 1),
                        sc=self.parameters.get('sc', 300),
                        src_type=self.src_type,
                        period_mode='dynamic',
                        cycle_detector_type=self.parameters.get('cycle_detector_type', 'hody_e'),
                        cycle_part=self.parameters.get('cycle_part', 0.5),
                        max_cycle=self.parameters.get('max_cycle', 124),
                        min_cycle=self.parameters.get('min_cycle', 13),
                        max_output=self.parameters.get('max_output', 124),
                        min_output=self.parameters.get('min_output', 13),
                        lp_period=self.parameters.get('lp_period', 13),
                        hp_period=self.parameters.get('hp_period', 124)
                    )
                else:
                    return smoother_class(
                        period=self.parameters.get('period', 16),
                        fc=self.parameters.get('fc', 1),
                        sc=self.parameters.get('sc', 300),
                        src_type=self.src_type
                    )
            
            elif self.smoother_type == 'super_smoother':
                if self.period_mode == 'dynamic':
                    return smoother_class(
                        length=self.parameters.get('length', 14),
                        num_poles=self.parameters.get('num_poles', 2),
                        src_type=self.src_type,
                        period_mode='dynamic',
                        cycle_detector_type=self.parameters.get('cycle_detector_type', 'hody_e'),
                        cycle_part=self.parameters.get('cycle_part', 0.5),
                        max_cycle=self.parameters.get('max_cycle', 124),
                        min_cycle=self.parameters.get('min_cycle', 13),
                        max_output=self.parameters.get('max_output', 124),
                        min_output=self.parameters.get('min_output', 13),
                        lp_period=self.parameters.get('lp_period', 13),
                        hp_period=self.parameters.get('hp_period', 124)
                    )
                else:
                    return smoother_class(
                        length=self.parameters.get('length', 14),
                        num_poles=self.parameters.get('num_poles', 2),
                        src_type=self.src_type
                    )
            
            elif self.smoother_type == 'ultimate_smoother':
                # UltimateSmootherã¯å‹•çš„æœŸé–“ã«å¯¾å¿œ
                if self.period_mode == 'dynamic':
                    return smoother_class(
                        period=self.parameters.get('period', 20.0),
                        src_type=self.src_type,
                        period_mode='dynamic',
                        cycle_detector_type=self.parameters.get('cycle_detector_type', 'absolute_ultimate'),
                        cycle_detector_cycle_part=self.parameters.get('cycle_part', 0.5),
                        cycle_detector_max_cycle=self.parameters.get('max_cycle', 120),
                        cycle_detector_min_cycle=self.parameters.get('min_cycle', 5),
                        cycle_period_multiplier=self.parameters.get('cycle_period_multiplier', 1.0),
                        cycle_detector_period_range=(
                            self.parameters.get('min_output', 5), 
                            self.parameters.get('max_output', 120)
                        )
                    )
                else:
                    return smoother_class(
                        period=self.parameters.get('period', 20.0),
                        src_type=self.src_type
                    )
            
            elif self.smoother_type in ['zero_lag_ema', 'zlema']:
                if self.period_mode == 'dynamic':
                    return ZeroLagEMA(
                        period=self.parameters.get('period', 21),
                        src_type=self.src_type,
                        fast_mode=self.parameters.get('fast_mode', False),
                        custom_alpha=self.parameters.get('custom_alpha', None),
                        period_mode='dynamic',
                        cycle_detector_type=self.parameters.get('cycle_detector_type', 'hody_e'),
                        cycle_part=self.parameters.get('cycle_part', 0.5),
                        max_cycle=self.parameters.get('max_cycle', 124),
                        min_cycle=self.parameters.get('min_cycle', 13),
                        max_output=self.parameters.get('max_output', 124),
                        min_output=self.parameters.get('min_output', 13),
                        lp_period=self.parameters.get('lp_period', 13),
                        hp_period=self.parameters.get('hp_period', 124)
                    )
                else:
                    return ZeroLagEMA(
                        period=self.parameters.get('period', 21),
                        src_type=self.src_type,
                        fast_mode=self.parameters.get('fast_mode', False),
                        custom_alpha=self.parameters.get('custom_alpha', None)
                    )
            
            elif self.smoother_type in ['laguerre_filter', 'laguerre']:
                # ãƒ©ã‚²ãƒ¼ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                if self.period_mode == 'dynamic':
                    return LaguerreFilter(
                        gamma=self.parameters.get('gamma', 0.5),
                        order=self.parameters.get('order', 4),
                        coefficients=self.parameters.get('coefficients', None),
                        src_type=self.src_type,
                        period=self.parameters.get('period', 4),
                        period_mode='dynamic',
                        cycle_detector_type=self.parameters.get('cycle_detector_type', 'hody_e'),
                        cycle_part=self.parameters.get('cycle_part', 0.5),
                        max_cycle=self.parameters.get('max_cycle', 124),
                        min_cycle=self.parameters.get('min_cycle', 13),
                        max_output=self.parameters.get('max_output', 124),
                        min_output=self.parameters.get('min_output', 13),
                        lp_period=self.parameters.get('lp_period', 13),
                        hp_period=self.parameters.get('hp_period', 124)
                    )
                else:
                    return LaguerreFilter(
                        gamma=self.parameters.get('gamma', 0.5),
                        order=self.parameters.get('order', 4),
                        coefficients=self.parameters.get('coefficients', None),
                        src_type=self.src_type,
                        period=self.parameters.get('period', 4)
                    )
            
            elif self.smoother_type == 'alma':
                # ALMA - Arnaud Legoux Moving Average
                if self.period_mode == 'dynamic':
                    return ALMA(
                        length=self.parameters.get('length', 9),
                        offset=self.parameters.get('offset', 0.85),
                        sigma=self.parameters.get('sigma', 6.0),
                        src_type=self.src_type,
                        period_mode='dynamic',
                        cycle_detector_type=self.parameters.get('cycle_detector_type', 'hody_e'),
                        cycle_part=self.parameters.get('cycle_part', 0.5),
                        max_cycle=self.parameters.get('max_cycle', 124),
                        min_cycle=self.parameters.get('min_cycle', 13),
                        max_output=self.parameters.get('max_output', 124),
                        min_output=self.parameters.get('min_output', 13),
                        lp_period=self.parameters.get('lp_period', 13),
                        hp_period=self.parameters.get('hp_period', 124)
                    )
                else:
                    return ALMA(
                        length=self.parameters.get('length', 9),
                        offset=self.parameters.get('offset', 0.85),
                        sigma=self.parameters.get('sigma', 6.0),
                        src_type=self.src_type
                    )
            
            elif self.smoother_type == 'hma':
                # HMA - Hull Moving Average
                if self.period_mode == 'dynamic':
                    return HMA(
                        length=self.parameters.get('length', 14),
                        src_type=self.src_type,
                        period_mode='dynamic',
                        cycle_detector_type=self.parameters.get('cycle_detector_type', 'hody_e'),
                        cycle_part=self.parameters.get('cycle_part', 0.5),
                        max_cycle=self.parameters.get('max_cycle', 124),
                        min_cycle=self.parameters.get('min_cycle', 13),
                        max_output=self.parameters.get('max_output', 124),
                        min_output=self.parameters.get('min_output', 13),
                        lp_period=self.parameters.get('lp_period', 13),
                        hp_period=self.parameters.get('hp_period', 124)
                    )
                else:
                    return HMA(
                        length=self.parameters.get('length', 14),
                        src_type=self.src_type
                    )
            
            elif self.smoother_type == 'ultimate_ma':
                # Ultimate MA
                if UltimateMA is not None:
                    return UltimateMA(
                        ultimate_smoother_period=self.parameters.get('ultimate_smoother_period', 5.0),
                        zero_lag_period=self.parameters.get('zero_lag_period', 21),
                        realtime_window=self.parameters.get('realtime_window', 89),
                        src_type=self.src_type,
                        slope_index=self.parameters.get('slope_index', 1),
                        range_threshold=self.parameters.get('range_threshold', 0.005),
                        use_adaptive_kalman=self.parameters.get('use_adaptive_kalman', True),
                        zero_lag_period_mode=self.parameters.get('zero_lag_period_mode', 'fixed'),
                        realtime_window_mode=self.parameters.get('realtime_window_mode', 'fixed')
                    )
                else:
                    raise ImportError("Ultimate MA ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            
            else:
                # æ±ç”¨ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
                return smoother_class(src_type=self.src_type, **self.parameters)
                
        except Exception as e:
            self.logger.error(f"ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼ ({self.smoother_type}): {e}")
            raise
    
    def _get_data_hash(self, data: Union[pd.DataFrame, np.ndarray]) -> str:
        """ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—"""
        try:
            if isinstance(data, pd.DataFrame):
                length = len(data)
                if length > 0:
                    first_val = float(data.iloc[0].get('close', data.iloc[0, -1]))
                    last_val = float(data.iloc[-1].get('close', data.iloc[-1, -1]))
                else:
                    first_val = last_val = 0.0
            else:
                length = len(data)
                if length > 0:
                    if data.ndim > 1:
                        first_val = float(data[0, -1])
                        last_val = float(data[-1, -1])
                    else:
                        first_val = float(data[0])
                        last_val = float(data[-1])
                else:
                    first_val = last_val = 0.0
            
            params_sig = f"{self.smoother_type}_{self.src_type}_{hash(str(sorted(self.parameters.items())))}"
            data_sig = (length, first_val, last_val)
            return f"{hash(data_sig)}_{hash(params_sig)}"
            
        except Exception:
            return f"{id(data)}_{self.smoother_type}_{self.src_type}"
    
    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> UnifiedSmootherResult:
        """
        çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã‚’è¨ˆç®—
        
        å‡¦ç†ãƒ•ãƒ­ãƒ¼: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ â†’ ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ â†’ ã‚¹ãƒ ãƒ¼ã‚µãƒ¼
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            UnifiedSmootherResult: è¨ˆç®—çµæœ
        """
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            data_hash = self._get_data_hash(data)
            
            if data_hash in self._result_cache:
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ
                if data_hash in self._cache_keys:
                    self._cache_keys.remove(data_hash)
                self._cache_keys.append(data_hash)
                cached_result = self._result_cache[data_hash]
                return self._copy_result(cached_result)
            
            # ã‚¹ãƒ†ãƒƒãƒ—1: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
            src_prices = PriceSource.calculate_source(data, self.src_type)
            data_length = len(src_prices)
            
            if data_length < 2:
                return self._create_empty_result(data_length, src_prices)
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®é©ç”¨ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            kalman_filtered_values = None
            processed_data = data
            
            if self.enable_kalman and self.kalman_filter is not None:
                # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨
                kalman_result = self.kalman_filter.calculate(data)
                kalman_filtered_values = kalman_result.values
                
                # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿å€¤ã§æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ /é…åˆ—ã‚’æ§‹ç¯‰
                processed_data = self._create_filtered_data(data, kalman_filtered_values)
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®è¨ˆç®—å®Ÿè¡Œ
            smoother_result = self.smoother.calculate(processed_data)
            
            # çµæœã®æ¨™æº–åŒ–
            if hasattr(smoother_result, 'values'):
                # æ§‹é€ åŒ–ã•ã‚ŒãŸçµæœã®å ´åˆ
                smoothed_values = smoother_result.values
                additional_data = self._extract_additional_data(smoother_result)
            elif hasattr(smoother_result, '_asdict'):  # NamedTupleï¼ˆUltimate MAï¼‰
                smoothed_values = smoother_result.values
                additional_data = self._extract_additional_data(smoother_result)
            else:
                # NumPyé…åˆ—ã®å ´åˆ
                smoothed_values = smoother_result
                additional_data = {}
            
            # NumPyé…åˆ—ã¸ã®å¤‰æ›ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
            if not isinstance(smoothed_values, np.ndarray):
                smoothed_values = np.array(smoothed_values)
            
            # çµæœã®ä½œæˆ
            result = UnifiedSmootherResult(
                values=smoothed_values.copy(),
                raw_values=src_prices.copy(),
                kalman_filtered_values=kalman_filtered_values.copy() if kalman_filtered_values is not None else None,
                smoother_type=self.smoother_type,
                kalman_type=self.kalman_type,
                parameters=self.parameters.copy(),
                kalman_parameters=self.kalman_parameters.copy(),
                additional_data=additional_data
            )
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
            if len(self._result_cache) >= self._max_cache_size and self._cache_keys:
                oldest_key = self._cache_keys.pop(0)
                if oldest_key in self._result_cache:
                    del self._result_cache[oldest_key]
            
            self._result_cache[data_hash] = result
            self._cache_keys.append(data_hash)
            
            # åŸºåº•ã‚¯ãƒ©ã‚¹ç”¨ã®å€¤è¨­å®š
            self._values = smoothed_values
            return result
            
        except Exception as e:
            error_msg = str(e)
            stack_trace = traceback.format_exc()
            self.logger.error(f"çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {error_msg}\n{stack_trace}")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºã®çµæœã‚’è¿”ã™
            if isinstance(data, (pd.DataFrame, np.ndarray)) and len(data) > 0:
                src_prices = PriceSource.calculate_source(data, self.src_type)
                return self._create_empty_result(len(src_prices), src_prices)
            else:
                return self._create_empty_result(0, np.array([]))
    
    def _extract_additional_data(self, smoother_result) -> Dict[str, np.ndarray]:
        """ã‚¹ãƒ ãƒ¼ã‚µãƒ¼å›ºæœ‰ã®è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        additional_data = {}
        
        try:
            # FRAMAå›ºæœ‰ãƒ‡ãƒ¼ã‚¿
            if hasattr(smoother_result, 'fractal_dimension'):
                additional_data['fractal_dimension'] = smoother_result.fractal_dimension.copy()
            if hasattr(smoother_result, 'alpha'):
                additional_data['alpha'] = smoother_result.alpha.copy()
            
            # ZLEMAå›ºæœ‰ãƒ‡ãƒ¼ã‚¿
            if hasattr(smoother_result, 'ema_values'):
                additional_data['ema_values'] = smoother_result.ema_values.copy()
            if hasattr(smoother_result, 'lag_reduced_data'):
                additional_data['lag_reduced_data'] = smoother_result.lag_reduced_data.copy()
            
            # ALMAå›ºæœ‰ãƒ‡ãƒ¼ã‚¿
            if hasattr(smoother_result, 'weights'):
                additional_data['alma_weights'] = smoother_result.weights.copy()
            
            # HMAå›ºæœ‰ãƒ‡ãƒ¼ã‚¿
            if hasattr(smoother_result, 'wma1_values'):
                additional_data['hma_wma1'] = smoother_result.wma1_values.copy()
            if hasattr(smoother_result, 'wma2_values'):
                additional_data['hma_wma2'] = smoother_result.wma2_values.copy()
            if hasattr(smoother_result, 'diff_values'):
                additional_data['hma_diff'] = smoother_result.diff_values.copy()
            
            # Ultimate MA å›ºæœ‰ãƒ‡ãƒ¼ã‚¿
            if hasattr(smoother_result, 'raw_values'):
                additional_data['ultimate_ma_raw_values'] = smoother_result.raw_values.copy()
            if hasattr(smoother_result, 'ukf_values'):
                additional_data['ultimate_ma_ukf_values'] = smoother_result.ukf_values.copy()
            if hasattr(smoother_result, 'kalman_values'):
                additional_data['ultimate_ma_kalman_values'] = smoother_result.kalman_values.copy()
            if hasattr(smoother_result, 'kalman_gains'):
                additional_data['ultimate_ma_kalman_gains'] = smoother_result.kalman_gains.copy()
            if hasattr(smoother_result, 'kalman_innovations'):
                additional_data['ultimate_ma_kalman_innovations'] = smoother_result.kalman_innovations.copy()
            if hasattr(smoother_result, 'kalman_confidence'):
                additional_data['ultimate_ma_kalman_confidence'] = smoother_result.kalman_confidence.copy()
            if hasattr(smoother_result, 'ultimate_smooth_values'):
                additional_data['ultimate_ma_ultimate_smooth_values'] = smoother_result.ultimate_smooth_values.copy()
            if hasattr(smoother_result, 'zero_lag_values'):
                additional_data['ultimate_ma_zero_lag_values'] = smoother_result.zero_lag_values.copy()
            if hasattr(smoother_result, 'amplitude'):
                additional_data['ultimate_ma_amplitude'] = smoother_result.amplitude.copy()
            if hasattr(smoother_result, 'phase'):
                additional_data['ultimate_ma_phase'] = smoother_result.phase.copy()
            if hasattr(smoother_result, 'realtime_trends'):
                additional_data['ultimate_ma_realtime_trends'] = smoother_result.realtime_trends.copy()
            if hasattr(smoother_result, 'trend_signals'):
                additional_data['ultimate_ma_trend_signals'] = smoother_result.trend_signals.copy()
            if hasattr(smoother_result, 'current_trend'):
                additional_data['ultimate_ma_current_trend'] = smoother_result.current_trend
            if hasattr(smoother_result, 'current_trend_value'):
                additional_data['ultimate_ma_current_trend_value'] = smoother_result.current_trend_value
            
        except Exception as e:
            self.logger.warning(f"è¿½åŠ ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        
        return additional_data
    
    def _create_filtered_data(self, data: Union[pd.DataFrame, np.ndarray], kalman_filtered_values: np.ndarray) -> Union[pd.DataFrame, np.ndarray]:
        """ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰"""
        if isinstance(data, pd.DataFrame):
            # DataFrameã®å ´åˆ: ã‚½ãƒ¼ã‚¹ä¾¡æ ¼ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿å€¤ã§ç½®æ›
            filtered_data = data.copy()
            filtered_data[self.src_type] = kalman_filtered_values
            
            # è«–ç†çš„æ•´åˆæ€§ã‚’ä¿æŒï¼ˆä»–ã®OHLVä¾¡æ ¼ã‚‚æ¯”ä¾‹èª¿æ•´ï¼‰
            if self.src_type == 'close':
                for i in range(len(filtered_data)):
                    if not np.isnan(kalman_filtered_values[i]) and not np.isnan(data.iloc[i]['close']) and data.iloc[i]['close'] != 0:
                        ratio = kalman_filtered_values[i] / data.iloc[i]['close']
                        for col in ['open', 'high', 'low']:
                            if col in filtered_data.columns:
                                filtered_data.iloc[i, filtered_data.columns.get_loc(col)] *= ratio
            
            return filtered_data
        else:
            # NumPyé…åˆ—ã®å ´åˆ
            filtered_data = data.copy()
            if filtered_data.ndim > 1 and filtered_data.shape[1] >= 4:
                # OHLCVå½¢å¼ã®å ´åˆã€é©åˆ‡ãªåˆ—ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿å€¤ã‚’è¨­å®š
                if self.src_type == 'close':
                    filtered_data[:, 3] = kalman_filtered_values  # closeåˆ—
                elif self.src_type == 'open':
                    filtered_data[:, 0] = kalman_filtered_values  # openåˆ—
                elif self.src_type == 'high':
                    filtered_data[:, 1] = kalman_filtered_values  # highåˆ—
                elif self.src_type == 'low':
                    filtered_data[:, 2] = kalman_filtered_values  # lowåˆ—
                else:
                    # hlc3, hl2, ohlc4ãªã©ã®è¤‡åˆä¾¡æ ¼ã®å ´åˆã¯å…¨ä½“ã‚’èª¿æ•´
                    filtered_data[:, 3] = kalman_filtered_values  # closeåˆ—ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä½¿ç”¨
            else:
                # 1æ¬¡å…ƒé…åˆ—ã®å ´åˆã¯ãã®ã¾ã¾ç½®æ›
                filtered_data = kalman_filtered_values
            
            return filtered_data
    
    def _copy_result(self, result: UnifiedSmootherResult) -> UnifiedSmootherResult:
        """çµæœã‚’ã‚³ãƒ”ãƒ¼"""
        return UnifiedSmootherResult(
            values=result.values.copy(),
            raw_values=result.raw_values.copy(),
            kalman_filtered_values=result.kalman_filtered_values.copy() if result.kalman_filtered_values is not None else None,
            smoother_type=result.smoother_type,
            kalman_type=result.kalman_type,
            parameters=result.parameters.copy(),
            kalman_parameters=result.kalman_parameters.copy(),
            additional_data={k: v.copy() if isinstance(v, np.ndarray) else v for k, v in result.additional_data.items()}
        )
    
    def _create_empty_result(self, length: int, raw_prices: np.ndarray) -> UnifiedSmootherResult:
        """ç©ºã®çµæœã‚’ä½œæˆ"""
        return UnifiedSmootherResult(
            values=np.full(length, np.nan),
            raw_values=raw_prices,
            kalman_filtered_values=None,
            smoother_type=self.smoother_type,
            kalman_type=self.kalman_type,
            parameters=self.parameters.copy(),
            kalman_parameters=self.kalman_parameters.copy(),
            additional_data={}
        )
    
    def get_values(self) -> Optional[np.ndarray]:
        """ã‚¹ãƒ ãƒ¼ã‚¹ã•ã‚ŒãŸå€¤ã‚’å–å¾—"""
        if not self._result_cache:
            return None
        
        result = self._get_latest_result()
        return result.values.copy() if result else None
    
    def get_raw_values(self) -> Optional[np.ndarray]:
        """å…ƒã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.raw_values.copy() if result else None
    
    def get_additional_data(self, key: str) -> Optional[np.ndarray]:
        """ã‚¹ãƒ ãƒ¼ã‚µãƒ¼å›ºæœ‰ã®è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        result = self._get_latest_result()
        if result and key in result.additional_data:
            return result.additional_data[key].copy()
        return None
    
    def get_smoother_info(self) -> Dict[str, Any]:
        """ã‚¹ãƒ ãƒ¼ã‚µãƒ¼æƒ…å ±ã‚’å–å¾—"""
        return {
            'type': self.smoother_type,
            'description': self._SMOOTHER_DESCRIPTIONS.get(self.smoother_type, 'Unknown'),
            'src_type': self.src_type,
            'parameters': self.parameters.copy()
        }
    
    def _get_latest_result(self) -> Optional[UnifiedSmootherResult]:
        """æœ€æ–°ã®çµæœã‚’å–å¾—"""
        if not self._result_cache:
            return None
        
        if self._cache_keys:
            return self._result_cache[self._cache_keys[-1]]
        else:
            return next(iter(self._result_cache.values()))
    
    def reset(self) -> None:
        """çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        super().reset()
        if hasattr(self.smoother, 'reset'):
            self.smoother.reset()
        self._result_cache = {}
        self._cache_keys = []
    
    @classmethod
    def get_available_smoothers(cls) -> Dict[str, str]:
        """
        åˆ©ç”¨å¯èƒ½ãªã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã¨ãã®èª¬æ˜ã‚’è¿”ã™
        
        Returns:
            Dict[str, str]: ã‚¹ãƒ ãƒ¼ã‚µãƒ¼åã¨ãã®èª¬æ˜ã®è¾æ›¸
        """
        return cls._SMOOTHER_DESCRIPTIONS.copy()
    
    @classmethod
    def get_default_parameters(cls, smoother_type: str) -> Dict[str, Any]:
        """
        æŒ‡å®šã•ã‚ŒãŸã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
        
        Args:
            smoother_type: ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¿ã‚¤ãƒ—
            
        Returns:
            Dict[str, Any]: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        """
        smoother_type = smoother_type.lower()
        return cls._DEFAULT_PARAMS.get(smoother_type, {}).copy()


# ä¾¿åˆ©é–¢æ•°
def smooth(
    data: Union[pd.DataFrame, np.ndarray], 
    smoother_type: str = 'frama',
    src_type: str = 'close',
    **kwargs
) -> np.ndarray:
    """
    çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®è¨ˆç®—ï¼ˆä¾¿åˆ©é–¢æ•°ï¼‰
    
    Args:
        data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        smoother_type: ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¿ã‚¤ãƒ—
        src_type: ä¾¡æ ¼ã‚½ãƒ¼ã‚¹
        **kwargs: ã‚¹ãƒ ãƒ¼ã‚µãƒ¼å›ºæœ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        
    Returns:
        ã‚¹ãƒ ãƒ¼ã‚¹ã•ã‚ŒãŸå€¤
    """
    smoother = UnifiedSmoother(smoother_type=smoother_type, src_type=src_type, **kwargs)
    result = smoother.calculate(data)
    return result.values


def compare_smoothers(
    data: Union[pd.DataFrame, np.ndarray],
    smoother_types: list = ['frama', 'super_smoother', 'zero_lag_ema'],
    src_type: str = 'close',
    **kwargs
) -> Dict[str, np.ndarray]:
    """
    è¤‡æ•°ã®ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚’æ¯”è¼ƒ
    
    Args:
        data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        smoother_types: æ¯”è¼ƒã™ã‚‹ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¿ã‚¤ãƒ—ã®ãƒªã‚¹ãƒˆ
        src_type: ä¾¡æ ¼ã‚½ãƒ¼ã‚¹
        **kwargs: ã‚¹ãƒ ãƒ¼ã‚µãƒ¼å›ºæœ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        
    Returns:
        Dict[str, np.ndarray]: ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¿ã‚¤ãƒ—åˆ¥ã®çµæœ
    """
    results = {}
    
    for smoother_type in smoother_types:
        try:
            smoother = UnifiedSmoother(smoother_type=smoother_type, src_type=src_type, **kwargs)
            result = smoother.calculate(data)
            results[smoother_type] = result.values
        except Exception as e:
            print(f"Error with {smoother_type}: {e}")
            results[smoother_type] = np.full(len(data), np.nan)
    
    return results


if __name__ == "__main__":
    """ç›´æ¥å®Ÿè¡Œæ™‚ã®ãƒ†ã‚¹ãƒˆ"""
    import numpy as np
    import pandas as pd
    from datetime import datetime, timedelta
    
    print("=== çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®ãƒ†ã‚¹ãƒˆ ===")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    np.random.seed(42)
    length = 100
    base_price = 100.0
    trend = 0.001
    volatility = 0.02
    
    prices = [base_price]
    for i in range(1, length):
        change = trend + np.random.normal(0, volatility)
        new_price = prices[-1] * (1 + change)
        prices.append(new_price)
    
    # OHLC ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
    data = []
    for i, close in enumerate(prices):
        daily_range = abs(np.random.normal(0, volatility * close * 0.5))
        
        high = close + daily_range * np.random.uniform(0.3, 1.0)
        low = close - daily_range * np.random.uniform(0.3, 1.0)
        
        if i == 0:
            open_price = close
        else:
            gap = np.random.normal(0, volatility * close * 0.2)
            open_price = prices[i-1] + gap
        
        # è«–ç†çš„æ•´åˆæ€§ã®ç¢ºä¿
        high = max(high, open_price, close)
        low = min(low, open_price, close)
        
        data.append({
            'open': open_price,
            'high': high,
            'low': low,
            'close': close,
            'volume': np.random.uniform(1000, 10000)
        })
    
    df = pd.DataFrame(data)
    start_date = datetime.now() - timedelta(days=length)
    df.index = [start_date + timedelta(hours=i) for i in range(length)]
    
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(df)}ãƒã‚¤ãƒ³ãƒˆ")
    print(f"ä¾¡æ ¼ç¯„å›²: {df['close'].min():.2f} - {df['close'].max():.2f}")
    
    # åˆ©ç”¨å¯èƒ½ãªã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚’è¡¨ç¤º
    smoothers = UnifiedSmoother.get_available_smoothers()
    print(f"\nåˆ©ç”¨å¯èƒ½ãªã‚¹ãƒ ãƒ¼ã‚µãƒ¼: {len(smoothers)}ç¨®é¡")
    for name, desc in list(smoothers.items())[:5]:  # æœ€åˆã®5å€‹ã®ã¿è¡¨ç¤º
        print(f"  {name}: {desc}")
    
    # å„ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚’ãƒ†ã‚¹ãƒˆ
    test_smoothers = ['frama', 'zero_lag_ema', 'super_smoother']
    print(f"\nãƒ†ã‚¹ãƒˆå¯¾è±¡: {test_smoothers}")
    
    for smoother_type in test_smoothers:
        try:
            print(f"\n{smoother_type} ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
            smoother = UnifiedSmoother(smoother_type=smoother_type, src_type='close')
            result = smoother.calculate(df)
            
            mean_smoothed = np.nanmean(result.values)
            mean_raw = np.nanmean(result.raw_values)
            valid_count = np.sum(~np.isnan(result.values))
            
            print(f"  å¹³å‡å€¤: {mean_smoothed:.4f} (å…ƒ: {mean_raw:.4f})")
            print(f"  æœ‰åŠ¹å€¤æ•°: {valid_count}/{len(df)}")
            print(f"  è¿½åŠ ãƒ‡ãƒ¼ã‚¿: {list(result.additional_data.keys()) if result.additional_data else 'ãªã—'}")
            
        except Exception as e:
            print(f"  ã‚¨ãƒ©ãƒ¼: {e}")
    
    print("\n=== ãƒ†ã‚¹ãƒˆå®Œäº† ===")