#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ultimate Chop Trend V3 - ä½é…å»¶ãƒ»é«˜ç²¾åº¦ãƒ»ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ

å³é¸ã•ã‚ŒãŸ5ã¤ã®æœ€å¼·ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚‹è¶…é«˜é€Ÿãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸åˆ¤å®šï¼š
ğŸ§  Hilbert Transform - ç¬æ™‚ä½ç›¸ãƒ»å‘¨æ³¢æ•°è§£æï¼ˆæœ€é‡è¦ãƒ»ä½é…å»¶ï¼‰
ğŸ“Š Incremental Regression - è¶…ä½é…å»¶çµ±è¨ˆçš„ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡º
âš¡ Multi-timeframe Consensus - EMAãƒ™ãƒ¼ã‚¹é«˜é€Ÿã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹
ğŸŒŠ Streaming Volatility - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ 
ğŸ¯ Zero-lag EMA - è¶…ä½é…å»¶ç§»å‹•å¹³å‡

V2ã®è¤‡é›‘ã•ã‚’æ’é™¤ã—ã€å®Ÿè¨¼æ¸ˆã¿ã®åŠ¹æœçš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ã¿ã‚’çµ±åˆ
"""

from dataclasses import dataclass
from typing import Union, Tuple, Dict, Any, Optional, NamedTuple, List
import numpy as np
import pandas as pd
from numba import jit, njit, prange
import traceback
import math
import warnings
warnings.filterwarnings("ignore")

# Base classes
try:
    from .indicator import Indicator
except ImportError:
    class Indicator:
        def __init__(self, name): self.name = name; self.logger = self._get_logger()
        def reset(self): pass
        def _get_logger(self): import logging; return logging.getLogger(self.__class__.__name__)


class UltimateChopTrendV3Result(NamedTuple):
    """Ultimate ChopTrend V3è¨ˆç®—çµæœ - ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ"""
    # ã‚³ã‚¢æŒ‡æ¨™
    trend_index: np.ndarray              # çµ±åˆãƒˆãƒ¬ãƒ³ãƒ‰æŒ‡æ•°ï¼ˆ0-1ï¼‰
    trend_direction: np.ndarray          # 1=ã‚¢ãƒƒãƒ—ãƒˆãƒ¬ãƒ³ãƒ‰, 0=ãƒ¬ãƒ³ã‚¸, -1=ãƒ€ã‚¦ãƒ³ãƒˆãƒ¬ãƒ³ãƒ‰
    trend_strength: np.ndarray           # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ï¼ˆ0-1ï¼‰
    confidence_score: np.ndarray         # äºˆæ¸¬ä¿¡é ¼åº¦ï¼ˆ0-1ï¼‰
    
    # æˆåˆ†æŒ‡æ¨™
    hilbert_component: np.ndarray        # ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›æˆåˆ†
    regression_component: np.ndarray     # å›å¸°çµ±è¨ˆæˆåˆ†
    consensus_component: np.ndarray      # ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ æˆåˆ†
    volatility_component: np.ndarray     # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æˆåˆ†
    zerollag_component: np.ndarray       # ã‚¼ãƒ­ãƒ©ã‚°EMAæˆåˆ†
    
    # ç¾åœ¨çŠ¶æ…‹
    current_trend: str
    current_strength: float
    current_confidence: float


@njit(fastmath=True, cache=True)
def hilbert_instantaneous_analysis_v3(prices: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """
    ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ã«ã‚ˆã‚‹ç¬æ™‚è§£æï¼ˆV3æœ€é©åŒ–ç‰ˆï¼‰
    
    Returns:
        (trend_signal, confidence)
    """
    n = len(prices)
    if n < 16:
        return np.full(n, 0.5), np.full(n, 0.5)
    
    trend_signal = np.full(n, 0.5)
    confidence = np.full(n, 0.5)
    
    for i in range(8, n):
        # 4ç‚¹ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ï¼ˆæœ€é©åŒ–ï¼‰
        real_part = (prices[i] + prices[i-2] + prices[i-4] + prices[i-6]) * 0.25
        imag_part = (prices[i-1] + prices[i-3] + prices[i-5] + prices[i-7]) * 0.25
        
        # ç¬æ™‚æŒ¯å¹…
        amplitude = math.sqrt(real_part * real_part + imag_part * imag_part)
        
        # ç¬æ™‚ä½ç›¸
        if real_part != 0:
            phase = math.atan2(imag_part, real_part)
        else:
            phase = 0
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†ï¼ˆä½ç›¸ã®æ–¹å‘æ€§ï¼‰
        if i >= 15:
            phase_trend = 0.0
            for j in range(7):
                phase_trend += math.sin(phase - j * 0.1)
            phase_trend /= 7.0
            
            # æ­£è¦åŒ–ã—ã¦ã‚·ã‚°ãƒŠãƒ«ã«å¤‰æ›
            trend_signal[i] = math.tanh(phase_trend) * 0.5 + 0.5
            
            # ä¿¡é ¼åº¦ï¼ˆæŒ¯å¹…ãƒ™ãƒ¼ã‚¹ï¼‰
            if i > 20:
                avg_amplitude = 0.0
                for j in range(5):
                    if i-j >= 0:
                        past_real = (prices[i-j] + prices[i-j-2] + prices[i-j-4] + prices[i-j-6]) * 0.25
                        past_imag = (prices[i-j-1] + prices[i-j-3] + prices[i-j-5] + prices[i-j-7]) * 0.25
                        avg_amplitude += math.sqrt(past_real * past_real + past_imag * past_imag)
                avg_amplitude /= 5.0
                
                if avg_amplitude > 0:
                    confidence[i] = min(amplitude / avg_amplitude, 2.0) * 0.5
                else:
                    confidence[i] = 0.5
    
    return trend_signal, confidence


@njit(fastmath=True, cache=True)
def incremental_regression_v3(prices: np.ndarray, alpha: float = 0.15) -> Tuple[np.ndarray, np.ndarray]:
    """
    å¢—åˆ†å›å¸°çµ±è¨ˆï¼ˆV3æœ€é©åŒ–ç‰ˆï¼‰
    
    Returns:
        (trend_signal, confidence)
    """
    n = len(prices)
    if n < 3:
        return np.full(n, 0.5), np.full(n, 0.5)
    
    trend_signal = np.full(n, 0.5)
    confidence = np.full(n, 0.5)
    
    # å¢—åˆ†çµ±è¨ˆ
    sum_x = 0.0
    sum_y = 0.0
    sum_xy = 0.0
    sum_x2 = 0.0
    count = 0.0
    
    for i in range(n):
        x_val = float(i)
        y_val = prices[i]
        
        # æŒ‡æ•°é‡ã¿ä»˜ãæ›´æ–°
        if i > 0:
            decay = 1.0 - alpha
            sum_x = decay * sum_x + alpha * x_val
            sum_y = decay * sum_y + alpha * y_val
            sum_xy = decay * sum_xy + alpha * x_val * y_val
            sum_x2 = decay * sum_x2 + alpha * x_val * x_val
            count = decay * count + alpha
        else:
            sum_x = x_val
            sum_y = y_val
            sum_xy = x_val * y_val
            sum_x2 = x_val * x_val
            count = 1.0
        
        # å›å¸°ä¿‚æ•°è¨ˆç®—
        if i >= 2 and count > 1e-10:
            x_mean = sum_x / count
            y_mean = sum_y / count
            
            numerator = sum_xy / count - x_mean * y_mean
            denominator = sum_x2 / count - x_mean * x_mean
            
            if abs(denominator) > 1e-10:
                slope = numerator / denominator
                
                # ãƒˆãƒ¬ãƒ³ãƒ‰ã‚·ã‚°ãƒŠãƒ«
                slope_normalized = math.tanh(slope * 5) * 0.5 + 0.5
                trend_signal[i] = slope_normalized
                
                # ä¿¡é ¼åº¦ï¼ˆRÂ²è¿‘ä¼¼ï¼‰
                if i > 5:
                    recent_var = 0.0
                    for j in range(min(5, i)):
                        diff = prices[i-j] - y_mean
                        recent_var += diff * diff
                    recent_var /= min(5, i)
                    
                    if recent_var > 1e-10:
                        r_squared = (numerator * numerator) / (denominator * recent_var)
                        confidence[i] = min(r_squared, 1.0)
    
    return trend_signal, confidence


@njit(fastmath=True, cache=True)
def multi_timeframe_consensus_v3(
    prices: np.ndarray,
    fast_alpha: float = 0.3,
    medium_alpha: float = 0.15,
    slow_alpha: float = 0.05
) -> Tuple[np.ndarray, np.ndarray]:
    """
    ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹ï¼ˆV3æœ€é©åŒ–ç‰ˆï¼‰
    
    Returns:
        (consensus_signal, agreement_strength)
    """
    n = len(prices)
    if n < 2:
        return np.full(n, 0.5), np.full(n, 0.5)
    
    consensus_signal = np.full(n, 0.5)
    agreement_strength = np.full(n, 0.5)
    
    # é©å¿œEMA
    fast_ema = np.zeros(n)
    medium_ema = np.zeros(n)
    slow_ema = np.zeros(n)
    
    fast_ema[0] = prices[0]
    medium_ema[0] = prices[0]
    slow_ema[0] = prices[0]
    
    for i in range(1, n):
        # EMAæ›´æ–°
        fast_ema[i] = fast_alpha * prices[i] + (1 - fast_alpha) * fast_ema[i-1]
        medium_ema[i] = medium_alpha * prices[i] + (1 - medium_alpha) * medium_ema[i-1]
        slow_ema[i] = slow_alpha * prices[i] + (1 - slow_alpha) * slow_ema[i-1]
        
        # å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ–¹å‘
        fast_dir = 1 if fast_ema[i] > fast_ema[i-1] else -1
        medium_dir = 1 if medium_ema[i] > medium_ema[i-1] else -1
        slow_dir = 1 if slow_ema[i] > slow_ema[i-1] else -1
        
        # é‡ã¿ä»˜ãã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹
        consensus = fast_dir * 0.5 + medium_dir * 0.3 + slow_dir * 0.2
        
        # ã‚·ã‚°ãƒŠãƒ«æ­£è¦åŒ–
        if abs(consensus) > 0.6:
            consensus_signal[i] = 0.5 + consensus * 0.4  # 0.1-0.9ã®ç¯„å›²
        else:
            consensus_signal[i] = 0.5  # ãƒ¬ãƒ³ã‚¸
        
        # ä¸€è‡´åº¦è¨ˆç®—
        agreements = 0
        if fast_dir == medium_dir:
            agreements += 1
        if medium_dir == slow_dir:
            agreements += 1
        if fast_dir == slow_dir:
            agreements += 1
        
        agreement_strength[i] = agreements / 3.0
    
    return consensus_signal, agreement_strength


@njit(fastmath=True, cache=True)
def streaming_volatility_v3(prices: np.ndarray, alpha: float = 0.12) -> Tuple[np.ndarray, np.ndarray]:
    """
    ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æï¼ˆV3æœ€é©åŒ–ç‰ˆï¼‰
    
    Returns:
        (volatility_signal, regime_strength)
    """
    n = len(prices)
    if n < 2:
        return np.full(n, 0.5), np.full(n, 0.5)
    
    volatility_signal = np.full(n, 0.5)
    regime_strength = np.full(n, 0.5)
    
    # ã‚ªãƒ³ãƒ©ã‚¤ãƒ³çµ±è¨ˆ
    running_mean = prices[0]
    running_var = 1.0
    
    for i in range(1, n):
        # ä¾¡æ ¼å¤‰åŒ–
        price_change = prices[i] - prices[i-1]
        
        # ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¹³å‡ãƒ»åˆ†æ•£æ›´æ–°
        delta = price_change - running_mean
        running_mean += alpha * delta
        running_var = (1 - alpha) * running_var + alpha * delta * delta
        running_var = max(running_var, 1e-10)
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¤å®š
        if running_var > 0:
            z_score = abs(delta) / math.sqrt(running_var)
            
            # ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†é¡
            if z_score > 2.0:  # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                volatility_signal[i] = 0.8
                regime_strength[i] = min(z_score / 3.0, 1.0)
            elif z_score > 1.0:  # ä¸­ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                volatility_signal[i] = 0.6
                regime_strength[i] = z_score / 2.0
            else:  # ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                volatility_signal[i] = 0.3
                regime_strength[i] = 0.5 - z_score / 2.0
    
    return volatility_signal, regime_strength


@njit(fastmath=True, cache=True)
def zero_lag_ema_v3(prices: np.ndarray, period: int = 14) -> Tuple[np.ndarray, np.ndarray]:
    """
    Zero-lag EMAï¼ˆV3æœ€é©åŒ–ç‰ˆï¼‰
    
    Returns:
        (zerollag_signal, momentum_strength)
    """
    n = len(prices)
    if n < period:
        return np.full(n, 0.5), np.full(n, 0.5)
    
    alpha = 2.0 / (period + 1)
    
    zerollag_signal = np.full(n, 0.5)
    momentum_strength = np.full(n, 0.5)
    
    ema1 = np.zeros(n)
    ema2 = np.zeros(n)
    
    ema1[0] = prices[0]
    ema2[0] = prices[0]
    
    for i in range(1, n):
        # æ¨™æº–EMA
        ema1[i] = alpha * prices[i] + (1 - alpha) * ema1[i-1]
        # EMAã®EMA
        ema2[i] = alpha * ema1[i] + (1 - alpha) * ema2[i-1]
        
        # Zero-lagè¨ˆç®—
        zlema = 2 * ema1[i] - ema2[i]
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰ã‚·ã‚°ãƒŠãƒ«
        if i >= period:
            price_vs_zlema = (prices[i] - zlema) / max(abs(zlema), 1e-10)
            zerollag_signal[i] = math.tanh(price_vs_zlema * 3) * 0.5 + 0.5
            
            # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ å¼·åº¦
            if i > period:
                momentum = (zlema - ema1[i-period//2]) / max(abs(ema1[i-period//2]), 1e-10)
                momentum_strength[i] = min(abs(momentum) * 5, 1.0)
    
    return zerollag_signal, momentum_strength


@njit(fastmath=True, cache=True)
def ensemble_integration_v3(
    hilbert_sig: np.ndarray, hilbert_conf: np.ndarray,
    regression_sig: np.ndarray, regression_conf: np.ndarray,
    consensus_sig: np.ndarray, consensus_conf: np.ndarray,
    volatility_sig: np.ndarray, volatility_conf: np.ndarray,
    zerollag_sig: np.ndarray, zerollag_conf: np.ndarray
) -> Tuple[np.ndarray, np.ndarray]:
    """
    ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆï¼ˆV3æœ€é©åŒ–ç‰ˆï¼‰
    
    Returns:
        (integrated_signal, integrated_confidence)
    """
    n = len(hilbert_sig)
    integrated_signal = np.full(n, 0.5)
    integrated_confidence = np.full(n, 0.5)
    
    # é‡ã¿é…åˆ†ï¼ˆåŠ¹æœå®Ÿè¨¼æ¸ˆã¿ï¼‰
    weights = np.array([0.35, 0.25, 0.20, 0.12, 0.08])  # Hilbertæœ€é‡è¦
    
    for i in range(n):
        # å„ã‚·ã‚°ãƒŠãƒ«ã®å®‰å…¨ãªå–å¾—
        signals = np.array([
            min(max(hilbert_sig[i] if not np.isnan(hilbert_sig[i]) else 0.5, 0.0), 1.0),
            min(max(regression_sig[i] if not np.isnan(regression_sig[i]) else 0.5, 0.0), 1.0),
            min(max(consensus_sig[i] if not np.isnan(consensus_sig[i]) else 0.5, 0.0), 1.0),
            min(max(volatility_sig[i] if not np.isnan(volatility_sig[i]) else 0.5, 0.0), 1.0),
            min(max(zerollag_sig[i] if not np.isnan(zerollag_sig[i]) else 0.5, 0.0), 1.0)
        ])
        
        confidences = np.array([
            min(max(hilbert_conf[i] if not np.isnan(hilbert_conf[i]) else 0.5, 0.1), 1.0),
            min(max(regression_conf[i] if not np.isnan(regression_conf[i]) else 0.5, 0.1), 1.0),
            min(max(consensus_conf[i] if not np.isnan(consensus_conf[i]) else 0.5, 0.1), 1.0),
            min(max(volatility_conf[i] if not np.isnan(volatility_conf[i]) else 0.5, 0.1), 1.0),
            min(max(zerollag_conf[i] if not np.isnan(zerollag_conf[i]) else 0.5, 0.1), 1.0)
        ])
        
        # ä¿¡é ¼åº¦é‡ã¿ä»˜ãçµ±åˆ
        effective_weights = weights * confidences
        weight_sum = np.sum(effective_weights)
        
        if weight_sum > 1e-10:
            integrated_signal[i] = np.sum(signals * effective_weights) / weight_sum
            integrated_confidence[i] = np.mean(confidences)
        else:
            integrated_signal[i] = 0.5
            integrated_confidence[i] = 0.5
        
        # ç¯„å›²åˆ¶é™
        integrated_signal[i] = min(max(integrated_signal[i], 0.0), 1.0)
        integrated_confidence[i] = min(max(integrated_confidence[i], 0.0), 1.0)
    
    return integrated_signal, integrated_confidence


@njit(fastmath=True, cache=True)
def calculate_trend_classification_v3(
    trend_index: np.ndarray,
    confidence: np.ndarray,
    prices: np.ndarray,
    trend_threshold: float = 0.58,
    confidence_threshold: float = 0.3
) -> Tuple[np.ndarray, np.ndarray]:
    """
    ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†é¡ï¼ˆV3å®Ÿè·µç‰ˆï¼‰
    
    Returns:
        (trend_direction, trend_strength)
    """
    n = len(trend_index)
    trend_direction = np.zeros(n, dtype=np.int8)
    trend_strength = np.zeros(n)
    
    # å®Ÿè·µçš„ã—ãã„å€¤
    upper_threshold = trend_threshold
    lower_threshold = 1.0 - trend_threshold
    strong_upper = 0.75
    strong_lower = 0.25
    
    for i in range(n):
        signal = trend_index[i] if not np.isnan(trend_index[i]) else 0.5
        conf = confidence[i] if not np.isnan(confidence[i]) else 0.5
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦è¨ˆç®—
        trend_strength[i] = abs(signal - 0.5) * 2.0 * conf
        
        # æ–¹å‘åˆ¤å®šï¼ˆä¿¡é ¼åº¦è€ƒæ…®ï¼‰
        if conf > confidence_threshold:
            if signal > strong_upper:
                trend_direction[i] = 1  # å¼·ã„ä¸Šæ˜‡
            elif signal > upper_threshold:
                trend_direction[i] = 1  # ä¸Šæ˜‡
            elif signal < strong_lower:
                trend_direction[i] = -1  # å¼·ã„ä¸‹é™
            elif signal < lower_threshold:
                trend_direction[i] = -1  # ä¸‹é™
            else:
                trend_direction[i] = 0  # ãƒ¬ãƒ³ã‚¸
        else:
            trend_direction[i] = 0  # ä½ä¿¡é ¼åº¦ã¯ãƒ¬ãƒ³ã‚¸
    
    return trend_direction, trend_strength


class UltimateChopTrendV3(Indicator):
    """
    Ultimate Chop Trend V3 - ä½é…å»¶ãƒ»é«˜ç²¾åº¦ãƒ»ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ
    
    å³é¸ã•ã‚ŒãŸ5ã¤ã®æœ€å¼·ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼š
    ğŸ§  Hilbert Transform - ç¬æ™‚ä½ç›¸ãƒ»å‘¨æ³¢æ•°è§£æï¼ˆæœ€é‡è¦ãƒ»ä½é…å»¶ï¼‰
    ğŸ“Š Incremental Regression - è¶…ä½é…å»¶çµ±è¨ˆçš„ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡º
    âš¡ Multi-timeframe Consensus - EMAãƒ™ãƒ¼ã‚¹é«˜é€Ÿã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹
    ğŸŒŠ Streaming Volatility - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ 
    ğŸ¯ Zero-lag EMA - è¶…ä½é…å»¶ç§»å‹•å¹³å‡
    
    V2ã®è¤‡é›‘ã•ã‚’æ’é™¤ã—ã€å®Ÿè¨¼æ¸ˆã¿ã®åŠ¹æœçš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ã¿ã‚’çµ±åˆ
    """
    
    def __init__(
        self,
        # ã‚³ã‚¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        analysis_period: int = 14,  # V2ã‚ˆã‚ŠçŸ­ç¸®
        fast_period: int = 7,
        
        # ã—ãã„å€¤ï¼ˆå®Ÿè·µçš„ï¼‰
        trend_threshold: float = 0.58,  # V2ã‚ˆã‚Šæ•æ„Ÿ
        confidence_threshold: float = 0.3,  # V2ã‚ˆã‚Šä½ã„
        
        # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æœ‰åŠ¹åŒ–ï¼ˆå…¨ã¦è»½é‡ã§åŠ¹æœçš„ï¼‰
        enable_hilbert: bool = True,
        enable_regression: bool = True,
        enable_consensus: bool = True,
        enable_volatility: bool = True,
        enable_zerollag: bool = True
    ):
        """
        Ultimate ChopTrend V3 - ä½é…å»¶ãƒ»é«˜ç²¾åº¦ãƒ»ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ
        
        Args:
            analysis_period: åˆ†ææœŸé–“ï¼ˆçŸ­ç¸®ã§ä½é…å»¶åŒ–ï¼‰
            fast_period: é«˜é€ŸæœŸé–“
            trend_threshold: ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šã—ãã„å€¤ï¼ˆå®Ÿè·µçš„ï¼‰
            confidence_threshold: ä¿¡é ¼åº¦ã—ãã„å€¤ï¼ˆå®Ÿè·µçš„ï¼‰
            enable_*: å„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æœ‰åŠ¹åŒ–ãƒ•ãƒ©ã‚°
        """
        super().__init__(f"UltimateChopTrendV3(P={analysis_period})")
        
        self.analysis_period = analysis_period
        self.fast_period = fast_period
        self.trend_threshold = trend_threshold
        self.confidence_threshold = confidence_threshold
        
        # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æœ‰åŠ¹åŒ–
        self.enable_hilbert = enable_hilbert
        self.enable_regression = enable_regression
        self.enable_consensus = enable_consensus
        self.enable_volatility = enable_volatility
        self.enable_zerollag = enable_zerollag
        
        self._result: Optional[UltimateChopTrendV3Result] = None
    
    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> UltimateChopTrendV3Result:
        """
        Ultimate ChopTrend V3ã‚’è¨ˆç®—
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿æº–å‚™
            if len(data) == 0:
                return self._create_empty_result(0)
            
            if isinstance(data, pd.DataFrame):
                prices = np.asarray(data['close'].values, dtype=np.float64)
            else:
                prices = np.asarray(data[:, 3], dtype=np.float64)
            
            n = len(prices)
            
            # å„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè¡Œ
            components = {}
            confidences = {}
            
            # 1. ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›è§£æï¼ˆæœ€é‡è¦ï¼‰
            if self.enable_hilbert:
                hilbert_sig, hilbert_conf = hilbert_instantaneous_analysis_v3(prices)
                components['hilbert'] = hilbert_sig
                confidences['hilbert'] = hilbert_conf
            else:
                components['hilbert'] = np.full(n, 0.5)
                confidences['hilbert'] = np.full(n, 0.5)
            
            # 2. å¢—åˆ†å›å¸°çµ±è¨ˆ
            if self.enable_regression:
                regression_sig, regression_conf = incremental_regression_v3(prices)
                components['regression'] = regression_sig
                confidences['regression'] = regression_conf
            else:
                components['regression'] = np.full(n, 0.5)
                confidences['regression'] = np.full(n, 0.5)
            
            # 3. ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹
            if self.enable_consensus:
                consensus_sig, consensus_conf = multi_timeframe_consensus_v3(prices)
                components['consensus'] = consensus_sig
                confidences['consensus'] = consensus_conf
            else:
                components['consensus'] = np.full(n, 0.5)
                confidences['consensus'] = np.full(n, 0.5)
            
            # 4. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            if self.enable_volatility:
                volatility_sig, volatility_conf = streaming_volatility_v3(prices)
                components['volatility'] = volatility_sig
                confidences['volatility'] = volatility_conf
            else:
                components['volatility'] = np.full(n, 0.5)
                confidences['volatility'] = np.full(n, 0.5)
            
            # 5. Zero-lag EMA
            if self.enable_zerollag:
                zerollag_sig, zerollag_conf = zero_lag_ema_v3(prices, self.analysis_period)
                components['zerollag'] = zerollag_sig
                confidences['zerollag'] = zerollag_conf
            else:
                components['zerollag'] = np.full(n, 0.5)
                confidences['zerollag'] = np.full(n, 0.5)
            
            # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆ
            trend_index, confidence_score = ensemble_integration_v3(
                components['hilbert'], confidences['hilbert'],
                components['regression'], confidences['regression'],
                components['consensus'], confidences['consensus'],
                components['volatility'], confidences['volatility'],
                components['zerollag'], confidences['zerollag']
            )
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†é¡
            trend_direction, trend_strength = calculate_trend_classification_v3(
                trend_index, confidence_score, prices,
                self.trend_threshold, self.confidence_threshold
            )
            
            # ç¾åœ¨çŠ¶æ…‹ã®åˆ¤å®š
            latest_direction = trend_direction[-1] if len(trend_direction) > 0 else 0
            latest_strength = trend_strength[-1] if len(trend_strength) > 0 else 0
            latest_confidence = confidence_score[-1] if len(confidence_score) > 0 else 0
            
            if latest_direction > 0:
                if latest_strength > 0.7:
                    current_trend = "strong_uptrend"
                else:
                    current_trend = "uptrend"
            elif latest_direction < 0:
                if latest_strength > 0.7:
                    current_trend = "strong_downtrend"
                else:
                    current_trend = "downtrend"
            else:
                current_trend = "range"
            
            # çµæœä½œæˆ
            result = UltimateChopTrendV3Result(
                trend_index=trend_index,
                trend_direction=trend_direction,
                trend_strength=trend_strength,
                confidence_score=confidence_score,
                hilbert_component=components['hilbert'],
                regression_component=components['regression'],
                consensus_component=components['consensus'],
                volatility_component=components['volatility'],
                zerollag_component=components['zerollag'],
                current_trend=current_trend,
                current_strength=latest_strength,
                current_confidence=latest_confidence
            )
            
            self._result = result
            self._values = trend_index
            
            return result
            
        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            self.logger.error(f"UltimateChopTrendV3è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}\nè©³ç´°:\n{error_details}")
            return self._create_empty_result(len(data))
    
    def _create_empty_result(self, length: int) -> UltimateChopTrendV3Result:
        """ç©ºã®çµæœã‚’ä½œæˆ"""
        return UltimateChopTrendV3Result(
            trend_index=np.full(length, np.nan),
            trend_direction=np.zeros(length),
            trend_strength=np.zeros(length),
            confidence_score=np.zeros(length),
            hilbert_component=np.full(length, np.nan),
            regression_component=np.full(length, np.nan),
            consensus_component=np.full(length, np.nan),
            volatility_component=np.full(length, np.nan),
            zerollag_component=np.full(length, np.nan),
            current_trend="range",
            current_strength=0.0,
            current_confidence=0.0
        )
    
    def get_values(self) -> Optional[np.ndarray]:
        """ãƒ¡ã‚¤ãƒ³æŒ‡æ¨™å€¤ã‚’å–å¾—"""
        if self._result is not None:
            return self._result.trend_index.copy()
        return None
    
    def get_result(self) -> Optional[UltimateChopTrendV3Result]:
        """å®Œå…¨ãªçµæœã‚’å–å¾—"""
        return self._result
    
    def reset(self) -> None:
        """ãƒªã‚»ãƒƒãƒˆ"""
        super().reset()
        self._result = None 