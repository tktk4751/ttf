#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ¯ **ER-Adaptive Unscented Kalman Filter V1.0** ğŸ¯

Efficiency Ratioï¼ˆåŠ¹ç‡æ¯”ï¼‰ã‚’ä½¿ç”¨ã—ã¦å‹•çš„é©å¿œã™ã‚‹ç„¡é¦™æ–™ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼

é©æ–°çš„ãª2æ®µéšãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ï¼š
1. Stage 1: HLC3ä¾¡æ ¼ã‚’é€šå¸¸ã®UKFã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
2. Stage 2: ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ä¾¡æ ¼ã‹ã‚‰ERã‚’è¨ˆç®—
3. Stage 3: ERå€¤ã«åŸºã¥ã„ã¦UKFãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å‹•çš„èª¿æ•´ã—ã¦æœ€çµ‚ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

ğŸŒŸ **ä¸»è¦æ©Ÿèƒ½:**
- ERå€¤ã«ã‚ˆã‚‹Î±ã€Î²ã€Îºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å‹•çš„èª¿æ•´
- ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸å¸‚å ´ã§ã®æœ€é©åŒ–ã•ã‚ŒãŸå¿œç­”æ€§
- Numbaæœ€é©åŒ–ã«ã‚ˆã‚‹é«˜é€Ÿè¨ˆç®—
- åŒ…æ‹¬çš„ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- ALMAãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãçµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

ğŸ”¬ **é©å¿œãƒ­ã‚¸ãƒƒã‚¯:**
- ER > 0.618: å¼·ãƒˆãƒ¬ãƒ³ãƒ‰ â†’ é«˜æ„Ÿåº¦ã€ä½ãƒã‚¤ã‚º
- ER < 0.382: ãƒ¬ãƒ³ã‚¸ç›¸å ´ â†’ ä½æ„Ÿåº¦ã€å®‰å®šåŒ–å„ªå…ˆ
- 0.382 â‰¤ ER â‰¤ 0.618: ä¸­é–“çŠ¶æ…‹ â†’ ãƒãƒ©ãƒ³ã‚¹èª¿æ•´
"""

from typing import Union, Optional, NamedTuple, Tuple
import numpy as np
import pandas as pd
from numba import jit, njit
import warnings
warnings.filterwarnings('ignore')

try:
    from .indicator import Indicator
    from .price_source import PriceSource
    from .efficiency_ratio import EfficiencyRatio
    from .kalman_filter_unified import unscented_kalman_filter_numba
    from .ehlers_unified_dc import EhlersUnifiedDC
except ImportError:
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from indicator import Indicator
    from price_source import PriceSource
    from efficiency_ratio import EfficiencyRatio
    from kalman_filter_unified import unscented_kalman_filter_numba
    from ehlers_unified_dc import EhlersUnifiedDC


class CycleERAdaptiveUKFResult(NamedTuple):
    """Cycle-ER-Adaptive UKFçµæœ"""
    values: np.ndarray                    # æœ€çµ‚ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿å€¤
    stage1_filtered: np.ndarray          # Stage1ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿å€¤
    cycle_values: np.ndarray             # Absolute Ultimate Cycleå€¤
    er_values: np.ndarray                # Efficiency Ratioå€¤
    er_trend_signals: np.ndarray         # ERãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡å·
    adaptive_alpha: np.ndarray           # å‹•çš„Î±ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    adaptive_beta: np.ndarray            # å‹•çš„Î²ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    adaptive_kappa: np.ndarray           # å‹•çš„Îºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    uncertainty: np.ndarray              # ä¸ç¢ºå®Ÿæ€§æ¨å®š
    kalman_gains: np.ndarray             # ã‚«ãƒ«ãƒãƒ³ã‚²ã‚¤ãƒ³
    confidence_scores: np.ndarray        # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
    current_trend: str                   # ç¾åœ¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰çŠ¶æ…‹
    current_trend_value: int             # ç¾åœ¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰å€¤


@njit(fastmath=True, cache=True)
def calculate_cycle_adaptive_parameters(
    cycle_values: np.ndarray,
    er_values: np.ndarray,
    base_alpha: float = 0.001,
    base_beta: float = 2.0,
    base_kappa: float = 0.0,
    # æ„Ÿåº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç¯„å›²ï¼ˆÎ±ã¨Îºï¼‰
    alpha_min: float = 0.0001,
    alpha_max: float = 0.01,
    kappa_min: float = -1.0,
    kappa_max: float = 3.0,
    # ãƒã‚¤ã‚ºèª¿æ•´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç¯„å›²ï¼ˆÎ²ï¼‰
    beta_min: float = 1.0,
    beta_max: float = 4.0,
    # ã‚µã‚¤ã‚¯ãƒ«åŸºæº–ã®é–¾å€¤ï¼ˆå‹•çš„ã«è¨­å®šï¼‰
    cycle_threshold_ratio_high: float = 0.8,  # é•·æœŸã‚µã‚¤ã‚¯ãƒ«é–¾å€¤ï¼ˆæœ€å¤§å€¤ã®80%ï¼‰
    cycle_threshold_ratio_low: float = 0.3    # çŸ­æœŸã‚µã‚¤ã‚¯ãƒ«é–¾å€¤ï¼ˆæœ€å¤§å€¤ã®30%ï¼‰
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    ã‚µã‚¤ã‚¯ãƒ«å€¤ã¨ERå€¤ã«åŸºã¥ã„ã¦UKFãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å‹•çš„èª¿æ•´
    
    Args:
        cycle_values: Absolute Ultimate Cycleã®å€¤é…åˆ—
        er_values: Efficiency Ratioå€¤ã®é…åˆ—
        base_alpha: ãƒ™ãƒ¼ã‚¹Î±ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        base_beta: ãƒ™ãƒ¼ã‚¹Î²ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        base_kappa: ãƒ™ãƒ¼ã‚¹Îºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        alpha_min/max: Î±ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€å°/æœ€å¤§å€¤
        kappa_min/max: Îºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€å°/æœ€å¤§å€¤
        beta_min/max: Î²ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€å°/æœ€å¤§å€¤
        cycle_threshold_ratio_high/low: ã‚µã‚¤ã‚¯ãƒ«é–¾å€¤æ¯”ç‡
        
    Returns:
        Tuple[adaptive_alpha, adaptive_beta, adaptive_kappa]
    """
    n = len(cycle_values)
    adaptive_alpha = np.full(n, base_alpha)
    adaptive_beta = np.full(n, base_beta)
    adaptive_kappa = np.full(n, base_kappa)
    
    # ã‚µã‚¤ã‚¯ãƒ«å€¤ã®å‹•çš„é–¾å€¤è¨ˆç®—
    valid_cycles = cycle_values[~np.isnan(cycle_values)]
    if len(valid_cycles) > 0:
        cycle_max = np.max(valid_cycles)
        cycle_min = np.min(valid_cycles)
        cycle_range = cycle_max - cycle_min
        
        # å‹•çš„é–¾å€¤è¨­å®š
        cycle_threshold_high = cycle_min + cycle_range * cycle_threshold_ratio_high
        cycle_threshold_low = cycle_min + cycle_range * cycle_threshold_ratio_low
    else:
        cycle_threshold_high = 30.0
        cycle_threshold_low = 10.0
    
    for i in range(n):
        if np.isnan(cycle_values[i]) or np.isnan(er_values[i]):
            continue
            
        cycle = cycle_values[i]
        er = er_values[i]
        
        # === 1. ã‚µã‚¤ã‚¯ãƒ«ãƒ™ãƒ¼ã‚¹ã®åŸºæœ¬é©å¿œï¼ˆå®Œå…¨ã‚¼ãƒ­é™¤ç®—é˜²æ­¢ï¼‰ ===
        MIN_SAFE_VALUE = 1e-10
        
        if cycle >= cycle_threshold_high:
            # é•·æœŸã‚µã‚¤ã‚¯ãƒ«: ä½æ„Ÿåº¦ã€é«˜å®‰å®šæ€§
            denom = max(cycle_max - cycle_threshold_high, MIN_SAFE_VALUE)
            cycle_factor = (cycle - cycle_threshold_high) / denom
            cycle_factor = max(min(cycle_factor, 1.0), 0.0)  # 0-1ç¯„å›²ã«åˆ¶é™
            base_alpha_mult = 0.5 - cycle_factor * 0.3  # Î±ä½ä¸‹ï¼ˆæ„Ÿåº¦ä½ä¸‹ï¼‰
            base_beta_mult = 1.5 + cycle_factor * 1.0   # Î²å¢—åŠ ï¼ˆå®‰å®šæ€§å‘ä¸Šï¼‰
            base_kappa_mult = -0.5 - cycle_factor * 0.3 # Îºä½ä¸‹
            
        elif cycle <= cycle_threshold_low:
            # çŸ­æœŸã‚µã‚¤ã‚¯ãƒ«: é«˜æ„Ÿåº¦ã€è¿…é€Ÿå¿œç­”
            denom = max(cycle_threshold_low - cycle_min, MIN_SAFE_VALUE)
            cycle_factor = (cycle_threshold_low - cycle) / denom
            cycle_factor = max(min(cycle_factor, 1.0), 0.0)  # 0-1ç¯„å›²ã«åˆ¶é™
            base_alpha_mult = 1.5 + cycle_factor * 1.0  # Î±å¢—åŠ ï¼ˆæ„Ÿåº¦å‘ä¸Šï¼‰
            base_beta_mult = 0.8 - cycle_factor * 0.3   # Î²ä½ä¸‹ï¼ˆå¿œç­”æ€§å‘ä¸Šï¼‰
            base_kappa_mult = 0.5 + cycle_factor * 0.5  # Îºå¢—åŠ 
            
        else:
            # ä¸­æœŸã‚µã‚¤ã‚¯ãƒ«: ãƒãƒ©ãƒ³ã‚¹èª¿æ•´
            mid_point = (cycle_threshold_high + cycle_threshold_low) / 2.0
            half_range = max(cycle_range / 2.0, MIN_SAFE_VALUE)
            mid_factor = abs(cycle - mid_point) / half_range
            mid_factor = max(min(mid_factor, 1.0), 0.0)  # 0-1ç¯„å›²ã«åˆ¶é™
            base_alpha_mult = 1.0 + mid_factor * 0.2
            base_beta_mult = 1.0 + mid_factor * 0.1
            base_kappa_mult = 0.0 + mid_factor * 0.1
        
        # === 2. ERå€¤ã«ã‚ˆã‚‹å¾®èª¿æ•´ ===
        # ERå€¤ã‚’0-1ç¯„å›²ã«æ­£è¦åŒ–ï¼ˆæƒ³å®šç¯„å›²: 0.0-1.0ï¼‰
        er_normalized = max(0.0, min(1.0, er))
        
        if er_normalized > 0.618:
            # é«˜åŠ¹ç‡ï¼ˆå¼·ãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰: æ„Ÿåº¦å¾®å¢—ã€ãƒã‚¤ã‚ºä½æ¸›
            er_factor = (er_normalized - 0.618) / (1.0 - 0.618)
            er_alpha_mult = 1.0 + er_factor * 0.3   # Î±å¾®å¢—
            er_beta_mult = 1.0 - er_factor * 0.2    # Î²å¾®æ¸›ï¼ˆãƒã‚¤ã‚ºä½æ¸›ï¼‰
            er_kappa_mult = 1.0 + er_factor * 0.2   # Îºå¾®å¢—
            
        elif er_normalized < 0.382:
            # ä½åŠ¹ç‡ï¼ˆãƒ¬ãƒ³ã‚¸ç›¸å ´ï¼‰: æ„Ÿåº¦ä½ä¸‹ã€å®‰å®šåŒ–
            er_factor = (0.382 - er_normalized) / 0.382
            er_alpha_mult = 1.0 - er_factor * 0.4   # Î±ä½ä¸‹
            er_beta_mult = 1.0 + er_factor * 0.5    # Î²å¢—åŠ ï¼ˆå®‰å®šåŒ–ï¼‰
            er_kappa_mult = 1.0 - er_factor * 0.3   # Îºä½ä¸‹
            
        else:
            # ä¸­åŠ¹ç‡: ä¸­ç«‹
            er_alpha_mult = 1.0
            er_beta_mult = 1.0
            er_kappa_mult = 1.0
        
        # === 3. æœ€çµ‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨ˆç®— ===
        # ã‚µã‚¤ã‚¯ãƒ«é©å¿œã¨ERå¾®èª¿æ•´ã®çµ±åˆ
        final_alpha_mult = base_alpha_mult * er_alpha_mult
        final_beta_mult = base_beta_mult * er_beta_mult
        final_kappa_mult = base_kappa_mult * er_kappa_mult
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€¤ã®è¨ˆç®—ã¨å¢ƒç•Œåˆ¶é™
        target_alpha = base_alpha * final_alpha_mult
        target_beta = base_beta * final_beta_mult
        target_kappa = base_kappa + final_kappa_mult
        
        # å‹•çš„ç¯„å›²åˆ¶é™ï¼ˆã‚µã‚¤ã‚¯ãƒ«ã«å¿œã˜ã¦ç¯„å›²ã‚‚èª¿æ•´ã€å®Œå…¨ã‚¼ãƒ­é™¤ç®—é˜²æ­¢ï¼‰
        # é•·æœŸã‚µã‚¤ã‚¯ãƒ«ã»ã©ä¿å®ˆçš„ãªç¯„å›²ã€çŸ­æœŸã‚µã‚¤ã‚¯ãƒ«ã»ã©ç©æ¥µçš„ãªç¯„å›²
        safe_cycle_range = max(cycle_range, MIN_SAFE_VALUE)
        cycle_norm = (cycle - cycle_min) / safe_cycle_range
        cycle_norm = max(min(cycle_norm, 1.0), 0.0)  # 0-1ç¯„å›²ã«åˆ¶é™
        
        # Î±ã®å‹•çš„ç¯„å›²
        dynamic_alpha_min = alpha_min + (alpha_max - alpha_min) * 0.1 * (1.0 - cycle_norm)
        dynamic_alpha_max = alpha_min + (alpha_max - alpha_min) * (0.3 + 0.7 * (1.0 - cycle_norm))
        
        # Î²ã®å‹•çš„ç¯„å›²
        dynamic_beta_min = beta_min + (beta_max - beta_min) * 0.1 * cycle_norm
        dynamic_beta_max = beta_min + (beta_max - beta_min) * (0.7 + 0.3 * cycle_norm)
        
        # Îºã®å‹•çš„ç¯„å›²
        dynamic_kappa_min = kappa_min + (kappa_max - kappa_min) * 0.2 * (1.0 - cycle_norm)
        dynamic_kappa_max = kappa_min + (kappa_max - kappa_min) * (0.4 + 0.6 * (1.0 - cycle_norm))
        
        # æœ€çµ‚åˆ¶é™é©ç”¨
        adaptive_alpha[i] = max(dynamic_alpha_min, min(dynamic_alpha_max, target_alpha))
        adaptive_beta[i] = max(dynamic_beta_min, min(dynamic_beta_max, target_beta))
        adaptive_kappa[i] = max(dynamic_kappa_min, min(dynamic_kappa_max, target_kappa))
    
    return adaptive_alpha, adaptive_beta, adaptive_kappa


@njit(fastmath=True, cache=True)
def cycle_er_adaptive_unscented_kalman_numba(
    prices: np.ndarray,
    cycle_values: np.ndarray,
    er_values: np.ndarray,
    adaptive_alpha: np.ndarray,
    adaptive_beta: np.ndarray,
    adaptive_kappa: np.ndarray
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    ã‚µã‚¤ã‚¯ãƒ«å€¤ã¨ERå€¤ã«åŸºã¥ãå‹•çš„é©å¿œUKFå®Ÿè£…ï¼ˆå®Œå…¨ã‚¼ãƒ­é™¤ç®—é˜²æ­¢ç‰ˆï¼‰
    
    Args:
        prices: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        cycle_values: Absolute Ultimate Cycleã®å€¤
        er_values: Efficiency Ratioå€¤
        adaptive_alpha: å‹•çš„Î±ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        adaptive_beta: å‹•çš„Î²ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        adaptive_kappa: å‹•çš„Îºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        
    Returns:
        Tuple[filtered_prices, trend_estimate, uncertainty, kalman_gains, confidence_scores]
    """
    n = len(prices)
    if n < 10:
        return (prices.copy(), np.zeros(n), np.ones(n), np.ones(n) * 0.5, np.ones(n))
    
    # æ‹¡å¼µçŠ¶æ…‹ç©ºé–“ï¼ˆ6æ¬¡å…ƒï¼‰
    # [ä¾¡æ ¼, é€Ÿåº¦, åŠ é€Ÿåº¦, ã‚µã‚¤ã‚¯ãƒ«é©å¿œåº¦, ERé©å¿œåº¦, ä¿¡é ¼åº¦æŒ‡æ¨™]
    L = 6
    
    # åˆæœŸçŠ¶æ…‹ï¼ˆå®‰å…¨åŒ–ï¼‰
    x = np.zeros(L)
    safe_initial_price = prices[0] if np.isfinite(prices[0]) and prices[0] != 0 else 100.0
    x[0] = safe_initial_price                    # ä¾¡æ ¼
    x[1] = 0.0                                   # é€Ÿåº¦
    x[2] = 0.0                                   # åŠ é€Ÿåº¦
    x[3] = cycle_values[0] if not np.isnan(cycle_values[0]) else 20.0  # ã‚µã‚¤ã‚¯ãƒ«é©å¿œåº¦
    x[4] = 0.5                                   # ERé©å¿œåº¦
    x[5] = 1.0                                   # ä¿¡é ¼åº¦æŒ‡æ¨™
    
    # åˆæœŸå…±åˆ†æ•£è¡Œåˆ—ï¼ˆå®‰å…¨åŒ–ï¼‰
    P = np.eye(L)
    P[0, 0] = 1.0        # ä¾¡æ ¼ã®ä¸ç¢ºå®Ÿæ€§
    P[1, 1] = 0.1        # é€Ÿåº¦ã®ä¸ç¢ºå®Ÿæ€§
    P[2, 2] = 0.01       # åŠ é€Ÿåº¦ã®ä¸ç¢ºå®Ÿæ€§
    P[3, 3] = 0.5        # ã‚µã‚¤ã‚¯ãƒ«é©å¿œåº¦ã®ä¸ç¢ºå®Ÿæ€§
    P[4, 4] = 0.1        # ERé©å¿œåº¦ã®ä¸ç¢ºå®Ÿæ€§
    P[5, 5] = 0.1        # ä¿¡é ¼åº¦ã®ä¸ç¢ºå®Ÿæ€§
    
    # å‡ºåŠ›é…åˆ—
    filtered_prices = np.zeros(n)
    trend_estimates = np.zeros(n)
    uncertainty_estimates = np.zeros(n)
    kalman_gains = np.zeros(n)
    confidence_scores = np.zeros(n)
    
    # åˆæœŸå€¤è¨­å®š
    filtered_prices[0] = safe_initial_price
    trend_estimates[0] = 0.0
    uncertainty_estimates[0] = 1.0
    kalman_gains[0] = 0.5
    confidence_scores[0] = 1.0
    
    # å®‰å…¨åŒ–å®šæ•°
    MIN_SAFE_VALUE = 1e-10
    MAX_SAFE_VALUE = 1e10
    
    for t in range(1, n):
        # ç¾åœ¨ã®ä¾¡æ ¼ã®å®‰å…¨åŒ–
        current_price = prices[t] if np.isfinite(prices[t]) and prices[t] != 0 else safe_initial_price
        
        # ç¾åœ¨ã®ã‚µã‚¤ã‚¯ãƒ«å€¤ã¨ERå€¤ã‚’å–å¾—ï¼ˆå®‰å…¨åŒ–ï¼‰
        current_cycle = cycle_values[t] if not np.isnan(cycle_values[t]) and np.isfinite(cycle_values[t]) else 20.0
        current_cycle = max(min(current_cycle, 120.0), 5.0)
        
        current_er = er_values[t] if not np.isnan(er_values[t]) and np.isfinite(er_values[t]) else 0.5
        current_er = max(min(current_er, 1.0), 0.0)
        
        current_alpha = adaptive_alpha[t] if np.isfinite(adaptive_alpha[t]) else 0.001
        current_beta = adaptive_beta[t] if np.isfinite(adaptive_beta[t]) else 2.0
        current_kappa = adaptive_kappa[t] if np.isfinite(adaptive_kappa[t]) else 0.0
        
        # UKFãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨ˆç®—ï¼ˆå®Œå…¨ã‚¼ãƒ­é™¤ç®—é˜²æ­¢ï¼‰
        # Î±ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å³æ ¼ãªå®‰å…¨åŒ–
        safe_alpha = max(min(current_alpha, 0.1), MIN_SAFE_VALUE)
        safe_beta = max(min(current_beta, 10.0), 0.1)
        safe_kappa = max(min(current_kappa, 5.0), -5.0)
        
        lambda_param = safe_alpha * safe_alpha * (L + safe_kappa) - L
        
        # gammaã®è¨ˆç®—ã§è² ã®å€¤ã‚’å®Œå…¨é˜²æ­¢
        gamma_arg = L + lambda_param
        if gamma_arg <= MIN_SAFE_VALUE:
            gamma_arg = MIN_SAFE_VALUE
        gamma = np.sqrt(gamma_arg)
        gamma = min(gamma, 10.0)  # ä¸Šé™åˆ¶é™
        
        # ã‚·ã‚°ãƒãƒã‚¤ãƒ³ãƒˆé‡ã¿ï¼ˆå®Œå…¨ã‚¼ãƒ­é™¤ç®—é˜²æ­¢ï¼‰
        denom = L + lambda_param
        if abs(denom) < MIN_SAFE_VALUE:
            denom = MIN_SAFE_VALUE if denom >= 0 else -MIN_SAFE_VALUE
        
        # é‡ã¿ã®å®‰å…¨è¨ˆç®—
        Wm0 = lambda_param / denom
        Wc0 = lambda_param / denom + (1 - safe_alpha * safe_alpha + safe_beta)
        Wi = 0.5 / denom
        
        # é‡ã¿ã®ç¯„å›²åˆ¶é™
        Wm0 = max(min(Wm0, 1.0), -1.0)
        Wc0 = max(min(Wc0, 2.0), -1.0)
        Wi = max(min(Wi, 1.0), MIN_SAFE_VALUE)
        
        # é©å¿œçš„ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚¤ã‚ºï¼ˆã‚µã‚¤ã‚¯ãƒ«ã¨ERä¾å­˜ï¼‰
        base_process_noise = 0.0001
        
        # ã‚µã‚¤ã‚¯ãƒ«ä¾å­˜ãƒã‚¤ã‚ºãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ï¼ˆé•·æœŸã‚µã‚¤ã‚¯ãƒ«ã»ã©ãƒã‚¤ã‚ºå¢—ï¼‰
        cycle_norm = max(0.0, min(1.0, (current_cycle - 5.0) / (120.0 - 5.0)))
        cycle_noise_factor = 1.0 + cycle_norm * 1.5  # é•·æœŸã‚µã‚¤ã‚¯ãƒ«â†’ãƒã‚¤ã‚ºå¢—
        
        # ERä¾å­˜ãƒã‚¤ã‚ºãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ï¼ˆä½åŠ¹ç‡â†’ãƒã‚¤ã‚ºå¢—ï¼‰
        er_noise_factor = 1.0 + (1.0 - current_er) * 1.0
        
        # çµ±åˆãƒã‚¤ã‚ºãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼
        combined_noise_factor = (cycle_noise_factor + er_noise_factor) / 2.0
        
        Q = np.eye(L) * base_process_noise
        Q[0, 0] = base_process_noise * combined_noise_factor  # ä¾¡æ ¼ãƒã‚¤ã‚º
        Q[1, 1] = base_process_noise * combined_noise_factor * 0.5  # é€Ÿåº¦ãƒã‚¤ã‚º
        Q[2, 2] = base_process_noise * 0.1                   # åŠ é€Ÿåº¦ãƒã‚¤ã‚º
        Q[3, 3] = base_process_noise * 0.3                   # ã‚µã‚¤ã‚¯ãƒ«é©å¿œåº¦ãƒã‚¤ã‚º
        Q[4, 4] = base_process_noise * 0.5                   # ERé©å¿œåº¦ãƒã‚¤ã‚º
        Q[5, 5] = base_process_noise * 0.1                   # ä¿¡é ¼åº¦ãƒã‚¤ã‚º
        
        # çŠ¶æ…‹é·ç§»é–¢æ•°ï¼ˆéç·šå½¢ã€ã‚µã‚¤ã‚¯ãƒ«ãƒ»ERé©å¿œã€å®Œå…¨ã‚¼ãƒ­é™¤ç®—é˜²æ­¢ï¼‰
        def state_transition(state):
            new_state = np.zeros(L)
            dt = 1.0
            
            # çŠ¶æ…‹å€¤ã®å®‰å…¨åŒ–
            safe_state = np.zeros(L)
            for i in range(L):
                if np.isfinite(state[i]):
                    safe_state[i] = state[i]
                else:
                    safe_state[i] = x[i]  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            
            # ã‚µã‚¤ã‚¯ãƒ«é©å¿œåº¦ã¨ERé©å¿œåº¦ã«ã‚ˆã‚‹å‹•çš„èª¿æ•´ï¼ˆå®Œå…¨å®‰å…¨åŒ–ï¼‰
            safe_cycle = max(min(safe_state[3], 120.0), 5.0)
            safe_er = max(min(safe_state[4], 1.0), 0.0)
            
            # ã‚¼ãƒ­é™¤ç®—é˜²æ­¢ã®ãŸã‚ã®åˆ†æ¯å®‰å…¨åŒ–
            safe_cycle_denom = max(safe_cycle, MIN_SAFE_VALUE)
            cycle_factor = safe_cycle / 120.0  # ã‚µã‚¤ã‚¯ãƒ«æ­£è¦åŒ–ï¼ˆ0-1ï¼‰
            er_factor = safe_er
            
            # ä¾¡æ ¼æ›´æ–°ï¼ˆã‚µã‚¤ã‚¯ãƒ«ãƒ»ERä¾å­˜ã®å‹•åŠ›å­¦ï¼‰
            # é•·æœŸã‚µã‚¤ã‚¯ãƒ«â†’æ…£æ€§å¤§ã€çŸ­æœŸã‚µã‚¤ã‚¯ãƒ«â†’å¿œç­”æ€§é‡è¦–
            momentum_factor = 1.0 + cycle_factor * 0.2  # é•·æœŸã‚µã‚¤ã‚¯ãƒ«ã§æ…£æ€§å¢—
            er_response = 1.0 + er_factor * 0.1         # ERé«˜ã§å¿œç­”æ€§å‘ä¸Š
            
            # é€Ÿåº¦ã®å®‰å…¨åŒ–ï¼ˆä¾¡æ ¼ã«å¯¾ã™ã‚‹ç›¸å¯¾çš„åˆ¶é™ï¼‰
            max_velocity = max(abs(current_price) * 0.3, 1.0)  # æœ€å°å€¤1.0ã‚’ä¿è¨¼
            safe_velocity = max(min(safe_state[1], max_velocity), -max_velocity)
            
            new_state[0] = safe_state[0] + safe_velocity * dt * momentum_factor * er_response
            
            # é€Ÿåº¦æ›´æ–°ï¼ˆã‚µã‚¤ã‚¯ãƒ«ãƒ»ERä¾å­˜ã®æ¸›è¡°ï¼‰
            cycle_damping = 0.98 - cycle_factor * 0.08  # é•·æœŸã‚µã‚¤ã‚¯ãƒ«â†’æ¸›è¡°å°
            er_damping = 0.95 - er_factor * 0.1         # ERé«˜â†’æ¸›è¡°å°ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰æŒç¶šï¼‰
            combined_damping = max(min((cycle_damping + er_damping) / 2.0, 0.99), 0.5)
            new_state[1] = safe_state[1] * combined_damping + safe_state[2] * dt
            
            # åŠ é€Ÿåº¦æ›´æ–°ï¼ˆå®‰å…¨åŒ–ï¼‰
            new_state[2] = safe_state[2] * 0.9
            
            # ã‚µã‚¤ã‚¯ãƒ«é©å¿œåº¦æ›´æ–°ï¼ˆç¾åœ¨ã®ã‚µã‚¤ã‚¯ãƒ«å€¤ã«å‘ã‹ã£ã¦ç·©ã‚„ã‹ã«åæŸï¼‰
            new_state[3] = safe_state[3] * 0.98 + current_cycle * 0.02
            
            # ERé©å¿œåº¦æ›´æ–°ï¼ˆç¾åœ¨ã®ERã«å‘ã‹ã£ã¦ç·©ã‚„ã‹ã«åæŸï¼‰
            new_state[4] = safe_state[4] * 0.95 + current_er * 0.05
            
            # ä¿¡é ¼åº¦æ›´æ–°ï¼ˆã‚µã‚¤ã‚¯ãƒ«ãƒ»ERä¸¡æ–¹ã‚’è€ƒæ…®ã€å®Œå…¨ã‚¼ãƒ­é™¤ç®—é˜²æ­¢ï¼‰
            price_denom = max(abs(safe_state[0]), MIN_SAFE_VALUE)
            price_diff = abs(current_price - safe_state[0])
            prediction_accuracy = 1.0 / (1.0 + price_diff / price_denom)
            
            cycle_denom = max(abs(safe_state[3]), MIN_SAFE_VALUE)
            cycle_diff = abs(current_cycle - safe_state[3])
            cycle_stability = 1.0 / (1.0 + cycle_diff / cycle_denom)
            
            new_state[5] = safe_state[5] * 0.9 + (prediction_accuracy * 0.7 + cycle_stability * 0.3) * 0.1
            
            # çµæœã®ç¯„å›²åˆ¶é™
            new_state[0] = max(min(new_state[0], MAX_SAFE_VALUE), -MAX_SAFE_VALUE)
            new_state[1] = max(min(new_state[1], max_velocity), -max_velocity)
            new_state[2] = max(min(new_state[2], max_velocity * 0.1), -max_velocity * 0.1)
            new_state[3] = max(min(new_state[3], 120.0), 5.0)
            new_state[4] = max(min(new_state[4], 1.0), 0.0)
            new_state[5] = max(min(new_state[5], 2.0), 0.1)
            
            return new_state
        
        # æ•°å€¤å®‰å®šåŒ–
        for i in range(L):
            if P[i, i] > 100.0:
                P[i, i] = 100.0
            elif P[i, i] <= 0:
                P[i, i] = 0.01
        
        # ã‚·ã‚°ãƒãƒã‚¤ãƒ³ãƒˆç”Ÿæˆï¼ˆç°¡ç•¥åŒ–UKFï¼‰
        # å¹³æ–¹æ ¹åˆ†è§£
        try:
            sqrt_P = np.linalg.cholesky(P + np.eye(L) * 1e-8)
        except:
            sqrt_P = np.zeros((L, L))
            for i in range(L):
                sqrt_P[i, i] = min(np.sqrt(max(P[i, i], 0.01)), 1.0)
        
        # ç°¡ç•¥åŒ–ã‚·ã‚°ãƒãƒã‚¤ãƒ³ãƒˆï¼ˆ2L+1å€‹ï¼‰
        sigma_points = np.zeros((2 * L + 1, L))
        sigma_points[0] = x  # ä¸­å¿ƒç‚¹
        
        # ã‚·ã‚°ãƒãƒã‚¤ãƒ³ãƒˆç”Ÿæˆï¼ˆå®‰å…¨åŒ–ï¼‰
        for i in range(L):
            # gammaã¨sqrt_Pã®å€¤ã‚’åˆ¶é™
            safe_gamma = min(gamma, 10.0)
            sqrt_col = sqrt_P[:, i]
            
            # ç•°å¸¸å€¤ã‚’åˆ¶é™
            for j in range(L):
                if abs(sqrt_col[j]) > 10.0:
                    sqrt_col[j] = np.sign(sqrt_col[j]) * 10.0
            
            sigma_points[i + 1] = x + safe_gamma * sqrt_col
            sigma_points[i + 1 + L] = x - safe_gamma * sqrt_col
        
        # ã‚·ã‚°ãƒãƒã‚¤ãƒ³ãƒˆä¼æ’­
        sigma_points_pred = np.zeros((2 * L + 1, L))
        for i in range(2 * L + 1):
            sigma_points_pred[i] = state_transition(sigma_points[i])
        
        # äºˆæ¸¬çŠ¶æ…‹è¨ˆç®—
        x_pred = Wm0 * sigma_points_pred[0]
        for i in range(1, 2 * L + 1):
            x_pred += Wi * sigma_points_pred[i]
        
        # äºˆæ¸¬å…±åˆ†æ•£è¨ˆç®—
        P_pred = Q.copy()
        diff = sigma_points_pred[0] - x_pred
        P_pred += Wc0 * np.outer(diff, diff)
        for i in range(1, 2 * L + 1):
            diff = sigma_points_pred[i] - x_pred
            P_pred += Wi * np.outer(diff, diff)
        
        # è¦³æ¸¬æ›´æ–°
        H = np.zeros(L)
        H[0] = 1.0  # ä¾¡æ ¼ã®ã¿è¦³æ¸¬
        
        # è¦³æ¸¬ãƒã‚¤ã‚ºï¼ˆã‚µã‚¤ã‚¯ãƒ«ãƒ»ERé©å¿œï¼‰
        base_obs_noise = 0.001
        cycle_obs_factor = 1.0 + cycle_norm * 0.5        # é•·æœŸã‚µã‚¤ã‚¯ãƒ«â†’è¦³æ¸¬ãƒã‚¤ã‚ºå¾®å¢—
        er_obs_factor = 1.0 + (1.0 - current_er) * 1.0   # ERä½â†’è¦³æ¸¬ãƒã‚¤ã‚ºå¢—
        R = base_obs_noise * (cycle_obs_factor + er_obs_factor) / 2.0
        
        # ã‚«ãƒ«ãƒãƒ³ã‚²ã‚¤ãƒ³ï¼ˆå®Œå…¨ã‚¼ãƒ­é™¤ç®—é˜²æ­¢ï¼‰
        H_P_pred = np.dot(H, P_pred)
        innovation_cov_raw = np.dot(H_P_pred, H.T) + R
        
        # ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³å…±åˆ†æ•£ã®å®Œå…¨å®‰å…¨åŒ–
        if not np.isfinite(innovation_cov_raw) or innovation_cov_raw <= MIN_SAFE_VALUE:
            innovation_cov = MIN_SAFE_VALUE
        else:
            innovation_cov = max(innovation_cov_raw, MIN_SAFE_VALUE)
        
        # ã‚«ãƒ«ãƒãƒ³ã‚²ã‚¤ãƒ³è¨ˆç®—ï¼ˆå®Œå…¨å®‰å…¨åŒ–ï¼‰
        P_pred_HT = np.dot(P_pred, H.T)
        
        # åˆ†æ¯ãŒã‚¼ãƒ­ã§ãªã„ã“ã¨ã‚’ä¿è¨¼
        safe_innovation_cov = max(abs(innovation_cov), MIN_SAFE_VALUE)
        K = P_pred_HT / safe_innovation_cov
        
        # ã‚«ãƒ«ãƒãƒ³ã‚²ã‚¤ãƒ³ã®å®Œå…¨å®‰å…¨åŒ–
        for i in range(L):
            if not np.isfinite(K[i]):
                K[i] = 0.5 if i == 0 else 0.0
            else:
                # ç¯„å›²åˆ¶é™ã‚’å³æ ¼åŒ–
                K[i] = max(min(K[i], 1.0), -1.0)
        
        # çŠ¶æ…‹æ›´æ–°ï¼ˆå®Œå…¨å®‰å…¨åŒ–ï¼‰
        innovation_raw = current_price - x_pred[0]
        
        # ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Œå…¨å®‰å…¨åŒ–
        if not np.isfinite(innovation_raw):
            innovation = 0.0
        else:
            max_innovation = max(abs(current_price) * 1.0, 1.0)  # æœ€å°å€¤1.0ã‚’ä¿è¨¼
            innovation = max(min(innovation_raw, max_innovation), -max_innovation)
        
        # çŠ¶æ…‹æ›´æ–°
        x = x_pred + K * innovation
        
        # å…±åˆ†æ•£æ›´æ–°ã®å®Œå…¨å®‰å…¨åŒ–
        try:
            H_P_pred_dot = np.dot(H, P_pred)
            K_H_P_pred = np.outer(K, H_P_pred_dot)
            P = P_pred - K_H_P_pred
        except:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯P_predã‚’ãã®ã¾ã¾ä½¿ç”¨
            P = P_pred.copy()
        
        # å…±åˆ†æ•£è¡Œåˆ—ã®å¯¾è§’è¦ç´ å®‰å…¨åŒ–
        for i in range(L):
            if not np.isfinite(P[i, i]) or P[i, i] <= 0:
                P[i, i] = 0.01
            elif P[i, i] > 100.0:
                P[i, i] = 100.0
        
        # çŠ¶æ…‹å€¤ã®å®Œå…¨å®‰å…¨åŒ–
        max_price_deviation = max(abs(current_price) * 1.5, 10.0)
        x[0] = max(min(x[0], max_price_deviation), -max_price_deviation)
        
        max_velocity = max(abs(current_price) * 0.2, 1.0)
        x[1] = max(min(x[1], max_velocity), -max_velocity)
        
        max_acceleration = max(abs(current_price) * 0.05, 0.1)
        x[2] = max(min(x[2], max_acceleration), -max_acceleration)
        
        # ã‚µã‚¤ã‚¯ãƒ«é©å¿œåº¦ã®åˆ¶é™
        x[3] = max(min(x[3], 120.0), 5.0)
        
        # ERé©å¿œåº¦ã®åˆ¶é™
        x[4] = max(min(x[4], 1.0), 0.0)
        
        # ä¿¡é ¼åº¦ã®åˆ¶é™
        x[5] = max(min(x[5], 2.0), 0.1)
        
        # çµæœè¨˜éŒ²ï¼ˆå®‰å…¨åŒ–ï¼‰
        filtered_prices[t] = x[0] if np.isfinite(x[0]) else current_price
        trend_estimates[t] = x[1] if np.isfinite(x[1]) else 0.0
        uncertainty_estimates[t] = np.sqrt(max(P[0, 0], MIN_SAFE_VALUE))
        kalman_gains[t] = K[0] if np.isfinite(K[0]) else 0.5
        
        # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ï¼ˆã‚µã‚¤ã‚¯ãƒ«ãƒ»ERè€ƒæ…®ã€å®Œå…¨ã‚¼ãƒ­é™¤ç®—é˜²æ­¢ï¼‰
        cycle_denom = max(abs(x[3]), MIN_SAFE_VALUE)
        cycle_diff = abs(current_cycle - x[3])
        cycle_confidence = max(0.0, min(1.0, 1.0 - cycle_diff / cycle_denom))  # ã‚µã‚¤ã‚¯ãƒ«å®‰å®šæ€§
        
        er_confidence = max(0.0, min(1.0, current_er))                         # ERåŠ¹ç‡æ€§
        prediction_confidence = max(0.0, min(1.0, x[5]))                       # äºˆæ¸¬ç²¾åº¦
        
        # ä¸ç¢ºå®Ÿæ€§ã®å®Œå…¨å®‰å…¨åŒ–
        safe_uncertainty = max(MIN_SAFE_VALUE, min(10.0, uncertainty_estimates[t]))
        uncertainty_denom = 1.0 + safe_uncertainty * 10
        uncertainty_confidence = 1.0 / max(uncertainty_denom, MIN_SAFE_VALUE)  # ä¸ç¢ºå®Ÿæ€§
        
        confidence_scores[t] = (
            0.25 * cycle_confidence +
            0.25 * er_confidence +
            0.25 * prediction_confidence +
            0.25 * uncertainty_confidence
        )
    
    return (filtered_prices, trend_estimates, uncertainty_estimates, 
            kalman_gains, confidence_scores)


class CycleERAdaptiveUKF(Indicator):
    """
    Cycle-ER-Adaptive Unscented Kalman Filter
    
    Absolute Ultimate Cycleã¨Efficiency Ratioï¼ˆåŠ¹ç‡æ¯”ï¼‰ã‚’ä½¿ç”¨ã—ã¦å‹•çš„é©å¿œã™ã‚‹ç„¡é¦™æ–™ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    
    ğŸŒŸ **3æ®µéšãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ :**
    1. HLC3ä¾¡æ ¼ã‚’é€šå¸¸ã®UKFã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆStage1ï¼‰
    2. ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ä¾¡æ ¼ã‹ã‚‰ERã‚’è¨ˆç®—
    3. åŒæ™‚ã«Absolute Ultimate Cycleã‚’è¨ˆç®—
    4. ã‚µã‚¤ã‚¯ãƒ«å€¤ã¨ERå€¤ã«åŸºã¥ã„ã¦UKFãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å‹•çš„èª¿æ•´ï¼ˆStage2ï¼‰
    
    ğŸ¯ **ã‚µã‚¤ã‚¯ãƒ«åŸºæº–é©å¿œãƒ­ã‚¸ãƒƒã‚¯:**
    - é•·æœŸã‚µã‚¤ã‚¯ãƒ«ï¼ˆä¸Šä½80%ï¼‰: ä½æ„Ÿåº¦ã€é«˜å®‰å®šæ€§ã€æ…£æ€§é‡è¦–
    - çŸ­æœŸã‚µã‚¤ã‚¯ãƒ«ï¼ˆä¸‹ä½30%ï¼‰: é«˜æ„Ÿåº¦ã€è¿…é€Ÿå¿œç­”ã€å¿œç­”æ€§é‡è¦–
    - ä¸­æœŸã‚µã‚¤ã‚¯ãƒ«: ãƒãƒ©ãƒ³ã‚¹èª¿æ•´
    
    âš¡ **ERå¾®èª¿æ•´ãƒ­ã‚¸ãƒƒã‚¯:**
    - ER > 0.618: é«˜åŠ¹ç‡ï¼ˆå¼·ãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰â†’ æ„Ÿåº¦å¾®å¢—ã€ãƒã‚¤ã‚ºä½æ¸›
    - ER < 0.382: ä½åŠ¹ç‡ï¼ˆãƒ¬ãƒ³ã‚¸ç›¸å ´ï¼‰â†’ æ„Ÿåº¦ä½ä¸‹ã€å®‰å®šåŒ–
    - ä¸­åŠ¹ç‡: ä¸­ç«‹èª¿æ•´
    
    ğŸ”§ **å‹•çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç¯„å›²èª¿æ•´:**
    - æ„Ÿåº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆÎ±, Îºï¼‰: ã‚µã‚¤ã‚¯ãƒ«ã«å¿œã˜ã¦ç¯„å›²å‹•çš„èª¿æ•´
    - ãƒã‚¤ã‚ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆÎ²ï¼‰: é•·æœŸã‚µã‚¤ã‚¯ãƒ«â†’ä¿å®ˆçš„ã€çŸ­æœŸã‚µã‚¤ã‚¯ãƒ«â†’ç©æ¥µçš„
    """
    
    def __init__(
        self,
        # UKFãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        ukf_alpha: float = 0.001,
        ukf_beta: float = 2.0,
        ukf_kappa: float = 0.0,
        # ERãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿  
        er_period: int = 14,
        er_smoothing_method: str = 'hma',
        er_slope_index: int = 1,
        er_range_threshold: float = 0.005,
        # ã‚µã‚¤ã‚¯ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        cycle_part: float = 1.0,
        cycle_max_output: int = 120,
        cycle_min_output: int = 5,
        cycle_period_range: Tuple[int, int] = (5, 120),
        # é©å¿œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç¯„å›²
        alpha_min: float = 0.0001,
        alpha_max: float = 0.01,
        beta_min: float = 1.0,
        beta_max: float = 4.0,
        kappa_min: float = -1.0,
        kappa_max: float = 3.0,
        # ã‚µã‚¤ã‚¯ãƒ«é–¾å€¤
        cycle_threshold_ratio_high: float = 0.8,
        cycle_threshold_ratio_low: float = 0.3,
        # ãã®ä»–
        volatility_window: int = 10
    ):
        """
        ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
        
        Args:
            ukf_alpha: UKFã‚¢ãƒ«ãƒ•ã‚¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            ukf_beta: UKFãƒ™ãƒ¼ã‚¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            ukf_kappa: UKFã‚«ãƒƒãƒ‘ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            er_period: ERè¨ˆç®—æœŸé–“
            er_smoothing_method: ERã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æ–¹æ³•
            er_slope_index: ERãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šæœŸé–“
            er_range_threshold: ERãƒ¬ãƒ³ã‚¸åˆ¤å®šé–¾å€¤
            cycle_part: ã‚µã‚¤ã‚¯ãƒ«éƒ¨åˆ†ã®å€ç‡
            cycle_max_output: ã‚µã‚¤ã‚¯ãƒ«æœ€å¤§å‡ºåŠ›å€¤
            cycle_min_output: ã‚µã‚¤ã‚¯ãƒ«æœ€å°å‡ºåŠ›å€¤
            cycle_period_range: ã‚µã‚¤ã‚¯ãƒ«æœŸé–“ã®ç¯„å›²
            alpha_min/max: Î±ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€å°/æœ€å¤§å€¤
            beta_min/max: Î²ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€å°/æœ€å¤§å€¤
            kappa_min/max: Îºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€å°/æœ€å¤§å€¤
            cycle_threshold_ratio_high/low: ã‚µã‚¤ã‚¯ãƒ«é–¾å€¤æ¯”ç‡
            volatility_window: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
        """
        name = f"CycleERAdaptiveUKF(Î±={ukf_alpha},Î²={ukf_beta},Îº={ukf_kappa},ER={er_period},Cycle={cycle_period_range})"
        super().__init__(name)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¿å­˜
        self.ukf_alpha = ukf_alpha
        self.ukf_beta = ukf_beta
        self.ukf_kappa = ukf_kappa
        self.er_period = er_period
        self.er_smoothing_method = er_smoothing_method
        self.er_slope_index = er_slope_index
        self.er_range_threshold = er_range_threshold
        self.cycle_part = cycle_part
        self.cycle_max_output = cycle_max_output
        self.cycle_min_output = cycle_min_output
        self.cycle_period_range = cycle_period_range
        self.alpha_min = alpha_min
        self.alpha_max = alpha_max
        self.beta_min = beta_min
        self.beta_max = beta_max
        self.kappa_min = kappa_min
        self.kappa_max = kappa_max
        self.cycle_threshold_ratio_high = cycle_threshold_ratio_high
        self.cycle_threshold_ratio_low = cycle_threshold_ratio_low
        self.volatility_window = volatility_window
        
        # Absolute Ultimate Cycleã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ç”¨ï¼‰- EhlersUnifiedDCçµŒç”±
        self.cycle_indicator = EhlersUnifiedDC(
            detector_type='absolute_ultimate',
            cycle_part=cycle_part,
            max_output=cycle_max_output,
            min_output=cycle_min_output,
            src_type='hlc3',
            period_range=cycle_period_range
        )
        
        # Efficiency Ratioã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ï¼ˆStage1ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ä¾¡æ ¼ç”¨ï¼‰
        self.er_indicator = EfficiencyRatio(
            period=er_period,
            src_type='hlc3',  # Stage1ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿HLC3ä¾¡æ ¼ã‚’ä½¿ç”¨
            smoothing_method=er_smoothing_method,
            use_dynamic_period=False,  # å›ºå®šæœŸé–“ãƒ¢ãƒ¼ãƒ‰
            slope_index=er_slope_index,
            range_threshold=er_range_threshold
        )
        
        # çµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._result: Optional[CycleERAdaptiveUKFResult] = None
        self._cache_hash: Optional[str] = None
    
    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> CycleERAdaptiveUKFResult:
        """
        Cycle-ER-Adaptive UKFã‚’è¨ˆç®—
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            CycleERAdaptiveUKFResult: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœ
        """
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        current_hash = self._get_data_hash(data)
        if self._cache_hash == current_hash and self._result is not None:
            return self._result
        
        # HLC3ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºï¼ˆå®‰å…¨åŒ–ï¼‰
        hlc3_prices = PriceSource.calculate_source(data, 'hlc3')
        n_data = len(hlc3_prices)
        
        # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®å®‰å…¨åŒ–
        hlc3_prices = np.where(np.isfinite(hlc3_prices), hlc3_prices, 100.0)
        
        print(f"ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
        print(f"  - ãƒ‡ãƒ¼ã‚¿é•·: {n_data}")
        print(f"  - HLC3ä¾¡æ ¼ç¯„å›²: {np.nanmin(hlc3_prices):.2f} - {np.nanmax(hlc3_prices):.2f}")
        
        # æœ€å°ãƒ‡ãƒ¼ã‚¿é•·ã‚’10ã«ç·©å’Œ
        if n_data < 10:
            print(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {n_data} < 10")
            return self._create_empty_result(n_data)
        
        # Stage 1: HLC3ä¾¡æ ¼ã‚’é€šå¸¸ã®UKFã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå®‰å…¨åŒ–ï¼‰
        print("  - Stage 1: UKFãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–‹å§‹")
        volatility = self._estimate_volatility(hlc3_prices)
        stage1_filtered, _, stage1_uncertainty, stage1_gains, stage1_confidence = unscented_kalman_filter_numba(
            hlc3_prices, volatility, self.ukf_alpha, self.ukf_beta, self.ukf_kappa
        )
        
        # Stage1çµæœã®å®‰å…¨åŒ–
        stage1_filtered = np.where(np.isfinite(stage1_filtered), stage1_filtered, hlc3_prices)
        
        # Stage1çµæœã®ç¢ºèª
        stage1_valid = np.sum(~np.isnan(stage1_filtered))
        print(f"  - Stage1æœ‰åŠ¹å€¤: {stage1_valid}/{n_data}")
        
        # Stage 2a: å…ƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Absolute Ultimate Cycleã‚’è¨ˆç®—ï¼ˆå®‰å…¨åŒ–ï¼‰
        print("  - Stage 2a: ã‚µã‚¤ã‚¯ãƒ«è¨ˆç®—é–‹å§‹")
        cycle_values = self.cycle_indicator.calculate(data)
        
        # ã‚µã‚¤ã‚¯ãƒ«å€¤ã®å®‰å…¨åŒ–
        cycle_values = np.where(np.isfinite(cycle_values), cycle_values, 20.0)
        cycle_values = np.clip(cycle_values, 5.0, 120.0)
        
        cycle_valid = np.sum(~np.isnan(cycle_values))
        print(f"  - ã‚µã‚¤ã‚¯ãƒ«æœ‰åŠ¹å€¤: {cycle_valid}/{n_data}")
        if cycle_valid > 0:
            print(f"  - ã‚µã‚¤ã‚¯ãƒ«å€¤ç¯„å›²: {np.nanmin(cycle_values):.2f} - {np.nanmax(cycle_values):.2f}")
        
        # Stage 2b: ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ä¾¡æ ¼ã‹ã‚‰ERã‚’è¨ˆç®—ï¼ˆå®‰å…¨åŒ–ï¼‰
        print("  - Stage 2b: ERè¨ˆç®—é–‹å§‹")
        
        # DataFrameã‚’ä½œæˆã—ã¦ERè¨ˆç®—ç”¨ã®HLC3ã¨ã—ã¦ä½¿ç”¨
        if isinstance(data, pd.DataFrame):
            # ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ä¾¡æ ¼ã‚’HLC3ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ãŸã‚ã®ãƒ€ãƒŸãƒ¼DataFrameä½œæˆ
            filtered_df = data.copy()
            filtered_df['high'] = stage1_filtered
            filtered_df['low'] = stage1_filtered  
            filtered_df['close'] = stage1_filtered
        else:
            # NumPyé…åˆ—ã®å ´åˆã¯DataFrameã«å¤‰æ›
            filtered_df = pd.DataFrame({
                'high': stage1_filtered,
                'low': stage1_filtered,
                'close': stage1_filtered
            })
        
        # ERã‚’è¨ˆç®—
        er_result = self.er_indicator.calculate(filtered_df)
        er_values = er_result.values
        er_trend_signals = er_result.trend_signals
        current_trend = er_result.current_trend
        current_trend_value = er_result.current_trend_value
        
        # ERå€¤ã®å®‰å…¨åŒ–
        er_values = np.where(np.isfinite(er_values), er_values, 0.5)
        er_values = np.clip(er_values, 0.0, 1.0)
        
        er_valid = np.sum(~np.isnan(er_values))
        print(f"  - ERæœ‰åŠ¹å€¤: {er_valid}/{n_data}")
        if er_valid > 0:
            print(f"  - ERå€¤ç¯„å›²: {np.nanmin(er_values):.3f} - {np.nanmax(er_values):.3f}")
        
        # Stage 3: ã‚µã‚¤ã‚¯ãƒ«å€¤ã¨ERå€¤ã«åŸºã¥ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ï¼ˆå®‰å…¨åŒ–ï¼‰
        print("  - Stage 3: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´é–‹å§‹")
        
        adaptive_alpha, adaptive_beta, adaptive_kappa = calculate_cycle_adaptive_parameters(
            cycle_values,
            er_values,
            self.ukf_alpha,
            self.ukf_beta,
            self.ukf_kappa,
            self.alpha_min,
            self.alpha_max,
            self.kappa_min,
            self.kappa_max,
            self.beta_min,
            self.beta_max,
            self.cycle_threshold_ratio_high,
            self.cycle_threshold_ratio_low
        )
        
        # é©å¿œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å®‰å…¨åŒ–
        adaptive_alpha = np.where(np.isfinite(adaptive_alpha), adaptive_alpha, self.ukf_alpha)
        adaptive_beta = np.where(np.isfinite(adaptive_beta), adaptive_beta, self.ukf_beta)
        adaptive_kappa = np.where(np.isfinite(adaptive_kappa), adaptive_kappa, self.ukf_kappa)
        
        adaptive_alpha = np.clip(adaptive_alpha, self.alpha_min, self.alpha_max)
        adaptive_beta = np.clip(adaptive_beta, self.beta_min, self.beta_max)
        adaptive_kappa = np.clip(adaptive_kappa, self.kappa_min, self.kappa_max)
        
        print(f"  - é©å¿œÎ±ç¯„å›²: {np.nanmin(adaptive_alpha):.6f} - {np.nanmax(adaptive_alpha):.6f}")
        print(f"  - é©å¿œÎ²ç¯„å›²: {np.nanmin(adaptive_beta):.3f} - {np.nanmax(adaptive_beta):.3f}")
        
        # Stage 4: é©å¿œUKFã«ã‚ˆã‚‹æœ€çµ‚ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå®‰å…¨åŒ–ï¼‰
        print("  - Stage 4: æœ€çµ‚ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–‹å§‹")
        
        final_filtered, trend_estimates, uncertainty_estimates, kalman_gains, confidence_scores = cycle_er_adaptive_unscented_kalman_numba(
            hlc3_prices,
            cycle_values,
            er_values,
            adaptive_alpha,
            adaptive_beta,
            adaptive_kappa
        )
        
        # æœ€çµ‚çµæœã®å®‰å…¨åŒ–
        final_filtered = np.where(np.isfinite(final_filtered), final_filtered, hlc3_prices)
        trend_estimates = np.where(np.isfinite(trend_estimates), trend_estimates, 0.0)
        uncertainty_estimates = np.where(np.isfinite(uncertainty_estimates), uncertainty_estimates, 1.0)
        kalman_gains = np.where(np.isfinite(kalman_gains), kalman_gains, 0.5)
        confidence_scores = np.where(np.isfinite(confidence_scores), confidence_scores, 0.5)
        
        # ç¯„å›²åˆ¶é™
        uncertainty_estimates = np.clip(uncertainty_estimates, 0.001, 10.0)
        kalman_gains = np.clip(kalman_gains, 0.0, 1.0)
        confidence_scores = np.clip(confidence_scores, 0.0, 1.0)
        
        final_valid = np.sum(~np.isnan(final_filtered))
        print(f"  - æœ€çµ‚ãƒ•ã‚£ãƒ«ã‚¿æœ‰åŠ¹å€¤: {final_valid}/{n_data}")
        if final_valid > 0:
            print(f"  - æœ€çµ‚ãƒ•ã‚£ãƒ«ã‚¿å€¤ç¯„å›²: {np.nanmin(final_filtered):.2f} - {np.nanmax(final_filtered):.2f}")
        
        # çµæœä½œæˆ
        result = CycleERAdaptiveUKFResult(
            values=final_filtered,
            stage1_filtered=stage1_filtered,
            cycle_values=cycle_values,
            er_values=er_values,
            er_trend_signals=er_trend_signals,
            adaptive_alpha=adaptive_alpha,
            adaptive_beta=adaptive_beta,
            adaptive_kappa=adaptive_kappa,
            uncertainty=uncertainty_estimates,
            kalman_gains=kalman_gains,
            confidence_scores=confidence_scores,
            current_trend=current_trend,
            current_trend_value=current_trend_value
        )
        
        print("âœ… è¨ˆç®—å®Œäº†")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°
        self._result = result
        self._cache_hash = current_hash
        
        return result
    
    def _estimate_volatility(self, prices: np.ndarray) -> np.ndarray:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’æ¨å®š"""
        n = len(prices)
        volatility = np.full(n, 0.01)
        
        if n < self.volatility_window:
            return volatility
        
        for i in range(self.volatility_window, n):
            window_prices = prices[i-self.volatility_window:i]
            if len(window_prices) > 1:
                vol = np.std(window_prices)
                volatility[i] = max(vol, 0.001)
        
        return volatility
    
    def _create_empty_result(self, length: int) -> CycleERAdaptiveUKFResult:
        """ç©ºã®çµæœã‚’ä½œæˆ"""
        return CycleERAdaptiveUKFResult(
            values=np.full(length, np.nan),
            stage1_filtered=np.full(length, np.nan),
            cycle_values=np.full(length, np.nan),
            er_values=np.full(length, np.nan),
            er_trend_signals=np.zeros(length, dtype=np.int8),
            adaptive_alpha=np.full(length, self.ukf_alpha),
            adaptive_beta=np.full(length, self.ukf_beta),
            adaptive_kappa=np.full(length, self.ukf_kappa),
            uncertainty=np.full(length, np.nan),
            kalman_gains=np.full(length, np.nan),
            confidence_scores=np.full(length, np.nan),
            current_trend='range',
            current_trend_value=0
        )
    
    def _get_data_hash(self, data) -> str:
        """ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—"""
        try:
            if hasattr(data, 'values'):
                return str(hash(data.values.tobytes()))
            else:
                return str(hash(data.tobytes()))
        except:
            return str(len(data))
    
    def get_values(self) -> Optional[np.ndarray]:
        """æœ€çµ‚ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿å€¤ã‚’å–å¾—"""
        if self._result is not None:
            return self._result.values.copy()
        return None
    
    def get_stage1_filtered(self) -> Optional[np.ndarray]:
        """Stage1ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿å€¤ã‚’å–å¾—"""
        if self._result is not None:
            return self._result.stage1_filtered.copy()
        return None
    
    def get_cycle_values(self) -> Optional[np.ndarray]:
        """ã‚µã‚¤ã‚¯ãƒ«å€¤ã‚’å–å¾—"""
        if self._result is not None:
            return self._result.cycle_values.copy()
        return None
    
    def get_er_values(self) -> Optional[np.ndarray]:
        """ERå€¤ã‚’å–å¾—"""
        if self._result is not None:
            return self._result.er_values.copy()
        return None
    
    def get_adaptive_parameters(self) -> Optional[Tuple[np.ndarray, np.ndarray, np.ndarray]]:
        """é©å¿œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—"""
        if self._result is not None:
            return (
                self._result.adaptive_alpha.copy(),
                self._result.adaptive_beta.copy(),
                self._result.adaptive_kappa.copy()
            )
        return None
    
    def get_confidence_scores(self) -> Optional[np.ndarray]:
        """ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’å–å¾—"""
        if self._result is not None:
            return self._result.confidence_scores.copy()
        return None
    
    def get_trend_info(self) -> Tuple[str, int, Optional[np.ndarray]]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’å–å¾—"""
        if self._result is not None:
            return (
                self._result.current_trend,
                self._result.current_trend_value,
                self._result.er_trend_signals.copy()
            )
        return ('range', 0, None)
    
    def get_metadata(self) -> dict:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        if self._result is None:
            return {}
        
        valid_cycle = self._result.cycle_values[~np.isnan(self._result.cycle_values)]
        valid_er = self._result.er_values[~np.isnan(self._result.er_values)]
        valid_confidence = self._result.confidence_scores[~np.isnan(self._result.confidence_scores)]
        
        metadata = {
            'indicator_name': self.name,
            'data_points': len(self._result.values),
            'avg_cycle': np.mean(valid_cycle) if len(valid_cycle) > 0 else np.nan,
            'cycle_range': (np.min(valid_cycle), np.max(valid_cycle)) if len(valid_cycle) > 0 else (np.nan, np.nan),
            'avg_er': np.mean(valid_er) if len(valid_er) > 0 else np.nan,
            'er_range': (np.min(valid_er), np.max(valid_er)) if len(valid_er) > 0 else (np.nan, np.nan),
            'avg_confidence': np.mean(valid_confidence) if len(valid_confidence) > 0 else np.nan,
            'trend_state': self._result.current_trend,
            'trend_value': self._result.current_trend_value,
            # ã‚µã‚¤ã‚¯ãƒ«åˆ†æ
            'long_cycle_ratio': np.mean(valid_cycle >= np.percentile(valid_cycle, 80)) if len(valid_cycle) > 0 else 0.0,
            'short_cycle_ratio': np.mean(valid_cycle <= np.percentile(valid_cycle, 30)) if len(valid_cycle) > 0 else 0.0,
            # ERåˆ†æ
            'high_efficiency_ratio': np.mean(valid_er > 0.618) if len(valid_er) > 0 else 0.0,
            'low_efficiency_ratio': np.mean(valid_er < 0.382) if len(valid_er) > 0 else 0.0,
            # é©å¿œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            'avg_adaptive_alpha': np.mean(self._result.adaptive_alpha),
            'avg_adaptive_beta': np.mean(self._result.adaptive_beta),
            'avg_adaptive_kappa': np.mean(self._result.adaptive_kappa),
            'parameter_variation': {
                'alpha_std': np.std(self._result.adaptive_alpha),
                'beta_std': np.std(self._result.adaptive_beta), 
                'kappa_std': np.std(self._result.adaptive_kappa)
            },
            # é©å¿œç¯„å›²æƒ…å ±
            'parameter_ranges': {
                'alpha_range': (self.alpha_min, self.alpha_max),
                'beta_range': (self.beta_min, self.beta_max),
                'kappa_range': (self.kappa_min, self.kappa_max)
            }
        }
        
        return metadata
    
    def reset(self) -> None:
        """çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self._result = None
        self._cache_hash = None
        if hasattr(self.cycle_indicator, 'reset'):
            self.cycle_indicator.reset()
        if hasattr(self.er_indicator, 'reset'):
            self.er_indicator.reset()


# ãƒ‡ãƒ¢æ©Ÿèƒ½
def demo_cycle_er_adaptive_ukf():
    """Cycle-ER-Adaptive UKFã®ãƒ‡ãƒ¢"""
    print("ğŸ¯ Cycle-ER-Adaptive UKF Demo")
    print("=" * 60)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    np.random.seed(42)
    n_periods = 200
    
    # ã‚ˆã‚Šè¤‡é›‘ãªãƒˆãƒ¬ãƒ³ãƒ‰ + ã‚µã‚¤ã‚¯ãƒ« + ãƒã‚¤ã‚ºã®ã‚ã‚‹ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
    trend = np.linspace(100, 120, n_periods)
    cycle = 5 * np.sin(np.linspace(0, 4 * np.pi, n_periods))  # ã‚µã‚¤ã‚¯ãƒ«æˆåˆ†
    noise = np.random.normal(0, 1, n_periods)
    prices = trend + cycle + noise
    
    # OHLCå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    data = pd.DataFrame({
        'high': prices + np.abs(np.random.normal(0, 0.5, n_periods)),
        'low': prices - np.abs(np.random.normal(0, 0.5, n_periods)), 
        'close': prices
    })
    
    # Cycle-ER-Adaptive UKFå®Ÿè¡Œ
    cycle_er_ukf = CycleERAdaptiveUKF(
        ukf_alpha=0.001,
        ukf_beta=2.0,
        er_period=14,
        er_smoothing_method='hma',
        cycle_part=1.0,
        cycle_max_output=120,
        cycle_min_output=5
    )
    
    result = cycle_er_ukf.calculate(data)
    
    # çµæœã®è¡¨ç¤º
    print(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {n_periods}")
    print(f"æœ€çµ‚ãƒ•ã‚£ãƒ«ã‚¿å€¤ç¯„å›²: {np.nanmin(result.values):.2f} - {np.nanmax(result.values):.2f}")
    print(f"å¹³å‡ã‚µã‚¤ã‚¯ãƒ«å€¤: {np.nanmean(result.cycle_values):.2f}")
    print(f"ã‚µã‚¤ã‚¯ãƒ«å€¤ç¯„å›²: {np.nanmin(result.cycle_values):.2f} - {np.nanmax(result.cycle_values):.2f}")
    print(f"å¹³å‡ERå€¤: {np.nanmean(result.er_values):.3f}")
    print(f"ç¾åœ¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰: {result.current_trend}")
    print(f"å¹³å‡ä¿¡é ¼åº¦: {np.nanmean(result.confidence_scores):.3f}")
    
    # é©å¿œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ±è¨ˆ
    print(f"\nğŸ”§ é©å¿œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ±è¨ˆ:")
    print(f"Î±ç¯„å›²: {np.nanmin(result.adaptive_alpha):.6f} - {np.nanmax(result.adaptive_alpha):.6f}")
    print(f"Î²ç¯„å›²: {np.nanmin(result.adaptive_beta):.3f} - {np.nanmax(result.adaptive_beta):.3f}")
    print(f"Îºç¯„å›²: {np.nanmin(result.adaptive_kappa):.3f} - {np.nanmax(result.adaptive_kappa):.3f}")
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
    metadata = cycle_er_ukf.get_metadata()
    print("\nğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿:")
    for key, value in metadata.items():
        if isinstance(value, dict):
            print(f"  {key}:")
            for sub_key, sub_value in value.items():
                print(f"    {sub_key}: {sub_value}")
        else:
            print(f"  {key}: {value}")
    
    print("\nâœ… ãƒ‡ãƒ¢å®Œäº†")


if __name__ == "__main__":
    demo_cycle_er_adaptive_ukf() 