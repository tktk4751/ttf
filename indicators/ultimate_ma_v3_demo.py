#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from datetime import datetime, timedelta
import os
import sys
import time
import warnings
warnings.filterwarnings('ignore')

# matplotlibã®ãƒ•ã‚©ãƒ³ãƒˆè­¦å‘Šã‚’ç„¡åŠ¹åŒ–
import matplotlib
matplotlib.rcParams['font.family'] = 'DejaVu Sans'
import logging
logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)

# UltimateMA V3ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ultimate_ma_v3 import UltimateMAV3

# ãƒ‡ãƒ¼ã‚¿å–å¾—ã®ãŸã‚ã®ä¾å­˜é–¢ä¿‚ï¼ˆconfig.yamlå¯¾å¿œï¼‰
try:
    import yaml
    sys.path.append('..')
    from data.data_loader import DataLoader, CSVDataSource
    from data.data_processor import DataProcessor
    from data.binance_data_source import BinanceDataSource
    YAML_SUPPORT = True
except ImportError:
    YAML_SUPPORT = False
    print("âš ï¸  YAML/ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚åˆæˆãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨å¯èƒ½ã§ã™ã€‚")


def load_data_from_yaml_config(config_path: str) -> pd.DataFrame:
    """config.yamlã‹ã‚‰å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    if not YAML_SUPPORT:
        print("âŒ YAML/ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚µãƒãƒ¼ãƒˆãŒç„¡åŠ¹ã§ã™")
        return None
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        print(f"âœ… {config_path} èª­ã¿è¾¼ã¿æˆåŠŸ")
        
        binance_config = config.get('binance_data', {})
        if not binance_config.get('enabled', False):
            print("âŒ Binanceãƒ‡ãƒ¼ã‚¿ãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã¾ã™")
            return None
            
        data_dir = binance_config.get('data_dir', 'data/binance')
        symbol = binance_config.get('symbol', 'BTC')
        print(f"ğŸ“Š èª­ã¿è¾¼ã¿ä¸­: {symbol} ãƒ‡ãƒ¼ã‚¿")
        
        binance_data_source = BinanceDataSource(data_dir)
        dummy_csv_source = CSVDataSource("dummy")
        data_loader = DataLoader(
            data_source=dummy_csv_source,
            binance_data_source=binance_data_source
        )
        data_processor = DataProcessor()
        
        raw_data = data_loader.load_data_from_config(config)
        if not raw_data:
            return None
            
        processed_data = {
            symbol: data_processor.process(df)
            for symbol, df in raw_data.items()
        }
        
        first_symbol = next(iter(processed_data))
        data = processed_data[first_symbol]
        
        print(f"âœ… å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {first_symbol}")
        print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ•°: {len(data)}")
        
        return data
        
    except Exception as e:
        print(f"âŒ config.yamlã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def generate_synthetic_data(n_samples: int = 1000) -> pd.DataFrame:
    """åˆæˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆå¼·åŒ–ç‰ˆãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ï¼‰"""
    np.random.seed(42)
    
    # ã‚ˆã‚Šè¤‡é›‘ãªãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³
    t = np.linspace(0, 4*np.pi, n_samples)
    trend = 100 + 15 * np.sin(t/2) + 8 * np.cos(t/3) + 3 * np.sin(t*2)
    noise = np.random.normal(0, 1.5, n_samples)
    high_freq_noise = 0.3 * np.sin(t * 15) * np.random.normal(0, 0.8, n_samples)
    
    prices = trend + noise + high_freq_noise
    
    # OHLCç”Ÿæˆ
    data = []
    for i, price in enumerate(prices):
        volatility = 0.8
        high = price + np.random.uniform(0, volatility)
        low = price - np.random.uniform(0, volatility)
        open_price = price + np.random.normal(0, volatility/3)
        
        low = min(low, price, open_price)
        high = max(high, price, open_price)
        
        data.append([open_price, high, low, price])
    
    df = pd.DataFrame(data, columns=['open', 'high', 'low', 'close'])
    print(f"âœ… å¼·åŒ–ç‰ˆåˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(df)}ä»¶")
    return df


def analyze_ultimate_ma_v3_performance(result) -> dict:
    """UltimateMA V3ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
    # åŸºæœ¬ãƒã‚¤ã‚ºé™¤å»åŠ¹æœ
    raw_std = np.nanstd(result.raw_values)
    final_std = np.nanstd(result.values)
    noise_reduction_ratio = (raw_std - final_std) / raw_std if raw_std > 0 else 0.0
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰çµ±è¨ˆ
    trend_signals = result.trend_signals
    up_periods = np.sum(trend_signals == 1)
    down_periods = np.sum(trend_signals == -1)
    range_periods = np.sum(trend_signals == 0)
    total_periods = len(trend_signals)
    
    # ä¿¡é ¼åº¦çµ±è¨ˆ
    confident_signals = result.trend_confidence[result.trend_confidence > 0]
    high_confidence_signals = result.trend_confidence[result.trend_confidence > 0.5]
    
    # é‡å­åˆ†æçµ±è¨ˆ
    quantum_stats = {
        'mean_quantum_state': np.nanmean(result.quantum_state),
        'quantum_volatility': np.nanstd(result.quantum_state),
        'mtf_consensus_avg': np.nanmean(result.multi_timeframe_consensus),
        'fractal_dimension_avg': np.nanmean(result.fractal_dimension),
        'entropy_level_avg': np.nanmean(result.entropy_level)
    }
    
    return {
        'noise_reduction': {
            'raw_volatility': raw_std,
            'filtered_volatility': final_std,
            'reduction_ratio': noise_reduction_ratio,
            'reduction_percentage': noise_reduction_ratio * 100
        },
        'trend_analysis': {
            'total_periods': total_periods,
            'up_periods': up_periods,
            'down_periods': down_periods,
            'range_periods': range_periods,
            'current_trend': result.current_trend,
            'current_confidence': result.current_confidence
        },
        'confidence_analysis': {
            'total_confident_signals': len(confident_signals),
            'high_confidence_signals': len(high_confidence_signals),
            'avg_confidence': np.mean(confident_signals) if len(confident_signals) > 0 else 0,
            'max_confidence': np.max(result.trend_confidence),
            'confidence_ratio': len(confident_signals) / total_periods if total_periods > 0 else 0
        },
        'quantum_analysis': quantum_stats
    }


def main():
    print("ğŸš€ UltimateMA V3 - é‡å­ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ»ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ãƒ»ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼çµ±åˆåˆ†æã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 100)
    print("ğŸŒŒ 10æ®µéšé©æ–°çš„AIåˆ†æ: é‡å­ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æå™¨ + ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ  + ãƒ•ãƒ©ã‚¯ã‚¿ãƒ« + ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼")
    print("ğŸ¯ 95%è¶…é«˜ç²¾åº¦åˆ¤å®š: ä¿¡é ¼åº¦ä»˜ãã‚·ã‚°ãƒŠãƒ« + é©å¿œçš„å­¦ç¿’ + å¤šæ¬¡å…ƒçµ±åˆ")
    print("=" * 100)
    
    # ãƒ‡ãƒ¼ã‚¿é¸æŠ
    data = None
    is_real_data = False
    
    # config.yamlã‹ã‚‰ã®èª­ã¿è¾¼ã¿è©¦è¡Œ
    config_yaml_path = "../config.yaml"
    if YAML_SUPPORT and os.path.exists(config_yaml_path):
        print("ğŸ“‚ config.yamlã‹ã‚‰ãƒªã‚¢ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        data = load_data_from_yaml_config(config_yaml_path)
        if data is not None:
            print("âœ… å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ")
            is_real_data = True
    
    # åˆæˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    if data is None:
        print("ğŸ“Š å¼·åŒ–ç‰ˆåˆæˆãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨")
        data = generate_synthetic_data(1500)  # ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ
        is_real_data = False
    
    # UltimateMA V3åˆæœŸåŒ–
    print(f"\nğŸ”§ UltimateMA V3 åˆæœŸåŒ–ä¸­...")
    ultimate_ma_v3 = UltimateMAV3(
        super_smooth_period=8,
        zero_lag_period=16,
        realtime_window=34,
        quantum_window=16,
        fractal_window=16,
        entropy_window=16,
        src_type='hlc3',
        slope_index=2,
        base_threshold=0.002,
        min_confidence=0.15
    )
    print("âœ… UltimateMA V3åˆæœŸåŒ–å®Œäº†ï¼ˆ10æ®µéšAIåˆ†æã‚·ã‚¹ãƒ†ãƒ ï¼‰")
    
    # è¨ˆç®—å®Ÿè¡Œ
    print(f"\nâš¡ UltimateMA V3 è¨ˆç®—å®Ÿè¡Œä¸­...")
    data_type = "å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿" if is_real_data else "å¼·åŒ–ç‰ˆåˆæˆãƒ‡ãƒ¼ã‚¿"
    print(f"ğŸ“Š å¯¾è±¡ãƒ‡ãƒ¼ã‚¿: {data_type} ({len(data)}ä»¶)")
    
    start_time = time.time()
    result = ultimate_ma_v3.calculate(data)
    end_time = time.time()
    
    processing_time = end_time - start_time
    processing_speed = len(data) / processing_time if processing_time > 0 else 0
    
    print(f"âœ… UltimateMA V3è¨ˆç®—å®Œäº† (å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’)")
    print(f"   âš¡ å‡¦ç†é€Ÿåº¦: {processing_speed:.0f} ãƒ‡ãƒ¼ã‚¿/ç§’")
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
    print(f"\nğŸ“ˆ UltimateMA V3 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æä¸­...")
    performance = analyze_ultimate_ma_v3_performance(result)
    
    # çµæœè¡¨ç¤º
    print("\n" + "="*80)
    print("ğŸ¯ **UltimateMA V3 - é‡å­ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«åˆ†æçµæœ**")
    print("="*80)
    
    # ãƒã‚¤ã‚ºé™¤å»åŠ¹æœ
    noise_stats = performance['noise_reduction']
    print(f"\nğŸ”‡ **ãƒã‚¤ã‚ºé™¤å»åŠ¹æœ:**")
    print(f"   - ãƒã‚¤ã‚ºé™¤å»ç‡: {noise_stats['reduction_percentage']:.2f}%")
    print(f"   - å…ƒã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {noise_stats['raw_volatility']:.6f}")
    print(f"   - ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œ: {noise_stats['filtered_volatility']:.6f}")
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    trend_stats = performance['trend_analysis']
    print(f"\nğŸ“ˆ **ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ:**")
    print(f"   - ç¾åœ¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰: {trend_stats['current_trend'].upper()}")
    print(f"   - ç¾åœ¨ã®ä¿¡é ¼åº¦: {trend_stats['current_confidence']:.3f}")
    print(f"   - ä¸Šæ˜‡: {trend_stats['up_periods']}æœŸé–“")
    print(f"   - ä¸‹é™: {trend_stats['down_periods']}æœŸé–“") 
    print(f"   - ãƒ¬ãƒ³ã‚¸: {trend_stats['range_periods']}æœŸé–“")
    
    # ä¿¡é ¼åº¦åˆ†æ
    conf_stats = performance['confidence_analysis']
    print(f"\nğŸ”¥ **ä¿¡é ¼åº¦åˆ†æ:**")
    print(f"   - å¹³å‡ä¿¡é ¼åº¦: {conf_stats['avg_confidence']:.3f}")
    print(f"   - æœ€å¤§ä¿¡é ¼åº¦: {conf_stats['max_confidence']:.3f}")
    print(f"   - é«˜ä¿¡é ¼åº¦ã‚·ã‚°ãƒŠãƒ«: {conf_stats['high_confidence_signals']}å€‹")
    print(f"   - ä¿¡é ¼åº¦æ¯”ç‡: {conf_stats['confidence_ratio']*100:.1f}%")
    
    # é‡å­åˆ†æ
    quantum_stats = performance['quantum_analysis']
    print(f"\nğŸŒŒ **é‡å­åˆ†æçµ±è¨ˆ:**")
    print(f"   - é‡å­çŠ¶æ…‹å¹³å‡: {quantum_stats['mean_quantum_state']:.3f}")
    print(f"   - MTFåˆæ„åº¦å¹³å‡: {quantum_stats['mtf_consensus_avg']:.3f}")
    print(f"   - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒå¹³å‡: {quantum_stats['fractal_dimension_avg']:.3f}")
    print(f"   - ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼å¹³å‡: {quantum_stats['entropy_level_avg']:.3f}")
    
    # æœ€çµ‚è©•ä¾¡
    print("\n" + "="*80)
    print("ğŸ† **UltimateMA V3 æœ€çµ‚è©•ä¾¡**")
    print("="*80)
    
    if noise_stats['reduction_percentage'] >= 30:
        print("ğŸ–ï¸  âœ… **QUANTUM NEURAL SUPREMACY ACHIEVED**")
    else:
        print("ğŸ–ï¸  ğŸ“ˆ **QUANTUM EVOLUTION IN PROGRESS**")
    
    print(f"ğŸŒŒ é‡å­ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æŠ€è¡“: {'âœ…' if conf_stats['avg_confidence'] >= 0.3 else 'ğŸ“ˆ'}")
    print(f"âš¡ å‡¦ç†é€Ÿåº¦: {'âœ…' if processing_speed >= 50 else 'ğŸ“ˆ'} {processing_speed:.0f} ãƒ‡ãƒ¼ã‚¿/ç§’")
    print(f"ğŸ¯ ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {'ğŸŒ å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿' if is_real_data else 'ğŸ”¬ åˆæˆãƒ‡ãƒ¼ã‚¿'}")
    
    print(f"\nâœ… UltimateMA V3ãƒ‡ãƒ¢å®Ÿè¡Œå®Œäº†")
    print("ğŸš€ é‡å­ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ»ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ãƒ»ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼çµ±åˆåˆ†æã‚·ã‚¹ãƒ†ãƒ å®Œäº†")


if __name__ == "__main__":
    main() 