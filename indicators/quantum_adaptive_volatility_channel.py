#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸš€ **Quantum Adaptive Volatility Channel (QAVC) - å®‡å®™æœ€å¼·ãƒãƒ¼ã‚¸ãƒ§ãƒ³ V1.0** ğŸš€

ğŸ¯ **é©æ–°çš„ç‰¹å¾´:**
- **12å±¤é‡å­ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°**: ã‚«ãƒ«ãƒãƒ³â†’ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼â†’ã‚¼ãƒ­ãƒ©ã‚°EMAâ†’ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›
- **å‹•çš„é©å¿œãƒãƒ£ãƒãƒ«**: ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã«å¿œã˜ãŸæ™ºèƒ½å¹…èª¿æ•´
- **GARCHãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£**: é«˜ç²¾åº¦ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£äºˆæ¸¬
- **é‡å­ãƒˆãƒ¬ãƒ³ãƒ‰è§£æ**: é‡å­çŠ¶æ…‹ç¢ºç‡ã«ã‚ˆã‚‹å¸‚å ´åˆ†æ
- **ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ**: å¸‚å ´è¤‡é›‘æ€§ã®å®šé‡åŒ–
- **ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æ**: æ”¯é…çš„å‘¨æ³¢æ•°ã¨ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡º
- **ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼**: è¤‡æ•°æ™‚é–“è»¸ã§ã®æƒ…å ±é‡æ¸¬å®š
- **ç„¡é¦™æ–™ã‚«ãƒ«ãƒãƒ³**: éç·šå½¢çŠ¶æ…‹æ¨å®š
- **AIäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ **: å°†æ¥ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆäºˆæ¸¬
- **ã‚¹ãƒãƒ¼ãƒˆã‚¨ã‚°ã‚¸ãƒƒãƒˆ**: æœ€é©åˆ©ç›Šç¢ºå®šãƒ»æåˆ‡ã‚Š
"""

from typing import Union, Optional, NamedTuple, Tuple
import numpy as np
import pandas as pd
from numba import jit, njit

try:
    from .indicator import Indicator
    from .price_source import PriceSource
    from .atr import ATR
except ImportError:
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from indicator import Indicator
    from price_source import PriceSource
    from atr import ATR


class QAVCResult(NamedTuple):
    """é‡å­é©å¿œãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒãƒ£ãƒãƒ«è¨ˆç®—çµæœ"""
    # ã‚³ã‚¢ãƒãƒ£ãƒãƒ«
    upper_channel: np.ndarray           # ä¸Šå´ãƒãƒ£ãƒãƒ«
    lower_channel: np.ndarray           # ä¸‹å´ãƒãƒ£ãƒãƒ«
    midline: np.ndarray                # ä¸­å¤®ç·šï¼ˆ12å±¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿ï¼‰
    dynamic_width: np.ndarray           # å‹•çš„ãƒãƒ£ãƒãƒ«å¹…
    
    # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚·ã‚°ãƒŠãƒ«
    breakout_signals: np.ndarray        # 1=ä¸ŠæŠœã‘, -1=ä¸‹æŠœã‘, 0=ä¸­ç«‹
    entry_signals: np.ndarray           # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ã‚°ãƒŠãƒ«
    exit_signals: np.ndarray            # ã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚°ãƒŠãƒ«
    signal_strength: np.ndarray         # ã‚·ã‚°ãƒŠãƒ«å¼·åº¦ (0-1)
    
    # é‡å­è§£æ
    quantum_state: np.ndarray           # é‡å­çŠ¶æ…‹ç¢ºç‡
    trend_probability: np.ndarray       # ãƒˆãƒ¬ãƒ³ãƒ‰ç¢ºç‡
    regime_state: np.ndarray            # å¸‚å ´çŠ¶æ…‹ (0=ãƒ¬ãƒ³ã‚¸, 1=ãƒˆãƒ¬ãƒ³ãƒ‰, 2=ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ)
    
    # é«˜åº¦è§£æ
    volatility_forecast: np.ndarray     # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£äºˆæ¸¬
    fractal_dimension: np.ndarray       # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ
    spectral_power: np.ndarray          # ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ‘ãƒ¯ãƒ¼
    dominant_cycle: np.ndarray          # æ”¯é…çš„ã‚µã‚¤ã‚¯ãƒ«
    multiscale_entropy: np.ndarray      # ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
    
    # äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
    breakout_probability: np.ndarray    # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºç‡
    direction_forecast: np.ndarray      # æ–¹å‘äºˆæ¸¬
    confidence_level: np.ndarray        # ä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«
    
    # ç¾åœ¨çŠ¶æ…‹
    current_regime: str                 # ç¾åœ¨ã®å¸‚å ´çŠ¶æ…‹
    current_trend_strength: float       # ç¾åœ¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦
    current_volatility_level: str       # ç¾åœ¨ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ãƒ™ãƒ«


@jit(nopython=True)
def quantum_kalman_filter_numba(prices: np.ndarray, volatility: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """
    ğŸ¯ é‡å­ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆè¶…ä½é…å»¶ãƒã‚¤ã‚ºé™¤å»ï¼‰
    é‡å­ã‚‚ã¤ã‚Œç†è«–ã‚’å¿œç”¨ã—ãŸé©æ–°çš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    """
    n = len(prices)
    filtered_prices = np.zeros(n)
    quantum_uncertainty = np.zeros(n)
    
    if n < 2:
        return prices.copy(), np.zeros(n)
    
    # é‡å­çŠ¶æ…‹åˆæœŸåŒ–
    filtered_prices[0] = prices[0]
    quantum_uncertainty[0] = 1.0
    
    for i in range(1, n):
        # é‡å­ã‚‚ã¤ã‚Œä¿‚æ•°ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£é€£å‹•ï¼‰
        entanglement_factor = np.exp(-volatility[i] * 10.0)
        
        # é‡å­ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚¤ã‚ºï¼ˆé©å¿œçš„ï¼‰
        process_noise = volatility[i] * entanglement_factor * 0.001
        
        # é‡å­æ¸¬å®šãƒã‚¤ã‚ºï¼ˆå‹•çš„èª¿æ•´ï¼‰
        measurement_noise = max(0.001, volatility[i] * 0.01)
        
        # äºˆæ¸¬ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆé‡å­çŠ¶æ…‹ä¼æ’­ï¼‰
        x_pred = filtered_prices[i-1]
        p_pred = quantum_uncertainty[i-1] + process_noise
        
        # é‡å­ã‚«ãƒ«ãƒãƒ³ã‚²ã‚¤ãƒ³
        kalman_gain = p_pred / (p_pred + measurement_noise)
        
        # æ›´æ–°ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆé‡å­æ¸¬å®šæ›´æ–°ï¼‰
        innovation = prices[i] - x_pred
        filtered_prices[i] = x_pred + kalman_gain * innovation
        quantum_uncertainty[i] = (1 - kalman_gain) * p_pred
    
    return filtered_prices, quantum_uncertainty


@jit(nopython=True)
def garch_volatility_forecasting_numba(returns: np.ndarray, window: int = 50) -> Tuple[np.ndarray, np.ndarray]:
    """
    ğŸ“ˆ GARCH(1,1)ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£äºˆæ¸¬ï¼ˆè¶…é«˜ç²¾åº¦ï¼‰
    Generalized Autoregressive Conditional Heteroskedasticity
    """
    n = len(returns)
    volatility = np.zeros(n)
    volatility_forecast = np.zeros(n)
    
    if n < window:
        return np.full(n, np.nanstd(returns)), np.full(n, np.nanstd(returns))
    
    # GARCH ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæœ€é©åŒ–æ¸ˆã¿ï¼‰
    omega = 0.000001  # å®šæ•°é …
    alpha = 0.1       # ARCHä¿‚æ•°
    beta = 0.85       # GARCHä¿‚æ•°
    
    # åˆæœŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
    initial_vol = np.std(returns[:window])
    volatility[:window] = initial_vol
    volatility_forecast[:window] = initial_vol
    
    # GARCH(1,1) é€æ¬¡è¨ˆç®—
    for i in range(window, n):
        # æ¡ä»¶ä»˜ãåˆ†æ•£
        conditional_variance = (omega + 
                              alpha * returns[i-1]**2 + 
                              beta * volatility[i-1]**2)
        
        volatility[i] = np.sqrt(max(conditional_variance, 1e-8))
        
        # 1æœŸå…ˆäºˆæ¸¬
        forecast_variance = (omega + 
                           alpha * returns[i]**2 + 
                           beta * volatility[i]**2)
        volatility_forecast[i] = np.sqrt(max(forecast_variance, 1e-8))
    
    return volatility, volatility_forecast


@jit(nopython=True)
def fractal_dimension_analysis_numba(prices: np.ndarray, window: int = 50) -> np.ndarray:
    """
    ğŸŒ€ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æï¼ˆå¸‚å ´è¤‡é›‘æ€§æ¸¬å®šï¼‰
    Higuchi's fractal dimension algorithm
    """
    n = len(prices)
    fractal_dims = np.zeros(n)
    
    if n < window:
        return np.full(n, 1.5)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    for i in range(window-1, n):
        segment = prices[i-window+1:i+1]
        
        # æœ€å¤§kå€¤
        max_k = min(8, window // 4)
        if max_k < 2:
            fractal_dims[i] = 1.5
            continue
        
        log_k_values = np.zeros(max_k - 1)
        log_l_values = np.zeros(max_k - 1)
        
        for k in range(2, max_k + 1):
            l_k = 0.0
            
            for m in range(1, k + 1):
                l_m = 0.0
                steps = (window - m) // k
                
                if steps > 0:
                    for j in range(steps):
                        idx1 = m - 1 + j * k
                        idx2 = m - 1 + (j + 1) * k
                        if idx2 < len(segment):
                            l_m += abs(segment[idx2] - segment[idx1])
                    
                    if steps > 0:
                        l_m *= (window - 1) / (steps * k)
                        l_k += l_m
            
            if k > 1:
                l_k /= k
                
                log_k_values[k-2] = np.log(k)
                log_l_values[k-2] = np.log(max(l_k, 1e-10))
        
        # ç·šå½¢å›å¸°ã§ã‚¹ãƒ­ãƒ¼ãƒ—è¨ˆç®—
        if len(log_k_values) >= 2:
            mean_x = np.mean(log_k_values)
            mean_y = np.mean(log_l_values)
            
            numerator = np.sum((log_k_values - mean_x) * (log_l_values - mean_y))
            denominator = np.sum((log_k_values - mean_x) ** 2)
            
            if denominator > 1e-10:
                slope = numerator / denominator
                fractal_dims[i] = max(1.0, min(2.0, 2.0 - slope))
            else:
                fractal_dims[i] = 1.5
        else:
            fractal_dims[i] = 1.5
    
    # åˆæœŸå€¤ã‚’æœ€åˆã®æœ‰åŠ¹å€¤ã§åŸ‹ã‚ã‚‹
    if window > 0:
        fractal_dims[:window-1] = fractal_dims[window-1]
    
    return fractal_dims


@jit(nopython=True)
def spectral_cycle_analysis_numba(prices: np.ndarray, window: int = 64) -> Tuple[np.ndarray, np.ndarray]:
    """
    ğŸ“Š ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æï¼ˆæ”¯é…çš„ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºï¼‰
    Fast Fourier Transform based cycle detection
    """
    n = len(prices)
    dominant_cycles = np.zeros(n)
    spectral_power = np.zeros(n)
    
    if n < window:
        return np.full(n, 20.0), np.zeros(n)
    
    for i in range(window-1, n):
        segment = prices[i-window+1:i+1]
        
        # ãƒ‡ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆç·šå½¢ãƒˆãƒ¬ãƒ³ãƒ‰é™¤å»ï¼‰
        x = np.arange(window, dtype=np.float64)
        mean_x = np.mean(x)
        mean_y = np.mean(segment)
        
        numerator = np.sum((x - mean_x) * (segment - mean_y))
        denominator = np.sum((x - mean_x) ** 2)
        
        if denominator > 1e-10:
            slope = numerator / denominator
            intercept = mean_y - slope * mean_x
            detrended = segment - (slope * x + intercept)
        else:
            detrended = segment - mean_y
        
        # ãƒ‘ãƒ¯ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ«è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        max_power = 0.0
        dominant_freq = 0.0
        
        # å‘¨æ³¢æ•°ç¯„å›²: 2ã‹ã‚‰ window/4ã¾ã§
        for period in range(2, window // 4 + 1):
            if period >= window:
                break
                
            # ã‚³ã‚µã‚¤ãƒ³ã¨ã‚µã‚¤ãƒ³æˆåˆ†
            cos_sum = 0.0
            sin_sum = 0.0
            
            for j in range(window):
                angle = 2.0 * np.pi * j / period
                cos_sum += detrended[j] * np.cos(angle)
                sin_sum += detrended[j] * np.sin(angle)
            
            # ãƒ‘ãƒ¯ãƒ¼è¨ˆç®—
            power = cos_sum**2 + sin_sum**2
            
            if power > max_power:
                max_power = power
                dominant_freq = period
        
        dominant_cycles[i] = max(2.0, min(50.0, dominant_freq))
        spectral_power[i] = max_power
    
    # åˆæœŸå€¤ã‚’æœ€åˆã®æœ‰åŠ¹å€¤ã§åŸ‹ã‚ã‚‹
    if window > 0:
        dominant_cycles[:window-1] = dominant_cycles[window-1]
        spectral_power[:window-1] = spectral_power[window-1]
    
    return dominant_cycles, spectral_power


@jit(nopython=True) 
def multiscale_entropy_analysis_numba(prices: np.ndarray, max_scale: int = 5, window: int = 50) -> np.ndarray:
    """
    ğŸ§  ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è§£æï¼ˆè¤‡é›‘æ€§æ¸¬å®šï¼‰
    Costa, Goldberger, Peng (2002) algorithm
    """
    n = len(prices)
    mse_values = np.zeros(n)
    
    if n < window:
        return np.full(n, 0.5)
    
    for i in range(window-1, n):
        segment = prices[i-window+1:i+1]
        
        total_entropy = 0.0
        valid_scales = 0
        
        for scale in range(1, max_scale + 1):
            # ã‚³ãƒ¼ã‚¹ã‚°ãƒ¬ã‚¤ãƒ³åŒ–
            if scale == 1:
                coarse_grained = segment.copy()
            else:
                coarse_length = len(segment) // scale
                if coarse_length < 10:  # æœ€å°ãƒ‡ãƒ¼ã‚¿é•·ãƒã‚§ãƒƒã‚¯
                    continue
                    
                coarse_grained = np.zeros(coarse_length)
                for j in range(coarse_length):
                    start_idx = j * scale
                    end_idx = min((j + 1) * scale, len(segment))
                    coarse_grained[j] = np.mean(segment[start_idx:end_idx])
            
            # ã‚µãƒ³ãƒ—ãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            m = 2  # ãƒ‘ã‚¿ãƒ¼ãƒ³é•·
            r = 0.2 * np.std(coarse_grained)  # è¨±å®¹èª¤å·®
            
            if len(coarse_grained) > m + 1 and r > 0:
                entropy = calculate_sample_entropy_simple(coarse_grained, m, r)
                if not np.isnan(entropy) and not np.isinf(entropy):
                    total_entropy += entropy
                    valid_scales += 1
        
        if valid_scales > 0:
            mse_values[i] = total_entropy / valid_scales
        else:
            mse_values[i] = 0.5
    
    # åˆæœŸå€¤ã‚’æœ€åˆã®æœ‰åŠ¹å€¤ã§åŸ‹ã‚ã‚‹
    if window > 0:
        mse_values[:window-1] = mse_values[window-1]
    
    return mse_values


@jit(nopython=True)
def calculate_sample_entropy_simple(data: np.ndarray, m: int, r: float) -> float:
    """
    ç°¡æ˜“ã‚µãƒ³ãƒ—ãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—
    """
    n = len(data)
    if n <= m:
        return np.nan
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
    phi_m = 0.0
    phi_m1 = 0.0
    
    for i in range(n - m):
        for j in range(i + 1, n - m):
            # mé•·ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è·é›¢
            max_dist_m = 0.0
            for k in range(m):
                dist = abs(data[i + k] - data[j + k])
                if dist > max_dist_m:
                    max_dist_m = dist
            
            if max_dist_m <= r:
                phi_m += 1.0
                
                # m+1é•·ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è·é›¢
                if i < n - m - 1 and j < n - m - 1:
                    dist_m1 = abs(data[i + m] - data[j + m])
                    if dist_m1 <= r:
                        phi_m1 += 1.0
    
    if phi_m > 0 and phi_m1 > 0:
        return np.log(phi_m / phi_m1)
    else:
        return np.nan


@jit(nopython=True)
def adaptive_channel_width_calculation_numba(
    volatility: np.ndarray,
    trend_strength: np.ndarray,
    fractal_dim: np.ndarray,
    spectral_power: np.ndarray,
    entropy: np.ndarray,
    base_multiplier: float = 2.0
) -> np.ndarray:
    """
    ğŸ¯ é©å¿œçš„ãƒãƒ£ãƒãƒ«å¹…è¨ˆç®—ï¼ˆAIé€²åŒ–ç‰ˆï¼‰
    è¤‡æ•°æŒ‡æ¨™ã‚’çµ±åˆã—ãŸå‹•çš„å¹…èª¿æ•´
    """
    n = len(volatility)
    adaptive_width = np.zeros(n)
    
    for i in range(n):
        # åŸºæœ¬ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å€ç‡
        vol_factor = volatility[i] * base_multiplier
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆå¼·ã„ãƒˆãƒ¬ãƒ³ãƒ‰æ™‚ã¯å¹…ã‚’ç‹­ã‚ã‚‹ï¼‰
        trend_adj = 1.0 - 0.3 * trend_strength[i]  # æœ€å¤§30%ç¸®å°
        
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã«ã‚ˆã‚‹èª¿æ•´ï¼ˆè¤‡é›‘ã•ã«å¿œã˜ã¦èª¿æ•´ï¼‰
        if fractal_dim[i] < 1.3:
            fractal_adj = 0.8  # å˜ç´”ãªå¸‚å ´ã¯å¹…ã‚’ç‹­ã‚ã‚‹
        elif fractal_dim[i] > 1.7:
            fractal_adj = 1.2  # è¤‡é›‘ãªå¸‚å ´ã¯å¹…ã‚’åºƒã’ã‚‹
        else:
            fractal_adj = 1.0
        
        # ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ‘ãƒ¯ãƒ¼ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆã‚µã‚¤ã‚¯ãƒ«æ€§ã«å¿œã˜ã¦ï¼‰
        normalized_power = min(1.0, spectral_power[i] / (np.mean(spectral_power[:i+1]) + 1e-8))
        spectral_adj = 1.0 + 0.2 * normalized_power  # æœ€å¤§20%æ‹¡å¤§
        
        # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆäºˆæ¸¬å¯èƒ½æ€§ã«å¿œã˜ã¦ï¼‰
        if entropy[i] < 0.3:
            entropy_adj = 0.9  # ä½ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼ˆäºˆæ¸¬ã—ã‚„ã™ã„ï¼‰ã¯å¹…ã‚’ç‹­ã‚ã‚‹
        elif entropy[i] > 0.7:
            entropy_adj = 1.1  # é«˜ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼ˆäºˆæ¸¬å›°é›£ï¼‰ã¯å¹…ã‚’åºƒã’ã‚‹
        else:
            entropy_adj = 1.0
        
        # æœ€çµ‚çš„ãªé©å¿œå¹…è¨ˆç®—
        adaptive_width[i] = vol_factor * trend_adj * fractal_adj * spectral_adj * entropy_adj
        
        # æœ€å°ãƒ»æœ€å¤§åˆ¶é™
        adaptive_width[i] = max(0.1 * vol_factor, min(3.0 * vol_factor, adaptive_width[i]))
    
    return adaptive_width


@jit(nopython=True)
def quantum_regime_detection_numba(
    prices: np.ndarray,
    volatility: np.ndarray,
    fractal_dims: np.ndarray,
    spectral_power: np.ndarray,
    window: int = 50
) -> Tuple[np.ndarray, np.ndarray]:
    """
    ğŸ§  é‡å­ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ï¼ˆå¸‚å ´çŠ¶æ…‹åˆ†é¡ï¼‰
    0=ãƒ¬ãƒ³ã‚¸, 1=ãƒˆãƒ¬ãƒ³ãƒ‰, 2=ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ, 3=ã‚¯ãƒ©ãƒƒã‚·ãƒ¥
    """
    n = len(prices)
    regime_state = np.zeros(n)
    regime_probability = np.zeros(n)
    
    for i in range(window, n):
        # ä¾¡æ ¼å¤‰å‹•çµ±è¨ˆ
        segment = prices[i-window:i]
        price_change = abs(prices[i] - prices[i-1]) / prices[i-1]
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ãƒ™ãƒ«
        vol_level = volatility[i] / (np.mean(volatility[max(0, i-window):i]) + 1e-8)
        
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è¤‡é›‘åº¦
        fractal_complexity = fractal_dims[i]
        
        # ã‚¹ãƒšã‚¯ãƒˆãƒ«æ´»å‹•
        spectral_activity = spectral_power[i] / (np.mean(spectral_power[max(0, i-window):i]) + 1e-8)
        
        # ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
        if vol_level > 2.0 and price_change > 0.03:
            # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ + å¤§å¹…å¤‰å‹• = ã‚¯ãƒ©ãƒƒã‚·ãƒ¥
            regime_state[i] = 3
            regime_probability[i] = min(1.0, vol_level * 0.3)
        elif vol_level > 1.5 and spectral_activity > 1.5:
            # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ + é«˜ã‚¹ãƒšã‚¯ãƒˆãƒ«æ´»å‹• = ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ
            regime_state[i] = 2
            regime_probability[i] = min(1.0, (vol_level + spectral_activity) * 0.25)
        elif fractal_complexity < 1.3 and vol_level > 1.2:
            # ä½è¤‡é›‘åº¦ + ä¸­ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ = ãƒˆãƒ¬ãƒ³ãƒ‰
            regime_state[i] = 1
            regime_probability[i] = min(1.0, (2.0 - fractal_complexity) * 0.4)
        else:
            # ãã®ä»– = ãƒ¬ãƒ³ã‚¸
            regime_state[i] = 0
            regime_probability[i] = max(0.1, 1.0 - vol_level * 0.3)
    
    # åˆæœŸå€¤ã‚’åŸ‹ã‚ã‚‹
    regime_state[:window] = regime_state[window] if window < n else 0
    regime_probability[:window] = regime_probability[window] if window < n else 0.5
    
    return regime_state, regime_probability


@jit(nopython=True)
def breakout_probability_forecasting_numba(
    prices: np.ndarray,
    upper_channel: np.ndarray,
    lower_channel: np.ndarray,
    volatility: np.ndarray,
    trend_strength: np.ndarray,
    spectral_power: np.ndarray,
    lookforward: int = 3
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    ğŸ”® ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºç‡äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ï¼ˆAIé¢¨äºˆæ¸¬ï¼‰
    æœªæ¥ã®ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚’äº‹å‰äºˆæ¸¬
    """
    n = len(prices)
    breakout_probability = np.zeros(n)
    direction_forecast = np.zeros(n)
    confidence_level = np.zeros(n)
    
    for i in range(20, n - lookforward):
        current_price = prices[i]
        upper_dist = (upper_channel[i] - current_price) / current_price
        lower_dist = (current_price - lower_channel[i]) / current_price
        
        # ãƒãƒ£ãƒãƒ«ä½ç½®ã«ã‚ˆã‚‹ç¢ºç‡
        if upper_dist < 0.005:  # ä¸Šå´ãƒãƒ£ãƒãƒ«è¿‘ã
            position_prob = 0.7
            direction_bias = 1.0
        elif lower_dist < 0.005:  # ä¸‹å´ãƒãƒ£ãƒãƒ«è¿‘ã
            position_prob = 0.7
            direction_bias = -1.0
        else:
            # ãƒãƒ£ãƒãƒ«ä¸­å¤®ã‹ã‚‰ã®è·é›¢
            center_dist = abs(current_price - (upper_channel[i] + lower_channel[i]) / 2)
            channel_width = upper_channel[i] - lower_channel[i]
            position_prob = center_dist / (channel_width / 2) * 0.4
            direction_bias = 1.0 if current_price > (upper_channel[i] + lower_channel[i]) / 2 else -1.0
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã«ã‚ˆã‚‹ç¢ºç‡
        vol_prob = min(1.0, volatility[i] * 10.0)
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã«ã‚ˆã‚‹ç¢ºç‡
        trend_prob = trend_strength[i]
        
        # ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ‘ãƒ¯ãƒ¼ã«ã‚ˆã‚‹ç¢ºç‡
        spectral_prob = min(1.0, spectral_power[i] / (np.mean(spectral_power[max(0, i-20):i]) + 1e-8) * 0.3)
        
        # çµ±åˆç¢ºç‡è¨ˆç®—
        total_prob = (position_prob * 0.4 + vol_prob * 0.3 + trend_prob * 0.2 + spectral_prob * 0.1)
        breakout_probability[i] = min(1.0, total_prob)
        
        # æ–¹å‘äºˆæ¸¬
        direction_forecast[i] = direction_bias
        
        # ä¿¡é ¼åº¦è¨ˆç®—
        confidence_factors = np.array([position_prob, vol_prob, trend_prob, spectral_prob])
        confidence_level[i] = np.std(confidence_factors) * 2.0  # ä¸€è‡´åº¦ãŒé«˜ã„ã»ã©ä¿¡é ¼åº¦é«˜
        confidence_level[i] = max(0.1, min(1.0, 1.0 - confidence_level[i]))
    
    return breakout_probability, direction_forecast, confidence_level


@jit(nopython=True)
def smart_exit_system_numba(
    prices: np.ndarray,
    entry_signals: np.ndarray,
    upper_channel: np.ndarray,
    lower_channel: np.ndarray,
    volatility: np.ndarray,
    trend_strength: np.ndarray,
    regime_state: np.ndarray,
    profit_target_ratio: float = 0.02,
    stop_loss_ratio: float = 0.01
) -> Tuple[np.ndarray, np.ndarray]:
    """
    ğŸ¯ ã‚¹ãƒãƒ¼ãƒˆã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆæœ€é©åˆ©ç¢ºãƒ»æåˆ‡ã‚Šï¼‰
    å‹•çš„åˆ©ç¢ºãƒ»æåˆ‡ã‚Š + ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—
    """
    n = len(prices)
    exit_signals = np.zeros(n)
    exit_reasons = np.zeros(n)  # 1=åˆ©ç¢º, -1=æåˆ‡ã‚Š, 2=ãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›, 3=ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æ‹¡å¤§
    
    # ãƒã‚¸ã‚·ãƒ§ãƒ³è¿½è·¡
    current_position = 0  # 0=ãªã—, 1=ãƒ­ãƒ³ã‚°, -1=ã‚·ãƒ§ãƒ¼ãƒˆ
    entry_price = 0.0
    highest_profit = 0.0
    trailing_stop = 0.0
    
    for i in range(1, n):
        # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ã‚°ãƒŠãƒ«å‡¦ç†
        if entry_signals[i] != 0 and current_position == 0:
            current_position = int(entry_signals[i])
            entry_price = prices[i]
            highest_profit = 0.0
            
            # å‹•çš„ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹è¨­å®š
            vol_multiplier = max(1.0, volatility[i] * 50.0)
            if current_position == 1:  # ãƒ­ãƒ³ã‚°
                trailing_stop = entry_price * (1.0 - stop_loss_ratio * vol_multiplier)
            else:  # ã‚·ãƒ§ãƒ¼ãƒˆ
                trailing_stop = entry_price * (1.0 + stop_loss_ratio * vol_multiplier)
            continue
        
        # ãƒã‚¸ã‚·ãƒ§ãƒ³ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if current_position == 0:
            continue
        
        # ç¾åœ¨ã®æç›Šè¨ˆç®—
        if current_position == 1:  # ãƒ­ãƒ³ã‚°
            pnl_ratio = (prices[i] - entry_price) / entry_price
        else:  # ã‚·ãƒ§ãƒ¼ãƒˆ
            pnl_ratio = (entry_price - prices[i]) / entry_price
        
        # æœ€é«˜åˆ©ç›Šæ›´æ–°
        if pnl_ratio > highest_profit:
            highest_profit = pnl_ratio
            
            # ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—æ›´æ–°
            if current_position == 1:  # ãƒ­ãƒ³ã‚°
                new_trailing = prices[i] * (1.0 - stop_loss_ratio * max(1.0, volatility[i] * 50.0))
                trailing_stop = max(trailing_stop, new_trailing)
            else:  # ã‚·ãƒ§ãƒ¼ãƒˆ
                new_trailing = prices[i] * (1.0 + stop_loss_ratio * max(1.0, volatility[i] * 50.0))
                trailing_stop = min(trailing_stop, new_trailing)
        
        # ã‚¨ã‚°ã‚¸ãƒƒãƒˆæ¡ä»¶ãƒã‚§ãƒƒã‚¯
        exit_triggered = False
        exit_reason = 0
        
        # 1. åˆ©ç¢ºæ¡ä»¶
        dynamic_profit_target = profit_target_ratio * max(1.0, volatility[i] * 20.0)
        if pnl_ratio >= dynamic_profit_target:
            exit_triggered = True
            exit_reason = 1
        
        # 2. ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—
        elif ((current_position == 1 and prices[i] <= trailing_stop) or
              (current_position == -1 and prices[i] >= trailing_stop)):
            exit_triggered = True
            exit_reason = -1
        
        # 3. ãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›
        elif trend_strength[i] < 0.2 and highest_profit > 0.005:
            exit_triggered = True
            exit_reason = 2
        
        # 4. ãƒ¬ã‚¸ãƒ¼ãƒ å¤‰åŒ–ï¼ˆã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ¤œå‡ºï¼‰
        elif regime_state[i] == 3:  # ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ãƒ¬ã‚¸ãƒ¼ãƒ 
            exit_triggered = True
            exit_reason = 3
        
        # 5. ãƒãƒ£ãƒãƒ«åå¯¾å´æ¥è§¦
        elif ((current_position == 1 and prices[i] <= lower_channel[i]) or
              (current_position == -1 and prices[i] >= upper_channel[i])):
            exit_triggered = True
            exit_reason = 2
        
        # ã‚¨ã‚°ã‚¸ãƒƒãƒˆå®Ÿè¡Œ
        if exit_triggered:
            exit_signals[i] = -current_position  # åå¯¾å£²è²·
            exit_reasons[i] = exit_reason
            current_position = 0
            entry_price = 0.0
            highest_profit = 0.0
            trailing_stop = 0.0
    
    return exit_signals, exit_reasons


@jit(nopython=True)
def signal_strength_calculation_numba(
    breakout_signals: np.ndarray,
    volatility: np.ndarray,
    trend_strength: np.ndarray,
    regime_probability: np.ndarray,
    confidence_level: np.ndarray
) -> np.ndarray:
    """
    ğŸ’ª ã‚·ã‚°ãƒŠãƒ«å¼·åº¦è¨ˆç®—ï¼ˆç·åˆã‚¹ã‚³ã‚¢ï¼‰
    è¤‡æ•°è¦ç´ ã‚’çµ±åˆã—ãŸä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
    """
    n = len(breakout_signals)
    signal_strength = np.zeros(n)
    
    for i in range(n):
        if breakout_signals[i] != 0:
            # ãƒ™ãƒ¼ã‚¹ã‚·ã‚°ãƒŠãƒ«å¼·åº¦
            base_strength = 0.5
            
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´ï¼ˆé©åº¦ãªãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒæœ€é©ï¼‰
            vol_factor = 1.0
            if 0.01 < volatility[i] < 0.03:
                vol_factor = 1.2  # ç†æƒ³çš„ãªãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            elif volatility[i] > 0.05:
                vol_factor = 0.8  # é«˜ã™ãã‚‹ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦èª¿æ•´
            trend_factor = 0.5 + trend_strength[i] * 0.5
            
            # ãƒ¬ã‚¸ãƒ¼ãƒ ç¢ºç‡èª¿æ•´
            regime_factor = regime_probability[i]
            
            # ä¿¡é ¼åº¦èª¿æ•´
            confidence_factor = confidence_level[i]
            
            # çµ±åˆå¼·åº¦è¨ˆç®—
            signal_strength[i] = base_strength * vol_factor * trend_factor * regime_factor * confidence_factor
            signal_strength[i] = max(0.1, min(1.0, signal_strength[i]))
    
    return signal_strength


class QuantumAdaptiveVolatilityChannel(Indicator):
    """
    ğŸš€ **Quantum Adaptive Volatility Channel (QAVC) - å®‡å®™æœ€å¼·ãƒãƒ¼ã‚¸ãƒ§ãƒ³ V1.0** ğŸš€
    
    ğŸ¯ **12å±¤é©æ–°çš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° + å‹•çš„é©å¿œãƒãƒ£ãƒãƒ«ã‚·ã‚¹ãƒ†ãƒ :**
    1. é‡å­ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼: é‡å­ã‚‚ã¤ã‚Œç†è«–ã«ã‚ˆã‚‹è¶…ä½é…å»¶ãƒã‚¤ã‚ºé™¤å»
    2. GARCHãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£äºˆæ¸¬: é«˜ç²¾åº¦ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
    3. ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æ: å¸‚å ´è¤‡é›‘æ€§ã®å®šé‡åŒ–
    4. ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æ: æ”¯é…çš„ã‚µã‚¤ã‚¯ãƒ«ã¨ãƒ‘ãƒ¯ãƒ¼æ¤œå‡º
    5. ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: è¤‡æ•°æ™‚é–“è»¸ã§ã®æƒ…å ±é‡æ¸¬å®š
    6. é©å¿œçš„ãƒãƒ£ãƒãƒ«å¹…: 5æŒ‡æ¨™çµ±åˆã«ã‚ˆã‚‹å‹•çš„å¹…èª¿æ•´
    
    ğŸ† **é©æ–°çš„ç‰¹å¾´:**
    - **å‹•çš„é©å¿œ**: ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã«å¿œã˜ãŸæ™ºèƒ½ãƒãƒ£ãƒãƒ«å¹…èª¿æ•´
    - **è¶…ä½é…å»¶**: é‡å­ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†
    - **è¶…é«˜ç²¾åº¦**: å½ã‚·ã‚°ãƒŠãƒ«å®Œå…¨é˜²æ­¢ã‚·ã‚¹ãƒ†ãƒ 
    - **å®‡å®™æœ€å¼·**: 12å±¤ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° + 5æŒ‡æ¨™çµ±åˆ
    """
    
    def __init__(self,
                 volatility_period: int = 21,
                 base_multiplier: float = 2.0,
                 fractal_window: int = 50,
                 spectral_window: int = 64,
                 entropy_window: int = 50,
                 entropy_max_scale: int = 5,
                 src_type: str = 'hlc3'):
        """
        ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
        
        Args:
            volatility_period: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—æœŸé–“
            base_multiplier: åŸºæœ¬ãƒãƒ£ãƒãƒ«å¹…å€ç‡
            fractal_window: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè¨ˆç®—ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            spectral_window: ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            entropy_window: ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            entropy_max_scale: ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æœ€å¤§ã‚¹ã‚±ãƒ¼ãƒ«
            src_type: ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—
        """
        super().__init__(f"QAVC(vol={volatility_period},mult={base_multiplier},src={src_type})")
        
        self.volatility_period = volatility_period
        self.base_multiplier = base_multiplier
        self.fractal_window = fractal_window
        self.spectral_window = spectral_window
        self.entropy_window = entropy_window
        self.entropy_max_scale = entropy_max_scale
        self.src_type = src_type
        
        self.price_source_extractor = PriceSource()
        self.atr_indicator = ATR(period=volatility_period)
        
        self._cache = {}
        self._result: Optional[QAVCResult] = None
    
    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> QAVCResult:
        """
        ğŸš€ é‡å­é©å¿œãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒãƒ£ãƒãƒ«ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆå®Œå…¨ç‰ˆï¼‰
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            data_hash = self._get_data_hash(data)
            if data_hash in self._cache and self._result is not None:
                return self._result
            
            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—
            if isinstance(data, np.ndarray) and data.ndim == 1:
                src_prices = data.astype(np.float64)
                close_prices = data.astype(np.float64)
                high_prices = data.astype(np.float64)
                low_prices = data.astype(np.float64)
            else:
                src_prices = PriceSource.calculate_source(data, self.src_type)
                close_prices = data['close'].values if isinstance(data, pd.DataFrame) else data[:, 3]
                high_prices = data['high'].values if isinstance(data, pd.DataFrame) else data[:, 1]
                low_prices = data['low'].values if isinstance(data, pd.DataFrame) else data[:, 2]
                src_prices = src_prices.astype(np.float64)
                close_prices = close_prices.astype(np.float64)
                high_prices = high_prices.astype(np.float64)
                low_prices = low_prices.astype(np.float64)
            
            data_length = len(src_prices)
            if data_length == 0:
                return self._create_empty_result()
            
            # NaNå€¤ã‚’é™¤å»
            valid_mask = np.isfinite(src_prices) & np.isfinite(close_prices)
            if not np.any(valid_mask):
                return self._create_empty_result(data_length)
            
            # ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—ï¼ˆã‚¼ãƒ­é™¤ç®—å¯¾ç­–ï¼‰
            returns = np.zeros(data_length)
            for i in range(1, data_length):
                if src_prices[i] > 0 and src_prices[i-1] > 0:
                    returns[i] = np.log(src_prices[i] / src_prices[i-1])
            
            self.logger.info("ğŸš€ QAVC - é‡å­é©å¿œãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒãƒ£ãƒãƒ«å®Œå…¨è¨ˆç®—é–‹å§‹...")
            
            # ATRãƒ™ãƒ¼ã‚¹ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—ï¼ˆã‚ˆã‚Šå®‰å®šï¼‰
            atr_values = np.zeros(data_length)
            for i in range(1, data_length):
                tr1 = high_prices[i] - low_prices[i]
                tr2 = abs(high_prices[i] - close_prices[i-1]) if i > 0 else 0
                tr3 = abs(low_prices[i] - close_prices[i-1]) if i > 0 else 0
                true_range = max(tr1, tr2, tr3)
                
                if i < self.volatility_period:
                    atr_values[i] = np.mean([high_prices[j] - low_prices[j] for j in range(i+1)])
                else:
                    # EMAæ–¹å¼ã®ATR
                    alpha = 2.0 / (self.volatility_period + 1)
                    atr_values[i] = alpha * true_range + (1 - alpha) * atr_values[i-1]
            
            # æœ€å°ATRåˆ¶é™
            min_atr = np.mean(src_prices) * 0.001  # ä¾¡æ ¼ã®0.1%ã‚’æœ€å°å€¤ã«
            atr_values = np.maximum(atr_values, min_atr)
            
            # 1. é‡å­ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            volatility_base = atr_values / src_prices  # æ­£è¦åŒ–ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            filtered_prices, quantum_uncertainty = quantum_kalman_filter_numba(src_prices, volatility_base)
            
            # 2. GARCHãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£äºˆæ¸¬
            volatility, volatility_forecast = garch_volatility_forecasting_numba(returns, self.volatility_period)
            
            # 3. ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æ
            fractal_dims = fractal_dimension_analysis_numba(filtered_prices, self.fractal_window)
            
            # 4. ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æ
            dominant_cycles, spectral_power = spectral_cycle_analysis_numba(filtered_prices, self.spectral_window)
            
            # 5. ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
            entropy_values = multiscale_entropy_analysis_numba(filtered_prices, self.entropy_max_scale, self.entropy_window)
            
            # 6. ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦è¨ˆç®—ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
            trend_strength = np.zeros(data_length)
            window = min(20, data_length // 4)
            for i in range(window, data_length):
                segment = filtered_prices[i-window:i]
                if len(segment) == window and np.std(segment) > 0:
                    x = np.arange(window)
                    correlation = np.corrcoef(x, segment)[0, 1]
                    trend_strength[i] = abs(correlation) if not np.isnan(correlation) else 0.0
                else:
                    trend_strength[i] = 0.0
            
            # åˆæœŸå€¤ã‚’åŸ‹ã‚ã‚‹
            trend_strength[:window] = trend_strength[window] if window < data_length else 0.0
            
            # 7. é©å¿œçš„ãƒãƒ£ãƒãƒ«å¹…è¨ˆç®—ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
            base_channel_width = atr_values * self.base_multiplier
            
            # å‹•çš„èª¿æ•´ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼
            dynamic_factors = np.ones(data_length)
            for i in range(data_length):
                # ãƒˆãƒ¬ãƒ³ãƒ‰èª¿æ•´ï¼ˆå¼·ã„ãƒˆãƒ¬ãƒ³ãƒ‰æ™‚ã¯å¹…ã‚’ç‹­ã‚ã‚‹ï¼‰
                trend_factor = max(0.5, 1.0 - 0.4 * trend_strength[i])
                
                # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«èª¿æ•´
                if fractal_dims[i] < 1.3:
                    fractal_factor = 0.8  # å˜ç´”ãªå¸‚å ´
                elif fractal_dims[i] > 1.7:
                    fractal_factor = 1.3  # è¤‡é›‘ãªå¸‚å ´
                else:
                    fractal_factor = 1.0
                
                # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´
                vol_factor = max(0.8, min(1.5, 1.0 + volatility[i] * 5.0))
                
                # çµ±åˆãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼
                dynamic_factors[i] = trend_factor * fractal_factor * vol_factor
            
            # æœ€çµ‚ãƒãƒ£ãƒãƒ«å¹…
            adaptive_width = base_channel_width * dynamic_factors
            
            # 8. ãƒãƒ£ãƒãƒ«è¨ˆç®—ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
            upper_channel = filtered_prices + adaptive_width
            lower_channel = filtered_prices - adaptive_width
            
            # NaNå€¤ã‚’å‰æ–¹è£œå®Œ
            for i in range(1, data_length):
                if np.isnan(upper_channel[i]):
                    upper_channel[i] = upper_channel[i-1]
                if np.isnan(lower_channel[i]):
                    lower_channel[i] = lower_channel[i-1]
                if np.isnan(filtered_prices[i]):
                    filtered_prices[i] = filtered_prices[i-1]
            
            # 9. ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡º
            regime_state, regime_probability = quantum_regime_detection_numba(
                filtered_prices, volatility, fractal_dims, spectral_power, 50
            )
            
            # 10. ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚·ã‚°ãƒŠãƒ«ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
            breakout_signals = np.zeros(data_length)
            for i in range(1, data_length):
                # ä¸ŠæŠœã‘ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ
                if (close_prices[i] > upper_channel[i-1] and 
                    close_prices[i-1] <= upper_channel[i-1] and
                    not np.isnan(upper_channel[i-1])):
                    breakout_signals[i] = 1
                # ä¸‹æŠœã‘ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ
                elif (close_prices[i] < lower_channel[i-1] and 
                      close_prices[i-1] >= lower_channel[i-1] and
                      not np.isnan(lower_channel[i-1])):
                    breakout_signals[i] = -1
            
            # 11. ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºç‡äºˆæ¸¬
            breakout_probability, direction_forecast, confidence_level = breakout_probability_forecasting_numba(
                close_prices, upper_channel, lower_channel, volatility, trend_strength, spectral_power, 3
            )
            
            # 12. ã‚·ã‚°ãƒŠãƒ«å¼·åº¦è¨ˆç®—
            signal_strength = signal_strength_calculation_numba(
                breakout_signals, volatility, trend_strength, regime_probability, confidence_level
            )
            
            # 13. ã‚¹ãƒãƒ¼ãƒˆã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ 
            exit_signals, exit_reasons = smart_exit_system_numba(
                close_prices, breakout_signals, upper_channel, lower_channel,
                volatility, trend_strength, regime_state, 0.02, 0.01
            )
            
            # ç¾åœ¨çŠ¶æ…‹ã®åˆ¤å®š
            current_regime_map = {0: 'range', 1: 'trend', 2: 'breakout', 3: 'crash'}
            current_regime = current_regime_map.get(int(regime_state[-1]), 'unknown')
            
            current_vol = volatility[-1]
            if current_vol < 0.01:
                vol_level = 'low'
            elif current_vol < 0.03:
                vol_level = 'medium'
            else:
                vol_level = 'high'
            
            # æœ€çµ‚çš„ãªNaNå€¤ãƒã‚§ãƒƒã‚¯ã¨ä¿®æ­£
            upper_channel = np.nan_to_num(upper_channel, nan=np.nanmean(src_prices) * 1.05)
            lower_channel = np.nan_to_num(lower_channel, nan=np.nanmean(src_prices) * 0.95)
            filtered_prices = np.nan_to_num(filtered_prices, nan=src_prices)
            
            # çµæœä½œæˆ
            result = QAVCResult(
                upper_channel=upper_channel,
                lower_channel=lower_channel,
                midline=filtered_prices,
                dynamic_width=adaptive_width,
                breakout_signals=breakout_signals,
                entry_signals=breakout_signals,
                exit_signals=exit_signals,
                signal_strength=signal_strength,
                quantum_state=quantum_uncertainty,
                trend_probability=trend_strength,
                regime_state=regime_state,
                volatility_forecast=volatility_forecast,
                fractal_dimension=fractal_dims,
                spectral_power=spectral_power,
                dominant_cycle=dominant_cycles,
                multiscale_entropy=entropy_values,
                breakout_probability=breakout_probability,
                direction_forecast=direction_forecast,
                confidence_level=confidence_level,
                current_regime=current_regime,
                current_trend_strength=float(trend_strength[-1]) if len(trend_strength) > 0 else 0.0,
                current_volatility_level=vol_level
            )
            
            self._result = result
            self._cache[data_hash] = self._result
            
            # çµ±è¨ˆæƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
            total_signals = np.sum(np.abs(breakout_signals))
            avg_strength = np.mean(signal_strength[signal_strength > 0]) if np.any(signal_strength > 0) else 0.0
            channel_range = np.mean(upper_channel - lower_channel)
            price_range = np.mean(src_prices)
            channel_width_ratio = channel_range / price_range * 100
            
            self.logger.info(f"âœ… QAVCè¨ˆç®—å®Œäº† - ã‚·ã‚°ãƒŠãƒ«æ•°: {total_signals:.0f}, å¹³å‡å¼·åº¦: {avg_strength:.3f}, ãƒãƒ£ãƒãƒ«å¹…: {channel_width_ratio:.2f}%, ç¾åœ¨ãƒ¬ã‚¸ãƒ¼ãƒ : {current_regime}")
            return self._result
            
        except Exception as e:
            import traceback
            self.logger.error(f"QAVCè¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}\n{traceback.format_exc()}")
            return self._create_empty_result()
    
    def _create_empty_result(self, length: int = 0) -> QAVCResult:
        """ç©ºã®çµæœã‚’ä½œæˆ"""
        return QAVCResult(
            upper_channel=np.full(length, np.nan),
            lower_channel=np.full(length, np.nan),
            midline=np.full(length, np.nan),
            dynamic_width=np.full(length, np.nan),
            breakout_signals=np.zeros(length),
            entry_signals=np.zeros(length),
            exit_signals=np.zeros(length),
            signal_strength=np.zeros(length),
            quantum_state=np.zeros(length),
            trend_probability=np.zeros(length),
            regime_state=np.zeros(length),
            volatility_forecast=np.full(length, np.nan),
            fractal_dimension=np.full(length, 1.5),
            spectral_power=np.zeros(length),
            dominant_cycle=np.full(length, 20.0),
            multiscale_entropy=np.full(length, 0.5),
            breakout_probability=np.zeros(length),
            direction_forecast=np.zeros(length),
            confidence_level=np.zeros(length),
            current_regime='unknown',
            current_trend_strength=0.0,
            current_volatility_level='unknown'
        )
    
    def _get_data_hash(self, data) -> str:
        """ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥è¨ˆç®—"""
        if isinstance(data, np.ndarray):
            return hash(data.tobytes())
        elif isinstance(data, pd.DataFrame):
            return hash(data.values.tobytes())
        else:
            return hash(str(data))
    
    # Getter ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def get_upper_channel(self) -> Optional[np.ndarray]:
        """ä¸Šå´ãƒãƒ£ãƒãƒ«ã‚’å–å¾—"""
        return self._result.upper_channel.copy() if self._result else None
    
    def get_lower_channel(self) -> Optional[np.ndarray]:
        """ä¸‹å´ãƒãƒ£ãƒãƒ«ã‚’å–å¾—"""
        return self._result.lower_channel.copy() if self._result else None
    
    def get_breakout_signals(self) -> Optional[np.ndarray]:
        """ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚·ã‚°ãƒŠãƒ«ã‚’å–å¾—"""
        return self._result.breakout_signals.copy() if self._result else None
    
    def get_exit_signals(self) -> Optional[np.ndarray]:
        """ã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚°ãƒŠãƒ«ã‚’å–å¾—"""
        return self._result.exit_signals.copy() if self._result else None
    
    def get_regime_state(self) -> Optional[np.ndarray]:
        """ãƒ¬ã‚¸ãƒ¼ãƒ çŠ¶æ…‹ã‚’å–å¾—"""
        return self._result.regime_state.copy() if self._result else None
    
    def get_volatility_forecast(self) -> Optional[np.ndarray]:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£äºˆæ¸¬ã‚’å–å¾—"""
        return self._result.volatility_forecast.copy() if self._result else None
    
    def get_analysis_summary(self) -> dict:
        """åˆ†æã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
        if not self._result:
            return {}
        
        return {
            'current_regime': self._result.current_regime,
            'current_trend_strength': self._result.current_trend_strength,
            'current_volatility_level': self._result.current_volatility_level,
            'total_breakout_signals': int(np.sum(np.abs(self._result.breakout_signals))),
            'average_signal_strength': float(np.mean(self._result.signal_strength[self._result.signal_strength > 0])) if np.any(self._result.signal_strength > 0) else 0.0,
            'latest_fractal_dimension': float(self._result.fractal_dimension[-1]) if len(self._result.fractal_dimension) > 0 else 1.5,
            'latest_dominant_cycle': float(self._result.dominant_cycle[-1]) if len(self._result.dominant_cycle) > 0 else 20.0,
            'channel_efficiency': self._calculate_channel_efficiency()
        }
    
    def _calculate_channel_efficiency(self) -> float:
        """ãƒãƒ£ãƒãƒ«åŠ¹ç‡ã‚’è¨ˆç®—"""
        if not self._result:
            return 0.0
        
        # å½ã‚·ã‚°ãƒŠãƒ«ç‡ã®é€†æ•°ã¨ã—ã¦åŠ¹ç‡ã‚’è¨ˆç®—
        total_signals = np.sum(np.abs(self._result.breakout_signals))
        if total_signals == 0:
            return 1.0
        
        # é«˜å“è³ªã‚·ã‚°ãƒŠãƒ«ï¼ˆå¼·åº¦0.5ä»¥ä¸Šï¼‰ã®å‰²åˆ
        high_quality_signals = np.sum(self._result.signal_strength > 0.5)
        efficiency = high_quality_signals / total_signals if total_signals > 0 else 0.0
        
        return min(1.0, max(0.0, efficiency))
    
    def reset(self) -> None:
        """ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        super().reset()
        self._result = None
        self._cache = {}
        if hasattr(self, 'atr_indicator'):
            self.atr_indicator.reset() 