#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ¯ **X_ATR - æ‹¡å¼µçš„Average True Range** ğŸ¯

STRã¨ATRã‚’çµ±åˆã—ã€True Rangeè¨ˆç®—æ–¹æ³•ã¨ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æ‰‹æ³•ã‚’é¸æŠå¯èƒ½ã«ã—ãŸ
æ¬¡ä¸–ä»£ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã€‚

ğŸŒŸ **ä¸»è¦æ©Ÿèƒ½:**
1. **TRè¨ˆç®—æ–¹æ³•ã®é¸æŠ**: ATRãƒ™ãƒ¼ã‚¹ vs STRãƒ™ãƒ¼ã‚¹
2. **çµ±åˆã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°**: unified_smootherã«ã‚ˆã‚‹å¤šæ§˜ãªã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æ‰‹æ³•
3. **ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ±åˆ**: é«˜å€¤ãƒ»å®‰å€¤ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦ãƒã‚¤ã‚ºé™¤å»
4. **å‡¦ç†ãƒ•ãƒ­ãƒ¼**: ã‚½ãƒ¼ã‚¹ä¾¡æ ¼â†’ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼â†’TRè¨ˆç®—â†’ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°

ğŸ“Š **å‡¦ç†é †åº:**
1. ãƒ—ãƒ©ã‚¤ã‚¹ã‚½ãƒ¼ã‚¹å–å¾—
2. ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
3. True Rangeè¨ˆç®—ï¼ˆATRã¾ãŸã¯STRæ–¹å¼ï¼‰
4. ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°é©ç”¨

ğŸ”§ **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- tr_method: 'atr' ã¾ãŸã¯ 'str' - True Rangeè¨ˆç®—æ–¹æ³•
- smoother_type: ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æ‰‹æ³•ï¼ˆFRAMA, Super Smoother, Ultimate Smoother, ZLEMAï¼‰
- enable_kalman: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä½¿ç”¨ãƒ•ãƒ©ã‚°
- kalman_type: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç¨®åˆ¥
- period_mode: 'fixed' ã¾ãŸã¯ 'dynamic' - æœŸé–“ãƒ¢ãƒ¼ãƒ‰
- cycle_detector_type: ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã‚¿ã‚¤ãƒ—ï¼ˆå‹•çš„æœŸé–“ãƒ¢ãƒ¼ãƒ‰ç”¨ï¼‰
"""

from dataclasses import dataclass
from typing import Union, Optional, Dict, Any, Tuple
import numpy as np
import pandas as pd
from numba import njit
import traceback


@njit(fastmath=True, cache=True)
def calculate_percentage_values(
    values: np.ndarray,
    close_prices: np.ndarray
) -> np.ndarray:
    """
    é‡‘é¡ãƒ™ãƒ¼ã‚¹ã®å€¤ã‚’%ãƒ™ãƒ¼ã‚¹ã«å¤‰æ›ã™ã‚‹ï¼ˆNumbaæœ€é©åŒ–ç‰ˆï¼‰
    
    Args:
        values: é‡‘é¡ãƒ™ãƒ¼ã‚¹ã®å€¤ã®é…åˆ—
        close_prices: çµ‚å€¤ã®é…åˆ—
        
    Returns:
        %ãƒ™ãƒ¼ã‚¹ã®å€¤ã®é…åˆ—
    """
    length = len(values)
    percentage_values = np.full(length, np.nan, dtype=np.float64)
    
    for i in range(length):
        if not np.isnan(values[i]) and not np.isnan(close_prices[i]) and close_prices[i] > 0:
            percentage_values[i] = (values[i] / close_prices[i]) * 100.0
    
    return percentage_values


@njit(fastmath=True, cache=True)
def calculate_str_percentile(str_values: np.ndarray, lookback_period: int) -> np.ndarray:
    """
    STRãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«è¨ˆç®— - é«˜ç²¾åº¦ç‰ˆ
    
    Args:
        str_values: STRå€¤ã®é…åˆ—
        lookback_period: ãƒ«ãƒƒã‚¯ãƒãƒƒã‚¯æœŸé–“
        
    Returns:
        ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«å€¤ã®é…åˆ—ï¼ˆ0-1ã®ç¯„å›²ï¼‰
    """
    length = len(str_values)
    percentiles = np.zeros(length, dtype=np.float64)
    
    for i in range(lookback_period, length):
        # éå»ã®STRå€¤ã‚’å–å¾—
        historical_values = str_values[i-lookback_period:i]
        
        # ç¾åœ¨å€¤ã¨ã®æ¯”è¼ƒ
        current_value = str_values[i]
        
        # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«è¨ˆç®—ï¼ˆé«˜ç²¾åº¦ï¼‰
        count_below = 0
        count_equal = 0
        
        for val in historical_values:
            if val < current_value:
                count_below += 1
            elif val == current_value:
                count_equal += 1
        
        # ã‚ˆã‚Šæ­£ç¢ºãªãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«è¨ˆç®—
        if len(historical_values) > 0:
            percentiles[i] = (count_below + count_equal * 0.5) / len(historical_values)
        else:
            percentiles[i] = 0.5
    
    return percentiles


@njit(fastmath=True, cache=True)
def calculate_volatility_classification(
    str_percentiles: np.ndarray,
    x_atr_values: np.ndarray,
    low_threshold: float = 0.3,
    high_threshold: float = 0.7
) -> tuple:
    """
    ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã«åŸºã¥ããƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†é¡
    
    Args:
        str_percentiles: STRãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«å€¤
        x_atr_values: X_ATRå€¤
        low_threshold: ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£é–¾å€¤
        high_threshold: é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£é–¾å€¤
        
    Returns:
        Tuple[np.ndarray, np.ndarray]: (ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çŠ¶æ…‹, ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å¼·åº¦)
    """
    length = len(str_percentiles)
    volatility_state = np.full(length, np.nan, dtype=np.float64)
    volatility_intensity = np.full(length, np.nan, dtype=np.float64)
    
    for i in range(length):
        if not np.isnan(str_percentiles[i]):
            percentile = str_percentiles[i]
            
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çŠ¶æ…‹ã®åˆ†é¡
            if percentile <= low_threshold:
                volatility_state[i] = 1.0  # ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            elif percentile >= high_threshold:
                volatility_state[i] = -1.0  # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            else:
                volatility_state[i] = 0.0  # ä¸­ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å¼·åº¦ï¼ˆ0-1ã®ç¯„å›²ã§æ­£è¦åŒ–ï¼‰
            if percentile <= 0.5:
                # ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å´ã®å¼·åº¦
                volatility_intensity[i] = (0.5 - percentile) / 0.5
            else:
                # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å´ã®å¼·åº¦
                volatility_intensity[i] = (percentile - 0.5) / 0.5
    
    return volatility_state, volatility_intensity


@njit(fastmath=True, cache=True)
def calculate_midline_and_volatility_signal(
    x_atr: np.ndarray,
    midline_period: int = 100
) -> tuple:
    """
    ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¨ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ä¿¡å·ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆNumbaæœ€é©åŒ–ç‰ˆï¼‰
    
    Args:
        x_atr: X_ATRå€¤ã®é…åˆ—
        midline_period: ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¨ˆç®—æœŸé–“
        
    Returns:
        Tuple[np.ndarray, np.ndarray]: (ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³, ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ä¿¡å·)
    """
    length = len(x_atr)
    midline = np.full(length, np.nan, dtype=np.float64)
    volatility_signal = np.full(length, np.nan, dtype=np.float64)
    
    for i in range(midline_period - 1, length):
        # æœŸé–“å†…ã®æœ€é«˜å€¤ã¨æœ€å®‰å€¤ã‚’è¨ˆç®—
        period_data = x_atr[i - midline_period + 1:i + 1]
        
        # NaNå€¤ã‚’é™¤å¤–
        valid_data = period_data[~np.isnan(period_data)]
        
        if len(valid_data) >= midline_period // 2:
            period_max = np.max(valid_data)
            period_min = np.min(valid_data)
            
            # ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ = (æœ€é«˜å€¤ + æœ€å®‰å€¤) / 2
            midline[i] = (period_max + period_min) / 2.0
            
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ä¿¡å·ã®åˆ¤å®š
            if not np.isnan(x_atr[i]):
                if x_atr[i] > midline[i]:
                    volatility_signal[i] = -1.0  # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                else:
                    volatility_signal[i] = 1.0   # ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
    
    return midline, volatility_signal

try:
    from ..indicator import Indicator
    from ..price_source import PriceSource
    from ..smoother.unified_smoother import UnifiedSmoother
    from ..kalman.unified_kalman import UnifiedKalman
    # STRã¨ATRã®ã‚³ã‚¢é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from ..str import calculate_true_range_values as str_calculate_true_range_values
    from ..atr import calculate_true_range as atr_calculate_true_range
except ImportError:
    # Fallback for standalone execution
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from indicator import Indicator
    from price_source import PriceSource
    from smoother.unified_smoother import UnifiedSmoother
    from kalman.unified_kalman import UnifiedKalman
    from str import calculate_true_range_values as str_calculate_true_range_values
    from atr import calculate_true_range as atr_calculate_true_range


@dataclass
class XATRResult:
    """X_ATRã®è¨ˆç®—çµæœ"""
    values: np.ndarray                    # ãƒ¡ã‚¤ãƒ³ã®X_ATRå€¤ï¼ˆé‡‘é¡ãƒ™ãƒ¼ã‚¹ï¼‰
    values_percentage: np.ndarray         # X_ATRå€¤ï¼ˆ%ãƒ™ãƒ¼ã‚¹ï¼‰
    true_range: np.ndarray               # True Rangeå€¤ï¼ˆé‡‘é¡ãƒ™ãƒ¼ã‚¹ï¼‰
    true_range_percentage: np.ndarray    # True Rangeå€¤ï¼ˆ%ãƒ™ãƒ¼ã‚¹ï¼‰
    raw_high: np.ndarray                 # å…ƒã®é«˜å€¤
    raw_low: np.ndarray                  # å…ƒã®å®‰å€¤
    raw_close: np.ndarray                # å…ƒã®çµ‚å€¤ï¼ˆ%è¨ˆç®—ç”¨ï¼‰
    filtered_high: Optional[np.ndarray]  # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®é«˜å€¤ï¼ˆä½¿ç”¨æ™‚ã®ã¿ï¼‰
    filtered_low: Optional[np.ndarray]   # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®å®‰å€¤ï¼ˆä½¿ç”¨æ™‚ã®ã¿ï¼‰
    tr_method: str                       # ä½¿ç”¨ã•ã‚ŒãŸTRè¨ˆç®—æ–¹æ³•
    smoother_type: str                   # ä½¿ç”¨ã•ã‚ŒãŸã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¿ã‚¤ãƒ—
    parameters: Dict[str, Any]           # ä½¿ç”¨ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    dynamic_periods: Optional[np.ndarray] # å‹•çš„æœŸé–“é…åˆ—ï¼ˆå‹•çš„ãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿ï¼‰
    midline: np.ndarray                  # ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³å€¤ï¼ˆé‡‘é¡ãƒ™ãƒ¼ã‚¹ï¼‰
    midline_percentage: np.ndarray       # ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³å€¤ï¼ˆ%ãƒ™ãƒ¼ã‚¹ï¼‰
    volatility_signal: np.ndarray        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ä¿¡å·ï¼ˆ1=ä½ãƒœãƒ©ã€-1=é«˜ãƒœãƒ©ï¼‰
    # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ
    str_percentiles: Optional[np.ndarray]    # STRãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«å€¤
    volatility_state: Optional[np.ndarray]   # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çŠ¶æ…‹ï¼ˆ-1=é«˜ã€0=ä¸­ã€1=ä½ï¼‰
    volatility_intensity: Optional[np.ndarray] # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å¼·åº¦ï¼ˆ0-1ï¼‰


class XATR(Indicator):
    """
    X_ATRï¼ˆæ‹¡å¼µçš„Average True Rangeï¼‰ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
    
    STRã¨ATRã‚’çµ±åˆã—ã€TRè¨ˆç®—æ–¹æ³•ã¨ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æ‰‹æ³•ã‚’é¸æŠå¯èƒ½ã«ã—ãŸ
    æ¬¡ä¸–ä»£ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã€‚
    
    ç‰¹å¾´:
    - TRè¨ˆç®—æ–¹æ³•ã®é¸æŠï¼ˆATRãƒ™ãƒ¼ã‚¹ vs STRãƒ™ãƒ¼ã‚¹ï¼‰
    - çµ±åˆã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆunified_smootherï¼‰
    - ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ±åˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    - å‹•çš„é©å¿œæœŸé–“å¯¾å¿œï¼ˆã‚¨ãƒ¼ãƒ©ãƒ¼ã‚ºçµ±åˆã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ï¼‰
    - çµ±ä¸€ã•ã‚ŒãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
    """
    
    def __init__(
        self,
        period: float = 12.0,
        tr_method: str = 'str',          # 'atr' ã¾ãŸã¯ 'str'
        smoother_type: str = 'frama',    # unified_smootherã®ç¨®åˆ¥
        src_type: str = 'close',         # ãƒ—ãƒ©ã‚¤ã‚¹ã‚½ãƒ¼ã‚¹
        enable_kalman: bool = False,     # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä½¿ç”¨ãƒ•ãƒ©ã‚°
        kalman_type: str = 'unscented',  # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç¨®åˆ¥
        # å‹•çš„é©å¿œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        period_mode: str = 'fixed',      # 'fixed' ã¾ãŸã¯ 'dynamic'
        cycle_detector_type: str = 'absolute_ultimate',
        cycle_detector_cycle_part: float = 0.5,
        cycle_detector_max_cycle: int = 55,
        cycle_detector_min_cycle: int = 5,
        cycle_period_multiplier: float = 1.0,
        cycle_detector_period_range: Tuple[int, int] = (5, 120),
        # ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        midline_period: int = 100,       # ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¨ˆç®—æœŸé–“
        # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        enable_percentile_analysis: bool = True,  # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹
        percentile_lookback_period: int = 50,     # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«è¨ˆç®—ã®ãƒ«ãƒƒã‚¯ãƒãƒƒã‚¯æœŸé–“
        percentile_low_threshold: float = 0.25,   # ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£é–¾å€¤
        percentile_high_threshold: float = 0.75,  # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£é–¾å€¤
        # ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        smoother_params: Optional[Dict[str, Any]] = None,
        # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        kalman_params: Optional[Dict[str, Any]] = None
    ):
        """
        ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
        
        Args:
            period: ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æœŸé–“
            tr_method: True Rangeè¨ˆç®—æ–¹æ³• ('atr' ã¾ãŸã¯ 'str')
            smoother_type: ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æ‰‹æ³•
            src_type: ãƒ—ãƒ©ã‚¤ã‚¹ã‚½ãƒ¼ã‚¹
            enable_kalman: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä½¿ç”¨ãƒ•ãƒ©ã‚°
            kalman_type: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç¨®åˆ¥
            
            # å‹•çš„é©å¿œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            period_mode: æœŸé–“ãƒ¢ãƒ¼ãƒ‰ ('fixed' ã¾ãŸã¯ 'dynamic')
            cycle_detector_type: ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã‚¿ã‚¤ãƒ— ('hody', 'phac', 'dudi', etc.)
            cycle_detector_cycle_part: ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®ã‚µã‚¤ã‚¯ãƒ«éƒ¨åˆ†å€ç‡
            cycle_detector_max_cycle: ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®æœ€å¤§ã‚µã‚¤ã‚¯ãƒ«æœŸé–“
            cycle_detector_min_cycle: ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®æœ€å°ã‚µã‚¤ã‚¯ãƒ«æœŸé–“
            cycle_period_multiplier: ã‚µã‚¤ã‚¯ãƒ«æœŸé–“ã®ä¹—æ•°
            cycle_detector_period_range: ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®å‘¨æœŸç¯„å›²
            
            smoother_params: ã‚¹ãƒ ãƒ¼ã‚µãƒ¼å›ºæœ‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            kalman_params: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å›ºæœ‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        """
        # ã‚¤ãƒ³ãƒ‡ã‚£ã‚±ãƒ¼ã‚¿ãƒ¼åã®è¨­å®š
        kalman_str = f"_K({kalman_type})" if enable_kalman else ""
        dynamic_str = f"({period_mode})" if period_mode == 'dynamic' else ""
        indicator_name = f"X_ATR({tr_method.upper()}, {smoother_type}, p={period}{dynamic_str}{kalman_str})"
        super().__init__(indicator_name)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼
        if tr_method.lower() not in ['atr', 'str']:
            raise ValueError(f"ç„¡åŠ¹ãªtr_method: {tr_method}ã€‚'atr' ã¾ãŸã¯ 'str' ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        
        if period_mode.lower() not in ['fixed', 'dynamic']:
            raise ValueError(f"ç„¡åŠ¹ãªperiod_mode: {period_mode}ã€‚'fixed' ã¾ãŸã¯ 'dynamic' ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¿å­˜
        self.period = period
        self.tr_method = tr_method.lower()
        self.smoother_type = smoother_type.lower()
        self.src_type = src_type.lower()
        self.enable_kalman = enable_kalman
        self.kalman_type = kalman_type.lower()
        
        # å‹•çš„é©å¿œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.period_mode = period_mode.lower()
        self.cycle_detector_type = cycle_detector_type
        self.cycle_detector_cycle_part = cycle_detector_cycle_part
        self.cycle_detector_max_cycle = cycle_detector_max_cycle
        self.cycle_detector_min_cycle = cycle_detector_min_cycle
        self.cycle_period_multiplier = cycle_period_multiplier
        self.cycle_detector_period_range = cycle_detector_period_range
        
        # ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.midline_period = midline_period
        
        # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.enable_percentile_analysis = enable_percentile_analysis
        self.percentile_lookback_period = percentile_lookback_period
        self.percentile_low_threshold = percentile_low_threshold
        self.percentile_high_threshold = percentile_high_threshold
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆæœŸåŒ–
        self.smoother_params = smoother_params or {}
        self.kalman_params = kalman_params or {}
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼
        if self.period <= 0:
            raise ValueError("periodã¯0ã‚ˆã‚Šå¤§ãã„å¿…è¦ãŒã‚ã‚Šã¾ã™")
        
        # ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®åˆæœŸåŒ–ï¼ˆå‹•çš„ãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿ï¼‰
        self.cycle_detector = None
        
        if self.period_mode == 'dynamic':
            try:
                # EhlersUnifiedDCã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
                from ..cycle.ehlers_unified_dc import EhlersUnifiedDC
                
                self.cycle_detector = EhlersUnifiedDC(
                    detector_type=self.cycle_detector_type,
                    cycle_part=self.cycle_detector_cycle_part,
                    max_cycle=self.cycle_detector_max_cycle,
                    min_cycle=self.cycle_detector_min_cycle,
                    src_type=self.src_type,
                    period_range=self.cycle_detector_period_range
                )
                self.logger.info(f"X_ATR: å‹•çš„é©å¿œã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã‚’åˆæœŸåŒ–: {self.cycle_detector_type}")
                
            except ImportError as e:
                self.logger.error(f"X_ATR: EhlersUnifiedDCã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
                self.period_mode = 'fixed'
                self.logger.warning("X_ATR: å‹•çš„é©å¿œãƒ¢ãƒ¼ãƒ‰ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ãŸãŸã‚ã€å›ºå®šãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã—ãŸã€‚")
            except Exception as e:
                self.logger.error(f"X_ATR: ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
                self.period_mode = 'fixed'
                self.logger.warning("X_ATR: å‹•çš„é©å¿œãƒ¢ãƒ¼ãƒ‰ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ãŸãŸã‚ã€å›ºå®šãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã—ãŸã€‚")
        
        # ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®åˆæœŸåŒ–
        smoother_config = {'period': self.period}
        smoother_config.update(self.smoother_params)
        
        # å‹•çš„æœŸé–“å¯¾å¿œã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        if self.period_mode == 'dynamic':
            smoother_config.update({
                'period_mode': self.period_mode,
                'cycle_detector_type': self.cycle_detector_type,
                'cycle_detector_cycle_part': self.cycle_detector_cycle_part,
                'cycle_detector_max_cycle': self.cycle_detector_max_cycle,
                'cycle_detector_min_cycle': self.cycle_detector_min_cycle,
                'cycle_period_multiplier': self.cycle_period_multiplier,
                'cycle_detector_period_range': self.cycle_detector_period_range
            })
        
        self.smoother = UnifiedSmoother(
            smoother_type=self.smoother_type,
            src_type='close',  # TRãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦é©ç”¨
            **smoother_config
        )
        
        # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®åˆæœŸåŒ–ï¼ˆå¿…è¦æ™‚ã®ã¿ï¼‰
        self.kalman_filter_high = None
        self.kalman_filter_low = None
        
        if self.enable_kalman:
            try:
                # é«˜å€¤ç”¨ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                self.kalman_filter_high = UnifiedKalman(
                    filter_type=self.kalman_type,
                    src_type='high',
                    **self.kalman_params
                )
                
                # å®‰å€¤ç”¨ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                self.kalman_filter_low = UnifiedKalman(
                    filter_type=self.kalman_type,
                    src_type='low',
                    **self.kalman_params
                )
                
                self.logger.info(f"ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼åˆæœŸåŒ–å®Œäº†: {self.kalman_type}")
                
            except Exception as e:
                self.logger.error(f"ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
                self.enable_kalman = False
                self.logger.warning("ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ç„¡åŠ¹åŒ–ã—ã¾ã—ãŸ")
        
        # çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._result_cache = {}
        self._max_cache_size = 10
        self._cache_keys = []
    
    def _get_data_hash(self, data: Union[pd.DataFrame, np.ndarray]) -> str:
        """ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—"""
        try:
            if isinstance(data, pd.DataFrame):
                length = len(data)
                if length > 0:
                    first_val = float(data.iloc[0].get('close', data.iloc[0, -1]))
                    last_val = float(data.iloc[-1].get('close', data.iloc[-1, -1]))
                else:
                    first_val = last_val = 0.0
            else:
                length = len(data)
                if length > 0:
                    if data.ndim > 1:
                        first_val = float(data[0, -1])
                        last_val = float(data[-1, -1])
                    else:
                        first_val = float(data[0])
                        last_val = float(data[-1])
                else:
                    first_val = last_val = 0.0
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚·ã‚°ãƒãƒãƒ£
            params_sig = (
                f"{self.tr_method}_{self.smoother_type}_{self.period}_"
                f"{self.period_mode}_{self.cycle_detector_type}_"
                f"{self.enable_kalman}_{self.kalman_type}_"
                f"{hash(str(sorted(self.smoother_params.items())))}_"
                f"{hash(str(sorted(self.kalman_params.items())))}"
            )
            
            data_sig = (length, first_val, last_val)
            return f"{hash(data_sig)}_{hash(params_sig)}"
            
        except Exception:
            return f"{id(data)}_{self.tr_method}_{self.smoother_type}_{self.period}"
    
    def _get_dynamic_periods(self, data: Union[pd.DataFrame, np.ndarray]) -> np.ndarray:
        """
        å‹•çš„é©å¿œæœŸé–“ã‚’è¨ˆç®—ã™ã‚‹
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            np.ndarray: å‹•çš„æœŸé–“é…åˆ—
        """
        data_length = len(data) if hasattr(data, '__len__') else 0
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§åˆæœŸåŒ–
        periods = np.full(data_length, self.period, dtype=np.float64)
        
        # å‹•çš„é©å¿œæœŸé–“ã®è¨ˆç®—
        if self.period_mode == 'dynamic' and self.cycle_detector is not None:
            try:
                # ãƒ‰ãƒŸãƒŠãƒ³ãƒˆã‚µã‚¤ã‚¯ãƒ«ã‚’è¨ˆç®—
                dominant_cycles = self.cycle_detector.calculate(data)
                
                if dominant_cycles is not None and len(dominant_cycles) == data_length:
                    # ã‚µã‚¤ã‚¯ãƒ«æœŸé–“ã«ä¹—æ•°ã‚’é©ç”¨
                    adjusted_cycles = dominant_cycles * self.cycle_period_multiplier
                    
                    # ã‚µã‚¤ã‚¯ãƒ«æœŸé–“ã‚’é©åˆ‡ãªç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—
                    periods = np.clip(adjusted_cycles, 
                                     self.cycle_detector_min_cycle, 
                                     self.cycle_detector_max_cycle)
                    
                    self.logger.debug(f"X_ATRå‹•çš„æœŸé–“è¨ˆç®—å®Œäº† - æœŸé–“ç¯„å›²: [{np.min(periods):.1f}-{np.max(periods):.1f}]")
                else:
                    self.logger.warning("X_ATR: ãƒ‰ãƒŸãƒŠãƒ³ãƒˆã‚µã‚¤ã‚¯ãƒ«ã®è¨ˆç®—çµæœãŒç„¡åŠ¹ã§ã™ã€‚å›ºå®šæœŸé–“ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                    
            except Exception as e:
                self.logger.error(f"X_ATR: å‹•çš„æœŸé–“è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å›ºå®šæœŸé–“ã‚’ä½¿ç”¨
        
        return periods
    
    def _apply_kalman_filtering(
        self, 
        data: Union[pd.DataFrame, np.ndarray]
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        é«˜å€¤ã¨å®‰å€¤ã«ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            Tuple[np.ndarray, np.ndarray]: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸé«˜å€¤ã¨å®‰å€¤
        """
        try:
            # é«˜å€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            high_result = self.kalman_filter_high.calculate(data)
            filtered_high = high_result.values
            
            # å®‰å€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            low_result = self.kalman_filter_low.calculate(data)
            filtered_low = low_result.values
            
            self.logger.debug("ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å®Œäº†")
            return filtered_high, filtered_low
            
        except Exception as e:
            self.logger.error(f"ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®é«˜å€¤ãƒ»å®‰å€¤ã‚’è¿”ã™
            if isinstance(data, pd.DataFrame):
                return data['high'].values, data['low'].values
            else:
                return data[:, 1], data[:, 2]  # high, low
    
    def _calculate_true_range(
        self,
        high: np.ndarray,
        low: np.ndarray,
        close: np.ndarray
    ) -> np.ndarray:
        """
        æŒ‡å®šã•ã‚ŒãŸæ–¹æ³•ã§True Rangeã‚’è¨ˆç®—
        
        Args:
            high: é«˜å€¤é…åˆ—
            low: å®‰å€¤é…åˆ—
            close: çµ‚å€¤é…åˆ—
            
        Returns:
            True Rangeé…åˆ—
        """
        if self.tr_method == 'str':
            # STRæ–¹å¼ã®True Rangeè¨ˆç®—
            true_high, true_low, true_range = str_calculate_true_range_values(high, low, close)
            return true_range
        else:
            # ATRæ–¹å¼ã®True Rangeè¨ˆç®—
            return atr_calculate_true_range(high, low, close)
    
    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> XATRResult:
        """
        X_ATRã‚’è¨ˆç®—ã™ã‚‹
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆDataFrameã¾ãŸã¯NumPyé…åˆ—ï¼‰
                å¿…è¦ãªã‚«ãƒ©ãƒ : high, low, close
        
        Returns:
            XATRResult: X_ATRã®è¨ˆç®—çµæœ
        """
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            data_hash = self._get_data_hash(data)
            
            if data_hash in self._result_cache:
                if data_hash in self._cache_keys:
                    self._cache_keys.remove(data_hash)
                self._cache_keys.append(data_hash)
                cached_result = self._result_cache[data_hash]
                return XATRResult(
                    values=cached_result.values.copy(),
                    values_percentage=cached_result.values_percentage.copy(),
                    true_range=cached_result.true_range.copy(),
                    true_range_percentage=cached_result.true_range_percentage.copy(),
                    raw_high=cached_result.raw_high.copy(),
                    raw_low=cached_result.raw_low.copy(),
                    raw_close=cached_result.raw_close.copy(),
                    filtered_high=cached_result.filtered_high.copy() if cached_result.filtered_high is not None else None,
                    filtered_low=cached_result.filtered_low.copy() if cached_result.filtered_low is not None else None,
                    tr_method=cached_result.tr_method,
                    smoother_type=cached_result.smoother_type,
                    parameters=cached_result.parameters.copy(),
                    dynamic_periods=cached_result.dynamic_periods.copy() if cached_result.dynamic_periods is not None else None,
                    midline=cached_result.midline.copy(),
                    midline_percentage=cached_result.midline_percentage.copy(),
                    volatility_signal=cached_result.volatility_signal.copy(),
                    str_percentiles=cached_result.str_percentiles.copy() if cached_result.str_percentiles is not None else None,
                    volatility_state=cached_result.volatility_state.copy() if cached_result.volatility_state is not None else None,
                    volatility_intensity=cached_result.volatility_intensity.copy() if cached_result.volatility_intensity is not None else None
                )
            
            # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            if isinstance(data, pd.DataFrame):
                required_cols = ['high', 'low', 'close']
                missing_cols = [col for col in required_cols if col not in data.columns]
                if missing_cols:
                    raise ValueError(f"å¿…è¦ãªã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_cols}")
                
                raw_high = data['high'].to_numpy()
                raw_low = data['low'].to_numpy()
                close = data['close'].to_numpy()
            else:
                if data.ndim != 2 or data.shape[1] < 4:
                    raise ValueError("NumPyé…åˆ—ã¯2æ¬¡å…ƒã§ã€å°‘ãªãã¨ã‚‚4åˆ—ï¼ˆOHLCï¼‰ãŒå¿…è¦ã§ã™")
                raw_high = data[:, 1]    # high
                raw_low = data[:, 2]     # low
                close = data[:, 3]       # close
            
            # NumPyé…åˆ—ã«å¤‰æ›
            raw_high = np.asarray(raw_high, dtype=np.float64)
            raw_low = np.asarray(raw_low, dtype=np.float64)
            close = np.asarray(close, dtype=np.float64)
            
            # ãƒ‡ãƒ¼ã‚¿é•·ã®æ¤œè¨¼
            data_length = len(close)
            if data_length == 0:
                raise ValueError("å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            
            # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if self.enable_kalman and self.kalman_filter_high and self.kalman_filter_low:
                filtered_high, filtered_low = self._apply_kalman_filtering(data)
                # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®å€¤ã‚’ä½¿ç”¨ã—ã¦TRè¨ˆç®—
                working_high = filtered_high
                working_low = filtered_low
            else:
                # å…ƒã®å€¤ã‚’ä½¿ç”¨
                working_high = raw_high
                working_low = raw_low
                filtered_high = None
                filtered_low = None
            
            # True Rangeè¨ˆç®—
            true_range = self._calculate_true_range(working_high, working_low, close)
            
            # å‹•çš„æœŸé–“ã®è¨ˆç®—
            dynamic_periods = self._get_dynamic_periods(data)
            
            # True Rangeã‚’DataFrameå½¢å¼ã«å¤‰æ›ã—ã¦ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã«æ¸¡ã™
            # ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ãŒFRAMAã®å ´åˆã€é«˜å€¤ãƒ»å®‰å€¤ã‚‚å«ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹
            tr_df = pd.DataFrame({
                'open': true_range,
                'high': true_range,
                'low': true_range,
                'close': true_range,
                'volume': np.ones_like(true_range)
            })
            
            # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°é©ç”¨
            smoother_result = self.smoother.calculate(tr_df)
            x_atr_values = smoother_result.values
            
            # ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¨ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ä¿¡å·ã®è¨ˆç®—
            midline, volatility_signal = calculate_midline_and_volatility_signal(
                x_atr_values, self.midline_period
            )
            
            # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            str_percentiles = None
            volatility_state = None
            volatility_intensity = None
            
            if self.enable_percentile_analysis:
                try:
                    # STRãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã‚’è¨ˆç®—ï¼ˆX_ATRå€¤ã‚’ä½¿ç”¨ï¼‰
                    str_percentiles = calculate_str_percentile(
                        x_atr_values, self.percentile_lookback_period
                    )
                    
                    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†é¡ã‚’è¨ˆç®—
                    volatility_state, volatility_intensity = calculate_volatility_classification(
                        str_percentiles, x_atr_values,
                        self.percentile_low_threshold, self.percentile_high_threshold
                    )
                    
                    self.logger.debug("ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æå®Œäº†")
                    
                except Exception as e:
                    self.logger.warning(f"ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯Noneã®ã¾ã¾
            else:
                self.logger.debug("ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ")
            
            # %ãƒ™ãƒ¼ã‚¹å€¤ã®è¨ˆç®—
            x_atr_percentage = calculate_percentage_values(x_atr_values, close)
            true_range_percentage = calculate_percentage_values(true_range, close)
            midline_percentage = calculate_percentage_values(midline, close)
            
            # çµæœã®ä¿å­˜
            result = XATRResult(
                values=x_atr_values.copy(),
                values_percentage=x_atr_percentage.copy(),
                true_range=true_range.copy(),
                true_range_percentage=true_range_percentage.copy(),
                raw_high=raw_high.copy(),
                raw_low=raw_low.copy(),
                raw_close=close.copy(),
                filtered_high=filtered_high.copy() if filtered_high is not None else None,
                filtered_low=filtered_low.copy() if filtered_low is not None else None,
                tr_method=self.tr_method,
                smoother_type=self.smoother_type,
                parameters={
                    'period': self.period,
                    'tr_method': self.tr_method,
                    'smoother_type': self.smoother_type,
                    'enable_kalman': self.enable_kalman,
                    'kalman_type': self.kalman_type,
                    'period_mode': self.period_mode,
                    'cycle_detector_type': self.cycle_detector_type,
                    'cycle_detector_cycle_part': self.cycle_detector_cycle_part,
                    'cycle_detector_max_cycle': self.cycle_detector_max_cycle,
                    'cycle_detector_min_cycle': self.cycle_detector_min_cycle,
                    'cycle_period_multiplier': self.cycle_period_multiplier,
                    'cycle_detector_period_range': self.cycle_detector_period_range,
                    'midline_period': self.midline_period,
                    'enable_percentile_analysis': self.enable_percentile_analysis,
                    'percentile_lookback_period': self.percentile_lookback_period,
                    'percentile_low_threshold': self.percentile_low_threshold,
                    'percentile_high_threshold': self.percentile_high_threshold,
                    'smoother_params': self.smoother_params.copy(),
                    'kalman_params': self.kalman_params.copy()
                },
                dynamic_periods=dynamic_periods.copy() if self.period_mode == 'dynamic' else None,
                midline=midline.copy(),
                midline_percentage=midline_percentage.copy(),
                volatility_signal=volatility_signal.copy(),
                str_percentiles=str_percentiles.copy() if str_percentiles is not None else None,
                volatility_state=volatility_state.copy() if volatility_state is not None else None,
                volatility_intensity=volatility_intensity.copy() if volatility_intensity is not None else None
            )
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
            if len(self._result_cache) >= self._max_cache_size and self._cache_keys:
                oldest_key = self._cache_keys.pop(0)
                if oldest_key in self._result_cache:
                    del self._result_cache[oldest_key]
            
            self._result_cache[data_hash] = result
            self._cache_keys.append(data_hash)
            
            # åŸºåº•ã‚¯ãƒ©ã‚¹ç”¨ã®å€¤è¨­å®š
            self._values = x_atr_values
            
            self.logger.debug(f"X_ATRè¨ˆç®—å®Œäº† - TRæ–¹æ³•: {self.tr_method}, ã‚¹ãƒ ãƒ¼ã‚µãƒ¼: {self.smoother_type}")
            return result
            
        except Exception as e:
            error_msg = str(e)
            stack_trace = traceback.format_exc()
            self.logger.error(f"X_ATRè¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {error_msg}\n{stack_trace}")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºã®çµæœã‚’è¿”ã™
            data_length = len(data) if hasattr(data, '__len__') else 0
            return XATRResult(
                values=np.full(data_length, np.nan),
                values_percentage=np.full(data_length, np.nan),
                true_range=np.full(data_length, np.nan),
                true_range_percentage=np.full(data_length, np.nan),
                raw_high=np.full(data_length, np.nan),
                raw_low=np.full(data_length, np.nan),
                raw_close=np.full(data_length, np.nan),
                filtered_high=None,
                filtered_low=None,
                tr_method=self.tr_method,
                smoother_type=self.smoother_type,
                parameters={},
                dynamic_periods=None,
                midline=np.full(data_length, np.nan),
                midline_percentage=np.full(data_length, np.nan),
                volatility_signal=np.full(data_length, np.nan),
                str_percentiles=None,
                volatility_state=None,
                volatility_intensity=None
            )
    
    def get_values(self) -> Optional[np.ndarray]:
        """X_ATRå€¤ã®ã¿ã‚’å–å¾—ã™ã‚‹ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰"""
        if not self._result_cache or not self._cache_keys:
            return None
        
        result = self._result_cache[self._cache_keys[-1]]
        return result.values.copy()
    
    def get_true_range(self) -> Optional[np.ndarray]:
        """True Rangeå€¤ã‚’å–å¾—ã™ã‚‹"""
        if not self._result_cache or not self._cache_keys:
            return None
        
        result = self._result_cache[self._cache_keys[-1]]
        return result.true_range.copy()
    
    def get_filtered_prices(self) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®é«˜å€¤ãƒ»å®‰å€¤ã‚’å–å¾—ã™ã‚‹"""
        if not self._result_cache or not self._cache_keys:
            return None, None
        
        result = self._result_cache[self._cache_keys[-1]]
        filtered_high = result.filtered_high.copy() if result.filtered_high is not None else None
        filtered_low = result.filtered_low.copy() if result.filtered_low is not None else None
        return filtered_high, filtered_low
    
    def get_dynamic_periods(self) -> Optional[np.ndarray]:
        """å‹•çš„æœŸé–“é…åˆ—ã‚’å–å¾—ã™ã‚‹"""
        if not self._result_cache or not self._cache_keys:
            return None
        
        result = self._result_cache[self._cache_keys[-1]]
        return result.dynamic_periods.copy() if result.dynamic_periods is not None else None
    
    def get_dynamic_periods_info(self) -> Dict[str, Any]:
        """å‹•çš„é©å¿œæœŸé–“ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹"""
        info = {
            'period_mode': self.period_mode,
            'cycle_detector_available': self.cycle_detector is not None
        }
        
        # ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®æƒ…å ±
        if self.cycle_detector is not None:
            info.update({
                'cycle_detector_type': self.cycle_detector_type,
                'cycle_detector_cycle_part': self.cycle_detector_cycle_part,
                'cycle_detector_max_cycle': self.cycle_detector_max_cycle,
                'cycle_detector_min_cycle': self.cycle_detector_min_cycle,
                'cycle_period_multiplier': self.cycle_period_multiplier,
                'cycle_detector_period_range': self.cycle_detector_period_range
            })
        
        return info
    
    def get_midline(self) -> Optional[np.ndarray]:
        """ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³å€¤ã‚’å–å¾—ã™ã‚‹"""
        result = self._get_latest_result()
        return result.midline.copy() if result else None
    
    def get_volatility_signal(self) -> Optional[np.ndarray]:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ä¿¡å·ã‚’å–å¾—ã™ã‚‹"""
        result = self._get_latest_result()
        return result.volatility_signal.copy() if result else None
    
    def get_values_percentage(self) -> Optional[np.ndarray]:
        """X_ATRå€¤ï¼ˆ%ãƒ™ãƒ¼ã‚¹ï¼‰ã‚’å–å¾—ã™ã‚‹"""
        result = self._get_latest_result()
        return result.values_percentage.copy() if result else None
    
    def get_true_range_percentage(self) -> Optional[np.ndarray]:
        """True Rangeå€¤ï¼ˆ%ãƒ™ãƒ¼ã‚¹ï¼‰ã‚’å–å¾—ã™ã‚‹"""
        result = self._get_latest_result()
        return result.true_range_percentage.copy() if result else None
    
    def get_midline_percentage(self) -> Optional[np.ndarray]:
        """ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³å€¤ï¼ˆ%ãƒ™ãƒ¼ã‚¹ï¼‰ã‚’å–å¾—ã™ã‚‹"""
        result = self._get_latest_result()
        return result.midline_percentage.copy() if result else None
    
    def get_str_percentiles(self) -> Optional[np.ndarray]:
        """STRãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«å€¤ã‚’å–å¾—ã™ã‚‹"""
        result = self._get_latest_result()
        return result.str_percentiles.copy() if result and result.str_percentiles is not None else None
    
    def get_volatility_state(self) -> Optional[np.ndarray]:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£çŠ¶æ…‹ã‚’å–å¾—ã™ã‚‹ï¼ˆ-1=é«˜ã€0=ä¸­ã€1=ä½ï¼‰"""
        result = self._get_latest_result()
        return result.volatility_state.copy() if result and result.volatility_state is not None else None
    
    def get_volatility_intensity(self) -> Optional[np.ndarray]:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å¼·åº¦ã‚’å–å¾—ã™ã‚‹ï¼ˆ0-1ã®ç¯„å›²ï¼‰"""
        result = self._get_latest_result()
        return result.volatility_intensity.copy() if result and result.volatility_intensity is not None else None
    
    def get_percentile_analysis_summary(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æã®è¦ç´„æƒ…å ±ã‚’å–å¾—ã™ã‚‹"""
        result = self._get_latest_result()
        if not result:
            return {}
        
        summary = {
            'percentile_analysis_enabled': self.enable_percentile_analysis,
            'lookback_period': self.percentile_lookback_period,
            'low_threshold': self.percentile_low_threshold,
            'high_threshold': self.percentile_high_threshold
        }
        
        if result.str_percentiles is not None:
            percentiles = result.str_percentiles
            valid_percentiles = percentiles[~np.isnan(percentiles)]
            
            if len(valid_percentiles) > 0:
                summary.update({
                    'percentile_mean': np.mean(valid_percentiles),
                    'percentile_std': np.std(valid_percentiles),
                    'percentile_min': np.min(valid_percentiles),
                    'percentile_max': np.max(valid_percentiles),
                    'current_percentile': percentiles[-1] if not np.isnan(percentiles[-1]) else None
                })
        
        if result.volatility_state is not None:
            state = result.volatility_state
            valid_state = state[~np.isnan(state)]
            
            if len(valid_state) > 0:
                # å„çŠ¶æ…‹ã®åˆ†å¸ƒã‚’è¨ˆç®—
                low_vol_count = np.sum(valid_state == 1.0)
                mid_vol_count = np.sum(valid_state == 0.0)
                high_vol_count = np.sum(valid_state == -1.0)
                total_count = len(valid_state)
                
                summary.update({
                    'volatility_distribution': {
                        'low': low_vol_count / total_count,
                        'medium': mid_vol_count / total_count,
                        'high': high_vol_count / total_count
                    },
                    'current_volatility_state': state[-1] if not np.isnan(state[-1]) else None
                })
        
        return summary
    
    def _get_latest_result(self) -> Optional[XATRResult]:
        """æœ€æ–°ã®çµæœã‚’å–å¾—"""
        if not self._result_cache:
            return None
        
        if self._cache_keys:
            return self._result_cache[self._cache_keys[-1]]
        else:
            return next(iter(self._result_cache.values()))
    
    def get_configuration(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®è¨­å®šæƒ…å ±ã‚’å–å¾—ã™ã‚‹"""
        return {
            'period': self.period,
            'tr_method': self.tr_method,
            'smoother_type': self.smoother_type,
            'src_type': self.src_type,
            'enable_kalman': self.enable_kalman,
            'kalman_type': self.kalman_type,
            'period_mode': self.period_mode,
            'cycle_detector_type': self.cycle_detector_type,
            'cycle_detector_cycle_part': self.cycle_detector_cycle_part,
            'cycle_detector_max_cycle': self.cycle_detector_max_cycle,
            'cycle_detector_min_cycle': self.cycle_detector_min_cycle,
            'cycle_period_multiplier': self.cycle_period_multiplier,
            'cycle_detector_period_range': self.cycle_detector_period_range,
            'midline_period': self.midline_period,
            'smoother_params': self.smoother_params.copy(),
            'kalman_params': self.kalman_params.copy()
        }
    
    def reset(self) -> None:
        """ã‚¤ãƒ³ãƒ‡ã‚£ã‚±ãƒ¼ã‚¿ãƒ¼ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹"""
        super().reset()
        self._result_cache = {}
        self._cache_keys = []
        
        # ã‚µãƒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒªã‚»ãƒƒãƒˆ
        if hasattr(self.smoother, 'reset'):
            self.smoother.reset()
        
        if self.kalman_filter_high and hasattr(self.kalman_filter_high, 'reset'):
            self.kalman_filter_high.reset()
        
        if self.kalman_filter_low and hasattr(self.kalman_filter_low, 'reset'):
            self.kalman_filter_low.reset()
        
        if self.cycle_detector and hasattr(self.cycle_detector, 'reset'):
            self.cycle_detector.reset()


# ä¾¿åˆ©é–¢æ•°
def calculate_x_atr(
    data: Union[pd.DataFrame, np.ndarray],
    period: float = 20.0,
    tr_method: str = 'atr',
    smoother_type: str = 'frama',
    enable_kalman: bool = False,
    kalman_type: str = 'unscented',
    period_mode: str = 'fixed',
    cycle_detector_type: str = 'absolute_ultimate',
    midline_period: int = 100,
    enable_percentile_analysis: bool = True,
    percentile_lookback_period: int = 50,
    percentile_low_threshold: float = 0.25,
    percentile_high_threshold: float = 0.75,
    **kwargs
) -> np.ndarray:
    """
    X_ATRã®è¨ˆç®—ï¼ˆä¾¿åˆ©é–¢æ•°ï¼‰
    
    Args:
        data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        period: ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æœŸé–“
        tr_method: True Rangeè¨ˆç®—æ–¹æ³•
        smoother_type: ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æ‰‹æ³•
        enable_kalman: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä½¿ç”¨ãƒ•ãƒ©ã‚°
        kalman_type: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç¨®åˆ¥
        period_mode: æœŸé–“ãƒ¢ãƒ¼ãƒ‰ ('fixed' ã¾ãŸã¯ 'dynamic')
        cycle_detector_type: ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã‚¿ã‚¤ãƒ—
        midline_period: ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¨ˆç®—æœŸé–“
        enable_percentile_analysis: ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹
        percentile_lookback_period: ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«è¨ˆç®—ã®ãƒ«ãƒƒã‚¯ãƒãƒƒã‚¯æœŸé–“
        percentile_low_threshold: ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£é–¾å€¤
        percentile_high_threshold: é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£é–¾å€¤
        **kwargs: è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        
    Returns:
        X_ATRå€¤ã®é…åˆ—
    """
    x_atr = XATR(
        period=period,
        tr_method=tr_method,
        smoother_type=smoother_type,
        enable_kalman=enable_kalman,
        kalman_type=kalman_type,
        period_mode=period_mode,
        cycle_detector_type=cycle_detector_type,
        midline_period=midline_period,
        enable_percentile_analysis=enable_percentile_analysis,
        percentile_lookback_period=percentile_lookback_period,
        percentile_low_threshold=percentile_low_threshold,
        percentile_high_threshold=percentile_high_threshold,
        **kwargs
    )
    result = x_atr.calculate(data)
    return result.values


if __name__ == "__main__":
    """ç›´æ¥å®Ÿè¡Œæ™‚ã®ãƒ†ã‚¹ãƒˆ"""
    try:
        import matplotlib.pyplot as plt
        from datetime import datetime, timedelta
        VISUALIZATION_AVAILABLE = True
    except ImportError:
        VISUALIZATION_AVAILABLE = False
    
    print("=== X_ATRã®ãƒ†ã‚¹ãƒˆ ===")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    np.random.seed(42)
    length = 200
    base_price = 100.0
    trend = 0.001
    volatility = 0.02
    
    prices = [base_price]
    for i in range(1, length):
        change = trend + np.random.normal(0, volatility)
        new_price = prices[-1] * (1 + change)
        prices.append(new_price)
    
    # OHLC ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
    data = []
    for i, close in enumerate(prices):
        daily_range = abs(np.random.normal(0, volatility * close * 0.5))
        
        high = close + daily_range * np.random.uniform(0.3, 1.0)
        low = close - daily_range * np.random.uniform(0.3, 1.0)
        
        if i == 0:
            open_price = close
        else:
            gap = np.random.normal(0, volatility * close * 0.2)
            open_price = prices[i-1] + gap
        
        # è«–ç†çš„æ•´åˆæ€§ã®ç¢ºä¿
        high = max(high, open_price, close)
        low = min(low, open_price, close)
        
        data.append({
            'open': open_price,
            'high': high,
            'low': low,
            'close': close,
            'volume': np.random.uniform(1000, 10000)
        })
    
    df = pd.DataFrame(data)
    
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(df)}ãƒã‚¤ãƒ³ãƒˆ")
    print(f"ä¾¡æ ¼ç¯„å›²: {df['close'].min():.2f} - {df['close'].max():.2f}")
    
    # å„è¨­å®šã§ã®ãƒ†ã‚¹ãƒˆ
    test_configs = [
        {'tr_method': 'atr', 'smoother_type': 'frama', 'enable_kalman': False, 'period_mode': 'fixed'},
        {'tr_method': 'str', 'smoother_type': 'frama', 'enable_kalman': False, 'period_mode': 'fixed'},
        {'tr_method': 'atr', 'smoother_type': 'zero_lag_ema', 'enable_kalman': False, 'period_mode': 'fixed'},
        {'tr_method': 'atr', 'smoother_type': 'frama', 'enable_kalman': True, 'kalman_type': 'unscented', 'period_mode': 'fixed'},
        {'tr_method': 'atr', 'smoother_type': 'ultimate_smoother', 'enable_kalman': False, 'period_mode': 'dynamic', 'cycle_detector_type': 'absolute_ultimate'},
    ]
    
    results = {}
    
    for i, config in enumerate(test_configs):
        try:
            print(f"\nè¨­å®š {i+1}: {config}")
            x_atr = XATR(period=20.0, **config)
            result = x_atr.calculate(df)
            
            mean_value = np.nanmean(result.values)
            valid_count = np.sum(~np.isnan(result.values))
            
            results[f"config_{i+1}"] = result
            
            print(f"  å¹³å‡X_ATR: {mean_value:.4f}")
            print(f"  æœ‰åŠ¹å€¤æ•°: {valid_count}/{len(df)}")
            print(f"  ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä½¿ç”¨: {config.get('enable_kalman', False)}")
            print(f"  æœŸé–“ãƒ¢ãƒ¼ãƒ‰: {config.get('period_mode', 'fixed')}")
            
            # å‹•çš„æœŸé–“ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯æœŸé–“æƒ…å ±ã‚‚è¡¨ç¤º
            if config.get('period_mode') == 'dynamic':
                dynamic_periods = result.dynamic_periods
                if dynamic_periods is not None:
                    print(f"  å‹•çš„æœŸé–“ç¯„å›²: {np.min(dynamic_periods):.1f} - {np.max(dynamic_periods):.1f}")
                else:
                    print(f"  å‹•çš„æœŸé–“: è¨ˆç®—ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            
        except Exception as e:
            print(f"  ã‚¨ãƒ©ãƒ¼: {e}")
    
    print("\n=== ãƒ†ã‚¹ãƒˆå®Œäº† ===")