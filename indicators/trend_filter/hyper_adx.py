#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ¯ **Hyper ADX - çµ±åˆå‹Average Directional Index** ğŸ¯

ãƒã‚¤ãƒ‘ãƒ¼ERã¨åŒã˜è¨ˆç®—ãƒ•ãƒ­ãƒ¼ã‚’æ¡ç”¨ã—ãŸADXã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã€‚
ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¨ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµ±åˆã«ã‚ˆã‚Šã€ãƒã‚¤ã‚ºé™¤å»ã¨ç²¾åº¦å‘ä¸Šã‚’å®Ÿç¾ã€‚

ğŸŒŸ **ä¸»è¦æ©Ÿèƒ½:**
1. **çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼**: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ã‚ºé™¤å»
2. **ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼**: è¿½åŠ ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
3. **çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼**: DXå€¤ã®å¿…é ˆå¹³æ»‘åŒ–ï¼ˆADXä½œæˆï¼‰
4. **å‹•çš„æœŸé–“å¯¾å¿œ**: ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã«ã‚ˆã‚‹æœŸé–“é©å¿œ
5. **100æœŸé–“ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³**: ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯

ğŸ“Š **å‡¦ç†ãƒ•ãƒ­ãƒ¼ï¼ˆãƒã‚¤ãƒ‘ãƒ¼ERã¨åŒã˜ï¼‰:**
1. ã‚½ãƒ¼ã‚¹ä¾¡æ ¼â†’çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†(ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
2. ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã«ã‚ˆã‚‹æœŸé–“æ¤œå‡º
3. ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†(ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
4. ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†æ¸ˆä¾¡æ ¼ã«ã‚ˆã‚‹ DX è¨ˆç®—
5. çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã«ã‚ˆã‚‹ DX ã®å¹³æ»‘åŒ–ï¼ˆADXä½œæˆã€å¿…é ˆæ©Ÿèƒ½ï¼‰
6. ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¨ˆç®—ã¨ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š

ğŸ”§ **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼: ãƒã‚¤ã‚ºé™¤å»ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
- ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼: è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
- çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼: DXâ†’ADXã®å¿…é ˆå¹³æ»‘åŒ–
- å‹•çš„æœŸé–“: ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã«ã‚ˆã‚‹é©å¿œæœŸé–“
"""

from dataclasses import dataclass
from typing import Union, Optional
import numpy as np
import pandas as pd
from numba import njit
import traceback

from ..indicator import Indicator
from ..price_source import PriceSource
from ..utils.percentile_analysis import (
    calculate_percentile,
    calculate_trend_classification,
    PercentileAnalysisMixin
)

# æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ï¼‰
try:
    from ..smoother.unified_smoother import UnifiedSmoother
    UNIFIED_SMOOTHER_AVAILABLE = True
except ImportError:
    try:
        # çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œï¼ˆãƒ‘ã‚¹èª¿æ•´ä»˜ãï¼‰
        import sys
        import os
        current_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        if current_dir not in sys.path:
            sys.path.insert(0, current_dir)
        from indicators.smoother.unified_smoother import UnifiedSmoother
        UNIFIED_SMOOTHER_AVAILABLE = True
    except ImportError:
        UnifiedSmoother = None
        UNIFIED_SMOOTHER_AVAILABLE = False

try:
    from ..cycle.ehlers_unified_dc import EhlersUnifiedDC
    EHLERS_UNIFIED_DC_AVAILABLE = True
except ImportError:
    try:
        # çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œï¼ˆãƒ‘ã‚¹èª¿æ•´ä»˜ãï¼‰
        import sys
        import os
        current_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        if current_dir not in sys.path:
            sys.path.insert(0, current_dir)
        from indicators.cycle.ehlers_unified_dc import EhlersUnifiedDC
        EHLERS_UNIFIED_DC_AVAILABLE = True
    except ImportError:
        EhlersUnifiedDC = None
        EHLERS_UNIFIED_DC_AVAILABLE = False

try:
    from ..kalman.unified_kalman import UnifiedKalman
    UNIFIED_KALMAN_AVAILABLE = True
except ImportError:
    try:
        # çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œï¼ˆãƒ‘ã‚¹èª¿æ•´ä»˜ãï¼‰
        import sys
        import os
        current_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        if current_dir not in sys.path:
            sys.path.insert(0, current_dir)
        from indicators.kalman.unified_kalman import UnifiedKalman
        UNIFIED_KALMAN_AVAILABLE = True
    except ImportError:
        UnifiedKalman = None
        UNIFIED_KALMAN_AVAILABLE = False

try:
    from ..smoother.roofing_filter import RoofingFilter
    ROOFING_FILTER_AVAILABLE = True
except ImportError:
    try:
        # çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œï¼ˆãƒ‘ã‚¹èª¿æ•´ä»˜ãï¼‰
        import sys
        import os
        current_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        if current_dir not in sys.path:
            sys.path.insert(0, current_dir)
        from indicators.smoother.roofing_filter import RoofingFilter
        ROOFING_FILTER_AVAILABLE = True
    except ImportError:
        RoofingFilter = None
        ROOFING_FILTER_AVAILABLE = False


@dataclass
class HyperADXResult:
    """Hyper ADXã®è¨ˆç®—çµæœ"""
    values: np.ndarray                    # Hyper ADXå€¤ï¼ˆçµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã§å¹³æ»‘åŒ–ã•ã‚ŒãŸADXï¼‰
    raw_dx: np.ndarray                    # ç”Ÿã®DXå€¤ï¼ˆå¹³æ»‘åŒ–å‰ï¼‰
    secondary_smoothed: Optional[np.ndarray]  # äºŒæ¬¡å¹³æ»‘åŒ–ã•ã‚ŒãŸADXå€¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    midline: np.ndarray                   # ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³å€¤
    trend_signal: np.ndarray              # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šä¿¡å·ï¼ˆ1=ãƒˆãƒ¬ãƒ³ãƒ‰ã€-1=ãƒ¬ãƒ³ã‚¸ï¼‰
    filtered_prices: np.ndarray           # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ä¾¡æ ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    roofing_values: np.ndarray            # ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å€¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    plus_di: np.ndarray                   # +DIå€¤
    minus_di: np.ndarray                  # -DIå€¤
    cycle_periods: np.ndarray             # ã‚µã‚¤ã‚¯ãƒ«æœŸé–“å€¤ï¼ˆå‹•çš„æœŸé–“ä½¿ç”¨æ™‚ï¼‰
    # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    percentiles: Optional[np.ndarray]     # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«å€¤
    trend_state: Optional[np.ndarray]     # ãƒˆãƒ¬ãƒ³ãƒ‰çŠ¶æ…‹ï¼ˆ-1=ãƒ¬ãƒ³ã‚¸ã€0=ä¸­ã€1=ãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰
    trend_intensity: Optional[np.ndarray] # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ï¼ˆ0-1ï¼‰


@njit(fastmath=True, cache=True)
def calculate_directional_movement_hyper(
    high: np.ndarray,
    low: np.ndarray
) -> tuple:
    """
    Directional Movementï¼ˆ+DM, -DMï¼‰ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆNumbaæœ€é©åŒ–ç‰ˆï¼‰
    
    Args:
        high: é«˜å€¤ã®é…åˆ—
        low: å®‰å€¤ã®é…åˆ—
        
    Returns:
        Tuple[np.ndarray, np.ndarray]: (+DM, -DM)ã®é…åˆ—
    """
    length = len(high)
    plus_dm = np.zeros(length, dtype=np.float64)
    minus_dm = np.zeros(length, dtype=np.float64)
    
    for i in range(1, length):
        up = high[i] - high[i-1]
        down = low[i-1] - low[i]
        
        if up > down and up > 0:
            plus_dm[i] = up
        else:
            plus_dm[i] = 0.0
            
        if down > up and down > 0:
            minus_dm[i] = down
        else:
            minus_dm[i] = 0.0
    
    return plus_dm, minus_dm


@njit(fastmath=True, cache=True)
def calculate_true_range_hyper(
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray
) -> np.ndarray:
    """
    True Rangeã‚’è¨ˆç®—ã™ã‚‹ï¼ˆNumbaæœ€é©åŒ–ç‰ˆï¼‰
    
    Args:
        high: é«˜å€¤ã®é…åˆ—
        low: å®‰å€¤ã®é…åˆ—
        close: çµ‚å€¤ã®é…åˆ—
        
    Returns:
        True Rangeå€¤ã®é…åˆ—
    """
    length = len(high)
    tr = np.zeros(length, dtype=np.float64)
    
    # æœ€åˆã®å€¤
    tr[0] = high[0] - low[0]
    
    # 2ç•ªç›®ä»¥é™
    for i in range(1, length):
        tr1 = high[i] - low[i]
        tr2 = abs(high[i] - close[i-1])
        tr3 = abs(low[i] - close[i-1])
        tr[i] = max(tr1, tr2, tr3)
    
    return tr


@njit(fastmath=True, cache=True)
def calculate_dx_values_numba(
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
    period: int,
    dynamic_periods: np.ndarray = None
) -> tuple:
    """
    DXå€¤ã¨+DIã€-DIå€¤ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆNumbaæœ€é©åŒ–ç‰ˆï¼‰
    å¹³æ»‘åŒ–ã¯çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã§å¾Œã‹ã‚‰è¡Œã†
    
    Args:
        high: é«˜å€¤ã®é…åˆ—
        low: å®‰å€¤ã®é…åˆ—
        close: çµ‚å€¤ã®é…åˆ—
        period: åŸºæœ¬è¨ˆç®—æœŸé–“
        dynamic_periods: å‹•çš„æœŸé–“é…åˆ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
    Returns:
        Tuple[np.ndarray, np.ndarray, np.ndarray]: (DXå€¤, +DIå€¤, -DIå€¤)
    """
    length = len(high)
    dx_values = np.full(length, np.nan, dtype=np.float64)
    plus_di = np.full(length, np.nan, dtype=np.float64)
    minus_di = np.full(length, np.nan, dtype=np.float64)
    
    # +DM, -DM, TRã®è¨ˆç®—
    plus_dm, minus_dm = calculate_directional_movement_hyper(high, low)
    tr_values = calculate_true_range_hyper(high, low, close)
    
    # æŒ‡æ•°ç§»å‹•å¹³å‡ã«ã‚ˆã‚‹å¹³æ»‘åŒ–
    alpha = 2.0 / (period + 1.0)
    
    # å¹³æ»‘åŒ–ç”¨ã®å¤‰æ•°
    smoothed_tr = np.zeros(length, dtype=np.float64)
    smoothed_plus_dm = np.zeros(length, dtype=np.float64)
    smoothed_minus_dm = np.zeros(length, dtype=np.float64)
    
    for i in range(period - 1, length):
        # å‹•çš„æœŸé–“ã¾ãŸã¯å›ºå®šæœŸé–“ã‚’ä½¿ç”¨
        current_period = period
        if dynamic_periods is not None and i < len(dynamic_periods) and not np.isnan(dynamic_periods[i]):
            current_period = max(5, min(int(dynamic_periods[i]), 50))  # 5-50æœŸé–“ã«åˆ¶é™
        
        current_alpha = 2.0 / (current_period + 1.0)
        
        # æœ€åˆã®å€¤ã®åˆæœŸåŒ–
        if i == period - 1:
            smoothed_tr[i] = tr_values[i]
            smoothed_plus_dm[i] = plus_dm[i]
            smoothed_minus_dm[i] = minus_dm[i]
        else:
            # æŒ‡æ•°ç§»å‹•å¹³å‡ã«ã‚ˆã‚‹å¹³æ»‘åŒ–
            smoothed_tr[i] = (tr_values[i] * current_alpha) + (smoothed_tr[i-1] * (1 - current_alpha))
            smoothed_plus_dm[i] = (plus_dm[i] * current_alpha) + (smoothed_plus_dm[i-1] * (1 - current_alpha))
            smoothed_minus_dm[i] = (minus_dm[i] * current_alpha) + (smoothed_minus_dm[i-1] * (1 - current_alpha))
        
        # +DI, -DIã®è¨ˆç®—
        if smoothed_tr[i] > 0:
            plus_di[i] = smoothed_plus_dm[i] / smoothed_tr[i]
            minus_di[i] = smoothed_minus_dm[i] / smoothed_tr[i]
        else:
            plus_di[i] = 0.0
            minus_di[i] = 0.0
        
        # DXã®è¨ˆç®—ï¼ˆADXã®å‰æ®µéšã€å¹³æ»‘åŒ–ãªã—ï¼‰
        di_sum = plus_di[i] + minus_di[i]
        if di_sum > 0:
            dx_values[i] = abs(plus_di[i] - minus_di[i]) / di_sum
        else:
            dx_values[i] = 0.0
    
    return dx_values, plus_di, minus_di


@njit(fastmath=True, cache=True)
def calculate_midline_and_trend_signal_hyper(
    hyper_adx: np.ndarray,
    midline_period: int = 100
) -> tuple:
    """
    ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¨ãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡å·ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆNumbaæœ€é©åŒ–ç‰ˆï¼‰
    
    Args:
        hyper_adx: Hyper ADXå€¤ã®é…åˆ—
        midline_period: ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¨ˆç®—æœŸé–“
        
    Returns:
        Tuple[np.ndarray, np.ndarray]: (ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³, ãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡å·)
    """
    length = len(hyper_adx)
    midline = np.full(length, np.nan, dtype=np.float64)
    trend_signal = np.full(length, np.nan, dtype=np.float64)
    
    for i in range(midline_period - 1, length):
        # æœŸé–“å†…ã®æœ€é«˜å€¤ã¨æœ€å®‰å€¤ã‚’è¨ˆç®—
        period_data = hyper_adx[i - midline_period + 1:i + 1]
        
        # NaNå€¤ã‚’é™¤å¤–
        valid_data = period_data[~np.isnan(period_data)]
        
        if len(valid_data) >= midline_period // 2:
            period_max = np.max(valid_data)
            period_min = np.min(valid_data)
            
            # ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ = (æœ€é«˜å€¤ + æœ€å®‰å€¤) / 2
            midline[i] = (period_max + period_min) / 2.0
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡å·ã®åˆ¤å®š
            if not np.isnan(hyper_adx[i]):
                if hyper_adx[i] > midline[i]:
                    trend_signal[i] = 1.0  # ãƒˆãƒ¬ãƒ³ãƒ‰
                else:
                    trend_signal[i] = -1.0  # ãƒ¬ãƒ³ã‚¸
    
    return midline, trend_signal


class HyperADX(Indicator, PercentileAnalysisMixin):
    """
    Hyper ADXï¼ˆçµ±åˆå‹Average Directional Indexï¼‰ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
    
    ãƒã‚¤ãƒ‘ãƒ¼ERã¨åŒã˜è¨ˆç®—ãƒ•ãƒ­ãƒ¼ã‚’æ¡ç”¨ã—ãŸADXã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã€‚
    çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã€ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã€çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã«ã‚ˆã‚‹é«˜ç²¾åº¦ãªãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºã‚’å®Ÿç¾ã€‚
    
    ç‰¹å¾´:
    - 0-1ã®å€¤ç¯„å›²ã§ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã‚’è¡¨ç¾
    - é«˜ã„å€¤=å¼·ã„ãƒˆãƒ¬ãƒ³ãƒ‰ã€ä½ã„å€¤=ãƒ¬ãƒ³ã‚¸ç›¸å ´
    - 100æœŸé–“ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã«ã‚ˆã‚‹ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šæ©Ÿèƒ½
    - çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã€ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã€çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼å¯¾å¿œ
    - å‹•çš„æœŸé–“é©å¿œæ©Ÿèƒ½
    
    è¨ˆç®—æ‰‹é †ï¼ˆãƒã‚¤ãƒ‘ãƒ¼ERã¨åŒã˜ãƒ•ãƒ­ãƒ¼ï¼‰:
    1. ã‚½ãƒ¼ã‚¹ä¾¡æ ¼â†’çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†(ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
    2. ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã«ã‚ˆã‚‹æœŸé–“æ¤œå‡º
    3. ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†(ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
    4. ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†æ¸ˆä¾¡æ ¼ã«ã‚ˆã‚‹ DX è¨ˆç®—
    5. çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã«ã‚ˆã‚‹ DX ã®å¹³æ»‘åŒ–ï¼ˆADXä½œæˆã€å¿…é ˆæ©Ÿèƒ½ï¼‰
    6. ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¨ˆç®—ã¨ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š
    
    æ³¨æ„: å¹³æ»‘åŒ–ã¯ XADX ã¨ç•°ãªã‚Šå¿…é ˆæ©Ÿèƒ½ã§ã™ã€‚DXå€¤ã‚’çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã§ADXã«å¤‰æ›ã—ã¾ã™ã€‚
    """
    
    def __init__(self,
        period: int = 14,
        midline_period: int = 100,
        # çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        use_kalman_filter: bool = True,
        kalman_filter_type: str = 'unscented',
        kalman_process_noise: float = 1e-5,
        kalman_min_observation_noise: float = 1e-6,
        kalman_adaptation_window: int = 5,
        # ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        use_roofing_filter: bool = True,
        roofing_hp_cutoff: float = 55.0,
        roofing_ss_band_edge: float = 10.0,
        # çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå¿…é ˆæ©Ÿèƒ½ï¼‰
        smoother_type: str = 'frama',
        smoother_period: int = 24,
        smoother_src_type: str = 'close',
        # äºŒæ¬¡å¹³æ»‘åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ï¼‰
        use_secondary_smoothing: bool = False,
        secondary_smoother_type: str = 'zlema',
        secondary_smoother_period: int = 8,
        # ã‚¨ãƒ©ãƒ¼ã‚ºçµ±åˆã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        use_dynamic_period: bool = True,
        detector_type: str = 'dft_dominant',
        lp_period: int = 13,
        hp_period: int = 124,
        cycle_part: float = 0.4,
        max_cycle: int = 124,
        min_cycle: int = 13,
        max_output: int = 3,
        min_output: int = 34,
        # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        enable_percentile_analysis: bool = False,
        percentile_lookback_period: int = 50,
        percentile_low_threshold: float = 0.25,
        percentile_high_threshold: float = 0.75
    ):
        """
        ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
        
        Args:
            period: ADXè¨ˆç®—æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 14ï¼‰
            midline_period: ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¨ˆç®—æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100ï¼‰
            use_kalman_filter: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰
            kalman_filter_type: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¿ã‚¤ãƒ—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'adaptive'ï¼‰
            kalman_process_noise: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚¤ã‚ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1e-5ï¼‰
            kalman_min_observation_noise: æœ€å°è¦³æ¸¬ãƒã‚¤ã‚ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1e-6ï¼‰
            kalman_adaptation_window: é©å¿œã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰
            use_roofing_filter: ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰
            roofing_hp_cutoff: ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®HighPassã‚«ãƒƒãƒˆã‚ªãƒ•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 48.0ï¼‰
            roofing_ss_band_edge: ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®SuperSmootherãƒãƒ³ãƒ‰ã‚¨ãƒƒã‚¸ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10.0ï¼‰
            smoother_type: çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¿ã‚¤ãƒ—ï¼ˆå¿…é ˆæ©Ÿèƒ½ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'frama'ï¼‰
            smoother_period: ã‚¹ãƒ ãƒ¼ã‚µãƒ¼æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 12ï¼‰
            smoother_src_type: ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'close'ï¼‰
            use_secondary_smoothing: äºŒæ¬¡å¹³æ»‘åŒ–ã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Falseï¼‰
            secondary_smoother_type: äºŒæ¬¡ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¿ã‚¤ãƒ—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'zlema'ï¼‰
            secondary_smoother_period: äºŒæ¬¡ã‚¹ãƒ ãƒ¼ã‚µãƒ¼æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8ï¼‰
            use_dynamic_period: å‹•çš„æœŸé–“ã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰
            detector_type: ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã‚¿ã‚¤ãƒ—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'dft_dominant'ï¼‰
            lp_period: ãƒ­ãƒ¼ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 13ï¼‰
            hp_period: ãƒã‚¤ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 124ï¼‰
            cycle_part: ã‚µã‚¤ã‚¯ãƒ«éƒ¨åˆ†ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.4ï¼‰
            max_cycle: æœ€å¤§ã‚µã‚¤ã‚¯ãƒ«æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 124ï¼‰
            min_cycle: æœ€å°ã‚µã‚¤ã‚¯ãƒ«æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 13ï¼‰
            max_output: æœ€å¤§å‡ºåŠ›å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 89ï¼‰
            min_output: æœ€å°å‡ºåŠ›å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰
            enable_percentile_analysis: ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰
            percentile_lookback_period: ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«è¨ˆç®—ã®ãƒ«ãƒƒã‚¯ãƒãƒƒã‚¯æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50ï¼‰
            percentile_low_threshold: ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ä½é–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.25ï¼‰
            percentile_high_threshold: ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«é«˜é–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.75ï¼‰
        """
        super().__init__(f"HyperADX(p={period},mid={midline_period})")
        
        self.period = period
        self.midline_period = midline_period
        
        # çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.use_kalman_filter = use_kalman_filter
        self.kalman_filter_type = kalman_filter_type
        self.kalman_process_noise = kalman_process_noise
        self.kalman_min_observation_noise = kalman_min_observation_noise
        self.kalman_adaptation_window = kalman_adaptation_window
        
        # ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.use_roofing_filter = use_roofing_filter
        self.roofing_hp_cutoff = roofing_hp_cutoff
        self.roofing_ss_band_edge = roofing_ss_band_edge
        
        # çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå¿…é ˆæ©Ÿèƒ½ï¼‰
        self.smoother_type = smoother_type
        self.smoother_period = smoother_period
        self.smoother_src_type = smoother_src_type
        
        # äºŒæ¬¡å¹³æ»‘åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ï¼‰
        self.use_secondary_smoothing = use_secondary_smoothing
        self.secondary_smoother_type = secondary_smoother_type
        self.secondary_smoother_period = secondary_smoother_period
        
        # ã‚¨ãƒ©ãƒ¼ã‚ºçµ±åˆã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.use_dynamic_period = use_dynamic_period
        self.detector_type = detector_type
        self.lp_period = lp_period
        self.hp_period = hp_period
        self.cycle_part = cycle_part
        self.max_cycle = max_cycle
        self.min_cycle = min_cycle
        self.max_output = max_output
        self.min_output = min_output
        
        # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆæœŸåŒ–
        self._add_percentile_analysis_params(
            enable_percentile_analysis=enable_percentile_analysis,
            percentile_lookback_period=percentile_lookback_period,
            percentile_low_threshold=percentile_low_threshold,
            percentile_high_threshold=percentile_high_threshold
        )
        
        # ä¾å­˜ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®åˆæœŸåŒ–
        self._init_dependencies()
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ãƒªã‚¶ãƒ«ãƒˆç®¡ç†
        self._result_cache = {}
        self._cache_keys = []
        self._max_cache_size = 10
        self._latest_result = None
    
    def _init_dependencies(self):
        """ä¾å­˜ã™ã‚‹ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–"""
        # çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®åˆæœŸåŒ–
        self.kalman_filter = None
        if self.use_kalman_filter and UNIFIED_KALMAN_AVAILABLE:
            try:
                kalman_params = {
                    'kalman_type': self.kalman_filter_type,
                    'process_noise': self.kalman_process_noise,
                    'min_observation_noise': self.kalman_min_observation_noise,
                    'adaptation_window': self.kalman_adaptation_window
                }
                self.kalman_filter = UnifiedKalman(**kalman_params)
                self.logger.debug(f"çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼({self.kalman_filter_type})ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
            except Exception as e:
                self.logger.warning(f"çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                self.use_kalman_filter = False
        elif self.use_kalman_filter and not UNIFIED_KALMAN_AVAILABLE:
            self.logger.warning("UnifiedKalmanãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚")
            self.use_kalman_filter = False
        
        # ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®åˆæœŸåŒ–
        self.roofing_filter = None
        if self.use_roofing_filter and ROOFING_FILTER_AVAILABLE:
            try:
                self.roofing_filter = RoofingFilter(
                    hp_cutoff=self.roofing_hp_cutoff,
                    ss_band_edge=self.roofing_ss_band_edge
                )
                self.logger.debug(f"ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼(hp={self.roofing_hp_cutoff}, ss={self.roofing_ss_band_edge})ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
            except Exception as e:
                self.logger.warning(f"ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                self.use_roofing_filter = False
        elif self.use_roofing_filter and not ROOFING_FILTER_AVAILABLE:
            self.logger.warning("RoofingFilterãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚")
            self.use_roofing_filter = False
        
        # çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®åˆæœŸåŒ–ï¼ˆå¿…é ˆæ©Ÿèƒ½ï¼‰
        self.smoother = None
        if UNIFIED_SMOOTHER_AVAILABLE:
            try:
                # å‹•çš„æœŸé–“å¯¾å¿œã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®ãƒã‚§ãƒƒã‚¯
                dynamic_supported_smoothers = ['ultimate_smoother', 'frama', 'super_smoother', 'zero_lag_ema', 'zlema']
                smoother_period_mode = 'fixed'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å›ºå®šæœŸé–“
                
                if self.use_dynamic_period:
                    if self.smoother_type in dynamic_supported_smoothers:
                        smoother_period_mode = 'dynamic'
                        self.logger.debug(f"{self.smoother_type}ã¯å‹•çš„æœŸé–“ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚å‹•çš„ãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–ã—ã¾ã™ã€‚")
                    else:
                        self.logger.warning(
                            f"{self.smoother_type}ã¯å‹•çš„æœŸé–“ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚"
                            f"å›ºå®šæœŸé–“ãƒ¢ãƒ¼ãƒ‰ã§ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã—ã¾ã™ã€‚"
                            f"å‹•çš„æœŸé–“å¯¾å¿œã‚¹ãƒ ãƒ¼ã‚µãƒ¼: {', '.join(dynamic_supported_smoothers)}"
                        )
                
                # ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
                smoother_params = {
                    'smoother_type': self.smoother_type,
                    'period': self.smoother_period,
                    'src_type': self.smoother_src_type,
                    'period_mode': smoother_period_mode
                }
                
                # å‹•çš„æœŸé–“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¿½åŠ 
                if smoother_period_mode == 'dynamic':
                    smoother_params.update({
                        'cycle_detector_type': self.detector_type,
                        'cycle_part': self.cycle_part,
                        'max_cycle': self.max_cycle,
                        'min_cycle': self.min_cycle,
                        'max_output': self.max_output,
                        'min_output': self.min_output,
                        'lp_period': self.lp_period,
                        'hp_period': self.hp_period
                    })
                
                self.smoother = UnifiedSmoother(**smoother_params)
                self.logger.debug(f"çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼({self.smoother_type})ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸï¼ˆå¿…é ˆæ©Ÿèƒ½ï¼‰")
                
            except Exception as e:
                self.logger.error(f"çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆå¿…é ˆæ©Ÿèƒ½ï¼‰: {e}")
                raise RuntimeError(f"Hyper ADXã§ã¯çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ãŒå¿…é ˆã§ã™ãŒã€åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        else:
            self.logger.error("UnifiedSmootherãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆå¿…é ˆæ©Ÿèƒ½ï¼‰")
            raise RuntimeError("Hyper ADXã§ã¯çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ãŒå¿…é ˆã§ã™ãŒã€åˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        # äºŒæ¬¡çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®åˆæœŸåŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ï¼‰
        self.secondary_smoother = None
        if self.use_secondary_smoothing and UNIFIED_SMOOTHER_AVAILABLE:
            try:
                # äºŒæ¬¡ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã¯å‹•çš„æœŸé–“å¯¾å¿œã—ãªã„ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ã«ä¿ã¤ï¼‰
                secondary_smoother_params = {
                    'smoother_type': self.secondary_smoother_type,
                    'period': self.secondary_smoother_period,
                    'src_type': 'close',  # å›ºå®šã§close
                    'period_mode': 'fixed'  # å›ºå®šæœŸé–“ãƒ¢ãƒ¼ãƒ‰
                }
                
                self.secondary_smoother = UnifiedSmoother(**secondary_smoother_params)
                self.logger.debug(f"äºŒæ¬¡çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼({self.secondary_smoother_type})ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ï¼‰")
                
            except Exception as e:
                self.logger.warning(f"äºŒæ¬¡çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}ã€‚äºŒæ¬¡å¹³æ»‘åŒ–æ©Ÿèƒ½ã‚’ç„¡åŠ¹ã«ã—ã¾ã™ã€‚")
                self.use_secondary_smoothing = False
        elif self.use_secondary_smoothing and not UNIFIED_SMOOTHER_AVAILABLE:
            self.logger.warning("UnifiedSmootherãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚äºŒæ¬¡å¹³æ»‘åŒ–æ©Ÿèƒ½ã‚’ç„¡åŠ¹ã«ã—ã¾ã™ã€‚")
            self.use_secondary_smoothing = False
        
        # ã‚¨ãƒ©ãƒ¼ã‚ºçµ±åˆã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®åˆæœŸåŒ–
        self.dc_detector = None
        if self.use_dynamic_period and EHLERS_UNIFIED_DC_AVAILABLE:
            try:
                self.dc_detector = EhlersUnifiedDC(
                    detector_type=self.detector_type,
                    lp_period=self.lp_period,
                    hp_period=self.hp_period,
                    cycle_part=self.cycle_part,
                    max_cycle=self.max_cycle,
                    min_cycle=self.min_cycle,
                    max_output=self.max_output,
                    min_output=self.min_output,
                    src_type='hlc3'
                )
                self.logger.debug(f"ã‚¨ãƒ©ãƒ¼ã‚ºçµ±åˆã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨({self.detector_type})ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
            except Exception as e:
                self.logger.warning(f"ã‚¨ãƒ©ãƒ¼ã‚ºçµ±åˆã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                self.use_dynamic_period = False
        elif self.use_dynamic_period and not EHLERS_UNIFIED_DC_AVAILABLE:
            self.logger.warning("EhlersUnifiedDCãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚å‹•çš„æœŸé–“ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚")
            self.use_dynamic_period = False
    
    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> HyperADXResult:
        """
        Hyper ADXã‚’è¨ˆç®—ã™ã‚‹
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆDataFrameã¾ãŸã¯NumPyé…åˆ—ï¼‰
                DataFrameã®å ´åˆã€'high', 'low', 'close'ã‚«ãƒ©ãƒ ãŒå¿…è¦
        
        Returns:
            HyperADXResult: Hyper ADXå€¤ã¨ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’å«ã‚€çµæœ
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã¨æº–å‚™
            if isinstance(data, pd.DataFrame):
                if not all(col in data.columns for col in ['high', 'low', 'close']):
                    raise ValueError("DataFrameã«ã¯'high', 'low', 'close'ã‚«ãƒ©ãƒ ãŒå¿…è¦ã§ã™")
                
                high = data['high'].values.astype(np.float64)
                low = data['low'].values.astype(np.float64)
                close = data['close'].values.astype(np.float64)
            else:
                if data.ndim != 2 or data.shape[1] < 4:
                    raise ValueError("NumPyé…åˆ—ã¯2æ¬¡å…ƒã§ã€å°‘ãªãã¨ã‚‚4åˆ—ï¼ˆOHLCï¼‰ãŒå¿…è¦ã§ã™")
                
                high = data[:, 1].astype(np.float64)
                low = data[:, 2].astype(np.float64)
                close = data[:, 3].astype(np.float64)
            
            length = len(high)
            
            # 1. ã‚½ãƒ¼ã‚¹ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            source_prices = PriceSource.calculate_source(data, 'hlc3')
            if isinstance(source_prices, pd.Series):
                source_prices = source_prices.values
            if not isinstance(source_prices, np.ndarray):
                source_prices = np.array(source_prices)
            if source_prices.dtype != np.float64:
                source_prices = source_prices.astype(np.float64)
            
            # çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            filtered_prices = source_prices.copy()
            if self.use_kalman_filter and self.kalman_filter is not None:
                try:
                    # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨
                    kalman_result = self.kalman_filter.calculate(source_prices)
                    if kalman_result is not None:
                        # UnifiedKalmanResultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                        if hasattr(kalman_result, 'filtered_values'):
                            filtered_values = kalman_result.filtered_values
                        elif hasattr(kalman_result, 'values'):
                            filtered_values = kalman_result.values
                        else:
                            filtered_values = kalman_result
                        
                        if len(filtered_values) == length:
                            filtered_prices = filtered_values.astype(np.float64)
                        
                        self.logger.debug("çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚‹ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’é©ç”¨ã—ã¾ã—ãŸ")
                    else:
                        self.logger.debug("ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®çµæœãŒç„¡åŠ¹ã€‚å…ƒã®ä¾¡æ ¼ã‚’ä½¿ç”¨ã—ã¾ã™")
                        
                except Exception as e:
                    self.logger.warning(f"çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}ã€‚å…ƒã®å€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            
            # 2. ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã«ã‚ˆã‚‹æœŸé–“æ¤œå‡º
            dynamic_periods = None
            cycle_periods = np.full(length, self.period, dtype=np.float64)
            
            if self.use_dynamic_period and self.dc_detector is not None:
                try:
                    # ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã‚’ä½¿ç”¨ã—ã¦ã‚µã‚¤ã‚¯ãƒ«å€¤ã‚’å–å¾—
                    cycle_result = self.dc_detector.calculate(data)
                    
                    # cycle_resultã®å‹ã‚’ç¢ºèªã—ã¦valuesã‚’å–å¾—
                    if hasattr(cycle_result, 'values'):
                        cycle_values = cycle_result.values
                    elif hasattr(cycle_result, 'cycle_periods'):
                        cycle_values = cycle_result.cycle_periods
                    elif isinstance(cycle_result, np.ndarray):
                        cycle_values = cycle_result
                    else:
                        cycle_values = np.array(cycle_result) if cycle_result is not None else np.full(length, self.period)
                    
                    # é…åˆ—ã®é•·ã•ã‚’èª¿æ•´
                    if len(cycle_values) != length:
                        if len(cycle_values) > length:
                            cycle_values = cycle_values[:length]
                        else:
                            # ä¸è¶³åˆ†ã¯æœ€å¾Œã®å€¤ã§åŸ‹ã‚ã‚‹
                            extended_cycles = np.full(length, self.period, dtype=np.float64)
                            extended_cycles[:len(cycle_values)] = cycle_values
                            if len(cycle_values) > 0:
                                last_valid = cycle_values[-1] if not np.isnan(cycle_values[-1]) else self.period
                                extended_cycles[len(cycle_values):] = last_valid
                            cycle_values = extended_cycles
                    
                    # ã‚µã‚¤ã‚¯ãƒ«å€¤ã‹ã‚‰æœŸé–“ã‚’è¨ˆç®—ï¼ˆãƒã‚¤ãƒ‘ãƒ¼ERã¨åŒã˜ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
                    valid_cycles = cycle_values[~np.isnan(cycle_values) & (cycle_values > 0)]
                    if len(valid_cycles) > 0:
                        # ã‚µã‚¤ã‚¯ãƒ«å€¤ã‚’æœŸé–“ã«å¤‰æ›ï¼ˆä¾‹ï¼šã‚µã‚¤ã‚¯ãƒ«å€¤ã®åŠåˆ†ã‚’æœŸé–“ã¨ã™ã‚‹ï¼‰
                        dynamic_periods = np.where(
                            ~np.isnan(cycle_values) & (cycle_values > 0),
                            np.clip(cycle_values * 0.5, 5, 50),
                            self.period
                        )
                        cycle_periods = cycle_values.copy()
                        self.logger.debug(f"å‹•çš„æœŸé–“ã‚’è¨ˆç®—: ç¯„å›² {np.min(dynamic_periods):.1f} - {np.max(dynamic_periods):.1f}")
                    else:
                        dynamic_periods = np.full(length, self.period)
                        self.logger.warning("æœ‰åŠ¹ãªã‚µã‚¤ã‚¯ãƒ«å€¤ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€å›ºå®šæœŸé–“ã‚’ä½¿ç”¨ã—ã¾ã™")
                    
                except Exception as e:
                    self.logger.warning(f"å‹•çš„æœŸé–“è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}ã€‚å›ºå®šæœŸé–“ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                    dynamic_periods = None
            
            # 3. ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚‹ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€ãƒã‚¤ãƒ‘ãƒ¼ERã¨åŒã˜ï¼‰
            roofing_values = np.full_like(filtered_prices, np.nan)
            
            if self.use_roofing_filter and self.roofing_filter is not None:
                try:
                    roofing_result = self.roofing_filter.calculate(data)
                    roofing_values = roofing_result.values
                    
                    # ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®çµæœã‚’ä½¿ç”¨ï¼ˆãƒã‚¤ãƒ‘ãƒ¼ERã¨åŒã˜ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
                    # ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯ä¾¡æ ¼ã®æŒ¯å‹•æˆåˆ†ã‚’æŠ½å‡ºã™ã‚‹ã®ã§ã€ç›´æ¥ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ä¾¡æ ¼ã¨ã—ã¦ä½¿ç”¨
                    # NaNå€¤ãŒå¤šã„å ´åˆã¯å…ƒã®ä¾¡æ ¼ã‚’ä½¿ç”¨
                    valid_roofing = np.sum(~np.isnan(roofing_values))
                    if valid_roofing > len(roofing_values) * 0.5:  # æœ‰åŠ¹å€¤ãŒ50%ä»¥ä¸Šã®å ´åˆ
                        # ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å€¤ã‚’ã‚½ãƒ¼ã‚¹ä¾¡æ ¼ã®ã‚¹ã‚±ãƒ¼ãƒ«ã«èª¿æ•´
                        roofing_range = np.nanmax(roofing_values) - np.nanmin(roofing_values)
                        price_range = np.nanmax(filtered_prices) - np.nanmin(filtered_prices)
                        if roofing_range > 0 and price_range > 0:
                            scale_factor = price_range / roofing_range * 0.1  # 10%ã®å½±éŸ¿åº¦
                            filtered_prices = filtered_prices + roofing_values * scale_factor
                        else:
                            filtered_prices = filtered_prices
                    else:
                        filtered_prices = filtered_prices
                    
                    # NumPyé…åˆ—ã¨ã—ã¦ç¢ºä¿
                    if not isinstance(filtered_prices, np.ndarray):
                        filtered_prices = np.array(filtered_prices)
                    if filtered_prices.dtype != np.float64:
                        filtered_prices = filtered_prices.astype(np.float64)
                    
                    self.logger.debug("ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚‹ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’é©ç”¨ã—ã¾ã—ãŸ")
                        
                except Exception as e:
                    self.logger.warning(f"ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}ã€‚å…ƒã®å€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                    roofing_values = np.full_like(filtered_prices, np.nan)
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ä¾¡æ ¼ã§HLCä¾¡æ ¼ã‚’èª¿æ•´ï¼ˆãƒã‚¤ãƒ‘ãƒ¼ERã§ã¯åŠ¹ç‡æ¯”è¨ˆç®—ã«filtered_pricesã‚’ä½¿ç”¨ï¼‰
            # ADXã§ã¯ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ä¾¡æ ¼ã‚’ä½¿ã£ã¦HLCå…¨ä½“ã‚’èª¿æ•´
            if np.any(~np.isnan(filtered_prices)):
                # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ä¾¡æ ¼ã¨å…ƒã®ã‚½ãƒ¼ã‚¹ä¾¡æ ¼ã®æ¯”ç‡ã‚’è¨ˆç®—
                adjustment_ratio = np.divide(filtered_prices, source_prices, 
                                           out=np.ones_like(filtered_prices), where=source_prices!=0)
                # HLCä¾¡æ ¼ã‚’èª¿æ•´
                high = high * adjustment_ratio
                low = low * adjustment_ratio 
                close = close * adjustment_ratio
            
            # NumPyé…åˆ—ã¨ã—ã¦ç¢ºä¿
            if not isinstance(close, np.ndarray):
                close = np.array(close)
            if close.dtype != np.float64:
                close = close.astype(np.float64)
            
            # 4. ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†æ¸ˆä¾¡æ ¼ã«ã‚ˆã‚‹ DX è¨ˆç®—
            raw_dx, plus_di, minus_di = calculate_dx_values_numba(
                high, low, close, self.period, dynamic_periods
            )
            
            # 5. çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã«ã‚ˆã‚‹ DX ã®å¹³æ»‘åŒ–ï¼ˆADXä½œæˆã€å¿…é ˆæ©Ÿèƒ½ï¼‰
            final_adx = np.full(length, np.nan, dtype=np.float64)
            if self.smoother is not None:
                try:
                    # NaNå€¤ã®å‡¦ç† - ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã‚ˆã†ã«NaNå€¤ã‚’å‰æ–¹è£œå®Œ
                    clean_dx = raw_dx.copy()
                    nan_mask = np.isnan(clean_dx)
                    
                    if np.any(nan_mask):
                        # æœ€åˆã®æœ‰åŠ¹å€¤ã‚’è¦‹ã¤ã‘ã¦å‰æ–¹è£œå®Œ
                        first_valid_idx = np.where(~nan_mask)[0]
                        if len(first_valid_idx) > 0:
                            first_valid = first_valid_idx[0]
                            first_value = clean_dx[first_valid]
                            # æœ€åˆã®æœ‰åŠ¹å€¤ã‚ˆã‚Šå‰ã‚’ãã®å€¤ã§è£œå®Œ
                            clean_dx[:first_valid] = first_value
                    
                    # DXã‚’DataFrameã«å¤‰æ›
                    if isinstance(data, pd.DataFrame):
                        dx_df = data.copy()
                        dx_df['close'] = clean_dx  # DXå€¤ã‚’closeã¨ã—ã¦ä½¿ç”¨
                    else:
                        dx_df = pd.DataFrame({
                            'open': data[:, 0],
                            'high': data[:, 1],
                            'low': data[:, 2],
                            'close': clean_dx,  # DXå€¤ã‚’closeã¨ã—ã¦ä½¿ç”¨
                            'volume': np.ones(length)
                        })
                    
                    # çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã§ADXã‚’è¨ˆç®—
                    smoother_result = self.smoother.calculate(dx_df)
                    if smoother_result is not None:
                        # UnifiedSmootherResultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                        if hasattr(smoother_result, 'values'):
                            smoothed_values = smoother_result.values
                        else:
                            smoothed_values = smoother_result
                        
                        if len(smoothed_values) == length:
                            final_adx = smoothed_values.astype(np.float64)
                            self.logger.debug("çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã«ã‚ˆã‚‹DXå€¤ã®å¹³æ»‘åŒ–ï¼ˆADXä½œæˆï¼‰ã‚’é©ç”¨ã—ã¾ã—ãŸ")
                        else:
                            self.logger.warning("çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®çµæœãŒç„¡åŠ¹ã§ã™")
                            final_adx = clean_dx.copy()
                    else:
                        self.logger.warning("çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®çµæœãŒç„¡åŠ¹ã§ã™")
                        final_adx = clean_dx.copy()
                        
                except Exception as e:
                    self.logger.error(f"çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼é©ç”¨ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å˜ç´”ãªEMAã§ADXã‚’è¨ˆç®—
                    for i in range(self.period - 1, length):
                        if not np.isnan(raw_dx[i]):
                            alpha = 2.0 / (self.period + 1.0)
                            if i == self.period - 1:
                                final_adx[i] = raw_dx[i]
                            else:
                                final_adx[i] = (raw_dx[i] * alpha) + (final_adx[i-1] * (1 - alpha))
            else:
                raise RuntimeError("çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆå¿…é ˆæ©Ÿèƒ½ï¼‰")
            
            # 6. äºŒæ¬¡å¹³æ»‘åŒ–å‡¦ç†ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            secondary_smoothed_adx = None
            if self.use_secondary_smoothing and self.secondary_smoother is not None:
                try:
                    # ä¸€æ¬¡å¹³æ»‘åŒ–ã•ã‚ŒãŸADXå€¤ï¼ˆfinal_adxï¼‰ã‚’ã•ã‚‰ã«å¹³æ»‘åŒ–
                    # NaNå€¤ã®å‡¦ç†
                    clean_adx = final_adx.copy()
                    nan_mask = np.isnan(clean_adx)
                    
                    if np.any(nan_mask):
                        # æœ€åˆã®æœ‰åŠ¹å€¤ã‚’è¦‹ã¤ã‘ã¦å‰æ–¹è£œå®Œ
                        first_valid_idx = np.where(~nan_mask)[0]
                        if len(first_valid_idx) > 0:
                            first_valid = first_valid_idx[0]
                            first_value = clean_adx[first_valid]
                            # æœ€åˆã®æœ‰åŠ¹å€¤ã‚ˆã‚Šå‰ã‚’ãã®å€¤ã§è£œå®Œ
                            clean_adx[:first_valid] = first_value
                    
                    # ADXã‚’DataFrameã«å¤‰æ›
                    if isinstance(data, pd.DataFrame):
                        adx_df = data.copy()
                        adx_df['close'] = clean_adx  # ADXå€¤ã‚’closeã¨ã—ã¦ä½¿ç”¨
                    else:
                        adx_df = pd.DataFrame({
                            'open': data[:, 0],
                            'high': data[:, 1],
                            'low': data[:, 2],
                            'close': clean_adx,  # ADXå€¤ã‚’closeã¨ã—ã¦ä½¿ç”¨
                            'volume': np.ones(length)
                        })
                    
                    # äºŒæ¬¡çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã§ã•ã‚‰ã«å¹³æ»‘åŒ–
                    secondary_result = self.secondary_smoother.calculate(adx_df)
                    if secondary_result is not None:
                        # UnifiedSmootherResultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                        if hasattr(secondary_result, 'values'):
                            secondary_values = secondary_result.values
                        else:
                            secondary_values = secondary_result
                        
                        if len(secondary_values) == length:
                            secondary_smoothed_adx = secondary_values.astype(np.float64)
                            # å…ƒã®NaNä½ç½®ã‚’å¾©å…ƒ
                            if np.any(nan_mask):
                                secondary_smoothed_adx[nan_mask] = np.nan
                            self.logger.debug("äºŒæ¬¡çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã«ã‚ˆã‚‹ADXå€¤ã®å¹³æ»‘åŒ–ã‚’é©ç”¨ã—ã¾ã—ãŸ")
                        else:
                            self.logger.warning("äºŒæ¬¡çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®çµæœãŒç„¡åŠ¹ã§ã™")
                    else:
                        self.logger.warning("äºŒæ¬¡çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®çµæœãŒç„¡åŠ¹ã§ã™")
                        
                except Exception as e:
                    self.logger.warning(f"äºŒæ¬¡çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼é©ç”¨ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            
            # 7. ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¨ˆç®—ã¨ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š
            midline, trend_signal = calculate_midline_and_trend_signal_hyper(
                final_adx, self.midline_period
            )
            
            # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æã®å®Ÿè¡Œ
            percentiles, trend_state, trend_intensity = self._calculate_percentile_analysis(
                final_adx, 'trend'
            )
            
            # çµæœã®ä½œæˆ
            result = HyperADXResult(
                values=final_adx.copy(),
                raw_dx=raw_dx.copy(),
                secondary_smoothed=secondary_smoothed_adx.copy() if secondary_smoothed_adx is not None else None,
                midline=midline.copy(),
                trend_signal=trend_signal.copy(),
                filtered_prices=filtered_prices.copy(),
                roofing_values=roofing_values.copy(),
                plus_di=plus_di.copy(),
                minus_di=minus_di.copy(),
                cycle_periods=cycle_periods.copy(),
                percentiles=percentiles.copy() if percentiles is not None else None,
                trend_state=trend_state.copy() if trend_state is not None else None,
                trend_intensity=trend_intensity.copy() if trend_intensity is not None else None
            )
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
            if len(self._result_cache) >= self._max_cache_size and self._cache_keys:
                oldest_key = self._cache_keys.pop(0)
                if oldest_key in self._result_cache:
                    del self._result_cache[oldest_key]
            
            self._latest_result = result
            
            # åŸºåº•ã‚¯ãƒ©ã‚¹ç”¨ã®å€¤è¨­å®š
            self._values = final_adx
            
            return result
            
        except Exception as e:
            error_msg = str(e)
            stack_trace = traceback.format_exc()
            self.logger.error(f"Hyper ADX '{self.name}' è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {error_msg}\n{stack_trace}")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ NaN ã§åŸ‹ã‚ãŸçµæœã‚’è¿”ã™
            length = len(data) if hasattr(data, '__len__') else 100
            empty_array = np.full(length, np.nan)
            error_result = HyperADXResult(
                values=empty_array,
                raw_dx=empty_array,
                secondary_smoothed=None,
                midline=empty_array,
                trend_signal=empty_array,
                filtered_prices=empty_array,
                roofing_values=empty_array,
                plus_di=empty_array,
                minus_di=empty_array,
                cycle_periods=empty_array,
                percentiles=None,
                trend_state=None,
                trend_intensity=None
            )
            return error_result
    
    def _get_latest_result(self) -> Optional[HyperADXResult]:
        """æœ€æ–°ã®çµæœã‚’å–å¾—"""
        return self._latest_result
    
    def reset(self) -> None:
        """ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        super().reset()
        self._latest_result = None
        self._result_cache = {}
        self._cache_keys = []
        
        # ä¾å­˜ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®ãƒªã‚»ãƒƒãƒˆ
        if self.kalman_filter and hasattr(self.kalman_filter, 'reset'):
            self.kalman_filter.reset()
        if self.roofing_filter and hasattr(self.roofing_filter, 'reset'):
            self.roofing_filter.reset()
        if self.smoother and hasattr(self.smoother, 'reset'):
            self.smoother.reset()
        if self.dc_detector and hasattr(self.dc_detector, 'reset'):
            self.dc_detector.reset()
    
    # è¿½åŠ ã®getterãƒ¡ã‚½ãƒƒãƒ‰
    def get_raw_dx(self) -> Optional[np.ndarray]:
        """ç”Ÿã®DXå€¤ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.raw_dx.copy() if result else None
    
    def get_midline(self) -> Optional[np.ndarray]:
        """ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³å€¤ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.midline.copy() if result else None
    
    def get_trend_signal(self) -> Optional[np.ndarray]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡å·ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.trend_signal.copy() if result else None
    
    def get_filtered_prices(self) -> Optional[np.ndarray]:
        """ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å€¤ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.filtered_prices.copy() if result else None
    
    def get_roofing_values(self) -> Optional[np.ndarray]:
        """ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å€¤ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.roofing_values.copy() if result else None
    
    def get_plus_di(self) -> Optional[np.ndarray]:
        """+DIå€¤ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.plus_di.copy() if result else None
    
    def get_minus_di(self) -> Optional[np.ndarray]:
        """-DIå€¤ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.minus_di.copy() if result else None
    
    def get_cycle_periods(self) -> Optional[np.ndarray]:
        """ã‚µã‚¤ã‚¯ãƒ«æœŸé–“å€¤ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.cycle_periods.copy() if result else None
    
    # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æé–¢é€£ã®getter ãƒ¡ã‚½ãƒƒãƒ‰
    def get_percentiles(self) -> Optional[np.ndarray]:
        """ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«å€¤ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.percentiles.copy() if result else None
    
    def get_trend_state(self) -> Optional[np.ndarray]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰çŠ¶æ…‹ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.trend_state.copy() if result else None
    
    def get_trend_intensity(self) -> Optional[np.ndarray]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.trend_intensity.copy() if result else None
    
    def get_indicator_info(self) -> dict:
        """ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼æƒ…å ±ã‚’å–å¾—"""
        info = {
            'name': self.name,
            'period': self.period,
            'midline_period': self.midline_period,
            'use_kalman_filter': self.use_kalman_filter,
            'kalman_filter_type': self.kalman_filter_type if self.use_kalman_filter else None,
            'use_roofing_filter': self.use_roofing_filter,
            'roofing_hp_cutoff': self.roofing_hp_cutoff if self.use_roofing_filter else None,
            'roofing_ss_band_edge': self.roofing_ss_band_edge if self.use_roofing_filter else None,
            'smoother_type': self.smoother_type,  # å¿…é ˆæ©Ÿèƒ½
            'smoother_period': self.smoother_period,
            'use_dynamic_period': self.use_dynamic_period,
            'detector_type': self.detector_type if self.use_dynamic_period else None,
            'enable_percentile_analysis': self.enable_percentile_analysis,
            'description': 'ADXãƒ™ãƒ¼ã‚¹ã®çµ±åˆå‹ãƒˆãƒ¬ãƒ³ãƒ‰ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ï¼ˆ0-1ç¯„å›²ã€é«˜å€¤=å¼·ã„ãƒˆãƒ¬ãƒ³ãƒ‰ã€ã‚«ãƒ«ãƒãƒ³ãƒ»ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ»ã‚¹ãƒ ãƒ¼ã‚µãƒ¼çµ±åˆï¼‰'
        }
        return info


# ä¾¿åˆ©é–¢æ•°
def calculate_hyper_adx(
    data: Union[pd.DataFrame, np.ndarray],
    period: int = 14,
    midline_period: int = 100,
    use_kalman_filter: bool = True,
    kalman_filter_type: str = 'adaptive',
    use_roofing_filter: bool = True,
    smoother_type: str = 'frama',
    smoother_period: int = 12,
    use_dynamic_period: bool = True,
    detector_type: str = 'dft_dominant',
    enable_percentile_analysis: bool = False,
    **kwargs
) -> np.ndarray:
    """
    Hyper ADXï¼ˆçµ±åˆå‹Average Directional Indexï¼‰ã‚’è¨ˆç®—ã™ã‚‹ä¾¿åˆ©é–¢æ•°
    
    Args:
        data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆDataFrameã¾ãŸã¯NumPyé…åˆ—ï¼‰
        period: ADXè¨ˆç®—æœŸé–“
        midline_period: ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¨ˆç®—æœŸé–“
        use_kalman_filter: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        kalman_filter_type: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¿ã‚¤ãƒ—
        use_roofing_filter: ãƒ«ãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        smoother_type: çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¿ã‚¤ãƒ—ï¼ˆå¿…é ˆæ©Ÿèƒ½ï¼‰
        smoother_period: ã‚¹ãƒ ãƒ¼ã‚µãƒ¼æœŸé–“
        use_dynamic_period: å‹•çš„æœŸé–“é©å¿œã‚’ä½¿ç”¨ã™ã‚‹ã‹
        detector_type: ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã‚¿ã‚¤ãƒ—
        enable_percentile_analysis: ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹
        **kwargs: ãã®ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        
    Returns:
        Hyper ADXå€¤ã®é…åˆ—
    """
    indicator = HyperADX(
        period=period,
        midline_period=midline_period,
        use_kalman_filter=use_kalman_filter,
        kalman_filter_type=kalman_filter_type,
        use_roofing_filter=use_roofing_filter,
        smoother_type=smoother_type,
        smoother_period=smoother_period,
        use_dynamic_period=use_dynamic_period,
        detector_type=detector_type,
        enable_percentile_analysis=enable_percentile_analysis,
        **kwargs
    )
    
    result = indicator.calculate(data)
    return result.values