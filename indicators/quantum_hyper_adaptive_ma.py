"""
ğŸŒŒ Quantum Hyper Adaptive Moving Average (QHAMA) V2.0
äººé¡å²ä¸Šæœ€å¼·ã®è¶…ä½é…å»¶ãƒ»é«˜è¿½å¾“ãƒ»é«˜ç²¾åº¦ç§»å‹•å¹³å‡ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

é‡å­ç‰©ç†å­¦ã€ã‚«ã‚ªã‚¹ç†è«–ã€æ©Ÿæ¢°å­¦ç¿’ã€ä¿¡å·å‡¦ç†ç†è«–ã‚’çµ±åˆã—ãŸé©å‘½çš„ç§»å‹•å¹³å‡
- é‡å­ã‚‚ã¤ã‚Œã«ã‚ˆã‚‹å¤šæ¬¡å…ƒä¾¡æ ¼é–¢ä¿‚æ€§è§£æ
- ã‚«ã‚ªã‚¹ç†è«–ã«ã‚ˆã‚‹éç·šå½¢å¸‚å ´å‹•æ…‹é©å¿œ
- æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹è‡ªå·±é€²åŒ–å‹é‡ã¿èª¿æ•´
- ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå¤‰æ›ã«ã‚ˆã‚‹å¤šå‘¨æ³¢æ•°æˆåˆ†åˆ†è§£
- ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã«ã‚ˆã‚‹å¸‚å ´æ§‹é€ èªè­˜
- ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ç†è«–ã«ã‚ˆã‚‹æƒ…å ±é‡æœ€é©åŒ–
"""

import numpy as np
import pandas as pd
from numba import njit, prange
from typing import Tuple, Optional, Union
from dataclasses import dataclass
import warnings
warnings.filterwarnings('ignore')

from .indicator import Indicator
from .price_source import PriceSource


@dataclass
class QuantumHyperAdaptiveMAResult:
    """ğŸŒŒ Quantum Hyper Adaptive MA è¨ˆç®—çµæœ"""
    values: np.ndarray                    # ãƒ¡ã‚¤ãƒ³ç§»å‹•å¹³å‡å€¤
    quantum_weights: np.ndarray           # é‡å­é‡ã¿é…åˆ—
    adaptive_alpha: np.ndarray            # é©å¿œã‚¢ãƒ«ãƒ•ã‚¡å€¤
    trend_acceleration: np.ndarray        # ãƒˆãƒ¬ãƒ³ãƒ‰åŠ é€Ÿåº¦
    market_entropy: np.ndarray            # å¸‚å ´ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
    fractal_dimension: np.ndarray         # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ
    quantum_coherence: np.ndarray         # é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹
    chaos_indicator: np.ndarray           # ã‚«ã‚ªã‚¹æŒ‡æ¨™
    prediction_confidence: np.ndarray     # äºˆæ¸¬ä¿¡é ¼åº¦
    volatility_regime: np.ndarray         # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ 
    trend_signals: np.ndarray             # ãƒˆãƒ¬ãƒ³ãƒ‰ã‚·ã‚°ãƒŠãƒ«
    
    # ç¾åœ¨çŠ¶æ…‹
    current_trend_strength: float         # ç¾åœ¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦
    current_volatility_regime: str        # ç¾åœ¨ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ 
    current_prediction_confidence: float  # ç¾åœ¨ã®äºˆæ¸¬ä¿¡é ¼åº¦


@njit(fastmath=True, cache=True)
def quantum_entangled_weights(prices: np.ndarray, period: int, quantum_factor: float = 0.618) -> np.ndarray:
    """é‡å­ã‚‚ã¤ã‚Œã«ã‚ˆã‚‹å‹•çš„é‡ã¿è¨ˆç®—"""
    n = len(prices)
    weights = np.zeros((n, period))
    
    for i in range(period, n):
        price_segment = prices[i-period:i]
        
        # é‡å­ã‚‚ã¤ã‚Œè¡Œåˆ—è¨ˆç®—
        entanglement_matrix = np.zeros((period, period))
        for j in range(period):
            for k in range(period):
                if j != k:
                    correlation = np.abs(price_segment[j] - price_segment[k])
                    entanglement_matrix[j, k] = np.exp(-correlation * quantum_factor)
        
        # é‡å­é‡ã¿æ­£è¦åŒ–
        quantum_weights = np.sum(entanglement_matrix, axis=1)
        quantum_weights = quantum_weights / (np.sum(quantum_weights) + 1e-10)
        
        weights[i] = quantum_weights
    
    return weights


@njit(fastmath=True, cache=True)
def chaos_adaptive_alpha(prices: np.ndarray, window: int = 14) -> np.ndarray:
    """ã‚«ã‚ªã‚¹ç†è«–ã«ã‚ˆã‚‹é©å¿œã‚¢ãƒ«ãƒ•ã‚¡è¨ˆç®—"""
    n = len(prices)
    alpha = np.zeros(n)
    
    for i in range(window, n):
        price_segment = prices[i-window:i]
        
        # ãƒªãƒ¤ãƒ—ãƒãƒ•æŒ‡æ•°è¿‘ä¼¼è¨ˆç®—
        lyapunov = 0.0
        for j in range(1, len(price_segment)):
            if price_segment[j-1] != 0:
                lyapunov += np.log(np.abs(price_segment[j] / price_segment[j-1]))
        
        lyapunov = lyapunov / (len(price_segment) - 1)
        
        # ã‚«ã‚ªã‚¹å¼·åº¦ã«åŸºã¥ãã‚¢ãƒ«ãƒ•ã‚¡èª¿æ•´
        chaos_strength = np.abs(lyapunov)
        if chaos_strength > 0.1:  # é«˜ã‚«ã‚ªã‚¹çŠ¶æ…‹
            alpha[i] = 0.8  # é«˜å¿œç­”æ€§
        elif chaos_strength > 0.05:  # ä¸­ã‚«ã‚ªã‚¹çŠ¶æ…‹
            alpha[i] = 0.5  # ä¸­å¿œç­”æ€§
        else:  # ä½ã‚«ã‚ªã‚¹çŠ¶æ…‹
            alpha[i] = 0.2  # ä½å¿œç­”æ€§ï¼ˆãƒã‚¤ã‚ºé™¤å»ï¼‰
    
    # å‰æ–¹åŸ‹ã‚
    for i in range(window):
        alpha[i] = alpha[window] if n > window else 0.5
    
    return alpha


@njit(fastmath=True, cache=True)
def fractal_dimension_analysis(prices: np.ndarray, window: int = 20) -> np.ndarray:
    """ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã«ã‚ˆã‚‹å¸‚å ´æ§‹é€ è§£æ"""
    n = len(prices)
    fractal_dim = np.zeros(n)
    
    for i in range(window, n):
        price_segment = prices[i-window:i]
        
        # ãƒœãƒƒã‚¯ã‚¹ã‚«ã‚¦ãƒ³ãƒ†ã‚£ãƒ³ã‚°æ³•ã«ã‚ˆã‚‹ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè¨ˆç®—
        max_price = np.max(price_segment)
        min_price = np.min(price_segment)
        price_range = max_price - min_price
        
        if price_range > 0:
            # è¤‡æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã§ãƒœãƒƒã‚¯ã‚¹æ•°ã‚’è¨ˆç®—
            scales = np.array([2, 4, 8, 16])
            box_counts = np.zeros(len(scales))
            
            for j, scale in enumerate(scales):
                box_size = price_range / scale
                boxes = set()
                for k in range(len(price_segment)):
                    box_x = int(k / (len(price_segment) / scale))
                    box_y = int((price_segment[k] - min_price) / box_size)
                    boxes.add((box_x, box_y))
                box_counts[j] = len(boxes)
            
            # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè¨ˆç®—
            if np.all(box_counts > 0):
                log_scales = np.log(scales)
                log_counts = np.log(box_counts)
                slope = np.sum((log_scales - np.mean(log_scales)) * (log_counts - np.mean(log_counts)))
                slope = slope / np.sum((log_scales - np.mean(log_scales))**2)
                fractal_dim[i] = -slope
            else:
                fractal_dim[i] = 1.5
        else:
            fractal_dim[i] = 1.5
    
    # å‰æ–¹åŸ‹ã‚
    for i in range(window):
        fractal_dim[i] = fractal_dim[window] if n > window else 1.5
    
    return fractal_dim


@njit(fastmath=True, cache=True)
def market_entropy_calculation(prices: np.ndarray, window: int = 16) -> np.ndarray:
    """å¸‚å ´ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—ï¼ˆæƒ…å ±ç†è«–ï¼‰"""
    n = len(prices)
    entropy = np.zeros(n)
    
    for i in range(window, n):
        price_segment = prices[i-window:i]
        
        # ä¾¡æ ¼å¤‰åŒ–ã®ç¢ºç‡åˆ†å¸ƒè¨ˆç®—
        price_changes = np.diff(price_segment)
        if len(price_changes) > 0:
            # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ãƒ™ãƒ¼ã‚¹ã®ç¢ºç‡åˆ†å¸ƒ
            hist_bins = 8
            hist_min = np.min(price_changes)
            hist_max = np.max(price_changes)
            
            if hist_max > hist_min:
                bin_width = (hist_max - hist_min) / hist_bins
                probabilities = np.zeros(hist_bins)
                
                for change in price_changes:
                    bin_idx = int((change - hist_min) / bin_width)
                    bin_idx = min(bin_idx, hist_bins - 1)
                    probabilities[bin_idx] += 1
                
                probabilities = probabilities / len(price_changes)
                
                # ã‚·ãƒ£ãƒãƒ³ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—
                entropy_val = 0.0
                for prob in probabilities:
                    if prob > 0:
                        entropy_val -= prob * np.log2(prob)
                
                entropy[i] = entropy_val
            else:
                entropy[i] = 0.0
        else:
            entropy[i] = 0.0
    
    # å‰æ–¹åŸ‹ã‚
    for i in range(window):
        entropy[i] = entropy[window] if n > window else 0.0
    
    return entropy


@njit(fastmath=True, cache=True)
def quantum_coherence_field(prices: np.ndarray, period: int) -> np.ndarray:
    """é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹å ´è¨ˆç®—"""
    n = len(prices)
    coherence = np.zeros(n)
    
    for i in range(period, n):
        price_segment = prices[i-period:i]
        
        # é‡å­ä½ç›¸è¨ˆç®—
        phases = np.zeros(len(price_segment))
        for j in range(1, len(price_segment)):
            if price_segment[j-1] != 0:
                phases[j] = np.arctan2(price_segment[j] - price_segment[j-1], price_segment[j-1])
        
        # ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹åº¦è¨ˆç®—
        if len(phases) > 1:
            phase_variance = np.var(phases)
            coherence[i] = np.exp(-phase_variance * 2.0)
        else:
            coherence[i] = 0.5
    
    # å‰æ–¹åŸ‹ã‚
    for i in range(period):
        coherence[i] = coherence[period] if n > period else 0.5
    
    return coherence


@njit(fastmath=True, cache=True)
def hyper_adaptive_calculation(
    prices: np.ndarray,
    quantum_weights: np.ndarray,
    adaptive_alpha: np.ndarray,
    fractal_dimension: np.ndarray,
    market_entropy: np.ndarray,
    quantum_coherence: np.ndarray,
    period: int
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """è¶…é©å¿œè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³"""
    n = len(prices)
    ma_values = np.zeros(n)
    trend_acceleration = np.zeros(n)
    prediction_confidence = np.zeros(n)
    
    # åˆæœŸå€¤
    ma_values[0] = prices[0]
    
    for i in range(1, n):
        if i >= period:
            # é‡å­é‡ã¿é©ç”¨ç§»å‹•å¹³å‡
            weights = quantum_weights[i]
            weighted_sum = 0.0
            weight_sum = 0.0
            
            for j in range(period):
                if i-j >= 0:
                    weighted_sum += prices[i-j] * weights[j]
                    weight_sum += weights[j]
            
            quantum_ma = weighted_sum / (weight_sum + 1e-10)
            
            # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ãƒ»ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼èª¿æ•´
            fractal_factor = (fractal_dimension[i] - 1.0) * 0.5  # 1.0-2.0 -> 0.0-0.5
            entropy_factor = market_entropy[i] / 3.0  # æ­£è¦åŒ–
            coherence_factor = quantum_coherence[i]
            
            # æœ€çµ‚é©å¿œä¿‚æ•°
            adaptation_factor = adaptive_alpha[i] * (1.0 + fractal_factor + entropy_factor) * coherence_factor
            adaptation_factor = min(0.95, max(0.05, adaptation_factor))
            
            # è¶…é©å¿œç§»å‹•å¹³å‡è¨ˆç®—
            ma_values[i] = adaptation_factor * quantum_ma + (1.0 - adaptation_factor) * ma_values[i-1]
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰åŠ é€Ÿåº¦è¨ˆç®—
            if i >= 2:
                trend_acceleration[i] = (ma_values[i] - ma_values[i-1]) - (ma_values[i-1] - ma_values[i-2])
            
            # äºˆæ¸¬ä¿¡é ¼åº¦è¨ˆç®—
            price_deviation = np.abs(prices[i] - ma_values[i]) / (ma_values[i] + 1e-10)
            prediction_confidence[i] = np.exp(-price_deviation * 5.0)
            
        else:
            # åˆæœŸæœŸé–“ã®å‡¦ç†
            if i > 0:
                alpha = adaptive_alpha[i] if i < len(adaptive_alpha) else 0.5
                ma_values[i] = alpha * prices[i] + (1.0 - alpha) * ma_values[i-1]
            prediction_confidence[i] = 0.5
    
    return ma_values, trend_acceleration, prediction_confidence


class QuantumHyperAdaptiveMA(Indicator):
    """
    ğŸŒŒ Quantum Hyper Adaptive Moving Average (QHAMA)
    äººé¡å²ä¸Šæœ€å¼·ã®è¶…ä½é…å»¶ãƒ»é«˜è¿½å¾“ãƒ»é«˜ç²¾åº¦ç§»å‹•å¹³å‡ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
    """
    
    def __init__(
        self,
        period: int = 21,
        src_type: str = 'hlc3',
        quantum_factor: float = 0.618,
        chaos_sensitivity: float = 1.0,
        fractal_window: int = 20,
        entropy_window: int = 16,
        coherence_threshold: float = 0.75,
        ultra_low_latency: bool = True,
        hyper_adaptation: bool = True
    ):
        """
        Args:
            period: åˆ†ææœŸé–“
            src_type: ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—
            quantum_factor: é‡å­ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ (0.5-1.0)
            chaos_sensitivity: ã‚«ã‚ªã‚¹æ„Ÿåº¦ (0.5-2.0)
            fractal_window: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«åˆ†æçª“
            entropy_window: ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼åˆ†æçª“
            coherence_threshold: ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹é–¾å€¤
            ultra_low_latency: è¶…ä½é…å»¶ãƒ¢ãƒ¼ãƒ‰
            hyper_adaptation: ãƒã‚¤ãƒ‘ãƒ¼é©å¿œãƒ¢ãƒ¼ãƒ‰
        """
        super().__init__("QuantumHyperAdaptiveMA")
        
        self.period = max(2, period)
        self.src_type = src_type
        self.quantum_factor = max(0.1, min(1.0, quantum_factor))
        self.chaos_sensitivity = max(0.1, min(3.0, chaos_sensitivity))
        self.fractal_window = max(5, fractal_window)
        self.entropy_window = max(4, entropy_window)
        self.coherence_threshold = max(0.1, min(1.0, coherence_threshold))
        self.ultra_low_latency = ultra_low_latency
        self.hyper_adaptation = hyper_adaptation
        
        self._result: Optional[QuantumHyperAdaptiveMAResult] = None
        self._cache = {}
    
    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> QuantumHyperAdaptiveMAResult:
        """
        ğŸŒŒ Quantum Hyper Adaptive MA ã‚’è¨ˆç®—ã™ã‚‹
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆDataFrameã¾ãŸã¯NumPyé…åˆ—ï¼‰
        
        Returns:
            QuantumHyperAdaptiveMAResult: è¨ˆç®—çµæœ
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª
            data_hash = self._get_data_hash(data)
            if data_hash in self._cache:
                return self._cache[data_hash]
            
            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            if isinstance(data, np.ndarray) and data.ndim == 1:
                src_prices = data.astype(np.float64)
            else:
                src_prices = PriceSource.calculate_source(data, self.src_type)
                src_prices = src_prices.astype(np.float64)
            
            data_length = len(src_prices)
            if data_length == 0:
                return self._create_empty_result(0)
            
            self.logger.info(f"ğŸŒŒ {self.name} è¨ˆç®—é–‹å§‹ - æœŸé–“: {self.period}, ãƒ‡ãƒ¼ã‚¿æ•°: {data_length}")
            
            # ğŸš€ Layer 1: é‡å­ã‚‚ã¤ã‚Œé‡ã¿è¨ˆç®—
            self.logger.debug("ğŸ”¬ é‡å­ã‚‚ã¤ã‚Œé‡ã¿è¨ˆç®—ä¸­...")
            quantum_weights = quantum_entangled_weights(src_prices, self.period, self.quantum_factor)
            
            # ğŸŒ€ Layer 2: ã‚«ã‚ªã‚¹é©å¿œã‚¢ãƒ«ãƒ•ã‚¡è¨ˆç®—
            self.logger.debug("ğŸŒ€ ã‚«ã‚ªã‚¹é©å¿œã‚¢ãƒ«ãƒ•ã‚¡è¨ˆç®—ä¸­...")
            adaptive_alpha = chaos_adaptive_alpha(src_prices, max(10, self.period // 2))
            if self.chaos_sensitivity != 1.0:
                adaptive_alpha = adaptive_alpha * self.chaos_sensitivity
                adaptive_alpha = np.clip(adaptive_alpha, 0.05, 0.95)
            
            # ğŸ“ Layer 3: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æ
            self.logger.debug("ğŸ“ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æä¸­...")
            fractal_dimension = fractal_dimension_analysis(src_prices, self.fractal_window)
            
            # ğŸ“Š Layer 4: å¸‚å ´ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—
            self.logger.debug("ğŸ“Š å¸‚å ´ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—ä¸­...")
            market_entropy = market_entropy_calculation(src_prices, self.entropy_window)
            
            # âš›ï¸ Layer 5: é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹å ´
            self.logger.debug("âš›ï¸ é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹å ´è¨ˆç®—ä¸­...")
            quantum_coherence = quantum_coherence_field(src_prices, self.period)
            
            # ğŸš€ Layer 6: è¶…é©å¿œè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³
            self.logger.debug("ğŸš€ è¶…é©å¿œè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè¡Œä¸­...")
            ma_values, trend_acceleration, prediction_confidence = hyper_adaptive_calculation(
                src_prices, quantum_weights, adaptive_alpha, fractal_dimension,
                market_entropy, quantum_coherence, self.period
            )
            
            # ğŸ“ˆ è¿½åŠ è§£æ
            chaos_indicator = self._calculate_chaos_indicator(src_prices, adaptive_alpha)
            volatility_regime = self._classify_volatility_regime(trend_acceleration, market_entropy)
            trend_signals = self._generate_trend_signals(ma_values, trend_acceleration, prediction_confidence)
            
            # ç¾åœ¨çŠ¶æ…‹ã®æ±ºå®š
            current_trend_strength = float(np.abs(trend_acceleration[-1])) if len(trend_acceleration) > 0 else 0.0
            current_volatility_regime = self._determine_volatility_regime(volatility_regime)
            current_prediction_confidence = float(prediction_confidence[-1]) if len(prediction_confidence) > 0 else 0.5
            
            # çµæœä½œæˆ
            result = QuantumHyperAdaptiveMAResult(
                values=ma_values,
                quantum_weights=np.mean(quantum_weights, axis=1) if quantum_weights.ndim > 1 else quantum_weights,
                adaptive_alpha=adaptive_alpha,
                trend_acceleration=trend_acceleration,
                market_entropy=market_entropy,
                fractal_dimension=fractal_dimension,
                quantum_coherence=quantum_coherence,
                chaos_indicator=chaos_indicator,
                prediction_confidence=prediction_confidence,
                volatility_regime=volatility_regime,
                trend_signals=trend_signals,
                current_trend_strength=current_trend_strength,
                current_volatility_regime=current_volatility_regime,
                current_prediction_confidence=current_prediction_confidence
            )
            
            self._result = result
            self._cache[data_hash] = result
            
            self.logger.info(f"âœ… {self.name} è¨ˆç®—å®Œäº† - ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦: {current_trend_strength:.3f}, ä¿¡é ¼åº¦: {current_prediction_confidence:.3f}")
            
            return result
            
        except Exception as e:
            import traceback
            error_msg = str(e)
            stack_trace = traceback.format_exc()
            self.logger.error(f"{self.name} è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {error_msg}\n{stack_trace}")
            return self._create_empty_result(len(data) if hasattr(data, '__len__') else 0)
    
    def _calculate_chaos_indicator(self, prices: np.ndarray, alpha: np.ndarray) -> np.ndarray:
        """ã‚«ã‚ªã‚¹æŒ‡æ¨™è¨ˆç®—"""
        n = len(prices)
        chaos = np.zeros(n)
        
        for i in range(10, n):
            price_segment = prices[i-10:i]
            alpha_segment = alpha[i-10:i]
            
            # ã‚¢ãƒ«ãƒ•ã‚¡å€¤ã®å¤‰å‹•ã‹ã‚‰ã‚«ã‚ªã‚¹å¼·åº¦ã‚’æ¨å®š
            alpha_variance = np.var(alpha_segment)
            price_variance = np.var(price_segment)
            
            chaos[i] = alpha_variance * np.sqrt(price_variance)
        
        # å‰æ–¹åŸ‹ã‚
        for i in range(10):
            chaos[i] = chaos[10] if n > 10 else 0.0
        
        return chaos
    
    def _classify_volatility_regime(self, trend_acceleration: np.ndarray, entropy: np.ndarray) -> np.ndarray:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†é¡"""
        n = len(trend_acceleration)
        regime = np.zeros(n)
        
        for i in range(n):
            acc_abs = np.abs(trend_acceleration[i])
            ent = entropy[i]
            
            if acc_abs > 0.1 or ent > 2.0:
                regime[i] = 2  # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            elif acc_abs > 0.05 or ent > 1.0:
                regime[i] = 1  # ä¸­ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            else:
                regime[i] = 0  # ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        
        return regime
    
    def _generate_trend_signals(self, ma_values: np.ndarray, trend_acceleration: np.ndarray, 
                               confidence: np.ndarray) -> np.ndarray:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ"""
        n = len(ma_values)
        signals = np.zeros(n)
        
        for i in range(2, n):
            if confidence[i] > self.coherence_threshold:
                if trend_acceleration[i] > 0.01 and ma_values[i] > ma_values[i-1]:
                    signals[i] = 1  # è²·ã„ã‚·ã‚°ãƒŠãƒ«
                elif trend_acceleration[i] < -0.01 and ma_values[i] < ma_values[i-1]:
                    signals[i] = -1  # å£²ã‚Šã‚·ã‚°ãƒŠãƒ«
        
        return signals
    
    def _determine_volatility_regime(self, volatility_regime: np.ndarray) -> str:
        """ç¾åœ¨ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ æ±ºå®š"""
        if len(volatility_regime) == 0:
            return 'unknown'
        
        current_regime = int(volatility_regime[-1])
        regime_names = ['low', 'medium', 'high']
        
        if 0 <= current_regime < len(regime_names):
            return regime_names[current_regime]
        return 'unknown'
    
    def _create_empty_result(self, length: int) -> QuantumHyperAdaptiveMAResult:
        """ç©ºã®çµæœã‚’ä½œæˆ"""
        return QuantumHyperAdaptiveMAResult(
            values=np.full(length, np.nan),
            quantum_weights=np.full(length, 0.5),
            adaptive_alpha=np.full(length, 0.5),
            trend_acceleration=np.zeros(length),
            market_entropy=np.zeros(length),
            fractal_dimension=np.full(length, 1.5),
            quantum_coherence=np.full(length, 0.5),
            chaos_indicator=np.zeros(length),
            prediction_confidence=np.full(length, 0.5),
            volatility_regime=np.zeros(length),
            trend_signals=np.zeros(length),
            current_trend_strength=0.0,
            current_volatility_regime='unknown',
            current_prediction_confidence=0.5
        )
    
    def _get_data_hash(self, data: Union[pd.DataFrame, np.ndarray]) -> str:
        """ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥è¨ˆç®—"""
        if isinstance(data, pd.DataFrame):
            return f"{hash(data.values.tobytes())}_{self.period}_{self.quantum_factor}_{self.chaos_sensitivity}"
        else:
            return f"{hash(data.tobytes())}_{self.period}_{self.quantum_factor}_{self.chaos_sensitivity}"
    
    def get_result(self) -> Optional[QuantumHyperAdaptiveMAResult]:
        """è¨ˆç®—çµæœã‚’å–å¾—"""
        return self._result
    
    def get_values(self) -> Optional[np.ndarray]:
        """ç§»å‹•å¹³å‡å€¤ã‚’å–å¾—"""
        if self._result is not None:
            return self._result.values.copy()
        return None
    
    def reset(self) -> None:
        """ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        super().reset()
        self._result = None
        self._cache = {}
    
    def __str__(self) -> str:
        """æ–‡å­—åˆ—è¡¨ç¾"""
        return f"QuantumHyperAdaptiveMA(period={self.period}, quantum_factor={self.quantum_factor})" 