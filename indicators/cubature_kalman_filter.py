#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ¯ **Cubature Kalman Filter (CKF) - ç«‹æ–¹ä½“ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼** ğŸ¯

UKFã‚’è¶…ãˆã‚‹é«˜ç²¾åº¦ãªéç·šå½¢ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼š
- ã‚¹ãƒ•ã‚£ãƒªã‚«ãƒ«-ãƒ©ã‚¸ã‚¢ãƒ«ç«‹æ–¹ä½“ãƒ«ãƒ¼ãƒ«ã«ã‚ˆã‚‹æ•°å€¤ç©åˆ†
- UKFã‚ˆã‚Šå°‘ãªã„ã‚·ã‚°ãƒãƒã‚¤ãƒ³ãƒˆã§é«˜ç²¾åº¦
- ã‚ˆã‚Šå®‰å®šã—ãŸæ•°å€¤ç‰¹æ€§
- é«˜æ¬¡ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆã®æ­£ç¢ºãªæ¨å®š

ğŸŒŸ **CKFã®å„ªä½æ€§:**
1. **åŠ¹ç‡æ€§**: UKFã®2L+1å€‹ã«å¯¾ã—ã€CKFã¯2Lå€‹ã®ã‚·ã‚°ãƒãƒã‚¤ãƒ³ãƒˆ
2. **ç²¾åº¦**: 3æ¬¡ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆã¾ã§UKFã¨åŒç­‰ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã¯ä½ã„
3. **å®‰å®šæ€§**: ã‚ˆã‚Šè‰¯ã„æ•°å€¤å®‰å®šæ€§
4. **ç†è«–çš„åŸºç›¤**: çƒé¢ç©åˆ†ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ãå³å¯†ãªç†è«–
"""

from dataclasses import dataclass
from typing import Union, Tuple, Dict, Optional, List, NamedTuple
import numpy as np
import pandas as pd
from numba import jit, njit, types
import traceback

try:
    from .indicator import Indicator
    from .price_source import PriceSource
except ImportError:
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from indicator import Indicator
    from price_source import PriceSource


@dataclass
class CKFResult:
    """ç«‹æ–¹ä½“ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®è¨ˆç®—çµæœ"""
    filtered_values: np.ndarray      # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿ä¾¡æ ¼
    velocity_estimates: np.ndarray   # é€Ÿåº¦æ¨å®šå€¤
    acceleration_estimates: np.ndarray  # åŠ é€Ÿåº¦æ¨å®šå€¤
    uncertainty: np.ndarray          # æ¨å®šä¸ç¢ºå®Ÿæ€§ï¼ˆæ¨™æº–åå·®ï¼‰
    kalman_gains: np.ndarray         # ã‚«ãƒ«ãƒãƒ³ã‚²ã‚¤ãƒ³
    innovations: np.ndarray          # ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆäºˆæ¸¬èª¤å·®ï¼‰
    cubature_points: np.ndarray      # æœ€çµ‚ç«‹æ–¹ä½“ãƒã‚¤ãƒ³ãƒˆ
    confidence_scores: np.ndarray    # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
    raw_values: np.ndarray          # å…ƒã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿


@njit(fastmath=True, cache=True)
def generate_cubature_points(mean: np.ndarray, covariance: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """
    ã‚¹ãƒ•ã‚£ãƒªã‚«ãƒ«-ãƒ©ã‚¸ã‚¢ãƒ«ç«‹æ–¹ä½“ãƒ«ãƒ¼ãƒ«ã«ã‚ˆã‚‹ã‚·ã‚°ãƒãƒã‚¤ãƒ³ãƒˆç”Ÿæˆ
    
    Args:
        mean: çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«
        covariance: å…±åˆ†æ•£è¡Œåˆ—
    
    Returns:
        cubature_points: ç«‹æ–¹ä½“ãƒã‚¤ãƒ³ãƒˆè¡Œåˆ— (2L x L)
        weights: é‡ã¿ (å…¨ã¦ç­‰ã—ã 1/(2L))
    """
    L = len(mean)  # çŠ¶æ…‹æ¬¡å…ƒ
    n_points = 2 * L  # CKFã®ãƒã‚¤ãƒ³ãƒˆæ•°
    
    # ç«‹æ–¹ä½“ãƒã‚¤ãƒ³ãƒˆåˆæœŸåŒ–
    cubature_points = np.zeros((n_points, L))
    weights = np.full(n_points, 1.0 / (2.0 * L))  # å…¨ã¦ç­‰é‡ã¿
    
    # å…±åˆ†æ•£è¡Œåˆ—ã®å¹³æ–¹æ ¹è¨ˆç®—ï¼ˆCholeskyåˆ†è§£ï¼‰
    try:
        sqrt_matrix = np.linalg.cholesky(L * covariance)
    except:
        # æ•°å€¤å®‰å®šæ€§ã®ãŸã‚ã®å¯¾å‡¦
        sqrt_matrix = np.zeros((L, L))
        for i in range(L):
            sqrt_matrix[i, i] = np.sqrt(max(L * covariance[i, i], 1e-8))
    
    # ã‚¹ãƒ•ã‚£ãƒªã‚«ãƒ«-ãƒ©ã‚¸ã‚¢ãƒ«ç«‹æ–¹ä½“ãƒã‚¤ãƒ³ãƒˆç”Ÿæˆ
    for i in range(L):
        # æ­£æ–¹å‘
        cubature_points[i] = mean + sqrt_matrix[:, i]
        # è² æ–¹å‘
        cubature_points[i + L] = mean - sqrt_matrix[:, i]
    
    return cubature_points, weights


@njit(fastmath=True, cache=True)
def state_transition_function_ckf(state: np.ndarray, dt: float = 1.0) -> np.ndarray:
    """
    CKFç”¨çŠ¶æ…‹é·ç§»é–¢æ•°ï¼ˆUKFã¨åŒã˜ãƒ¢ãƒ‡ãƒ«ï¼‰
    
    Args:
        state: ç¾åœ¨ã®çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ« [ä¾¡æ ¼, é€Ÿåº¦, åŠ é€Ÿåº¦]
        dt: æ™‚é–“å·®åˆ†
    
    Returns:
        æ¬¡ã®çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«
    """
    price, velocity, acceleration = state[0], state[1], state[2]
    
    # éç·šå½¢å‹•åŠ›å­¦ãƒ¢ãƒ‡ãƒ«
    new_price = price + velocity * dt + 0.5 * acceleration * dt * dt
    
    # é€Ÿåº¦ã®æ¸›è¡°ã¨åŠ é€Ÿåº¦ã®å½±éŸ¿
    damping_factor = 0.95
    new_velocity = velocity * damping_factor + acceleration * dt
    
    # åŠ é€Ÿåº¦ã®æ¸›è¡°ï¼ˆå¹³å‡å›å¸°ï¼‰
    new_acceleration = acceleration * 0.9
    
    return np.array([new_price, new_velocity, new_acceleration])


@njit(fastmath=True, cache=True)
def observation_function_ckf(state: np.ndarray) -> float:
    """
    CKFç”¨è¦³æ¸¬é–¢æ•°ï¼ˆä¾¡æ ¼ã®ã¿è¦³æ¸¬ï¼‰
    
    Args:
        state: çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«
    
    Returns:
        è¦³æ¸¬å€¤ï¼ˆä¾¡æ ¼ï¼‰
    """
    return state[0]


@njit(fastmath=True, cache=True)
def calculate_cubature_kalman_filter(
    prices: np.ndarray,
    volatility: np.ndarray,
    process_noise_scale: float = 0.001,
    adaptive_noise: bool = True
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    ç«‹æ–¹ä½“ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆCKFï¼‰ã®å®Ÿè£…
    
    Args:
        prices: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        volatility: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æ¨å®šå€¤
        process_noise_scale: ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚¤ã‚ºã®ã‚¹ã‚±ãƒ¼ãƒ«
        adaptive_noise: é©å¿œçš„ãƒã‚¤ã‚ºæ¨å®šã‚’ä½¿ç”¨ã™ã‚‹ã‹
    
    Returns:
        filtered_prices: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿ä¾¡æ ¼
        velocity_estimates: é€Ÿåº¦æ¨å®š
        acceleration_estimates: åŠ é€Ÿåº¦æ¨å®š
        uncertainty: ä¸ç¢ºå®Ÿæ€§
        kalman_gains: ã‚«ãƒ«ãƒãƒ³ã‚²ã‚¤ãƒ³
        innovations: ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³
        confidence_scores: ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
        final_cubature_points: æœ€çµ‚ç«‹æ–¹ä½“ãƒã‚¤ãƒ³ãƒˆ
    """
    n = len(prices)
    L = 3  # çŠ¶æ…‹æ¬¡å…ƒ [ä¾¡æ ¼, é€Ÿåº¦, åŠ é€Ÿåº¦]
    
    if n < 5:
        # ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®å ´åˆ
        return (prices.copy(), np.zeros(n), np.zeros(n), np.ones(n), 
                np.ones(n) * 0.5, np.zeros(n), np.ones(n), np.zeros((6, L)))
    
    # çµæœé…åˆ—ã®åˆæœŸåŒ–
    filtered_prices = np.zeros(n)
    velocity_estimates = np.zeros(n)
    acceleration_estimates = np.zeros(n)
    uncertainty = np.zeros(n)
    kalman_gains = np.zeros(n)
    innovations = np.zeros(n)
    confidence_scores = np.zeros(n)
    
    # åˆæœŸçŠ¶æ…‹
    x = np.array([prices[0], 0.0, 0.0])  # [ä¾¡æ ¼, é€Ÿåº¦, åŠ é€Ÿåº¦]
    P = np.array([[1.0, 0.0, 0.0],       # åˆæœŸå…±åˆ†æ•£è¡Œåˆ—
                  [0.0, 0.1, 0.0],
                  [0.0, 0.0, 0.01]])
    
    # ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚¤ã‚ºè¡Œåˆ—
    Q = np.array([[process_noise_scale, 0.0, 0.0],
                  [0.0, process_noise_scale * 0.1, 0.0],
                  [0.0, 0.0, process_noise_scale * 0.01]])
    
    # åˆæœŸå€¤è¨­å®š
    filtered_prices[0] = prices[0]
    velocity_estimates[0] = 0.0
    acceleration_estimates[0] = 0.0
    uncertainty[0] = np.sqrt(P[0, 0])
    kalman_gains[0] = 0.5
    innovations[0] = 0.0
    confidence_scores[0] = 1.0
    
    # æœ€çµ‚ç«‹æ–¹ä½“ãƒã‚¤ãƒ³ãƒˆï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    final_cubature_points = np.zeros((2 * L, L))
    
    # CKFãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
    for t in range(1, n):
        # === äºˆæ¸¬ã‚¹ãƒ†ãƒƒãƒ— ===
        
        # 1. ç«‹æ–¹ä½“ãƒã‚¤ãƒ³ãƒˆç”Ÿæˆ
        cubature_points, weights = generate_cubature_points(x, P)
        
        # 2. å„ç«‹æ–¹ä½“ãƒã‚¤ãƒ³ãƒˆã‚’çŠ¶æ…‹é·ç§»é–¢æ•°ã«é€šã™
        n_points = len(cubature_points)
        cubature_points_pred = np.zeros((n_points, L))
        
        for i in range(n_points):
            cubature_points_pred[i] = state_transition_function_ckf(cubature_points[i], 1.0)
        
        # 3. äºˆæ¸¬çŠ¶æ…‹ã®å¹³å‡è¨ˆç®—
        x_pred = np.zeros(L)
        for i in range(n_points):
            x_pred += weights[i] * cubature_points_pred[i]
        
        # 4. äºˆæ¸¬å…±åˆ†æ•£è¨ˆç®—
        P_pred = Q.copy()  # ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚¤ã‚ºã‚’åŠ ç®—
        for i in range(n_points):
            diff = cubature_points_pred[i] - x_pred
            P_pred += weights[i] * np.outer(diff, diff)
        
        # === æ›´æ–°ã‚¹ãƒ†ãƒƒãƒ— ===
        
        # 5. æ–°ã—ã„ç«‹æ–¹ä½“ãƒã‚¤ãƒ³ãƒˆç”Ÿæˆï¼ˆäºˆæ¸¬å€¤ç”¨ï¼‰
        cubature_points_update, weights_update = generate_cubature_points(x_pred, P_pred)
        
        # 6. è¦³æ¸¬äºˆæ¸¬å€¤è¨ˆç®—
        z_points = np.zeros(len(cubature_points_update))
        for i in range(len(cubature_points_update)):
            z_points[i] = observation_function_ckf(cubature_points_update[i])
        
        # 7. äºˆæ¸¬è¦³æ¸¬å€¤ã®å¹³å‡
        z_pred = 0.0
        for i in range(len(z_points)):
            z_pred += weights_update[i] * z_points[i]
        
        # 8. è¦³æ¸¬ãƒã‚¤ã‚ºã®é©å¿œçš„èª¿æ•´
        if adaptive_noise and t >= 5:
            recent_vol = np.mean(volatility[max(0, t-5):t])
            R = max(recent_vol * recent_vol, 0.0001)
        else:
            R = max(volatility[t] * volatility[t], 0.0001)
        
        # 9. ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³å…±åˆ†æ•£ã¨ç›¸äº’å…±åˆ†æ•£è¨ˆç®—
        S = R  # è¦³æ¸¬ãƒã‚¤ã‚º
        Pxz = np.zeros(L)  # çŠ¶æ…‹-è¦³æ¸¬é–“ã®ç›¸äº’å…±åˆ†æ•£
        
        for i in range(len(z_points)):
            z_diff = z_points[i] - z_pred
            x_diff = cubature_points_update[i] - x_pred
            
            S += weights_update[i] * z_diff * z_diff
            Pxz += weights_update[i] * x_diff * z_diff
        
        # 10. ã‚«ãƒ«ãƒãƒ³ã‚²ã‚¤ãƒ³è¨ˆç®—
        if S > 1e-12:
            K = Pxz / S
        else:
            K = np.array([0.5, 0.0, 0.0])
        
        # 11. çŠ¶æ…‹æ›´æ–°
        innovation = prices[t] - z_pred
        x = x_pred + K * innovation
        P = P_pred - np.outer(K, K) * S
        
        # 12. æ•°å€¤å®‰å®šæ€§ã®ç¢ºä¿
        for i in range(L):
            if P[i, i] < 1e-8:
                P[i, i] = 1e-8
        
        # çŠ¶æ…‹å€¤ã®å¢ƒç•Œåˆ¶é™
        max_velocity = abs(prices[t]) * 0.5
        if abs(x[1]) > max_velocity:
            x[1] = np.sign(x[1]) * max_velocity
            
        max_acceleration = abs(prices[t]) * 0.1
        if abs(x[2]) > max_acceleration:
            x[2] = np.sign(x[2]) * max_acceleration
        
        # 13. çµæœã®ä¿å­˜
        filtered_prices[t] = x[0]
        velocity_estimates[t] = x[1]
        acceleration_estimates[t] = x[2]
        uncertainty[t] = np.sqrt(max(P[0, 0], 0))
        kalman_gains[t] = K[0]
        innovations[t] = innovation
        
        # ä¿¡é ¼åº¦è¨ˆç®—
        confidence_scores[t] = 1.0 / (1.0 + uncertainty[t] * 10.0)
        
        # æœ€çµ‚ç«‹æ–¹ä½“ãƒã‚¤ãƒ³ãƒˆã®ä¿å­˜
        if t == n - 1:
            final_cubature_points = cubature_points_update.copy()
    
    return (filtered_prices, velocity_estimates, acceleration_estimates, uncertainty,
            kalman_gains, innovations, confidence_scores, final_cubature_points)


@njit(fastmath=True, cache=True)
def estimate_volatility_ckf(prices: np.ndarray, window: int = 10) -> np.ndarray:
    """CKFç”¨ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æ¨å®š"""
    n = len(prices)
    volatility = np.full(n, 0.01)
    
    for i in range(window, n):
        window_prices = prices[i-window:i]
        vol = np.std(window_prices)
        volatility[i] = max(vol, 0.001)
    
    if n >= window:
        initial_vol = volatility[window]
        for i in range(window):
            volatility[i] = initial_vol
    
    return volatility


class CubatureKalmanFilter(Indicator):
    """
    ç«‹æ–¹ä½“ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆCKFï¼‰ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
    
    UKFã‚’è¶…ãˆã‚‹é«˜ç²¾åº¦ãªéç·šå½¢ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼š
    - ã‚¹ãƒ•ã‚£ãƒªã‚«ãƒ«-ãƒ©ã‚¸ã‚¢ãƒ«ç«‹æ–¹ä½“ãƒ«ãƒ¼ãƒ«
    - ã‚ˆã‚Šå°‘ãªã„ã‚·ã‚°ãƒãƒã‚¤ãƒ³ãƒˆã§é«˜ç²¾åº¦
    - å„ªã‚ŒãŸæ•°å€¤å®‰å®šæ€§
    - å³å¯†ãªç†è«–çš„åŸºç›¤
    
    ğŸ† **UKFã«å¯¾ã™ã‚‹å„ªä½æ€§:**
    - åŠ¹ç‡æ€§: 2Lå€‹ã®ãƒã‚¤ãƒ³ãƒˆï¼ˆUKFã¯2L+1å€‹ï¼‰
    - ç²¾åº¦: åŒç­‰ã®ç²¾åº¦ã§ã‚ˆã‚Šå°‘ãªã„è¨ˆç®—
    - å®‰å®šæ€§: ã‚ˆã‚Šè‰¯ã„æ•°å€¤ç‰¹æ€§
    - ç†è«–: çƒé¢ç©åˆ†ã«åŸºã¥ãå³å¯†æ€§
    """
    
    def __init__(
        self,
        src_type: str = 'close',           # ä¾¡æ ¼ã‚½ãƒ¼ã‚¹
        process_noise_scale: float = 0.001,  # ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚¤ã‚ºã‚¹ã‚±ãƒ¼ãƒ«
        volatility_window: int = 10,      # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—çª“
        adaptive_noise: bool = True       # é©å¿œçš„ãƒã‚¤ã‚ºæ¨å®š
    ):
        """
        ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
        
        Args:
            src_type: ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ ('close', 'hlc3', 'hl2', 'ohlc4')
            process_noise_scale: ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚¤ã‚ºã®ã‚¹ã‚±ãƒ¼ãƒ«
            volatility_window: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            adaptive_noise: é©å¿œçš„ãƒã‚¤ã‚ºæ¨å®šã‚’ä½¿ç”¨ã™ã‚‹ã‹
        """
        indicator_name = f"CKF(src={src_type}, noise={process_noise_scale})"
        super().__init__(indicator_name)
        
        self.src_type = src_type.lower()
        self.process_noise_scale = process_noise_scale
        self.volatility_window = volatility_window
        self.adaptive_noise = adaptive_noise
        
        # ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã®æ¤œè¨¼
        valid_sources = ['close', 'hlc3', 'hl2', 'ohlc4', 'high', 'low', 'open',
                        'ukf', 'ukf_close', 'ukf_hlc3', 'ukf_hl2', 'ukf_ohlc4']
        if self.src_type not in valid_sources:
            raise ValueError(f"ç„¡åŠ¹ãªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—: {src_type}")
        
        # çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._result_cache = {}
        self._max_cache_size = 10
        self._cache_keys = []
    
    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> CKFResult:
        """
        ç«‹æ–¹ä½“ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’è¨ˆç®—
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆDataFrameã¾ãŸã¯é…åˆ—ï¼‰
        
        Returns:
            CKFResult: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœ
        """
        try:
            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
            src_prices = PriceSource.calculate_source(data, self.src_type)
            
            if len(src_prices) < 5:
                return self._create_empty_result(len(src_prices), src_prices)
            
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æ¨å®š
            volatility = estimate_volatility_ckf(src_prices, self.volatility_window)
            
            # CKFè¨ˆç®—
            (filtered_prices, velocity_estimates, acceleration_estimates, uncertainty,
             kalman_gains, innovations, confidence_scores, final_cubature_points) = calculate_cubature_kalman_filter(
                src_prices, volatility, self.process_noise_scale, self.adaptive_noise
            )
            
            # çµæœä½œæˆ
            result = CKFResult(
                filtered_values=filtered_prices.copy(),
                velocity_estimates=velocity_estimates.copy(),
                acceleration_estimates=acceleration_estimates.copy(),
                uncertainty=uncertainty.copy(),
                kalman_gains=kalman_gains.copy(),
                innovations=innovations.copy(),
                cubature_points=final_cubature_points.copy(),
                confidence_scores=confidence_scores.copy(),
                raw_values=src_prices.copy()
            )
            
            self._values = filtered_prices  # åŸºåº•ã‚¯ãƒ©ã‚¹ç”¨
            return result
            
        except Exception as e:
            self.logger.error(f"CKFè¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}\n{traceback.format_exc()}")
            
            if isinstance(data, (pd.DataFrame, np.ndarray)) and len(data) > 0:
                src_prices = PriceSource.calculate_source(data, self.src_type)
                return self._create_empty_result(len(src_prices), src_prices)
            else:
                return self._create_empty_result(0, np.array([]))
    
    def _create_empty_result(self, length: int, raw_prices: np.ndarray) -> CKFResult:
        """ç©ºã®çµæœã‚’ä½œæˆ"""
        return CKFResult(
            filtered_values=np.full(length, np.nan),
            velocity_estimates=np.full(length, np.nan),
            acceleration_estimates=np.full(length, np.nan),
            uncertainty=np.full(length, np.nan),
            kalman_gains=np.full(length, np.nan),
            innovations=np.full(length, np.nan),
            cubature_points=np.full((6, 3), np.nan),  # 2*3=6ç«‹æ–¹ä½“ãƒã‚¤ãƒ³ãƒˆ, 3æ¬¡å…ƒçŠ¶æ…‹
            confidence_scores=np.full(length, np.nan),
            raw_values=raw_prices
        )
    
    def get_filter_metadata(self) -> Dict:
        """ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        return {
            'filter_type': 'Cubature Kalman Filter',
            'src_type': self.src_type,
            'process_noise_scale': self.process_noise_scale,
            'advantages_over_ukf': [
                'ã‚ˆã‚Šå°‘ãªã„ã‚·ã‚°ãƒãƒã‚¤ãƒ³ãƒˆï¼ˆ2L vs 2L+1ï¼‰',
                'ã‚ˆã‚Šè‰¯ã„æ•°å€¤å®‰å®šæ€§',
                'å³å¯†ãªçƒé¢ç©åˆ†ãƒ«ãƒ¼ãƒ«',
                'åŒç­‰ç²¾åº¦ã§ã‚ˆã‚Šé«˜åŠ¹ç‡'
            ]
        } 