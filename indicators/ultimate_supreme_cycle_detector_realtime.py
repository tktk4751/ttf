#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸš€ Ultimate Supreme Cycle Detector - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä½é…å»¶ç‰ˆ
===============================================================

ã€ç‰¹åŒ–è¨­è¨ˆã€‘
- å¿œç­”é…å»¶: ç›®æ¨™ < 3æœŸé–“
- è¨ˆç®—æ™‚é–“: < 0.1ms/ç‚¹
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æœ€å°åŒ–
- ã‚·ãƒ³ãƒ—ãƒ«ã§åŠ¹æœçš„ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

ã€æ ¸å¿ƒæŠ€è¡“ã€‘
1. è»½é‡é©å¿œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆå‰æ–¹ãƒ‘ã‚¹ã®ã¿ï¼‰
2. é«˜é€ŸFFT ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºã‚¨ãƒ³ã‚¸ãƒ³
3. é‡å­é©å¿œã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆç°¡ç´ ç‰ˆï¼‰
4. ãƒã‚¤ã‚ºé™¤å»ã¨å¿œç­”æ€§ã®ãƒãƒ©ãƒ³ã‚¹æœ€é©åŒ–
"""

from dataclasses import dataclass
from typing import Union, Optional, Tuple, Dict, Any
import numpy as np
import pandas as pd
from numba import njit
import logging

try:
    from .indicator import Indicator
    from .price_source import PriceSource
except ImportError:
    # ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œæ™‚ã®å¯¾å¿œ
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from indicator import Indicator
    from price_source import PriceSource


@dataclass
class RealtimeCycleResult:
    """ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºçµæœ"""
    dominant_cycle: np.ndarray       # æ”¯é…çš„ã‚µã‚¤ã‚¯ãƒ«æœŸé–“
    cycle_strength: np.ndarray       # ã‚µã‚¤ã‚¯ãƒ«å¼·åº¦ (0-1)
    cycle_confidence: np.ndarray     # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ (0-1)
    adaptation_speed: np.ndarray     # é©å¿œé€Ÿåº¦
    noise_rejection: np.ndarray      # ãƒã‚¤ã‚ºé™¤å»ç‡
    
    # ç¾åœ¨çŠ¶æ…‹
    current_cycle: float             # ç¾åœ¨ã®æ”¯é…çš„ã‚µã‚¤ã‚¯ãƒ«
    current_strength: float          # ç¾åœ¨ã®ã‚µã‚¤ã‚¯ãƒ«å¼·åº¦
    current_confidence: float        # ç¾åœ¨ã®ä¿¡é ¼åº¦


class UltimateSupremeCycleDetectorRealtime(Indicator):
    """ğŸš€ Ultra Supreme Cycle Detector - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä½é…å»¶ç‰ˆ"""
    
    def __init__(
        self,
        # åŸºæœ¬è¨­å®šï¼ˆä½é…å»¶ç‰¹åŒ–ï¼‰
        period_range: Tuple[int, int] = (20, 100),
        adaptivity_factor: float = 0.7,      # ä½é…å»¶ã®ãŸã‚é©å¿œæ€§ã‚’ä¸‹ã’ã‚‹
        noise_threshold: float = 0.02,       # ãƒã‚¤ã‚ºãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é–¾å€¤
        src_type: str = 'hlc3'
    ):
        super().__init__("UltimateSupremeCycleDetectorRealtime")
        self.period_range = period_range
        self.adaptivity_factor = adaptivity_factor
        self.noise_threshold = noise_threshold
        self.src_type = src_type
        self._result = None
        
        # ãƒ­ã‚¬ãƒ¼è¨­å®š
        self.logger = logging.getLogger(self.__class__.__name__)
        
    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> RealtimeCycleResult:
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå®Ÿè¡Œ"""
        try:
            # ãƒ‡ãƒ¼ã‚¿å¤‰æ›
            if isinstance(data, pd.DataFrame):
                src_prices = PriceSource.calculate_source(data, self.src_type)
            else:
                src_prices = data.astype(np.float64)
            
            if len(src_prices) < 20:
                return self._create_empty_result(len(src_prices))
            
            # === ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ ===
            self.logger.debug("ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä½é…å»¶ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºé–‹å§‹...")
            
            # Stage 1: è»½é‡é©å¿œãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            filtered_prices = lightweight_adaptive_filter(src_prices, self.noise_threshold)
            
            # Stage 2: é«˜é€Ÿã‚µã‚¤ã‚¯ãƒ«æ¤œå‡º
            cycles, strengths, confidences = fast_cycle_detection_engine(
                filtered_prices, self.period_range[0], self.period_range[1]
            )
            
            # Stage 3: é‡å­é©å¿œçµ±åˆï¼ˆç°¡ç´ ç‰ˆï¼‰
            final_cycles, final_strengths, final_confidences, adaptation_speeds = simple_quantum_integration(
                cycles, strengths, confidences, self.adaptivity_factor
            )
            
            # ãƒã‚¤ã‚ºé™¤å»ç‡è¨ˆç®—
            raw_volatility = np.std(src_prices)
            filtered_volatility = np.std(filtered_prices)
            noise_rejection = np.full(len(src_prices), 
                                    (raw_volatility - filtered_volatility) / raw_volatility 
                                    if raw_volatility > 0 else 0.0)
            
            # ç¾åœ¨çŠ¶æ…‹
            current_cycle = final_cycles[-1] if len(final_cycles) > 0 else 50.0
            current_strength = final_strengths[-1] if len(final_strengths) > 0 else 0.0
            current_confidence = final_confidences[-1] if len(final_confidences) > 0 else 0.0
            
            # çµæœä½œæˆ
            result = RealtimeCycleResult(
                dominant_cycle=final_cycles,
                cycle_strength=final_strengths,
                cycle_confidence=final_confidences,
                adaptation_speed=adaptation_speeds,
                noise_rejection=noise_rejection,
                current_cycle=current_cycle,
                current_strength=current_strength,
                current_confidence=current_confidence
            )
            
            self._result = result
            self.logger.info(f"âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¨ˆç®—å®Œäº† - ç¾åœ¨ã‚µã‚¤ã‚¯ãƒ«: {current_cycle:.1f}æœŸé–“")
            return result
            
        except Exception as e:
            self.logger.error(f"è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return self._create_empty_result(len(data) if hasattr(data, '__len__') else 0)
    
    def _create_empty_result(self, length: int) -> RealtimeCycleResult:
        """ç©ºã®çµæœã‚’ä½œæˆ"""
        return RealtimeCycleResult(
            dominant_cycle=np.full(length, 50.0, dtype=np.float64),
            cycle_strength=np.zeros(length, dtype=np.float64),
            cycle_confidence=np.zeros(length, dtype=np.float64),
            adaptation_speed=np.zeros(length, dtype=np.float64),
            noise_rejection=np.zeros(length, dtype=np.float64),
            current_cycle=50.0,
            current_strength=0.0,
            current_confidence=0.0
        )
    
    def get_result(self) -> Optional[RealtimeCycleResult]:
        """çµæœã‚’å–å¾—"""
        return self._result


# ================== è»½é‡è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ç¾¤ ==================

@njit(fastmath=True, cache=True)
def lightweight_adaptive_filter(prices: np.ndarray, noise_threshold: float = 0.02) -> np.ndarray:
    """ğŸ¯ è»½é‡é©å¿œãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆè¶…ä½é…å»¶ï¼‰"""
    n = len(prices)
    filtered = np.zeros(n)
    
    if n < 2:
        return prices.copy()
    
    filtered[0] = prices[0]
    
    # é©å¿œçš„ãƒã‚¤ã‚ºãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    for i in range(1, n):
        price_change = abs(prices[i] - prices[i-1]) / (prices[i-1] + 1e-10)
        
        if price_change < noise_threshold:
            # å°ã•ãªå¤‰åŒ–ã¯ãƒã‚¤ã‚ºã¨ã—ã¦å¹³æ»‘åŒ–
            alpha = 0.3
        else:
            # å¤§ããªå¤‰åŒ–ã¯å³åº§ã«è¿½å¾“
            alpha = 0.8
        
        filtered[i] = alpha * prices[i] + (1 - alpha) * filtered[i-1]
    
    return filtered


@njit(fastmath=True, cache=True)
def fast_cycle_detection_engine(
    prices: np.ndarray, 
    min_period: int = 20, 
    max_period: int = 100
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """ğŸš€ é«˜é€Ÿã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºã‚¨ãƒ³ã‚¸ãƒ³"""
    n = len(prices)
    cycles = np.full(n, 50.0)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ50æœŸé–“
    strengths = np.zeros(n)
    confidences = np.zeros(n)
    
    if n < max_period:
        return cycles, strengths, confidences
    
    # ç§»å‹•ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡º
    window_size = min(max_period * 2, n // 2)
    
    for i in range(window_size, n):
        start_idx = i - window_size
        window_data = prices[start_idx:i]
        
        # ç°¡æ˜“è‡ªå·±ç›¸é–¢ã«ã‚ˆã‚‹ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡º
        best_period = 50.0
        best_correlation = 0.0
        
        for period in range(min_period, min(max_period, len(window_data) // 2)):
            correlation = calculate_autocorrelation(window_data, period)
            
            if correlation > best_correlation:
                best_correlation = correlation
                best_period = float(period)
        
        cycles[i] = best_period
        strengths[i] = min(best_correlation, 1.0)
        confidences[i] = min(best_correlation * 1.2, 1.0)
    
    # å‰ã®å€¤ã§åŸ‹ã‚ã‚‹
    for i in range(window_size):
        cycles[i] = cycles[window_size] if window_size < n else 50.0
        strengths[i] = strengths[window_size] if window_size < n else 0.0
        confidences[i] = confidences[window_size] if window_size < n else 0.0
    
    return cycles, strengths, confidences


@njit(fastmath=True, cache=True)
def calculate_autocorrelation(data: np.ndarray, lag: int) -> float:
    """è‡ªå·±ç›¸é–¢è¨ˆç®—ï¼ˆé«˜é€Ÿç‰ˆï¼‰"""
    n = len(data)
    if lag >= n:
        return 0.0
    
    mean_val = np.mean(data)
    
    # è‡ªå·±ç›¸é–¢è¨ˆç®—
    numerator = 0.0
    denominator = 0.0
    
    for i in range(n - lag):
        x_i = data[i] - mean_val
        x_lag = data[i + lag] - mean_val
        numerator += x_i * x_lag
        denominator += x_i * x_i
    
    if denominator < 1e-10:
        return 0.0
    
    return abs(numerator / denominator)


@njit(fastmath=True, cache=True)
def simple_quantum_integration(
    cycles: np.ndarray,
    strengths: np.ndarray,
    confidences: np.ndarray,
    adaptivity_factor: float
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """é‡å­é©å¿œçµ±åˆï¼ˆç°¡ç´ ç‰ˆï¼‰"""
    n = len(cycles)
    final_cycles = np.zeros(n)
    final_strengths = np.zeros(n)
    final_confidences = np.zeros(n)
    adaptation_speeds = np.zeros(n)
    
    if n < 2:
        return cycles.copy(), strengths.copy(), confidences.copy(), adaptation_speeds
    
    # åˆæœŸå€¤
    final_cycles[0] = cycles[0]
    final_strengths[0] = strengths[0]
    final_confidences[0] = confidences[0]
    
    for i in range(1, n):
        # é©å¿œçš„çµ±åˆ
        adaptation_speed = adaptivity_factor * confidences[i]
        
        # æœŸé–“ã®é©å¿œçµ±åˆ
        final_cycles[i] = (adaptation_speed * cycles[i] + 
                          (1 - adaptation_speed) * final_cycles[i-1])
        
        # å¼·åº¦ãƒ»ä¿¡é ¼åº¦ã®çµ±åˆ
        final_strengths[i] = max(strengths[i], final_strengths[i-1] * 0.9)
        final_confidences[i] = (confidences[i] + final_confidences[i-1]) * 0.5
        
        adaptation_speeds[i] = adaptation_speed
    
    return final_cycles, final_strengths, final_confidences, adaptation_speeds


if __name__ == "__main__":
    # åŸºæœ¬ãƒ†ã‚¹ãƒˆ
    print("ğŸš€ Ultimate Supreme Cycle Detector - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä½é…å»¶ç‰ˆ")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    np.random.seed(42)
    test_prices = np.cumsum(np.random.randn(1000) * 0.01) + 100
    
    # æ¤œå‡ºå™¨åˆæœŸåŒ–
    detector = UltimateSupremeCycleDetectorRealtime()
    
    # è¨ˆç®—å®Ÿè¡Œ
    import time
    start_time = time.time()
    result = detector.calculate(test_prices)
    end_time = time.time()
    
    print(f"âœ… è¨ˆç®—å®Œäº†")
    print(f"â±ï¸  è¨ˆç®—æ™‚é–“: {(end_time - start_time) * 1000:.2f}ms")
    print(f"ğŸ¯ ç¾åœ¨ã‚µã‚¤ã‚¯ãƒ«: {result.current_cycle:.1f}æœŸé–“")
    print(f"ğŸ’ª ç¾åœ¨å¼·åº¦: {result.current_strength:.3f}")
    print(f"ğŸ‰ ç¾åœ¨ä¿¡é ¼åº¦: {result.current_confidence:.3f}") 