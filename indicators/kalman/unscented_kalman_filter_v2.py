#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ¯ **Unscented Kalman Filter V2 (UKF V2) - ç„¡é¦™æ–™ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼V2** ğŸ¯

æä¾›ã•ã‚ŒãŸã‚¢ã‚«ãƒ‡ãƒŸãƒƒã‚¯ãªç„¡é¦™æ–™ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å®Ÿè£…ï¼š
- ãƒãƒ«ãƒãƒ¬ãƒ¼ãƒˆå‡¦ç†å¯¾å¿œï¼ˆäºˆæ¸¬ã¨æ›´æ–°ã®åˆ†é›¢ï¼‰
- æ±ç”¨çš„ãªçŠ¶æ…‹é·ç§»é–¢æ•°ã¨è¦³æ¸¬é–¢æ•°ã®å¯¾å¿œ
- ã‚ˆã‚Šå³å¯†ãªæ•°å­¦çš„å®Ÿè£…
- ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªã‚·ã‚¹ãƒ†ãƒ é–¢æ•°

ğŸŒŸ **UKF V2ã®ç‰¹å¾´:**
1. **æ±ç”¨ã‚·ã‚¹ãƒ†ãƒ é–¢æ•°**: f(x, u)ã¨h(x)ã‚’è‡ªç”±ã«å®šç¾©å¯èƒ½
2. **ãƒãƒ«ãƒãƒ¬ãƒ¼ãƒˆå‡¦ç†**: äºˆæ¸¬ã¨æ›´æ–°ã‚’ç‹¬ç«‹ã—ã¦å®Ÿè¡Œ
3. **å³å¯†ãªå®Ÿè£…**: ã‚¢ã‚«ãƒ‡ãƒŸãƒƒã‚¯ãªç†è«–ã«å¿ å®Ÿ
4. **æŸ”è»Ÿæ€§**: æ§˜ã€…ãªçŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œ
"""

from dataclasses import dataclass
from typing import Union, Tuple, Dict, Optional, List, Callable
import numpy as np
import pandas as pd
from numba import njit
import traceback
import math

try:
    from ..indicator import Indicator
    from ..price_source import PriceSource
except ImportError:
    # Fallback for potential execution context issues
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from indicator import Indicator
    from price_source import PriceSource


@dataclass
class UKFV2Result:
    """ç„¡é¦™æ–™ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼V2ã®è¨ˆç®—çµæœ"""
    filtered_values: np.ndarray      # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿ä¾¡æ ¼
    state_estimates: np.ndarray      # çŠ¶æ…‹æ¨å®šå€¤ï¼ˆå…¨çŠ¶æ…‹ï¼‰
    error_covariance: np.ndarray     # ã‚¨ãƒ©ãƒ¼å…±åˆ†æ•£ï¼ˆå¯¾è§’æˆåˆ†ï¼‰
    innovations: np.ndarray          # ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆäºˆæ¸¬èª¤å·®ï¼‰
    confidence_scores: np.ndarray    # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
    raw_values: np.ndarray          # å…ƒã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
    prediction_history: np.ndarray   # äºˆæ¸¬å±¥æ­´
    update_history: np.ndarray      # æ›´æ–°å±¥æ­´

# Aliases for compatibility
UKFResult = UKFV2Result
UnscentedKalmanResult = UKFV2Result


class UnscentedKalmanFilterV2(object):
    """
    ç„¡é¦™æ–™ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼V2
    
    æ±ç”¨çš„ãªç„¡é¦™æ–™ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å®Ÿè£…ï¼š
    - çŠ¶æ…‹é‡: Xk+1 = f(Xk, Uk) + v
    - è¦³æ¸¬é‡: Yk+1 = h(Xk+1) + w
    - ãƒãƒ«ãƒãƒ¬ãƒ¼ãƒˆå‡¦ç†å¯¾å¿œ
    - ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªã‚·ã‚¹ãƒ†ãƒ é–¢æ•°
    """
    
    def __init__(
        self, 
        f: Callable[[np.ndarray, np.ndarray], np.ndarray],
        h: Callable[[np.ndarray], np.ndarray], 
        Q: np.ndarray, 
        R: np.ndarray, 
        x0_estimate: np.ndarray, 
        P0: np.ndarray, 
        u_dim: int, 
        step: int, 
        kappa: float = 0.0
    ):
        """
        åˆæœŸåŒ–
        
        Args:
            f: çŠ¶æ…‹é·ç§»é–¢æ•° f(xt, ut) -> x_dimæ¬¡å…ƒã®np.ndarray
            h: è¦³æ¸¬é–¢æ•° h(xt) -> y_dimæ¬¡å…ƒã®np.ndarray  
            Q: ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚¤ã‚ºå…±åˆ†æ•£è¡Œåˆ— (x_dim x x_dim)
            R: è¦³æ¸¬ãƒã‚¤ã‚ºå…±åˆ†æ•£è¡Œåˆ— (y_dim x y_dim)
            x0_estimate: çŠ¶æ…‹åˆæœŸå€¤ (x_dim,)
            P0: åˆæœŸèª¤å·®å…±åˆ†æ•£è¡Œåˆ— (x_dim x x_dim)
            u_dim: åˆ¶å¾¡å…¥åŠ›æ¬¡å…ƒ
            step: æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•°
            kappa: UKFãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        """
        # å…¥åŠ›æ¤œè¨¼
        assert isinstance(Q, np.ndarray) and Q.shape[0] == Q.shape[1], \
               'Qã¯æ­£æ–¹è¡Œåˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚'
        self.Q = Q.copy()
        self.x_dim = Q.shape[0]  # çŠ¶æ…‹é‡æ¬¡å…ƒ
        
        assert isinstance(R, np.ndarray) and R.shape[0] == R.shape[1], \
               'Rã¯æ­£æ–¹è¡Œåˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚'
        self.R = R.copy()
        self.y_dim = R.shape[0]  # è¦³æ¸¬é‡æ¬¡å…ƒ
        
        self.u_dim = u_dim  # åˆ¶å¾¡é‡æ¬¡å…ƒ
        
        # ã‚·ã‚¹ãƒ†ãƒ é–¢æ•°ã®è¨­å®š
        self.f = f
        self.h = h
        
        # ã‚·ã‚¹ãƒ†ãƒ é–¢æ•°ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        self._check_system_function()
        
        assert isinstance(x0_estimate, np.ndarray) and len(x0_estimate) == self.x_dim, \
               'x0ã¯çŠ¶æ…‹æ¬¡å…ƒã¨ä¸€è‡´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚'
        
        assert isinstance(P0, np.ndarray) and P0.shape == (self.x_dim, self.x_dim), \
               'P0ã¯çŠ¶æ…‹æ¬¡å…ƒã®æ­£æ–¹è¡Œåˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚'
        self.Pk = P0.copy()
        
        self.t_dim = step + 1  # æ™‚åˆ»æ¬¡å…ƒ
        self.kappa = kappa
        self._k = 0  # ç¾åœ¨ã®äºˆæ¸¬ã‚¹ãƒ†ãƒƒãƒ—
        self._k_correct = 0  # ç¾åœ¨ã®æ›´æ–°ã‚¹ãƒ†ãƒƒãƒ—
        
        # çŠ¶æ…‹å±¥æ­´ã®åˆæœŸåŒ–
        self.X = np.zeros((self.x_dim, self.t_dim))
        self.X[:, self._k] = x0_estimate.copy()
        
        # UKFãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.omega = 0.5 / (self.x_dim + self.kappa)
        self.omega0 = self.kappa / (self.x_dim + self.kappa)
        
        # äºˆæ¸¬ãƒ»æ›´æ–°å±¥æ­´
        self.prediction_history = np.zeros((self.x_dim, self.t_dim))
        self.update_history = np.zeros((self.x_dim, self.t_dim))
        self.prediction_history[:, 0] = x0_estimate.copy()
        self.update_history[:, 0] = x0_estimate.copy()
    
    def _check_system_function(self):
        """ã‚·ã‚¹ãƒ†ãƒ é–¢æ•°ã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        # ãƒ©ãƒ³ãƒ€ãƒ ãªå…¥åŠ›ã§ãƒ†ã‚¹ãƒˆ
        x_test = np.random.randn(self.x_dim)
        u_test = np.random.randn(self.u_dim)
        
        # çŠ¶æ…‹é·ç§»é–¢æ•°ã®ãƒ†ã‚¹ãƒˆ
        x_next = self.f(x_test, u_test)
        assert isinstance(x_next, np.ndarray) and len(x_next) == self.x_dim, \
               'fã®è¿”ã‚Šå€¤ã¯çŠ¶æ…‹æ¬¡å…ƒã¨ä¸€è‡´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚'
        
        # è¦³æ¸¬é–¢æ•°ã®ãƒ†ã‚¹ãƒˆ
        y = self.h(x_test)
        assert isinstance(y, np.ndarray) and len(y) == self.y_dim, \
               'hã®è¿”ã‚Šå€¤ã¯è¦³æ¸¬æ¬¡å…ƒã¨ä¸€è‡´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚'
    
    def estimate(self, u: np.ndarray) -> bool:
        """
        äºˆæ¸¬ã‚¹ãƒ†ãƒƒãƒ—
        
        Args:
            u: åˆ¶å¾¡å…¥åŠ› (u_dim,)
            
        Returns:
            bool: äºˆæ¸¬ãŒæˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        if self._k + 1 >= self.t_dim:
            return False
        
        assert isinstance(u, np.ndarray) and len(u) == self.u_dim, \
               'uã¯åˆ¶å¾¡å…¥åŠ›æ¬¡å…ƒã¨ä¸€è‡´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚'
        
        # ç¾åœ¨ã®çŠ¶æ…‹æ¨å®šå€¤ã‚’å–å¾—
        X = self.get_current_estimate_value()
        
        # ã‚·ã‚°ãƒãƒã‚¤ãƒ³ãƒˆç”Ÿæˆ
        X_sigma = self._generate_sigma_points(X, self.Pk)
        
        # å„ã‚·ã‚°ãƒãƒã‚¤ãƒ³ãƒˆã‚’çŠ¶æ…‹é·ç§»é–¢æ•°ã«é€šã™
        for i in range(X_sigma.shape[1]):
            X_sigma[:, i] = self.f(X_sigma[:, i], u)
        
        # äºˆæ¸¬çŠ¶æ…‹ã®è¨ˆç®—ï¼ˆé‡ã¿ä»˜ãå¹³å‡ï¼‰
        Xk_priori = self.omega0 * X_sigma[:, 0]
        for i in range(1, X_sigma.shape[1]):
            Xk_priori += self.omega * X_sigma[:, i]
        
        # äºˆæ¸¬å…±åˆ†æ•£ã®è¨ˆç®—
        diff = X_sigma[:, 0] - Xk_priori
        P_priori = self.Q + self.omega0 * np.outer(diff, diff)
        for i in range(1, X_sigma.shape[1]):
            diff = X_sigma[:, i] - Xk_priori
            P_priori += self.omega * np.outer(diff, diff)
        
        # çŠ¶æ…‹ã‚’æ›´æ–°
        self._k += 1
        self.X[:, self._k] = Xk_priori
        self.Pk = P_priori
        self.prediction_history[:, self._k] = Xk_priori.copy()
        
        return True
    
    def correct(self, Y: np.ndarray) -> bool:
        """
        æ›´æ–°ã‚¹ãƒ†ãƒƒãƒ—
        
        Args:
            Y: è¦³æ¸¬å€¤ (y_dim,)
            
        Returns:
            bool: æ›´æ–°ãŒæˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        if self._k_correct >= self._k:
            return False
        
        assert isinstance(Y, np.ndarray) and len(Y) == self.y_dim, \
               'Yã¯è¦³æ¸¬æ¬¡å…ƒã¨ä¸€è‡´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚'
        
        # ç¾åœ¨ã®çŠ¶æ…‹æ¨å®šå€¤ã‚’å–å¾—
        X = self.get_current_estimate_value()
        
        # ã‚·ã‚°ãƒãƒã‚¤ãƒ³ãƒˆç”Ÿæˆ
        X_sigma = self._generate_sigma_points(X, self.Pk)
        
        # è¦³æ¸¬ã‚·ã‚°ãƒãƒã‚¤ãƒ³ãƒˆè¨ˆç®—
        Y_sigma = np.zeros((self.y_dim, X_sigma.shape[1]))
        for i in range(X_sigma.shape[1]):
            Y_sigma[:, i] = self.h(X_sigma[:, i])
        
        # äºˆæ¸¬è¦³æ¸¬å€¤ã®è¨ˆç®—ï¼ˆé‡ã¿ä»˜ãå¹³å‡ï¼‰
        Y_estimate = self.omega0 * Y_sigma[:, 0]
        for i in range(1, Y_sigma.shape[1]):
            Y_estimate += self.omega * Y_sigma[:, i]
        
        # ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³å…±åˆ†æ•£ã®è¨ˆç®—
        diff = Y_sigma[:, 0] - Y_estimate
        P_yy = self.R + self.omega0 * np.outer(diff, diff)
        for i in range(1, Y_sigma.shape[1]):
            diff = Y_sigma[:, i] - Y_estimate
            P_yy += self.omega * np.outer(diff, diff)
        
        # çŠ¶æ…‹-è¦³æ¸¬é–“ã®ç›¸äº’å…±åˆ†æ•£ã®è¨ˆç®—
        xdiff = X_sigma[:, 0] - X
        ydiff = Y_sigma[:, 0] - Y_estimate
        P_xy = self.omega0 * np.outer(xdiff, ydiff)
        for i in range(1, X_sigma.shape[1]):
            xdiff = X_sigma[:, i] - X
            ydiff = Y_sigma[:, i] - Y_estimate
            P_xy += self.omega * np.outer(xdiff, ydiff)
        
        # ã‚«ãƒ«ãƒãƒ³ã‚²ã‚¤ãƒ³è¨ˆç®—
        try:
            K_gain = P_xy @ np.linalg.inv(P_yy)
        except np.linalg.LinAlgError:
            # ç‰¹ç•°è¡Œåˆ—ã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            K_gain = np.zeros((self.x_dim, self.y_dim))
        
        # çŠ¶æ…‹ã¨å…±åˆ†æ•£ã®æ›´æ–°
        innovation = Y - Y_estimate
        self.X[:, self._k] = X + K_gain @ innovation
        self.Pk = self.Pk - K_gain @ P_xy.T
        
        # æ•°å€¤å®‰å®šæ€§ã®ç¢ºä¿
        self.Pk = (self.Pk + self.Pk.T) / 2  # å¯¾ç§°æ€§ã®ä¿è¨¼
        eigenvals = np.linalg.eigvals(self.Pk)
        if np.any(eigenvals < 1e-8):
            self.Pk += np.eye(self.x_dim) * 1e-8
        
        self._k_correct = self._k
        self.update_history[:, self._k] = self.X[:, self._k].copy()
        
        return True
    
    def _generate_sigma_points(self, mean: np.ndarray, covariance: np.ndarray) -> np.ndarray:
        """
        ã‚·ã‚°ãƒãƒã‚¤ãƒ³ãƒˆç”Ÿæˆ
        
        Args:
            mean: å¹³å‡ãƒ™ã‚¯ãƒˆãƒ«
            covariance: å…±åˆ†æ•£è¡Œåˆ—
            
        Returns:
            ã‚·ã‚°ãƒãƒã‚¤ãƒ³ãƒˆè¡Œåˆ— (x_dim, 2*x_dim+1)
        """
        X_sigma = np.zeros((self.x_dim, 1 + self.x_dim * 2))
        X_sigma[:, 0] = mean
        
        try:
            # ã‚³ãƒ¬ã‚¹ã‚­ãƒ¼åˆ†è§£
            P_cholesky = np.linalg.cholesky(covariance)
            
            for i in range(self.x_dim):
                diff = math.sqrt(self.x_dim + self.kappa) * P_cholesky[:, i]
                X_sigma[:, i + 1] = mean + diff
                X_sigma[:, self.x_dim + i + 1] = mean - diff
                
        except np.linalg.LinAlgError:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å›ºæœ‰å€¤åˆ†è§£
            try:
                eigenvals, eigenvecs = np.linalg.eigh(covariance)
                eigenvals = np.maximum(eigenvals, 1e-8)  # è² ã®å›ºæœ‰å€¤ã‚’ä¿®æ­£
                sqrt_matrix = eigenvecs @ np.diag(np.sqrt(eigenvals))
                
                for i in range(self.x_dim):
                    diff = math.sqrt(self.x_dim + self.kappa) * sqrt_matrix[:, i]
                    X_sigma[:, i + 1] = mean + diff
                    X_sigma[:, self.x_dim + i + 1] = mean - diff
                    
            except:
                # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¯¾è§’è¡Œåˆ—
                for i in range(self.x_dim):
                    std_dev = math.sqrt(max(covariance[i, i], 1e-8))
                    diff = math.sqrt(self.x_dim + self.kappa) * std_dev
                    X_sigma[i, i + 1] = mean[i] + diff
                    X_sigma[i, self.x_dim + i + 1] = mean[i] - diff
        
        return X_sigma
    
    def get_estimate_value(self) -> np.ndarray:
        """å…¨ã‚¹ãƒ†ãƒƒãƒ—ã®çŠ¶æ…‹æ¨å®šå€¤ã‚’å–å¾—"""
        return self.X[:, :self._k + 1]
    
    def get_current_estimate_value(self) -> np.ndarray:
        """ç¾åœ¨ã‚¹ãƒ†ãƒƒãƒ—ã®çŠ¶æ…‹æ¨å®šå€¤ã‚’å–å¾—"""
        return self.X[:, self._k]


# é‡‘èãƒ‡ãƒ¼ã‚¿ç”¨ã®ã‚·ã‚¹ãƒ†ãƒ é–¢æ•°å®šç¾©
def financial_state_transition(x: np.ndarray, u: np.ndarray) -> np.ndarray:
    """
    é‡‘èãƒ‡ãƒ¼ã‚¿ç”¨ã®çŠ¶æ…‹é·ç§»é–¢æ•°
    
    çŠ¶æ…‹: [ä¾¡æ ¼, é€Ÿåº¦, åŠ é€Ÿåº¦]
    åˆ¶å¾¡: [å¸‚å ´ãƒ‰ãƒªãƒ•ãƒˆ]
    """
    if len(x) < 3:
        return x
    
    price, velocity, acceleration = x[0], x[1], x[2]
    market_drift = u[0] if len(u) > 0 else 0.0
    
    dt = 1.0
    damping = 0.95
    
    # çŠ¶æ…‹é·ç§»
    new_price = price + velocity * dt + 0.5 * acceleration * dt * dt + market_drift
    new_velocity = velocity * damping + acceleration * dt
    new_acceleration = acceleration * 0.9
    
    return np.array([new_price, new_velocity, new_acceleration])


def financial_observation(x: np.ndarray) -> np.ndarray:
    """
    é‡‘èãƒ‡ãƒ¼ã‚¿ç”¨ã®è¦³æ¸¬é–¢æ•°
    
    è¦³æ¸¬: [ä¾¡æ ¼] (ä¾¡æ ¼ã®ã¿ã‚’è¦³æ¸¬)
    """
    return np.array([x[0]])


class UnscentedKalmanFilterV2Wrapper(Indicator):
    """
    UKF V2ã®Indicatorãƒ©ãƒƒãƒ‘ãƒ¼
    
    é‡‘èãƒ‡ãƒ¼ã‚¿å‡¦ç†ç”¨ã®ç„¡é¦™æ–™ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼š
    - æ±ç”¨çš„ãªUKF V2å®Ÿè£…ã‚’ãƒ™ãƒ¼ã‚¹
    - é‡‘èãƒ‡ãƒ¼ã‚¿ç‰¹åŒ–ã®çŠ¶æ…‹é·ç§»ãƒ»è¦³æ¸¬é–¢æ•°
    - ãƒãƒ«ãƒãƒ¬ãƒ¼ãƒˆå‡¦ç†å¯¾å¿œ
    - æ—¢å­˜ã®Indicatorã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«æº–æ‹ 
    """
    
    def __init__(
        self,
        src_type: str = 'close',
        kappa: float = 0.0,
        process_noise_scale: float = 0.01,
        observation_noise_scale: float = 0.001,
        max_steps: int = 1000
    ):
        """
        ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
        
        Args:
            src_type: ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ ('close', 'hlc3', 'hl2', 'ohlc4')
            kappa: UKFãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            process_noise_scale: ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚¤ã‚ºã‚¹ã‚±ãƒ¼ãƒ«
            observation_noise_scale: è¦³æ¸¬ãƒã‚¤ã‚ºã‚¹ã‚±ãƒ¼ãƒ«
            max_steps: æœ€å¤§å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—æ•°
        """
        indicator_name = f"UKF_V2(src={src_type}, Îº={kappa})"
        super().__init__(indicator_name)
        
        self.src_type = src_type.lower()
        self.kappa = kappa
        self.process_noise_scale = process_noise_scale
        self.observation_noise_scale = observation_noise_scale
        self.max_steps = max_steps
        
        # ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã®æ¤œè¨¼
        valid_sources = ['close', 'hlc3', 'hl2', 'ohlc4', 'high', 'low', 'open', 'oc2']
        if self.src_type not in valid_sources:
            raise ValueError(f"ç„¡åŠ¹ãªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—: {src_type}")
        
        # çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._result_cache = {}
        self._max_cache_size = 10
        self._cache_keys = []
    
    def _get_data_hash(self, data: Union[pd.DataFrame, np.ndarray]) -> str:
        """ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—"""
        try:
            if isinstance(data, pd.DataFrame):
                length = len(data)
                if length > 0:
                    first_val = float(data.iloc[0].get('close', data.iloc[0, -1]))
                    last_val = float(data.iloc[-1].get('close', data.iloc[-1, -1]))
                else:
                    first_val = last_val = 0.0
            else:
                length = len(data)
                if length > 0:
                    if data.ndim > 1:
                        first_val = float(data[0, -1])
                        last_val = float(data[-1, -1])
                    else:
                        first_val = float(data[0])
                        last_val = float(data[-1])
                else:
                    first_val = last_val = 0.0
            
            params_sig = f"{self.kappa}_{self.src_type}_{self.process_noise_scale}_{self.observation_noise_scale}"
            data_sig = (length, first_val, last_val)
            return f"{hash(data_sig)}_{hash(params_sig)}"
            
        except Exception:
            return f"{id(data)}_{self.kappa}_{self.src_type}"
    
    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> UKFV2Result:
        """
        UKF V2ã‚’ä½¿ç”¨ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’è¨ˆç®—
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            UKFV2Result: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæœ
        """
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            data_hash = self._get_data_hash(data)
            
            if data_hash in self._result_cache:
                if data_hash in self._cache_keys:
                    self._cache_keys.remove(data_hash)
                self._cache_keys.append(data_hash)
                cached_result = self._result_cache[data_hash]
                return UKFV2Result(
                    filtered_values=cached_result.filtered_values.copy(),
                    state_estimates=cached_result.state_estimates.copy(),
                    error_covariance=cached_result.error_covariance.copy(),
                    innovations=cached_result.innovations.copy(),
                    confidence_scores=cached_result.confidence_scores.copy(),
                    raw_values=cached_result.raw_values.copy(),
                    prediction_history=cached_result.prediction_history.copy(),
                    update_history=cached_result.update_history.copy()
                )
            
            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
            src_prices = PriceSource.calculate_source(data, self.src_type)
            data_length = len(src_prices)
            
            if data_length < 5:
                return self._create_empty_result(data_length, src_prices)
            
            # UKF V2ã®è¨­å®š
            x_dim = 3  # [ä¾¡æ ¼, é€Ÿåº¦, åŠ é€Ÿåº¦]
            y_dim = 1  # [ä¾¡æ ¼]
            u_dim = 1  # [å¸‚å ´ãƒ‰ãƒªãƒ•ãƒˆ]
            
            # ãƒã‚¤ã‚ºè¡Œåˆ—
            Q = np.array([
                [self.process_noise_scale, 0.0, 0.0],
                [0.0, self.process_noise_scale * 0.1, 0.0],
                [0.0, 0.0, self.process_noise_scale * 0.01]
            ])
            R = np.array([[self.observation_noise_scale]])
            
            # åˆæœŸçŠ¶æ…‹
            x0 = np.array([src_prices[0], 0.0, 0.0])
            P0 = np.array([
                [1.0, 0.0, 0.0],
                [0.0, 0.1, 0.0],
                [0.0, 0.0, 0.01]
            ])
            
            # UKF V2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
            ukf = UnscentedKalmanFilterV2(
                f=financial_state_transition,
                h=financial_observation,
                Q=Q, R=R, x0_estimate=x0, P0=P0,
                u_dim=u_dim, step=min(data_length, self.max_steps),
                kappa=self.kappa
            )
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
            filtered_values = np.zeros(data_length)
            state_estimates = np.zeros((data_length, x_dim))
            error_covariance = np.zeros((data_length, x_dim))
            innovations = np.zeros(data_length)
            confidence_scores = np.zeros(data_length)
            
            # åˆæœŸå€¤è¨­å®š
            filtered_values[0] = src_prices[0]
            state_estimates[0] = x0
            error_covariance[0] = np.diag(P0)
            innovations[0] = 0.0
            confidence_scores[0] = 1.0
            
            # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
            for i in range(1, min(data_length, ukf.t_dim)):
                # å¸‚å ´ãƒ‰ãƒªãƒ•ãƒˆæ¨å®šï¼ˆç°¡å˜ãªä¾‹ï¼‰
                if i > 1:
                    market_drift = (src_prices[i-1] - src_prices[i-2]) * 0.1
                else:
                    market_drift = 0.0
                
                u = np.array([market_drift])
                
                # äºˆæ¸¬ã‚¹ãƒ†ãƒƒãƒ—
                if ukf.estimate(u):
                    # æ›´æ–°ã‚¹ãƒ†ãƒƒãƒ—
                    y_obs = np.array([src_prices[i]])
                    ukf.correct(y_obs)
                    
                    # çµæœã®ä¿å­˜
                    current_state = ukf.get_current_estimate_value()
                    filtered_values[i] = current_state[0]
                    state_estimates[i] = current_state
                    error_covariance[i] = np.diag(ukf.Pk)
                    
                    # ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³è¨ˆç®—
                    predicted_obs = ukf.h(current_state)
                    innovations[i] = src_prices[i] - predicted_obs[0]
                    
                    # ä¿¡é ¼åº¦è¨ˆç®—
                    uncertainty = np.sqrt(ukf.Pk[0, 0])
                    confidence_scores[i] = 1.0 / (1.0 + uncertainty * 10.0)
                else:
                    # äºˆæ¸¬ãŒå¤±æ•—ã—ãŸå ´åˆ
                    filtered_values[i] = filtered_values[i-1] if i > 0 else src_prices[i]
                    state_estimates[i] = state_estimates[i-1] if i > 0 else x0
                    error_covariance[i] = error_covariance[i-1] if i > 0 else np.diag(P0)
                    innovations[i] = 0.0
                    confidence_scores[i] = 0.5
            
            # å±¥æ­´ã®å–å¾—
            ukf_history = ukf.get_estimate_value()
            prediction_history = ukf.prediction_history[:, :ukf._k+1]
            update_history = ukf.update_history[:, :ukf._k_correct+1]
            
            # çµæœã®ä½œæˆ
            result = UKFV2Result(
                filtered_values=filtered_values.copy(),
                state_estimates=state_estimates.copy(),
                error_covariance=error_covariance.copy(),
                innovations=innovations.copy(),
                confidence_scores=confidence_scores.copy(),
                raw_values=src_prices.copy(),
                prediction_history=prediction_history.copy(),
                update_history=update_history.copy()
            )
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
            if len(self._result_cache) >= self._max_cache_size and self._cache_keys:
                oldest_key = self._cache_keys.pop(0)
                if oldest_key in self._result_cache:
                    del self._result_cache[oldest_key]
            
            self._result_cache[data_hash] = result
            self._cache_keys.append(data_hash)
            
            self._values = filtered_values  # åŸºåº•ã‚¯ãƒ©ã‚¹ç”¨
            return result
            
        except Exception as e:
            error_msg = str(e)
            stack_trace = traceback.format_exc()
            self.logger.error(f"UKF V2è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {error_msg}\n{stack_trace}")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºã®çµæœã‚’è¿”ã™
            if isinstance(data, (pd.DataFrame, np.ndarray)) and len(data) > 0:
                src_prices = PriceSource.calculate_source(data, self.src_type)
                return self._create_empty_result(len(src_prices), src_prices)
            else:
                return self._create_empty_result(0, np.array([]))
    
    def _create_empty_result(self, length: int, raw_prices: np.ndarray) -> UKFV2Result:
        """ç©ºã®çµæœã‚’ä½œæˆ"""
        return UKFV2Result(
            filtered_values=np.full(length, np.nan),
            state_estimates=np.full((length, 3), np.nan),
            error_covariance=np.full((length, 3), np.nan),
            innovations=np.full(length, np.nan),
            confidence_scores=np.full(length, np.nan),
            raw_values=raw_prices,
            prediction_history=np.full((3, length), np.nan),
            update_history=np.full((3, length), np.nan)
        )
    
    def get_values(self) -> Optional[np.ndarray]:
        """ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿ä¾¡æ ¼ã‚’å–å¾—"""
        if not self._result_cache:
            return None
        
        result = self._get_latest_result()
        return result.filtered_values.copy() if result else None
    
    def get_state_estimates(self) -> Optional[np.ndarray]:
        """çŠ¶æ…‹æ¨å®šå€¤ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.state_estimates.copy() if result else None
    
    def get_velocity_estimates(self) -> Optional[np.ndarray]:
        """é€Ÿåº¦æ¨å®šå€¤ã‚’å–å¾—"""
        result = self._get_latest_result()
        if result and result.state_estimates.shape[1] >= 2:
            return result.state_estimates[:, 1].copy()
        return None
    
    def get_acceleration_estimates(self) -> Optional[np.ndarray]:
        """åŠ é€Ÿåº¦æ¨å®šå€¤ã‚’å–å¾—"""
        result = self._get_latest_result()
        if result and result.state_estimates.shape[1] >= 3:
            return result.state_estimates[:, 2].copy()
        return None
    
    def get_confidence_scores(self) -> Optional[np.ndarray]:
        """ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.confidence_scores.copy() if result else None
    
    def get_innovations(self) -> Optional[np.ndarray]:
        """ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.innovations.copy() if result else None
    
    def get_prediction_history(self) -> Optional[np.ndarray]:
        """äºˆæ¸¬å±¥æ­´ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.prediction_history.copy() if result else None
    
    def get_update_history(self) -> Optional[np.ndarray]:
        """æ›´æ–°å±¥æ­´ã‚’å–å¾—"""
        result = self._get_latest_result()
        return result.update_history.copy() if result else None
    
    def _get_latest_result(self) -> Optional[UKFV2Result]:
        """æœ€æ–°ã®çµæœã‚’å–å¾—"""
        if not self._result_cache:
            return None
        
        if self._cache_keys:
            return self._result_cache[self._cache_keys[-1]]
        else:
            return next(iter(self._result_cache.values()))
    
    def reset(self) -> None:
        """çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        super().reset()
        self._result_cache = {}
        self._cache_keys = []