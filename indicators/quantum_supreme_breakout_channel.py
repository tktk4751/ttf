#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸŒŒ Quantum Supreme Breakout Channel V1.0 - äººé¡å²ä¸Šæœ€å¼·ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ™ãƒ¼ã‚¹ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆãƒãƒ£ãƒãƒ«

ç¾ä»£é‡‘èå·¥å­¦ã€é‡å­ç‰©ç†å­¦ã€ã‚«ã‚ªã‚¹ç†è«–ã€æ©Ÿæ¢°å­¦ç¿’ã€ä¿¡å·å‡¦ç†ç†è«–ã‚’çµ±åˆã—ãŸé©å‘½çš„ãªãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆãƒãƒ£ãƒãƒ«ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
äºˆæ¸¬ã§ã¯ãªãã€Œè¶…é«˜ç²¾åº¦é©å¿œã€ã‚’ã‚³ãƒ³ã‚»ãƒ—ãƒˆã¨ã—ã€å¸‚å ´ã®å¾®ç´°ãªçŠ¶æ…‹å¤‰åŒ–ã‚’ç¬æ™‚ã«æ¤œå‡ºã—ã€ãƒãƒ£ãƒãƒ«å¹…ã‚’å‹•çš„ã«èª¿æ•´ã™ã‚‹å®‡å®™æœ€å¼·ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
"""

from typing import Union, Optional, NamedTuple, Tuple, Dict
import numpy as np
import pandas as pd
from numba import jit, njit
from dataclasses import dataclass

# ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‹ã‚‰çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤‰æ›´
try:
    from .indicator import Indicator
    from .price_source import PriceSource
    from .ultimate_ma import UltimateMA
    from .ultimate_chop_trend import UltimateChopTrend
    from .ultimate_volatility import UltimateVolatility
    from .efficiency_ratio import EfficiencyRatio
    from .ehlers_absolute_ultimate_cycle import EhlersAbsoluteUltimateCycle
    from .quantum_hyper_adaptive_ma import QuantumHyperAdaptiveMA
except ImportError:
    # ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œæ™‚ã®å¯¾å¿œ
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from indicator import Indicator
    from price_source import PriceSource
    from ultimate_ma import UltimateMA
    from ultimate_chop_trend import UltimateChopTrend
    from ultimate_volatility import UltimateVolatility
    from efficiency_ratio import EfficiencyRatio
    from ehlers_absolute_ultimate_cycle import EhlersAbsoluteUltimateCycle
    from quantum_hyper_adaptive_ma import QuantumHyperAdaptiveMA


@dataclass
class QuantumSupremeBreakoutChannelResult:
    """ğŸŒŒ Quantum Supreme Breakout Channel è¨ˆç®—çµæœ"""
    # ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒãƒ«
    upper_channel: np.ndarray           # ä¸Šä½ãƒãƒ£ãƒãƒ«
    middle_line: np.ndarray             # ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ (é‡å­é©å¿œ)
    lower_channel: np.ndarray           # ä¸‹ä½ãƒãƒ£ãƒãƒ«
    
    # å¸‚å ´çŠ¶æ…‹åˆ†æ
    market_regime: np.ndarray           # å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ  (0=ãƒ¬ãƒ³ã‚¸, 1=ãƒˆãƒ¬ãƒ³ãƒ‰, 2=ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ)
    trend_strength: np.ndarray          # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ (0-1)
    volatility_regime: np.ndarray       # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ 
    efficiency_score: np.ndarray        # åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢
    
    # é‡å­è¨ˆæ¸¬å€¤
    quantum_coherence: np.ndarray       # é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹
    quantum_entanglement: np.ndarray    # é‡å­ã‚‚ã¤ã‚Œ
    superposition_state: np.ndarray     # é‡ã­åˆã‚ã›çŠ¶æ…‹
    
    # å‹•çš„é©å¿œå€¤
    dynamic_multiplier: np.ndarray      # å‹•çš„ä¹—æ•° (1.0-6.0)
    channel_width_ratio: np.ndarray     # ãƒãƒ£ãƒãƒ«å¹…æ¯”ç‡
    adaptation_confidence: np.ndarray   # é©å¿œä¿¡é ¼åº¦
    
    # äºˆæ¸¬ãƒ»åˆ†æå€¤
    breakout_probability: np.ndarray    # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºç‡
    trend_persistence: np.ndarray       # ãƒˆãƒ¬ãƒ³ãƒ‰æŒç¶šæ€§
    volatility_forecast: np.ndarray     # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£äºˆæ¸¬
    
    # ã‚·ã‚°ãƒŠãƒ«
    breakout_signals: np.ndarray        # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚·ã‚°ãƒŠãƒ« (1=ä¸ŠæŠœã‘, -1=ä¸‹æŠœã‘, 0=ç„¡ã—)
    trend_signals: np.ndarray           # ãƒˆãƒ¬ãƒ³ãƒ‰ã‚·ã‚°ãƒŠãƒ«
    regime_change_signals: np.ndarray   # ãƒ¬ã‚¸ãƒ¼ãƒ å¤‰åŒ–ã‚·ã‚°ãƒŠãƒ«
    
    # ç¾åœ¨çŠ¶æ…‹
    current_regime: str                 # ç¾åœ¨ã®ãƒ¬ã‚¸ãƒ¼ãƒ 
    current_trend_strength: float       # ç¾åœ¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦
    current_breakout_probability: float # ç¾åœ¨ã®ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºç‡
    current_adaptation_mode: str        # ç¾åœ¨ã®é©å¿œãƒ¢ãƒ¼ãƒ‰


@njit(fastmath=True, cache=True)
def quantum_hilbert_transform_analysis(prices: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    ğŸŒ€ é‡å­å¼·åŒ–ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›åˆ†æ
    ç¬æ™‚æŒ¯å¹…ãƒ»ä½ç›¸ãƒ»å‘¨æ³¢æ•°ãƒ»ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ã®åŒæ™‚è§£æ
    """
    n = len(prices)
    amplitude = np.zeros(n)
    phase = np.zeros(n)
    frequency = np.zeros(n)
    coherence = np.zeros(n)
    
    if n < 8:
        return amplitude, phase, frequency, coherence
    
    # æ”¹è‰¯å‹ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›
    for i in range(4, n-4):
        # å®Ÿéƒ¨ï¼ˆå…ƒä¿¡å·ï¼‰
        real_part = prices[i]
        
        # è™šéƒ¨ï¼ˆé‡å­å¼·åŒ–ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ï¼‰
        imag_part = (prices[i-3] - prices[i+3] + 
                    3 * (prices[i+1] - prices[i-1])) / 8.0
        
        # ç¬æ™‚æŒ¯å¹…ï¼ˆé‡å­ã‚‚ã¤ã‚Œè£œæ­£ï¼‰
        amplitude[i] = np.sqrt(real_part**2 + imag_part**2)
        
        # ç¬æ™‚ä½ç›¸
        if real_part != 0:
            phase[i] = np.arctan2(imag_part, real_part)
        
        # ç¬æ™‚å‘¨æ³¢æ•°ï¼ˆä½ç›¸å¾®åˆ†ï¼‰
        if i > 4:
            phase_diff = phase[i] - phase[i-1]
            # ä½ç›¸ãƒ©ãƒƒãƒ”ãƒ³ã‚°è£œæ­£
            if phase_diff > np.pi:
                phase_diff -= 2 * np.pi
            elif phase_diff < -np.pi:
                phase_diff += 2 * np.pi
            frequency[i] = abs(phase_diff) / (2 * np.pi)
        
        # é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹
        if i >= 8:
            amp_var = np.var(amplitude[i-8:i])
            phase_consistency = 1.0 / (1.0 + amp_var * 10.0)
            coherence[i] = phase_consistency
    
    # å¢ƒç•Œå€¤å‡¦ç†
    for i in range(4):
        amplitude[i] = amplitude[4] if n > 4 else 0.0
        phase[i] = phase[4] if n > 4 else 0.0
        frequency[i] = frequency[4] if n > 4 else 0.0
        coherence[i] = coherence[4] if n > 4 else 0.0
    for i in range(n-4, n):
        amplitude[i] = amplitude[n-5] if n > 4 else 0.0
        phase[i] = phase[n-5] if n > 4 else 0.0
        frequency[i] = frequency[n-5] if n > 4 else 0.0
        coherence[i] = coherence[n-5] if n > 4 else 0.0
    
    return amplitude, phase, frequency, coherence


@njit(fastmath=True, cache=True)
def calculate_fractal_dimension(prices: np.ndarray, window: int = 20) -> np.ndarray:
    """
    ğŸ“ ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè¨ˆç®—ï¼ˆãƒãƒ¼ã‚¹ãƒˆæŒ‡æ•°ãƒ™ãƒ¼ã‚¹ï¼‰
    å¸‚å ´æ§‹é€ ã®è¤‡é›‘ã•ã‚’å®šé‡åŒ–
    """
    n = len(prices)
    fractal_dims = np.zeros(n)
    
    if n < window:
        return fractal_dims
    
    for i in range(window, n):
        data_segment = prices[i-window:i]
        
        # å¤‰åˆ†æ³•ã«ã‚ˆã‚‹ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè¨ˆç®—
        scales = np.array([2, 4, 8, 16], dtype=np.float64)
        variations = np.zeros(len(scales))
        
        for j, scale in enumerate(scales):
            if scale < window:
                n_segments = int(window // scale)
                total_variation = 0.0
                
                for k in range(n_segments):
                    start_idx = int(k * scale)
                    end_idx = min(int((k + 1) * scale), window)
                    if end_idx > start_idx:
                        segment = data_segment[start_idx:end_idx]
                        if len(segment) > 1:
                            variation = np.sum(np.abs(np.diff(segment)))
                            total_variation += variation
                
                variations[j] = total_variation / n_segments if n_segments > 0 else 0.0
        
        # ç·šå½¢å›å¸°ã«ã‚ˆã‚‹å‚¾ãè¨ˆç®—
        valid_variations = variations[variations > 0]
        valid_scales = scales[:len(valid_variations)]
        
        if len(valid_variations) >= 2:
            log_scales = np.log(valid_scales)
            log_variations = np.log(valid_variations)
            
            # æœ€å°äºŒä¹—æ³•
            n_points = len(log_scales)
            sum_x = np.sum(log_scales)
            sum_y = np.sum(log_variations)
            sum_xy = np.sum(log_scales * log_variations)
            sum_x2 = np.sum(log_scales * log_scales)
            
            denominator = n_points * sum_x2 - sum_x * sum_x
            if abs(denominator) > 1e-10:
                slope = (n_points * sum_xy - sum_x * sum_y) / denominator
                fractal_dims[i] = 2.0 - slope  # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ
            else:
                fractal_dims[i] = 1.5
        else:
            fractal_dims[i] = 1.5
    
    # å‰æ–¹åŸ‹ã‚
    for i in range(window):
        fractal_dims[i] = fractal_dims[window] if n > window else 1.5
    
    return fractal_dims


@njit(fastmath=True, cache=True)
def calculate_multiscale_entropy(prices: np.ndarray, max_scale: int = 5) -> np.ndarray:
    """
    ğŸ”¬ ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—
    å¸‚å ´ã®ä¸ç¢ºå®Ÿæ€§ã¨ãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’å®šé‡åŒ–
    """
    n = len(prices)
    entropy_values = np.zeros(n)
    
    if n < 20:
        return entropy_values
    
    for i in range(20, n):
        window_data = prices[i-20:i]
        total_entropy = 0.0
        
        for scale in range(1, min(max_scale + 1, 6)):  # max 5 scales
            # ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            if scale == 1:
                scaled_data = window_data
            else:
                scaled_length = len(window_data) // scale
                if scaled_length < 3:
                    continue
                    
                scaled_data = np.zeros(scaled_length)
                for j in range(scaled_length):
                    start_idx = j * scale
                    end_idx = min((j + 1) * scale, len(window_data))
                    scaled_data[j] = np.mean(window_data[start_idx:end_idx])
            
            # ã‚µãƒ³ãƒ—ãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—ï¼ˆç°¡ç•¥ç‰ˆï¼‰
            if len(scaled_data) >= 3:
                # ç›¸å¯¾å·®åˆ†ã‚’è¨ˆç®—
                diffs = np.abs(np.diff(scaled_data))
                if len(diffs) > 0:
                    # æ­£è¦åŒ–
                    max_diff = np.max(diffs)
                    if max_diff > 0:
                        normalized_diffs = diffs / max_diff
                        # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—
                        entropy = -np.mean(normalized_diffs * np.log(normalized_diffs + 1e-10))
                        total_entropy += entropy / scale
        
        entropy_values[i] = total_entropy
    
    # å‰æ–¹åŸ‹ã‚
    for i in range(20):
        entropy_values[i] = entropy_values[20] if n > 20 else 0.0
    
    return entropy_values


@njit(fastmath=True, cache=True)
def calculate_ultra_smooth_dynamic_multiplier(
    trend_strength: float,
    efficiency_ratio: float,
    volatility_persistence: float,
    fractal_dimension: float,
    entropy: float,
    regime_change_probability: float,
    previous_multiplier: float
) -> float:
    """
    ğŸš€ è¶…ä½é…å»¶ã‚¹ãƒ ãƒ¼ã‚ºå‹•çš„ä¹—æ•°è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³
    1æœŸé–“ä»¥å†…ã§å¸‚å ´çŠ¶æ…‹ã‚’åˆ¤å®šã—ã€1.0-6.0ã®ç¯„å›²ã§æ»‘ã‚‰ã‹ã«èª¿æ•´
    """
    # ğŸ¯ Step 1: ç¬æ™‚å¸‚å ´çŠ¶æ…‹åˆ¤å®š
    trend_score = trend_strength * 2.0          # 0-2.0
    efficiency_score = efficiency_ratio * 1.5   # 0-1.5
    chaos_score = (2.0 - fractal_dimension)     # 0.5-1.0
    entropy_score = entropy                     # 0-1.0
    
    # ğŸŒŠ Step 2: é‡ã¿ä»˜ãçµ±åˆã‚¹ã‚³ã‚¢
    market_order_score = (trend_score * 0.4 + 
                         efficiency_score * 0.3 + 
                         chaos_score * 0.2 + 
                         (1.0 - entropy_score) * 0.1)
    
    # ğŸ›ï¸ Step 3: ä¹—æ•°ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆ1.0-6.0ç¯„å›²ã«èª¿æ•´ï¼‰
    normalized_score = max(0.0, min(1.0, market_order_score / 2.5))
    
    if normalized_score > 0.75:
        # å¼·ãƒˆãƒ¬ãƒ³ãƒ‰: 1.0-2.0
        base_multiplier = 1.0
        range_multiplier = 1.0 * (normalized_score - 0.75) / 0.25
    elif normalized_score < 0.25:
        # å¼·ãƒ¬ãƒ³ã‚¸: 5.0-6.0
        base_multiplier = 5.0
        range_multiplier = 1.0 * (0.25 - normalized_score) / 0.25
    else:
        # ä¸­é–“çŠ¶æ…‹: 2.0-5.0
        transition_factor = (normalized_score - 0.25) / 0.5
        sigmoid_factor = 1.0 / (1.0 + np.exp(-8.0 * (transition_factor - 0.5)))
        base_multiplier = 2.0 + 3.0 * (1.0 - sigmoid_factor)
        range_multiplier = 0.0
    
    raw_multiplier = base_multiplier + range_multiplier
    
    # ğŸŒ€ Step 4: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å¾®èª¿æ•´
    volatility_adjustment = volatility_persistence * 0.4  # èª¿æ•´å¹…ã‚’ç¸®å°
    if raw_multiplier < 3.5:
        adjusted_multiplier = raw_multiplier + volatility_adjustment
    else:
        adjusted_multiplier = raw_multiplier + volatility_adjustment * 0.5
    
    # ğŸ“ Step 5: å³å¯†ç¯„å›²åˆ¶é™ï¼ˆ1.0-6.0ï¼‰
    clamped_multiplier = max(1.0, min(6.0, adjusted_multiplier))
    
    # âš¡ Step 6: è¶…ä½é…å»¶ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
    change_magnitude = abs(clamped_multiplier - previous_multiplier)
    adaptive_alpha = 0.15 + 0.25 * min(change_magnitude / 2.0, 1.0)
    
    if regime_change_probability > 0.6:
        adaptive_alpha = min(adaptive_alpha * 1.5, 0.5)
    
    smooth_multiplier = (adaptive_alpha * clamped_multiplier + 
                        (1.0 - adaptive_alpha) * previous_multiplier)
    
    return smooth_multiplier


@njit(fastmath=True, cache=True)
def calculate_breakout_signals(
    prices: np.ndarray,
    upper_channel: np.ndarray,
    lower_channel: np.ndarray,
    middle_line: np.ndarray,
    dynamic_multiplier: np.ndarray,
    trend_strength: np.ndarray
) -> Tuple[np.ndarray, np.ndarray]:
    """
    ğŸ¯ ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚·ã‚°ãƒŠãƒ«è¨ˆç®—
    è¶…é«˜ç²¾åº¦ãªãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆæ¤œå‡ºã¨ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºç‡
    """
    n = len(prices)
    breakout_signals = np.zeros(n)
    breakout_probability = np.zeros(n)
    
    if n < 5:
        return breakout_signals, breakout_probability
    
    for i in range(3, n):
        current_price = prices[i]
        upper = upper_channel[i]
        lower = lower_channel[i]
        middle = middle_line[i]
        
        # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆåˆ¤å®š
        upper_breakout = current_price > upper
        lower_breakout = current_price < lower
        
        # ç¢ºç‡è¨ˆç®—ï¼ˆãƒãƒ£ãƒãƒ«å†…ã§ã®ä½ç½®ã¨å‹•çš„ä¹—æ•°ã‚’è€ƒæ…®ï¼‰
        if upper > lower:
            channel_position = (current_price - lower) / (upper - lower)
            
            # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºç‡
            if upper_breakout:
                # ä¸Šæ–¹ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ
                breakout_signals[i] = 1.0
                excess = (current_price - upper) / (upper - middle)
                breakout_probability[i] = min(0.95, 0.7 + excess * 0.25)
            elif lower_breakout:
                # ä¸‹æ–¹ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ
                breakout_signals[i] = -1.0
                excess = (lower - current_price) / (middle - lower)
                breakout_probability[i] = min(0.95, 0.7 + excess * 0.25)
            else:
                # ãƒãƒ£ãƒãƒ«å†…
                breakout_signals[i] = 0.0
                
                # åœ§ç¸®ã•ã‚ŒãŸãƒãƒ£ãƒãƒ«ï¼ˆä½ä¹—æ•°ï¼‰ã§ã¯é«˜ã„ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºç‡
                compression_factor = 3.5 / dynamic_multiplier[i]  # 1.0ã§æœ€å¤§ã€6.0ã§æœ€å°
                
                if channel_position > 0.8:
                    # ä¸Šæ–¹å‘ã¸ã®å¯èƒ½æ€§
                    breakout_probability[i] = min(0.6, 0.3 + (channel_position - 0.8) * 1.5 * compression_factor)
                elif channel_position < 0.2:
                    # ä¸‹æ–¹å‘ã¸ã®å¯èƒ½æ€§
                    breakout_probability[i] = min(0.6, 0.3 + (0.2 - channel_position) * 1.5 * compression_factor)
                else:
                    # ä¸­å¤®ä»˜è¿‘
                    breakout_probability[i] = 0.1 * compression_factor
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã«ã‚ˆã‚‹è£œæ­£
        breakout_probability[i] *= (0.5 + trend_strength[i] * 0.5)
    
    return breakout_signals, breakout_probability


class QuantumSupremeBreakoutChannel(Indicator):
    """
    ğŸŒŒ Quantum Supreme Breakout Channel V1.0 - äººé¡å²ä¸Šæœ€å¼·ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ™ãƒ¼ã‚¹ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆãƒãƒ£ãƒãƒ«
    
    ç¾ä»£é‡‘èå·¥å­¦ã€é‡å­ç‰©ç†å­¦ã€ã‚«ã‚ªã‚¹ç†è«–ã€æ©Ÿæ¢°å­¦ç¿’ã€ä¿¡å·å‡¦ç†ç†è«–ã‚’çµ±åˆã—ãŸé©å‘½çš„ãªãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆãƒãƒ£ãƒãƒ«ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
    
    ğŸš€ ä¸»è¦ç‰¹å¾´:
    - å‹•çš„ä¹—æ•° 1.0-6.0 ã®è¶…ä½é…å»¶ã‚¹ãƒ ãƒ¼ã‚ºèª¿æ•´
    - é‡å­å¼·åŒ–ä¾¡æ ¼åˆ†æã‚¨ãƒ³ã‚¸ãƒ³
    - è¶…é«˜é€Ÿé©å¿œã‚¨ãƒ³ã‚¸ãƒ³
    - é‡å­ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æã‚¨ãƒ³ã‚¸ãƒ³
    - å‹•çš„ãƒãƒ£ãƒãƒ«é©å¿œã‚¨ãƒ³ã‚¸ãƒ³
    """
    
    def __init__(
        self,
        # åŸºæœ¬è¨­å®š
        analysis_period: int = 21,
        src_type: str = 'hlc3',
        min_multiplier: float = 1.0,
        max_multiplier: float = 6.0,
        smoothing_alpha: float = 0.25,
        
        # é‡å­ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        quantum_coherence_threshold: float = 0.75,
        entanglement_factor: float = 0.618,
        superposition_weight: float = 0.5,
        
        # é©å¿œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        trend_sensitivity: float = 0.85,
        range_sensitivity: float = 0.75,
        adaptation_speed: float = 0.12,
        memory_decay: float = 0.95,
        multiplier_smoothing_mode: str = 'adaptive',
        ultra_low_latency: bool = True,
        smooth_transition_threshold: float = 0.3,
        
        # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æœ‰åŠ¹åŒ–
        enable_quantum_hilbert: bool = True,
        enable_fractal_analysis: bool = True,
        enable_wavelet_decomp: bool = True,
        enable_kalman_quantum: bool = True,
        enable_garch_volatility: bool = True,
        enable_regime_switching: bool = True,
        enable_spectral_analysis: bool = True,
        enable_entropy_analysis: bool = True,
        enable_chaos_theory: bool = True,
        enable_efficiency_ratio: bool = True,
        enable_x_trend_index: bool = True,
        enable_roc_persistence: bool = True
    ):
        """
        ğŸŒŒ Quantum Supreme Breakout Channel ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
        """
        super().__init__(f"QuantumSupremeBreakoutChannel(period={analysis_period},mult={min_multiplier}-{max_multiplier},src={src_type})")
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        self.analysis_period = analysis_period
        self.src_type = src_type
        self.min_multiplier = min_multiplier
        self.max_multiplier = max_multiplier
        self.smoothing_alpha = smoothing_alpha
        
        # é‡å­ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.quantum_coherence_threshold = quantum_coherence_threshold
        self.entanglement_factor = entanglement_factor
        self.superposition_weight = superposition_weight
        
        # é©å¿œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.trend_sensitivity = trend_sensitivity
        self.range_sensitivity = range_sensitivity
        self.adaptation_speed = adaptation_speed
        self.memory_decay = memory_decay
        self.multiplier_smoothing_mode = multiplier_smoothing_mode
        self.ultra_low_latency = ultra_low_latency
        self.smooth_transition_threshold = smooth_transition_threshold
        
        # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æœ‰åŠ¹åŒ–ãƒ•ãƒ©ã‚°
        self.enable_quantum_hilbert = enable_quantum_hilbert
        self.enable_fractal_analysis = enable_fractal_analysis
        self.enable_wavelet_decomp = enable_wavelet_decomp
        self.enable_kalman_quantum = enable_kalman_quantum
        self.enable_garch_volatility = enable_garch_volatility
        self.enable_regime_switching = enable_regime_switching
        self.enable_spectral_analysis = enable_spectral_analysis
        self.enable_entropy_analysis = enable_entropy_analysis
        self.enable_chaos_theory = enable_chaos_theory
        self.enable_efficiency_ratio = enable_efficiency_ratio
        self.enable_x_trend_index = enable_x_trend_index
        self.enable_roc_persistence = enable_roc_persistence
        
        # å†…éƒ¨çŠ¶æ…‹
        self._cache = {}
        self._result: Optional[QuantumSupremeBreakoutChannelResult] = None
        self._previous_multiplier = 4.75  # åˆæœŸå€¤ï¼ˆä¸­å¤®å€¤ï¼‰
        
        # ã‚µãƒ–ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–
        self._initialize_sub_indicators()

    def _initialize_sub_indicators(self):
        """ã‚µãƒ–ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®åˆæœŸåŒ–"""
        try:
            # Quantum Hyper Adaptive MA (è¶…é«˜æ€§èƒ½ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ç”¨)
            if self.enable_kalman_quantum:
                self.quantum_hyper_ma = QuantumHyperAdaptiveMA(
                    period=self.analysis_period,
                    src_type=self.src_type,
                    quantum_factor=self.entanglement_factor,
                    chaos_sensitivity=1.2,
                    fractal_window=min(20, self.analysis_period),
                    entropy_window=min(16, self.analysis_period),
                    coherence_threshold=self.quantum_coherence_threshold,
                    ultra_low_latency=self.ultra_low_latency,
                    hyper_adaptation=True
                )
            
            # Ultimate Chop Trend (å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡ºç”¨)
            if self.enable_regime_switching:
                self.chop_trend = UltimateChopTrend(
                    analysis_period=self.analysis_period,
                    ensemble_window=30,
                    enable_hilbert=True,
                    enable_fractal=True,
                    enable_wavelet=True,
                    enable_kalman=True,
                    enable_entropy=True,
                    enable_chaos=True
                )
            
            # Ultimate Volatility (é‡å­ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç”¨)
            if self.enable_garch_volatility:
                self.ultimate_volatility = UltimateVolatility(
                    period=14,
                    trend_window=10,
                    hilbert_window=12,
                    src_type=self.src_type
                )
            
            # Efficiency Ratio (åŠ¹ç‡æ€§è¨ˆç®—ç”¨)
            if self.enable_efficiency_ratio:
                self.efficiency_ratio = EfficiencyRatio(
                    period=self.analysis_period,
                    src_type=self.src_type,
                    use_dynamic_period=True,
                    detector_type='absolute_ultimate'
                )
            
            # Ehlers Absolute Ultimate Cycle (ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºç”¨)
            if self.enable_spectral_analysis:
                self.cycle_detector = EhlersAbsoluteUltimateCycle(
                    cycle_part=0.5,
                    max_output=50,
                    min_output=8,
                    src_type=self.src_type
                )
                
        except Exception as e:
            self.logger.error(f"ã‚µãƒ–ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç„¡åŠ¹åŒ–
            self.enable_kalman_quantum = False
            self.enable_regime_switching = False
            self.enable_garch_volatility = False
            self.enable_efficiency_ratio = False
            self.enable_spectral_analysis = False

    def calculate(self, data: Union[pd.DataFrame, np.ndarray]) -> QuantumSupremeBreakoutChannelResult:
        """
        ğŸŒŒ Quantum Supreme Breakout Channel ã‚’è¨ˆç®—ã™ã‚‹
        äººé¡å²ä¸Šæœ€å¼·ã®ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆãƒãƒ£ãƒãƒ«è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³
        
        Args:
            data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆDataFrameã¾ãŸã¯NumPyé…åˆ—ï¼‰
        
        Returns:
            QuantumSupremeBreakoutChannelResult: å…¨è§£æçµæœ
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
            if isinstance(data, np.ndarray) and data.ndim == 1:
                src_prices = data.astype(np.float64)
                data_hash_key = f"{hash(src_prices.tobytes())}_{self.analysis_period}_{self.min_multiplier}_{self.max_multiplier}"
            else:
                data_hash = self._get_data_hash(data)
                if data_hash in self._cache and self._result is not None:
                    return self._result
                
                src_prices = PriceSource.calculate_source(data, self.src_type)
                src_prices = src_prices.astype(np.float64)
                data_hash_key = data_hash

            data_length = len(src_prices)
            if data_length == 0:
                return self._create_empty_result(0)

            self.logger.info("ğŸŒŒ Quantum Supreme Breakout Channel è¨ˆç®—é–‹å§‹...")

            # ğŸš€ Layer 1: é‡å­å¼·åŒ–ä¾¡æ ¼åˆ†æã‚¨ãƒ³ã‚¸ãƒ³
            self.logger.debug("ğŸŒŠ Layer 1: é‡å­å¼·åŒ–ä¾¡æ ¼åˆ†æã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè¡Œä¸­...")
            
            # 1.1 é‡å­ãƒ’ãƒ«ãƒ™ãƒ«ãƒˆå¤‰æ›ãƒãƒˆãƒªãƒƒã‚¯ã‚¹
            if self.enable_quantum_hilbert:
                hilbert_amplitude, hilbert_phase, hilbert_frequency, quantum_coherence = quantum_hilbert_transform_analysis(src_prices)
            else:
                hilbert_amplitude = np.zeros(data_length)
                hilbert_phase = np.zeros(data_length)
                hilbert_frequency = np.zeros(data_length)
                quantum_coherence = np.full(data_length, 0.5)

            # 1.2 ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒé©å¿œãƒ•ã‚£ãƒ«ã‚¿
            if self.enable_fractal_analysis:
                fractal_dimension = calculate_fractal_dimension(src_prices, min(20, self.analysis_period))
            else:
                fractal_dimension = np.full(data_length, 1.5)

            # 1.3 ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
            if self.enable_entropy_analysis:
                entropy_values = calculate_multiscale_entropy(src_prices, max_scale=5)
            else:
                entropy_values = np.full(data_length, 0.5)

            # âš¡ Layer 2: è¶…é«˜é€Ÿé©å¿œã‚¨ãƒ³ã‚¸ãƒ³
            self.logger.debug("âš¡ Layer 2: è¶…é«˜é€Ÿé©å¿œã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè¡Œä¸­...")
            
            # 2.1 Quantum Hyper Adaptive MA (è¶…é«˜æ€§èƒ½ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³)
            if self.enable_kalman_quantum and hasattr(self, 'quantum_hyper_ma'):
                quantum_ma_result = self.quantum_hyper_ma.calculate(data)
                middle_line = quantum_ma_result.values
                quantum_ma_trend_signals = quantum_ma_result.trend_signals
                
                # è¿½åŠ ã®é‡å­ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—
                quantum_ma_coherence = quantum_ma_result.quantum_coherence
                quantum_ma_entropy = quantum_ma_result.market_entropy
                quantum_ma_fractal = quantum_ma_result.fractal_dimension
                quantum_ma_confidence = quantum_ma_result.prediction_confidence
                
                self.logger.debug(f"ğŸŒŒ Quantum Hyper Adaptive MA - ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦: {quantum_ma_result.current_trend_strength:.3f}, ä¿¡é ¼åº¦: {quantum_ma_result.current_prediction_confidence:.3f}")
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: EMA
                middle_line = self._calculate_ema(src_prices, self.analysis_period)
                quantum_ma_trend_signals = np.zeros(data_length)
                quantum_ma_coherence = np.full(data_length, 0.5)
                quantum_ma_entropy = np.full(data_length, 0.5)
                quantum_ma_fractal = np.full(data_length, 1.5)
                quantum_ma_confidence = np.full(data_length, 0.5)

            # 2.2 Ultimate Chop Trend (ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡º)
            if self.enable_regime_switching and hasattr(self, 'chop_trend'):
                chop_trend_result = self.chop_trend.calculate(data)
                market_regime_raw = chop_trend_result.regime_state
                trend_strength = chop_trend_result.trend_strength
                regime_change_signals = chop_trend_result.trend_signals
            else:
                market_regime_raw = np.full(data_length, 1)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ãƒˆãƒ¬ãƒ³ãƒ‰
                trend_strength = np.full(data_length, 0.5)
                regime_change_signals = np.zeros(data_length)

            # 2.3 Ultimate Volatility (é‡å­ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£)
            if self.enable_garch_volatility and hasattr(self, 'ultimate_volatility'):
                volatility_result = self.ultimate_volatility.calculate(data)
                quantum_volatility = volatility_result.ultimate_volatility
                volatility_regime = volatility_result.regime_indicator
                volatility_forecast = volatility_result.volatility_forecast
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ATR
                quantum_volatility = self._calculate_atr(data, 14)
                volatility_regime = np.full(data_length, 1)
                volatility_forecast = quantum_volatility.copy()

            # ğŸ”¬ Layer 3: é‡å­åŠ¹ç‡æ€§è§£æ
            self.logger.debug("ğŸ”¬ Layer 3: é‡å­åŠ¹ç‡æ€§è§£æå®Ÿè¡Œä¸­...")
            
            if self.enable_efficiency_ratio and hasattr(self, 'efficiency_ratio'):
                efficiency_result = self.efficiency_ratio.calculate(data)
                efficiency_score = efficiency_result.values
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚·ãƒ³ãƒ—ãƒ«åŠ¹ç‡æ¯”
                efficiency_score = self._calculate_simple_efficiency(src_prices, self.analysis_period)

            # ğŸŒ€ Layer 4: å‹•çš„ãƒãƒ£ãƒãƒ«é©å¿œã‚¨ãƒ³ã‚¸ãƒ³
            self.logger.debug("ğŸŒ€ Layer 4: å‹•çš„ãƒãƒ£ãƒãƒ«é©å¿œã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè¡Œä¸­...")
            
            # ROCæŒç¶šæ€§ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æŒç¶šæ€§ã¨ã—ã¦ä½¿ç”¨ï¼‰
            volatility_persistence = self._calculate_volatility_persistence(quantum_volatility, 10)
            
            # ãƒ¬ã‚¸ãƒ¼ãƒ å¤‰åŒ–ç¢ºç‡
            regime_change_probability = self._calculate_regime_change_probability(
                trend_strength, efficiency_score, volatility_persistence, 5
            )

            # ğŸš€ å‹•çš„ä¹—æ•°è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆQuantum Hyper MAã®çŸ¥è¦‹ã‚’çµ±åˆï¼‰
            self.logger.debug("ğŸš€ å‹•çš„ä¹—æ•°è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè¡Œä¸­...")
            dynamic_multiplier = np.zeros(data_length)
            
            for i in range(data_length):
                # Quantum Hyper MAã®è¿½åŠ æƒ…å ±ã‚’æ´»ç”¨
                enhanced_fractal = (fractal_dimension[i] + quantum_ma_fractal[i]) / 2.0
                enhanced_entropy = (entropy_values[i] + quantum_ma_entropy[i]) / 2.0
                enhanced_coherence = (quantum_coherence[i] + quantum_ma_coherence[i]) / 2.0
                
                # è¶…é«˜ç²¾åº¦å‹•çš„ä¹—æ•°è¨ˆç®—
                dynamic_multiplier[i] = calculate_ultra_smooth_dynamic_multiplier(
                    trend_strength[i] * quantum_ma_confidence[i],  # ä¿¡é ¼åº¦ã§é‡ã¿ä»˜ã‘
                    efficiency_score[i],
                    volatility_persistence[i],
                    enhanced_fractal,
                    enhanced_entropy,
                    regime_change_probability[i],
                    self._previous_multiplier
                )
                self._previous_multiplier = dynamic_multiplier[i]

            # ğŸ“Š ãƒãƒ£ãƒãƒ«è¨ˆç®—
            self.logger.debug("ğŸ“Š æœ€çµ‚ãƒãƒ£ãƒãƒ«è¨ˆç®—å®Ÿè¡Œä¸­...")
            
            # éå¯¾ç§°æ€§èª¿æ•´ï¼ˆQuantum MAã®ã‚·ã‚°ãƒŠãƒ«ã‚’ä½¿ç”¨ï¼‰
            trend_bias = self._calculate_trend_bias(quantum_ma_trend_signals)
            asymmetry_up, asymmetry_down = self._calculate_asymmetry_factors(trend_bias)
            
            # æœ€çµ‚ãƒãƒ£ãƒãƒ«
            upper_channel = middle_line + quantum_volatility * dynamic_multiplier * asymmetry_up
            lower_channel = middle_line - quantum_volatility * dynamic_multiplier * asymmetry_down

            # ãƒãƒ£ãƒãƒ«é †åºã®æ¤œè¨¼ã¨ä¿®æ­£
            for i in range(data_length):
                if upper_channel[i] <= middle_line[i]:
                    upper_channel[i] = middle_line[i] + quantum_volatility[i] * dynamic_multiplier[i] * 0.1
                if lower_channel[i] >= middle_line[i]:
                    lower_channel[i] = middle_line[i] - quantum_volatility[i] * dynamic_multiplier[i] * 0.1
                if upper_channel[i] <= lower_channel[i]:
                    mid_val = (upper_channel[i] + lower_channel[i]) / 2.0
                    spread = quantum_volatility[i] * dynamic_multiplier[i] * 0.05
                    upper_channel[i] = mid_val + spread
                    lower_channel[i] = mid_val - spread

            # ğŸ¯ ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ
            self.logger.debug("ğŸ¯ ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆå®Ÿè¡Œä¸­...")
            
            breakout_signals, breakout_probability = calculate_breakout_signals(
                src_prices, upper_channel, lower_channel, middle_line, 
                dynamic_multiplier, trend_strength
            )

            # ğŸ“ˆ è¿½åŠ è¨ˆç®—ï¼ˆé‡å­ãƒ¡ãƒˆãƒªã‚¯ã‚¹çµ±åˆï¼‰
            market_regime = self._classify_market_regime(market_regime_raw, trend_strength, efficiency_score)
            quantum_entanglement = self._calculate_quantum_entanglement(hilbert_amplitude, hilbert_phase)
            superposition_state = self._calculate_superposition_state(quantum_coherence, quantum_entanglement)
            channel_width_ratio = dynamic_multiplier / 4.75  # æ­£è¦åŒ–
            adaptation_confidence = self._calculate_adaptation_confidence(
                quantum_coherence, trend_strength, efficiency_score
            )
            trend_persistence = self._calculate_trend_persistence(trend_strength, 10)
            trend_signals = self._generate_trend_signals(src_prices, middle_line, trend_strength)

            # ç¾åœ¨çŠ¶æ…‹ã®æ±ºå®š
            current_regime = self._determine_current_regime(market_regime)
            current_trend_strength = float(trend_strength[-1]) if len(trend_strength) > 0 else 0.0
            current_breakout_probability = float(breakout_probability[-1]) if len(breakout_probability) > 0 else 0.0
            current_adaptation_mode = self._determine_adaptation_mode(dynamic_multiplier[-1] if len(dynamic_multiplier) > 0 else 4.75)

            # çµæœä½œæˆ
            result = QuantumSupremeBreakoutChannelResult(
                upper_channel=upper_channel,
                middle_line=middle_line,
                lower_channel=lower_channel,
                market_regime=market_regime,
                trend_strength=trend_strength,
                volatility_regime=volatility_regime,
                efficiency_score=efficiency_score,
                quantum_coherence=quantum_coherence,
                quantum_entanglement=quantum_entanglement,
                superposition_state=superposition_state,
                dynamic_multiplier=dynamic_multiplier,
                channel_width_ratio=channel_width_ratio,
                adaptation_confidence=adaptation_confidence,
                breakout_probability=breakout_probability,
                trend_persistence=trend_persistence,
                volatility_forecast=volatility_forecast,
                breakout_signals=breakout_signals,
                trend_signals=trend_signals,
                regime_change_signals=regime_change_signals,
                current_regime=current_regime,
                current_trend_strength=current_trend_strength,
                current_breakout_probability=current_breakout_probability,
                current_adaptation_mode=current_adaptation_mode
            )

            self._result = result
            self._cache[data_hash_key] = self._result
            
            mult_min = np.min(dynamic_multiplier) if len(dynamic_multiplier) > 0 else 1.5
            mult_max = np.max(dynamic_multiplier) if len(dynamic_multiplier) > 0 else 8.0
            
            # ãƒãƒ£ãƒãƒ«é †åºã®æœ€çµ‚æ¤œè¨¼
            sample_indices = [len(upper_channel)//4, len(upper_channel)//2, len(upper_channel)*3//4, len(upper_channel)-1]
            for idx in sample_indices:
                if idx < len(upper_channel):
                    self.logger.debug(f"ãƒãƒ£ãƒãƒ«æ¤œè¨¼ [{idx}]: Upper={upper_channel[idx]:.2f}, Middle={middle_line[idx]:.2f}, Lower={lower_channel[idx]:.2f}")
            
            # Quantum MAã®ä¿¡é ¼åº¦ã‚’å®‰å…¨ã«å–å¾—
            quantum_confidence = 0.5
            if self.enable_kalman_quantum and hasattr(self, 'quantum_hyper_ma') and 'quantum_ma_result' in locals():
                quantum_confidence = quantum_ma_result.current_prediction_confidence
            
            self.logger.info(f"âœ… Quantum Supreme Breakout Channel è¨ˆç®—å®Œäº† - ãƒ¬ã‚¸ãƒ¼ãƒ : {current_regime}, ä¹—æ•°ç¯„å›²: {mult_min:.2f}-{mult_max:.2f}, Quantum MAä¿¡é ¼åº¦: {quantum_confidence:.3f}")
            
            return result

        except Exception as e:
            import traceback
            error_msg = str(e)
            stack_trace = traceback.format_exc()
            self.logger.error(f"{self.name} è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {error_msg}\n{stack_trace}")
            data_len = len(data) if hasattr(data, '__len__') else 0
            self._result = None
            return self._create_empty_result(data_len)

    def _create_empty_result(self, length: int) -> QuantumSupremeBreakoutChannelResult:
        """ç©ºã®çµæœã‚’ä½œæˆ"""
        return QuantumSupremeBreakoutChannelResult(
            upper_channel=np.full(length, np.nan),
            middle_line=np.full(length, np.nan),
            lower_channel=np.full(length, np.nan),
            market_regime=np.zeros(length),
            trend_strength=np.full(length, 0.5),
            volatility_regime=np.ones(length),
            efficiency_score=np.full(length, 0.5),
            quantum_coherence=np.full(length, 0.5),
            quantum_entanglement=np.full(length, 0.5),
            superposition_state=np.full(length, 0.5),
            dynamic_multiplier=np.full(length, 4.75),
            channel_width_ratio=np.full(length, 1.0),
            adaptation_confidence=np.full(length, 0.5),
            breakout_probability=np.full(length, 0.1),
            trend_persistence=np.full(length, 0.5),
            volatility_forecast=np.full(length, np.nan),
            breakout_signals=np.zeros(length),
            trend_signals=np.zeros(length),
            regime_change_signals=np.zeros(length),
            current_regime='range',
            current_trend_strength=0.5,
            current_breakout_probability=0.1,
            current_adaptation_mode='neutral'
        )

    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    @staticmethod
    @njit(fastmath=True, cache=True)
    def _calculate_ema_numba(prices: np.ndarray, period: int) -> np.ndarray:
        """EMAè¨ˆç®—ï¼ˆNumbaæœ€é©åŒ–ï¼‰"""
        n = len(prices)
        ema = np.zeros(n)
        alpha = 2.0 / (period + 1.0)
        
        ema[0] = prices[0]
        for i in range(1, n):
            ema[i] = alpha * prices[i] + (1.0 - alpha) * ema[i-1]
        
        return ema

    def _calculate_ema(self, prices: np.ndarray, period: int) -> np.ndarray:
        """EMAè¨ˆç®—"""
        return self._calculate_ema_numba(prices, period)

    def _calculate_atr(self, data: Union[pd.DataFrame, np.ndarray], period: int = 14) -> np.ndarray:
        """ATRè¨ˆç®—"""
        if isinstance(data, pd.DataFrame):
            high = data['high'].values
            low = data['low'].values
            close = data['close'].values
        else:
            # NumPyé…åˆ—ã®å ´åˆã€[high, low, close]ã¨ä»®å®š
            if data.ndim == 2 and data.shape[1] >= 3:
                high = data[:, 1]
                low = data[:, 2]
                close = data[:, 3]
            else:
                # 1æ¬¡å…ƒã®å ´åˆã¯ã‚¯ãƒ­ãƒ¼ã‚ºä¾¡æ ¼ã¨ã—ã¦æ‰±ã„ã€ç°¡æ˜“ATR
                close = data
                return np.full(len(close), np.std(np.diff(close)) if len(close) > 1 else 0.1)

        n = len(close)
        tr = np.zeros(n)
        atr = np.zeros(n)
        
        for i in range(1, n):
            tr[i] = max(
                high[i] - low[i],
                abs(high[i] - close[i-1]),
                abs(low[i] - close[i-1])
            )
        
        tr[0] = high[0] - low[0] if high[0] > low[0] else 0.1
        
        # ATRè¨ˆç®—ï¼ˆWilder's smoothingï¼‰
        atr[0] = tr[0]
        alpha = 1.0 / period
        for i in range(1, n):
            atr[i] = alpha * tr[i] + (1.0 - alpha) * atr[i-1]
        
        return atr

    def _calculate_simple_efficiency(self, prices: np.ndarray, period: int) -> np.ndarray:
        """ã‚·ãƒ³ãƒ—ãƒ«åŠ¹ç‡æ¯”è¨ˆç®—"""
        n = len(prices)
        efficiency = np.zeros(n)
        
        for i in range(period, n):
            price_change = abs(prices[i] - prices[i-period])
            volatility = np.sum(np.abs(np.diff(prices[i-period:i])))
            
            if volatility > 0:
                efficiency[i] = price_change / volatility
            else:
                efficiency[i] = 0.0
        
        # å‰æ–¹åŸ‹ã‚
        for i in range(period):
            efficiency[i] = efficiency[period] if n > period else 0.0
        
        return efficiency

    def _calculate_volatility_persistence(self, volatility: np.ndarray, window: int) -> np.ndarray:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æŒç¶šæ€§è¨ˆç®—"""
        n = len(volatility)
        persistence = np.zeros(n)
        
        for i in range(window, n):
            vol_segment = volatility[i-window:i]
            if len(vol_segment) > 1:
                # è‡ªå·±ç›¸é–¢ã«ã‚ˆã‚‹æŒç¶šæ€§æ¸¬å®š
                vol_normalized = (vol_segment - np.mean(vol_segment)) / (np.std(vol_segment) + 1e-10)
                autocorr = np.corrcoef(vol_normalized[:-1], vol_normalized[1:])[0, 1]
                persistence[i] = max(0.0, autocorr) if not np.isnan(autocorr) else 0.0
        
        # å‰æ–¹åŸ‹ã‚
        for i in range(window):
            persistence[i] = persistence[window] if n > window else 0.0
        
        return persistence

    def _calculate_regime_change_probability(self, trend_strength: np.ndarray, efficiency: np.ndarray, 
                                           volatility_persistence: np.ndarray, window: int) -> np.ndarray:
        """ãƒ¬ã‚¸ãƒ¼ãƒ å¤‰åŒ–ç¢ºç‡è¨ˆç®—"""
        n = len(trend_strength)
        regime_change_prob = np.zeros(n)
        
        for i in range(window, n):
            # æœ€è¿‘ã®æŒ‡æ¨™å¤‰åŒ–ã‚’åˆ†æ
            trend_change = np.std(trend_strength[i-window:i])
            efficiency_change = np.std(efficiency[i-window:i])
            vol_persistence_change = np.std(volatility_persistence[i-window:i])
            
            # å¤‰åŒ–ã®å¤§ãã•ã‹ã‚‰ç¢ºç‡ã‚’è¨ˆç®—
            total_change = trend_change + efficiency_change + vol_persistence_change
            regime_change_prob[i] = min(0.9, total_change * 2.0)
        
        # å‰æ–¹åŸ‹ã‚
        for i in range(window):
            regime_change_prob[i] = regime_change_prob[window] if n > window else 0.1
        
        return regime_change_prob

    def _calculate_trend_bias(self, trend_signals: np.ndarray) -> np.ndarray:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ãƒã‚¤ã‚¢ã‚¹è¨ˆç®—"""
        return trend_signals.copy()

    def _calculate_asymmetry_factors(self, trend_bias: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """éå¯¾ç§°æ€§ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼è¨ˆç®—"""
        n = len(trend_bias)
        asymmetry_up = np.ones(n)
        asymmetry_down = np.ones(n)
        
        # åŸºæœ¬çš„ã«ã¯å¯¾ç§°ãƒãƒ£ãƒãƒ«ã‚’ç¶­æŒ
        # éå¯¾ç§°æ€§èª¿æ•´ã¯è»½å¾®ã«ã¨ã©ã‚ã‚‹
        for i in range(n):
            if trend_bias[i] > 0:  # ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰
                asymmetry_up[i] = 1.05   # ä¸Šä½ãƒãƒ£ãƒãƒ«ã‚’ã‚ãšã‹ã«åºƒã’ã‚‹
                asymmetry_down[i] = 0.95 # ä¸‹ä½ãƒãƒ£ãƒãƒ«ã‚’ã‚ãšã‹ã«ç‹­ã‚ã‚‹
            elif trend_bias[i] < 0:  # ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰
                asymmetry_up[i] = 0.95   # ä¸Šä½ãƒãƒ£ãƒãƒ«ã‚’ã‚ãšã‹ã«ç‹­ã‚ã‚‹
                asymmetry_down[i] = 1.05 # ä¸‹ä½ãƒãƒ£ãƒãƒ«ã‚’ã‚ãšã‹ã«åºƒã’ã‚‹
            # else: å¯¾ç§°ã®ã¾ã¾ (1.0, 1.0)
        
        return asymmetry_up, asymmetry_down 

    def _classify_market_regime(self, regime_raw: np.ndarray, trend_strength: np.ndarray, 
                               efficiency: np.ndarray) -> np.ndarray:
        """
        ğŸ¯ å®Ÿè·µçš„å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†é¡ - BTCç›¸å ´ã«æœ€é©åŒ–
        ã‚ˆã‚Šç¾å®Ÿçš„ã§å®Ÿç”¨çš„ãªãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºã‚’å®Ÿç¾
        """
        n = len(regime_raw)
        market_regime = np.zeros(n)
        
        # å‹•çš„é–¾å€¤è¨ˆç®—ï¼ˆéå»20æœŸé–“ã®çµ±è¨ˆã«åŸºã¥ãï¼‰
        window = min(20, n)
        
        for i in range(n):
            # ç¾åœ¨ã®å¸‚å ´çŠ¶æ…‹
            current_trend = trend_strength[i]
            current_efficiency = efficiency[i]
            
            # å‹•çš„é–¾å€¤ã®è¨ˆç®—ï¼ˆéå»ã®çµ±è¨ˆã«åŸºã¥ãï¼‰
            start_idx = max(0, i - window)
            trend_segment = trend_strength[start_idx:i+1]
            efficiency_segment = efficiency[i-window:i+1] if i >= window else efficiency[:i+1]
            
            # çµ±è¨ˆçš„é–¾å€¤ï¼ˆä¸­å¤®å€¤ + æ¨™æº–åå·®ã®å€æ•°ï¼‰
            trend_median = np.median(trend_segment)
            trend_std = np.std(trend_segment)
            efficiency_median = np.median(efficiency_segment)
            efficiency_std = np.std(efficiency_segment)
            
            # å®Ÿè·µçš„é–¾å€¤è¨­å®šï¼ˆBTCç›¸å ´ã«æœ€é©åŒ–ï¼‰
            trend_threshold_low = max(0.35, trend_median + 0.3 * trend_std)      # ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºä¸‹é™
            trend_threshold_high = max(0.65, trend_median + 1.0 * trend_std)     # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆæ¤œå‡ºä¸‹é™
            efficiency_threshold_low = max(0.25, efficiency_median + 0.2 * efficiency_std)   # åŠ¹ç‡æ€§ä¸‹é™
            efficiency_threshold_high = max(0.45, efficiency_median + 0.8 * efficiency_std)  # é«˜åŠ¹ç‡æ€§ä¸‹é™
            
            # è¿½åŠ æ¡ä»¶ï¼šä¾¡æ ¼å¤‰å‹•ç‡ã«ã‚ˆã‚‹è£œæ­£
            if i > 0:
                # ç›´è¿‘ã®ä¾¡æ ¼å¤‰å‹•ã‚’è€ƒæ…®
                recent_volatility = abs(regime_raw[i] - regime_raw[i-1]) / regime_raw[i-1] if regime_raw[i-1] != 0 else 0
                volatility_boost = min(0.15, recent_volatility * 5)  # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã«ã‚ˆã‚‹é–¾å€¤å¼•ãä¸‹ã’
                trend_threshold_low -= volatility_boost
                efficiency_threshold_low -= volatility_boost * 0.5
            
            # ğŸš€ ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆåˆ¤å®šï¼ˆæœ€å„ªå…ˆï¼‰
            if (current_trend > trend_threshold_high and current_efficiency > efficiency_threshold_high):
                market_regime[i] = 2  # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ
            
            # ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šï¼ˆä¸­å„ªå…ˆï¼‰
            elif (current_trend > trend_threshold_low and current_efficiency > efficiency_threshold_low):
                market_regime[i] = 1  # ãƒˆãƒ¬ãƒ³ãƒ‰
                
                # é€£ç¶šæ€§ãƒã‚§ãƒƒã‚¯ï¼šå‰ã®æœŸé–“ã‚‚ãƒˆãƒ¬ãƒ³ãƒ‰ãªã‚‰ç¶™ç¶šã—ã‚„ã™ãã™ã‚‹
                if i > 0 and market_regime[i-1] == 1:
                    # ç¶™ç¶šãƒˆãƒ¬ãƒ³ãƒ‰ã®å ´åˆã€ã‚„ã‚„ç·©ã„æ¡ä»¶ã§ã‚‚ç¶­æŒ
                    if current_trend > trend_threshold_low * 0.85:
                        market_regime[i] = 1
            
            # ğŸ“Š ãƒ¬ãƒ³ã‚¸åˆ¤å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
            else:
                market_regime[i] = 0  # ãƒ¬ãƒ³ã‚¸
                
                # ãƒ¬ãƒ³ã‚¸ç¶™ç¶šã®å®‰å®šåŒ–ï¼šæ€¥æ¿€ãªå¤‰åŒ–ã‚’æŠ‘åˆ¶
                if i > 2:
                    recent_regimes = market_regime[i-3:i]
                    if np.all(recent_regimes == 0):  # ç›´è¿‘3æœŸé–“ãŒãƒ¬ãƒ³ã‚¸
                        # ãƒ¬ãƒ³ã‚¸ç¶™ç¶šä¸­ã¯ã€ã‚ˆã‚Šå³ã—ã„æ¡ä»¶ã§ã®ã¿ãƒˆãƒ¬ãƒ³ãƒ‰ã«ç§»è¡Œ
                        if not (current_trend > trend_threshold_low * 1.2 and current_efficiency > efficiency_threshold_low * 1.1):
                            market_regime[i] = 0
        
        # å¾Œå‡¦ç†ï¼šãƒã‚¤ã‚ºé™¤å»ã¨ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
        market_regime = self._smooth_regime_transitions(market_regime)
        
        return market_regime
    
    def _smooth_regime_transitions(self, market_regime: np.ndarray) -> np.ndarray:
        """
        ğŸŒŠ ãƒ¬ã‚¸ãƒ¼ãƒ é·ç§»ã®ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
        çŸ­æœŸé–“ã®ãƒã‚¤ã‚ºã‚’é™¤å»ã—ã€å®‰å®šã—ãŸãƒ¬ã‚¸ãƒ¼ãƒ åˆ¤å®šã‚’å®Ÿç¾
        """
        n = len(market_regime)
        smoothed = market_regime.copy()
        
        # çŸ­æœŸé–“ã®å­¤ç«‹ã—ãŸãƒ¬ã‚¸ãƒ¼ãƒ ã‚’ä¿®æ­£
        for i in range(2, n-2):
            current = market_regime[i]
            prev2 = market_regime[i-2]
            prev1 = market_regime[i-1]
            next1 = market_regime[i+1]
            next2 = market_regime[i+2]
            
            # å­¤ç«‹ç‚¹ã®ä¿®æ­£ï¼ˆå‰å¾ŒãŒåŒã˜ãƒ¬ã‚¸ãƒ¼ãƒ ã®å ´åˆï¼‰
            if prev1 == next1 and prev1 != current:
                if abs(prev2 - prev1) <= 1 and abs(next1 - next2) <= 1:
                    smoothed[i] = prev1
            
            # çŸ­æœŸé–“ã®æŒ¯å‹•ã‚’æŠ‘åˆ¶
            if i >= 3 and i < n-1:
                window = market_regime[i-3:i+2]
                unique_values, counts = np.unique(window, return_counts=True)
                if len(unique_values) > 1:
                    # æœ€é »å€¤ã§ç½®æ›ï¼ˆãŸã ã—ç¾åœ¨å€¤ã¨ã®å·®ãŒ1ä»¥ä¸‹ã®å ´åˆã®ã¿ï¼‰
                    most_frequent = unique_values[np.argmax(counts)]
                    if abs(current - most_frequent) <= 1:
                        smoothed[i] = most_frequent
        
        return smoothed

    def _calculate_quantum_entanglement(self, amplitude: np.ndarray, phase: np.ndarray) -> np.ndarray:
        """é‡å­ã‚‚ã¤ã‚Œè¨ˆç®—"""
        n = len(amplitude)
        entanglement = np.zeros(n)
        
        for i in range(5, n):
            # æŒ¯å¹…ã¨ä½ç›¸ã®ç›¸é–¢ã«ã‚ˆã‚‹é‡å­ã‚‚ã¤ã‚Œè¨ˆç®—
            amp_segment = amplitude[i-5:i]
            phase_segment = phase[i-5:i]
            
            if len(amp_segment) > 1 and len(phase_segment) > 1:
                correlation = np.corrcoef(amp_segment, phase_segment)[0, 1]
                entanglement[i] = abs(correlation) if not np.isnan(correlation) else 0.0
        
        # å‰æ–¹åŸ‹ã‚
        for i in range(5):
            entanglement[i] = entanglement[5] if n > 5 else 0.0
        
        return entanglement

    def _calculate_superposition_state(self, coherence: np.ndarray, entanglement: np.ndarray) -> np.ndarray:
        """é‡ã­åˆã‚ã›çŠ¶æ…‹è¨ˆç®—"""
        return (coherence + entanglement) / 2.0

    def _calculate_adaptation_confidence(self, coherence: np.ndarray, trend_strength: np.ndarray, 
                                       efficiency: np.ndarray) -> np.ndarray:
        """é©å¿œä¿¡é ¼åº¦è¨ˆç®—"""
        return (coherence * 0.4 + trend_strength * 0.3 + efficiency * 0.3)

    def _calculate_trend_persistence(self, trend_strength: np.ndarray, window: int) -> np.ndarray:
        """ãƒˆãƒ¬ãƒ³ãƒ‰æŒç¶šæ€§è¨ˆç®—"""
        n = len(trend_strength)
        persistence = np.zeros(n)
        
        for i in range(window, n):
            segment = trend_strength[i-window:i]
            # æ¨™æº–åå·®ãŒå°ã•ã„ã»ã©æŒç¶šæ€§ãŒé«˜ã„
            std_val = np.std(segment)
            persistence[i] = 1.0 / (1.0 + std_val * 5.0)
        
        # å‰æ–¹åŸ‹ã‚
        for i in range(window):
            persistence[i] = persistence[window] if n > window else 0.5
        
        return persistence

    def _generate_trend_signals(self, prices: np.ndarray, middle_line: np.ndarray, 
                               trend_strength: np.ndarray) -> np.ndarray:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ"""
        n = len(prices)
        signals = np.zeros(n)
        
        for i in range(1, n):
            if prices[i] > middle_line[i] and trend_strength[i] > 0.6:
                signals[i] = 1.0  # ä¸Šæ˜‡ã‚·ã‚°ãƒŠãƒ«
            elif prices[i] < middle_line[i] and trend_strength[i] > 0.6:
                signals[i] = -1.0  # ä¸‹é™ã‚·ã‚°ãƒŠãƒ«
            # else: 0 (ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«)
        
        return signals

    def _determine_current_regime(self, market_regime: np.ndarray) -> str:
        """ç¾åœ¨ã®ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¤å®š"""
        if len(market_regime) == 0:
            return 'range'
        
        current_value = market_regime[-1]
        if current_value == 0:
            return 'range'
        elif current_value == 1:
            return 'trend'
        else:
            return 'breakout'

    def _determine_adaptation_mode(self, multiplier: float) -> str:
        """é©å¿œãƒ¢ãƒ¼ãƒ‰åˆ¤å®š"""
        if multiplier <= 2.0:
            return 'trend_following'
        elif multiplier >= 5.0:
            return 'range_trading'
        else:
            return 'transitional'

    def _get_data_hash(self, data: Union[pd.DataFrame, np.ndarray]) -> str:
        """ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥è¨ˆç®—"""
        try:
            if isinstance(data, pd.DataFrame):
                data_str = f"{data.shape}_{data.iloc[0].sum() if len(data) > 0 else 0}_{data.iloc[-1].sum() if len(data) > 0 else 0}"
            else:
                data_str = f"{data.shape}_{data[0] if len(data) > 0 else 0}_{data[-1] if len(data) > 0 else 0}"
            
            param_str = f"{self.analysis_period}_{self.min_multiplier}_{self.max_multiplier}_{self.src_type}"
            return f"{hash(data_str)}_{param_str}"
        except Exception:
            return f"fallback_{hash(str(data))}_{self.analysis_period}"

    # çµæœå–å¾—ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def get_result(self) -> Optional[QuantumSupremeBreakoutChannelResult]:
        """å®Œå…¨ãªçµæœã‚’å–å¾—"""
        return self._result

    def get_upper_channel(self) -> Optional[np.ndarray]:
        """ä¸Šä½ãƒãƒ£ãƒãƒ«ã‚’å–å¾—"""
        if self._result is not None:
            return self._result.upper_channel.copy()
        return None

    def get_middle_line(self) -> Optional[np.ndarray]:
        """ãƒŸãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å–å¾—"""
        if self._result is not None:
            return self._result.middle_line.copy()
        return None

    def get_lower_channel(self) -> Optional[np.ndarray]:
        """ä¸‹ä½ãƒãƒ£ãƒãƒ«ã‚’å–å¾—"""
        if self._result is not None:
            return self._result.lower_channel.copy()
        return None

    def get_channels(self) -> Optional[Tuple[np.ndarray, np.ndarray, np.ndarray]]:
        """å…¨ãƒãƒ£ãƒãƒ«ï¼ˆä¸Šä½ã€ä¸­å¤®ã€ä¸‹ä½ï¼‰ã‚’å–å¾—"""
        if self._result is not None:
            return (
                self._result.upper_channel.copy(),
                self._result.middle_line.copy(),
                self._result.lower_channel.copy()
            )
        return None

    def get_dynamic_multiplier(self) -> Optional[np.ndarray]:
        """å‹•çš„ä¹—æ•°ã‚’å–å¾—"""
        if self._result is not None:
            return self._result.dynamic_multiplier.copy()
        return None

    def get_market_regime(self) -> Optional[np.ndarray]:
        """å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ ã‚’å–å¾—"""
        if self._result is not None:
            return self._result.market_regime.copy()
        return None

    def get_breakout_signals(self) -> Optional[np.ndarray]:
        """ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã‚·ã‚°ãƒŠãƒ«ã‚’å–å¾—"""
        if self._result is not None:
            return self._result.breakout_signals.copy()
        return None

    def get_breakout_probability(self) -> Optional[np.ndarray]:
        """ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºç‡ã‚’å–å¾—"""
        if self._result is not None:
            return self._result.breakout_probability.copy()
        return None

    def get_quantum_metrics(self) -> Optional[Dict]:
        """é‡å­ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—"""
        if self._result is not None:
            return {
                'quantum_coherence': self._result.quantum_coherence.copy(),
                'quantum_entanglement': self._result.quantum_entanglement.copy(),
                'superposition_state': self._result.superposition_state.copy()
            }
        return None

    def get_current_status(self) -> Dict:
        """ç¾åœ¨ã®çŠ¶æ…‹æƒ…å ±ã‚’å–å¾—"""
        if self._result is not None:
            return {
                'current_regime': self._result.current_regime,
                'current_trend_strength': self._result.current_trend_strength,
                'current_breakout_probability': self._result.current_breakout_probability,
                'current_adaptation_mode': self._result.current_adaptation_mode,
                'latest_multiplier': float(self._result.dynamic_multiplier[-1]) if len(self._result.dynamic_multiplier) > 0 else 3.5
            }
        return {
            'current_regime': 'unknown',
            'current_trend_strength': 0.0,
            'current_breakout_probability': 0.0,
            'current_adaptation_mode': 'unknown',
            'latest_multiplier': 3.5
        }

    def reset(self) -> None:
        """ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        super().reset()
        self._result = None
        self._cache = {}
        self._previous_multiplier = 4.75
        
        # ã‚µãƒ–ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®ãƒªã‚»ãƒƒãƒˆ
        if hasattr(self, 'quantum_hyper_ma'):
            self.quantum_hyper_ma.reset()
        if hasattr(self, 'chop_trend'):
            self.chop_trend.reset()
        if hasattr(self, 'ultimate_volatility'):
            self.ultimate_volatility.reset()
        if hasattr(self, 'efficiency_ratio'):
            self.efficiency_ratio.reset()
        if hasattr(self, 'cycle_detector'):
            self.cycle_detector.reset()

    def __str__(self) -> str:
        """æ–‡å­—åˆ—è¡¨ç¾"""
        return f"QuantumSupremeBreakoutChannel(period={self.analysis_period}, mult_range={self.min_multiplier}-{self.max_multiplier})"

    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    @staticmethod
    @njit(fastmath=True, cache=True)
    def _calculate_ema_numba(prices: np.ndarray, period: int) -> np.ndarray:
        """EMAè¨ˆç®—ï¼ˆNumbaæœ€é©åŒ–ï¼‰"""
        n = len(prices)
        ema = np.zeros(n)
        alpha = 2.0 / (period + 1.0)
        
        ema[0] = prices[0]
        for i in range(1, n):
            ema[i] = alpha * prices[i] + (1.0 - alpha) * ema[i-1]
        
        return ema

    def _calculate_ema(self, prices: np.ndarray, period: int) -> np.ndarray:
        """EMAè¨ˆç®—"""
        return self._calculate_ema_numba(prices, period)

    def _calculate_atr(self, data: Union[pd.DataFrame, np.ndarray], period: int = 14) -> np.ndarray:
        """ATRè¨ˆç®—"""
        if isinstance(data, pd.DataFrame):
            high = data['high'].values
            low = data['low'].values
            close = data['close'].values
        else:
            # NumPyé…åˆ—ã®å ´åˆã€[high, low, close]ã¨ä»®å®š
            if data.ndim == 2 and data.shape[1] >= 3:
                high = data[:, 1]
                low = data[:, 2]
                close = data[:, 3]
            else:
                # 1æ¬¡å…ƒã®å ´åˆã¯ã‚¯ãƒ­ãƒ¼ã‚ºä¾¡æ ¼ã¨ã—ã¦æ‰±ã„ã€ç°¡æ˜“ATR
                close = data
                return np.full(len(close), np.std(np.diff(close)) if len(close) > 1 else 0.1)

        n = len(close)
        tr = np.zeros(n)
        atr = np.zeros(n)
        
        for i in range(1, n):
            tr[i] = max(
                high[i] - low[i],
                abs(high[i] - close[i-1]),
                abs(low[i] - close[i-1])
            )
        
        tr[0] = high[0] - low[0] if high[0] > low[0] else 0.1
        
        # ATRè¨ˆç®—ï¼ˆWilder's smoothingï¼‰
        atr[0] = tr[0]
        alpha = 1.0 / period
        for i in range(1, n):
            atr[i] = alpha * tr[i] + (1.0 - alpha) * atr[i-1]
        
        return atr

    def _calculate_simple_efficiency(self, prices: np.ndarray, period: int) -> np.ndarray:
        """ã‚·ãƒ³ãƒ—ãƒ«åŠ¹ç‡æ¯”è¨ˆç®—"""
        n = len(prices)
        efficiency = np.zeros(n)
        
        for i in range(period, n):
            price_change = abs(prices[i] - prices[i-period])
            volatility = np.sum(np.abs(np.diff(prices[i-period:i])))
            
            if volatility > 0:
                efficiency[i] = price_change / volatility
            else:
                efficiency[i] = 0.0
        
        # å‰æ–¹åŸ‹ã‚
        for i in range(period):
            efficiency[i] = efficiency[period] if n > period else 0.0
        
        return efficiency

    def _calculate_volatility_persistence(self, volatility: np.ndarray, window: int) -> np.ndarray:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æŒç¶šæ€§è¨ˆç®—"""
        n = len(volatility)
        persistence = np.zeros(n)
        
        for i in range(window, n):
            vol_segment = volatility[i-window:i]
            if len(vol_segment) > 1:
                # è‡ªå·±ç›¸é–¢ã«ã‚ˆã‚‹æŒç¶šæ€§æ¸¬å®š
                vol_normalized = (vol_segment - np.mean(vol_segment)) / (np.std(vol_segment) + 1e-10)
                autocorr = np.corrcoef(vol_normalized[:-1], vol_normalized[1:])[0, 1]
                persistence[i] = max(0.0, autocorr) if not np.isnan(autocorr) else 0.0
        
        # å‰æ–¹åŸ‹ã‚
        for i in range(window):
            persistence[i] = persistence[window] if n > window else 0.0
        
        return persistence

    def _calculate_regime_change_probability(self, trend_strength: np.ndarray, efficiency: np.ndarray, 
                                           volatility_persistence: np.ndarray, window: int) -> np.ndarray:
        """ãƒ¬ã‚¸ãƒ¼ãƒ å¤‰åŒ–ç¢ºç‡è¨ˆç®—"""
        n = len(trend_strength)
        regime_change_prob = np.zeros(n)
        
        for i in range(window, n):
            # æœ€è¿‘ã®æŒ‡æ¨™å¤‰åŒ–ã‚’åˆ†æ
            trend_change = np.std(trend_strength[i-window:i])
            efficiency_change = np.std(efficiency[i-window:i])
            vol_persistence_change = np.std(volatility_persistence[i-window:i])
            
            # å¤‰åŒ–ã®å¤§ãã•ã‹ã‚‰ç¢ºç‡ã‚’è¨ˆç®—
            total_change = trend_change + efficiency_change + vol_persistence_change
            regime_change_prob[i] = min(0.9, total_change * 2.0)
        
        # å‰æ–¹åŸ‹ã‚
        for i in range(window):
            regime_change_prob[i] = regime_change_prob[window] if n > window else 0.1
        
        return regime_change_prob

    def _calculate_trend_bias(self, trend_signals: np.ndarray) -> np.ndarray:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ãƒã‚¤ã‚¢ã‚¹è¨ˆç®—"""
        return trend_signals.copy()

    def _calculate_asymmetry_factors(self, trend_bias: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """éå¯¾ç§°æ€§ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼è¨ˆç®—"""
        n = len(trend_bias)
        asymmetry_up = np.ones(n)
        asymmetry_down = np.ones(n)
        
        # åŸºæœ¬çš„ã«ã¯å¯¾ç§°ãƒãƒ£ãƒãƒ«ã‚’ç¶­æŒ
        # éå¯¾ç§°æ€§èª¿æ•´ã¯è»½å¾®ã«ã¨ã©ã‚ã‚‹
        for i in range(n):
            if trend_bias[i] > 0:  # ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰
                asymmetry_up[i] = 1.05   # ä¸Šä½ãƒãƒ£ãƒãƒ«ã‚’ã‚ãšã‹ã«åºƒã’ã‚‹
                asymmetry_down[i] = 0.95 # ä¸‹ä½ãƒãƒ£ãƒãƒ«ã‚’ã‚ãšã‹ã«ç‹­ã‚ã‚‹
            elif trend_bias[i] < 0:  # ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰
                asymmetry_up[i] = 0.95   # ä¸Šä½ãƒãƒ£ãƒãƒ«ã‚’ã‚ãšã‹ã«ç‹­ã‚ã‚‹
                asymmetry_down[i] = 1.05 # ä¸‹ä½ãƒãƒ£ãƒãƒ«ã‚’ã‚ãšã‹ã«åºƒã’ã‚‹
            # else: å¯¾ç§°ã®ã¾ã¾ (1.0, 1.0)
        
        return asymmetry_up, asymmetry_down 
