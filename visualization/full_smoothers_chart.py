#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ãƒ•ãƒ«ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆ

@indicators/smoother/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã™ã¹ã¦ã®ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ä½¿ç”¨:
- UltimateSmoother: ã‚¸ãƒ§ãƒ³ãƒ»ã‚¨ãƒ¼ãƒ©ãƒ¼ã‚ºã®ã‚¢ãƒ«ãƒ†ã‚£ãƒ¡ãƒƒãƒˆã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼
- SuperSmoother: 2æ¥µã¨3æ¥µã®ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼
- FRAMA: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«é©å¿œç§»å‹•å¹³å‡
- UnscentedKalmanFilter: ç„¡é¦™æ–™ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼  
- AdaptiveKalman: é©å¿œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼

å®Ÿéš›ã®ã‚¤ãƒ³ãƒ‡ã‚£ã‚±ãƒ¼ã‚¿ãƒ¼ã‚¯ãƒ©ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€
ç°¡æ˜“å®Ÿè£…ã‚ˆã‚Šã‚‚æ­£ç¢ºãªæ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨é©åˆ‡ãªãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºã‚’å®Ÿç¾ã€‚
"""

import sys
import os
import traceback
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Union, Tuple

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.gridspec import GridSpec
import yaml

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ãƒ‡ã‚£ã‚±ãƒ¼ã‚¿ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from indicators.smoother.ultimate_smoother import UltimateSmoother
    from indicators.smoother.super_smoother import SuperSmoother
    from indicators.smoother.frama import FRAMA
    from indicators.smoother.unscented_kalman_filter import UnscentedKalmanFilter
    from indicators.smoother.adaptive_kalman import AdaptiveKalman
    print("âœ… ã™ã¹ã¦ã®ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ãƒ‡ã‚£ã‚±ãƒ¼ã‚¿ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†")
except ImportError as e:
    print(f"âŒ ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ãƒ‡ã‚£ã‚±ãƒ¼ã‚¿ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åˆ©ç”¨å¯èƒ½ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã¿ä½¿ç”¨")
    UltimateSmoother = None
    SuperSmoother = None
    FRAMA = None
    UnscentedKalmanFilter = None
    AdaptiveKalman = None


def load_config() -> Dict:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    config_path = project_root / "config.yaml"
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        print("Warning: config.yaml not found. Using default settings.")
        return {
            'binance_data': {
                'symbol': 'SOL',
                'timeframe': '4h',
                'start': '2023-01-01',
                'end': '2024-12-31'
            }
        }


def generate_sample_data(num_points: int = 1000) -> pd.DataFrame:
    """ãƒªã‚¢ãƒ«ãªå¸‚å ´ãƒ‡ãƒ¼ã‚¿é¢¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    np.random.seed(42)
    
    # æ—¥ä»˜ç¯„å›²ã‚’ç”Ÿæˆ
    dates = pd.date_range(start='2023-01-01', periods=num_points, freq='4H')
    
    # åŸºæœ¬ä¾¡æ ¼ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆå¤šæ§˜ãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    trend = np.linspace(100, 180, num_points)
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯
    random_walk = np.cumsum(np.random.randn(num_points) * 0.5)
    
    # è¤‡æ•°ã®å‘¨æœŸçš„å¤‰å‹•
    cycle1 = 8 * np.sin(2 * np.pi * np.arange(num_points) / 50)  # çŸ­æœŸã‚µã‚¤ã‚¯ãƒ«
    cycle2 = 5 * np.sin(2 * np.pi * np.arange(num_points) / 100) # ä¸­æœŸã‚µã‚¤ã‚¯ãƒ«
    cycle3 = 3 * np.sin(2 * np.pi * np.arange(num_points) / 200) # é•·æœŸã‚µã‚¤ã‚¯ãƒ«
    
    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼
    volatility = 1 + 0.5 * np.sin(2 * np.pi * np.arange(num_points) / 150)
    noise = np.random.randn(num_points) * volatility
    
    # ä¾¡æ ¼ã‚·ãƒªãƒ¼ã‚ºã®åˆæˆ
    close_prices = trend + random_walk + cycle1 + cycle2 + cycle3 + noise
    
    # OHLCç”Ÿæˆ
    high_offset = np.abs(np.random.randn(num_points)) * volatility
    low_offset = np.abs(np.random.randn(num_points)) * volatility
    open_offset = np.random.randn(num_points) * 0.5
    
    data = pd.DataFrame({
        'timestamp': dates,
        'open': close_prices + open_offset,
        'high': close_prices + high_offset,
        'low': close_prices - low_offset,
        'close': close_prices,
        'volume': np.random.lognormal(8, 1, num_points)
    })
    
    # ä¾¡æ ¼ã®æ•´åˆæ€§ã‚’ä¿ã¤
    data['high'] = np.maximum.reduce([data['open'], data['high'], data['close']])
    data['low'] = np.minimum.reduce([data['open'], data['low'], data['close']])
    
    return data


def calculate_all_smoothers_full(data: pd.DataFrame) -> Dict[str, np.ndarray]:
    """ã™ã¹ã¦ã®ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚’è¨ˆç®—ï¼ˆå®Ÿéš›ã®ã‚¤ãƒ³ãƒ‡ã‚£ã‚±ãƒ¼ã‚¿ãƒ¼ä½¿ç”¨ï¼‰"""
    results = {}
    
    # å…ƒã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
    results['Original'] = data['close'].values
    
    print("ğŸ“Š ãƒ•ãƒ«ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼è¨ˆç®—é–‹å§‹...")
    
    # Ultimate Smoother
    if UltimateSmoother is not None:
        try:
            print("ğŸ”„ Ultimate Smoother è¨ˆç®—ä¸­...")
            ultimate_smoother = UltimateSmoother(period=20.0, src_type='close')
            us_result = ultimate_smoother.calculate(data)
            results['UltimateSmoother'] = us_result.values
            print("âœ… Ultimate Smoother å®Œäº†")
        except Exception as e:
            print(f"âŒ Ultimate Smoother å¤±æ•—: {e}")
            results['UltimateSmoother'] = data['close'].values.copy()
    else:
        print("â­ï¸ Ultimate Smoother ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæœªã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰")
    
    # Super Smoother (2-pole)
    if SuperSmoother is not None:
        try:
            print("ğŸ”„ Super Smoother (2æ¥µ) è¨ˆç®—ä¸­...")
            super_smoother_2 = SuperSmoother(length=15, num_poles=2, src_type='close')
            ss2_result = super_smoother_2.calculate(data)
            results['SuperSmoother_2pole'] = ss2_result.values
            print("âœ… Super Smoother (2æ¥µ) å®Œäº†")
        except Exception as e:
            print(f"âŒ Super Smoother (2æ¥µ) å¤±æ•—: {e}")
            results['SuperSmoother_2pole'] = data['close'].values.copy()
    else:
        print("â­ï¸ Super Smoother ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæœªã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰")
    
    # Super Smoother (3-pole)
    if SuperSmoother is not None:
        try:
            print("ğŸ”„ Super Smoother (3æ¥µ) è¨ˆç®—ä¸­...")
            super_smoother_3 = SuperSmoother(length=15, num_poles=3, src_type='close')
            ss3_result = super_smoother_3.calculate(data)
            results['SuperSmoother_3pole'] = ss3_result.values
            print("âœ… Super Smoother (3æ¥µ) å®Œäº†")
        except Exception as e:
            print(f"âŒ Super Smoother (3æ¥µ) å¤±æ•—: {e}")
            results['SuperSmoother_3pole'] = data['close'].values.copy()
    else:
        print("â­ï¸ Super Smoother (3æ¥µ) ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæœªã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰")
    
    # FRAMA
    if FRAMA is not None:
        try:
            print("ğŸ”„ FRAMA è¨ˆç®—ä¸­...")
            frama = FRAMA(period=16, fc=1, sc=198, src_type='close')
            frama_result = frama.calculate(data)
            results['FRAMA'] = frama_result.values
            print("âœ… FRAMA å®Œäº†")
        except Exception as e:
            print(f"âŒ FRAMA å¤±æ•—: {e}")
            results['FRAMA'] = data['close'].values.copy()
    else:
        print("â­ï¸ FRAMA ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæœªã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰")
    
    # Adaptive Kalman
    if AdaptiveKalman is not None:
        try:
            print("ğŸ”„ Adaptive Kalman è¨ˆç®—ä¸­...")
            adaptive_kalman = AdaptiveKalman(process_noise=1e-5, src_type='close')
            ak_result = adaptive_kalman.calculate(data)
            results['AdaptiveKalman'] = ak_result.filtered_signal
            print("âœ… Adaptive Kalman å®Œäº†")
        except Exception as e:
            print(f"âŒ Adaptive Kalman å¤±æ•—: {e}")
            results['AdaptiveKalman'] = data['close'].values.copy()
    else:
        print("â­ï¸ Adaptive Kalman ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæœªã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰")
    
    # Unscented Kalman Filter
    if UnscentedKalmanFilter is not None:
        try:
            print("ğŸ”„ Unscented Kalman Filter è¨ˆç®—ä¸­...")
            ukf = UnscentedKalmanFilter(
                alpha=0.1,  # ä¿®æ­£ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ 
                beta=2.0,
                kappa=0.0,
                process_noise_scale=0.01,  # ä¿®æ­£ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                src_type='close'
            )
            ukf_result = ukf.calculate(data)
            results['UKF'] = ukf_result.filtered_values
            print("âœ… Unscented Kalman Filter å®Œäº†")
        except Exception as e:
            print(f"âŒ Unscented Kalman Filter å¤±æ•—: {e}")
            traceback.print_exc()
            results['UKF'] = data['close'].values.copy()
    else:
        print("â­ï¸ UKF ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæœªã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰")
    
    return results


def create_full_comparison_chart(data: pd.DataFrame, smoother_results: Dict[str, np.ndarray], config: Dict):
    """ãƒ•ãƒ«æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ"""
    print("\nğŸ¨ ãƒ•ãƒ«ãƒãƒ£ãƒ¼ãƒˆä½œæˆä¸­...")
    
    symbol = config.get('binance_data', {}).get('symbol', 'SOL')
    timeframe = config.get('binance_data', {}).get('timeframe', '4h')
    
    # æ—¥ä»˜ã®æº–å‚™
    if 'timestamp' in data.columns:
        dates = pd.to_datetime(data['timestamp'])
    else:
        dates = data.index
    
    # ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆ
    colors = {
        'Original': '#333333',
        'UltimateSmoother': '#FF6B6B',
        'SuperSmoother_2pole': '#4ECDC4', 
        'SuperSmoother_3pole': '#45B7D1',
        'FRAMA': '#96CEB4',
        'UKF': '#FFEAA7',
        'AdaptiveKalman': '#DDA0DD'
    }
    
    # ãƒ•ã‚£ã‚®ãƒ¥ã‚¢è¨­å®š
    fig = plt.figure(figsize=(18, 14))
    gs = GridSpec(5, 2, height_ratios=[3, 1, 1, 1, 1], hspace=0.35, wspace=0.3)
    
    # ãƒ‡ãƒ¼ã‚¿ç¯„å›²ã®åˆ¶é™
    display_range = min(500, len(data))
    start_idx = max(0, len(data) - display_range)
    dates_display = dates[start_idx:]
    
    # ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒ¼ãƒˆ
    ax_main = fig.add_subplot(gs[0, :])
    
    # ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆ
    for name, values in smoother_results.items():
        if len(values) > 0:
            values_display = values[start_idx:]
            line_width = 2.5 if name == 'Original' else 1.8
            alpha = 0.9 if name == 'Original' else 0.75
            
            ax_main.plot(dates_display, values_display, 
                        label=name, color=colors.get(name, '#888888'),
                        linewidth=line_width, alpha=alpha)
    
    ax_main.set_title(f'å…¨ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ãƒ‡ã‚£ã‚±ãƒ¼ã‚¿ãƒ¼æ¯”è¼ƒ (å®Ÿè£…ç‰ˆ) - {symbol} {timeframe}', 
                     fontsize=16, fontweight='bold')
    ax_main.set_ylabel('ä¾¡æ ¼', fontsize=12)
    ax_main.grid(True, alpha=0.3)
    ax_main.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    # å·®åˆ†ãƒãƒ£ãƒ¼ãƒˆ
    ax_diff = fig.add_subplot(gs[1, :])
    original_values = smoother_results['Original'][start_idx:]
    
    for name, values in smoother_results.items():
        if name != 'Original' and len(values) > 0:
            values_display = values[start_idx:]
            diff = values_display - original_values
            ax_diff.plot(dates_display, diff, 
                        label=f'{name} - Original', 
                        color=colors.get(name, '#888888'),
                        linewidth=1.5, alpha=0.75)
    
    ax_diff.set_title('å…ƒä¾¡æ ¼ã¨ã®å·®åˆ†', fontsize=12, fontweight='bold')
    ax_diff.set_ylabel('å·®åˆ†', fontsize=10)
    ax_diff.grid(True, alpha=0.3)
    ax_diff.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax_diff.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    # ç§»å‹•å¹³å‡ä¹–é›¢ç‡ãƒãƒ£ãƒ¼ãƒˆ
    ax_dev = fig.add_subplot(gs[2, :])
    ma_period = 20
    original_ma = np.convolve(original_values, np.ones(ma_period)/ma_period, mode='same')
    
    for name, values in smoother_results.items():
        if len(values) > 0:
            values_display = values[start_idx:]
            deviation = ((values_display - original_ma) / original_ma) * 100
            ax_dev.plot(dates_display, deviation, 
                       label=f'{name}', 
                       color=colors.get(name, '#888888'),
                       linewidth=1.5, alpha=0.75)
    
    ax_dev.set_title(f'ç§»å‹•å¹³å‡(MA{ma_period})ã‹ã‚‰ã®ä¹–é›¢ç‡ (%)', fontsize=12, fontweight='bold')
    ax_dev.set_ylabel('ä¹–é›¢ç‡ (%)', fontsize=10)
    ax_dev.grid(True, alpha=0.3)
    ax_dev.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax_dev.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒãƒ£ãƒ¼ãƒˆ
    ax_vol = fig.add_subplot(gs[3, :])
    
    for name, values in smoother_results.items():
        if len(values) > 0:
            values_display = values[start_idx:]
            # ãƒ­ãƒ¼ãƒªãƒ³ã‚°æ¨™æº–åå·®ã§ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’è¨ˆç®—
            window = 20
            volatility = pd.Series(values_display).rolling(window=window, min_periods=1).std()
            ax_vol.plot(dates_display, volatility, 
                       label=f'{name}', 
                       color=colors.get(name, '#888888'),
                       linewidth=1.5, alpha=0.75)
    
    ax_vol.set_title(f'ãƒ­ãƒ¼ãƒªãƒ³ã‚°ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ (çª“{window})', fontsize=12, fontweight='bold')
    ax_vol.set_ylabel('ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£', fontsize=10)
    ax_vol.grid(True, alpha=0.3)
    ax_vol.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    # ç›¸é–¢ä¿‚æ•°ãƒãƒ£ãƒ¼ãƒˆ
    ax_corr = fig.add_subplot(gs[4, :])
    
    # ãƒ­ãƒ¼ãƒªãƒ³ã‚°ç›¸é–¢ã‚’è¨ˆç®—
    correlation_window = 50
    for name, values in smoother_results.items():
        if name != 'Original' and len(values) > 0:
            values_display = values[start_idx:]
            # ãƒ­ãƒ¼ãƒªãƒ³ã‚°ç›¸é–¢ã‚’è¨ˆç®—
            rolling_corr = []
            for i in range(len(values_display)):
                start = max(0, i - correlation_window + 1)
                end = i + 1
                if end - start >= 10:  # æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°
                    corr = np.corrcoef(original_values[start:end], values_display[start:end])[0, 1]
                    rolling_corr.append(corr if not np.isnan(corr) else 0)
                else:
                    rolling_corr.append(0)
            
            ax_corr.plot(dates_display, rolling_corr, 
                        label=f'{name}', 
                        color=colors.get(name, '#888888'),
                        linewidth=1.5, alpha=0.75)
    
    ax_corr.set_title(f'ãƒ­ãƒ¼ãƒªãƒ³ã‚°ç›¸é–¢ä¿‚æ•° (çª“{correlation_window})', fontsize=12, fontweight='bold')
    ax_corr.set_ylabel('ç›¸é–¢ä¿‚æ•°', fontsize=10)
    ax_corr.set_xlabel('æ—¥æ™‚', fontsize=10)
    ax_corr.grid(True, alpha=0.3)
    ax_corr.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax_corr.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    ax_corr.axhline(y=1, color='green', linestyle='--', alpha=0.3)
    ax_corr.set_ylim(-0.2, 1.1)
    
    # æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¨­å®š
    for ax in [ax_main, ax_diff, ax_dev, ax_vol, ax_corr]:
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))
        ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=3))
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    fig.suptitle(f'å…¨ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ãƒ‡ã‚£ã‚±ãƒ¼ã‚¿ãƒ¼æ¯”è¼ƒåˆ†æ (å®Ÿè£…ç‰ˆ)\\n{symbol} {timeframe} - æœ€æ–° {display_range} ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ', 
                fontsize=20, fontweight='bold', y=0.98)
    
    plt.tight_layout()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"full_smoothers_comparison_{symbol}_{timeframe}_{timestamp}.png"
    filepath = project_root / filename
    
    try:
        plt.savefig(filepath, dpi=300, bbox_inches='tight', 
                   facecolor='white', edgecolor='none')
        print(f"ğŸ“ ãƒ•ãƒ«ãƒãƒ£ãƒ¼ãƒˆä¿å­˜å®Œäº†: {filepath}")
        
    except Exception as e:
        print(f"âš ï¸ ãƒ•ãƒ«ãƒãƒ£ãƒ¼ãƒˆä¿å­˜å¤±æ•—: {e}")
    
    plt.show()


def calculate_full_smoother_statistics(smoother_results: Dict[str, np.ndarray]) -> Dict:
    """ãƒ•ãƒ«ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼çµ±è¨ˆè¨ˆç®—"""
    stats = {}
    original = smoother_results.get('Original', np.array([]))
    
    if len(original) == 0:
        return stats
    
    for name, values in smoother_results.items():
        if name == 'Original' or len(values) == 0:
            continue
            
        # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã®ã¿
        valid_mask = ~np.isnan(values) & ~np.isnan(original)
        if not np.any(valid_mask):
            continue
            
        valid_values = values[valid_mask]
        valid_original = original[valid_mask]
        
        if len(valid_values) < 10:  # æœ€å°ãƒ‡ãƒ¼ã‚¿æ•°ãƒã‚§ãƒƒã‚¯
            continue
        
        # çµ±è¨ˆè¨ˆç®—
        mae = np.mean(np.abs(valid_values - valid_original))
        rmse = np.sqrt(np.mean((valid_values - valid_original) ** 2))
        correlation = np.corrcoef(valid_values, valid_original)[0, 1]
        
        # ã‚¹ãƒ ãƒ¼ã‚ºãƒã‚¹ï¼ˆå¤‰åŒ–ç‡ã®æ¨™æº–åå·®ï¼‰
        smoothness = np.std(np.diff(valid_values))
        
        # ãƒ©ã‚°è¨ˆç®—ï¼ˆæœ€å¤§ç›¸é–¢ã§ã®ãƒ©ã‚°ï¼‰
        lag = 0
        if len(valid_values) > 50:
            max_lag = min(20, len(valid_values) // 4)
            cross_corr = np.correlate(valid_values, valid_original, mode='full')
            lags = np.arange(-max_lag, max_lag + 1)
            if len(lags) <= len(cross_corr):
                mid = len(cross_corr) // 2
                start = mid - max_lag
                end = mid + max_lag + 1
                lag_corr = cross_corr[start:end]
                lag = lags[np.argmax(lag_corr)]
        
        # ä¿¡å·å¯¾é›‘éŸ³æ¯”
        signal_power = np.var(valid_values)
        noise_power = np.var(valid_values - valid_original)
        snr = signal_power / (noise_power + 1e-10)
        
        stats[name] = {
            'MAE': mae,
            'RMSE': rmse,
            'Correlation': correlation,
            'Smoothness': smoothness,
            'Lag': lag,
            'SNR': snr,
            'Data_Points': len(valid_values)
        }
    
    return stats


def print_full_statistics(stats: Dict):
    """ãƒ•ãƒ«çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º"""
    print("\nğŸ“Š ãƒ•ãƒ«ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼æ€§èƒ½çµ±è¨ˆ:")
    print("=" * 100)
    print(f"{'ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼å':<20} {'MAE':<8} {'RMSE':<8} {'ç›¸é–¢':<6} {'å¹³æ»‘åº¦':<8} {'ãƒ©ã‚°':<5} {'SNR':<6} {'ãƒ‡ãƒ¼ã‚¿ç‚¹':<8}")
    print("-" * 100)
    
    for name, stat in stats.items():
        print(f"{name:<20} {stat['MAE']:<8.3f} {stat['RMSE']:<8.3f} "
              f"{stat['Correlation']:<6.3f} {stat['Smoothness']:<8.3f} "
              f"{stat['Lag']:<5} {stat['SNR']:<6.2f} {stat['Data_Points']:<8}")
    
    print("=" * 100)
    print("MAE: å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰")
    print("RMSE: äºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·®ï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰") 
    print("ç›¸é–¢: å…ƒä¾¡æ ¼ã¨ã®ç›¸é–¢ä¿‚æ•°ï¼ˆ1ã«è¿‘ã„ã»ã©è‰¯ã„ï¼‰")
    print("å¹³æ»‘åº¦: å¹³æ»‘ã•ã®æŒ‡æ¨™ï¼ˆå°ã•ã„ã»ã©æ»‘ã‚‰ã‹ï¼‰")
    print("ãƒ©ã‚°: é…å»¶ãƒãƒ¼æ•°ï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰")
    print("SNR: ä¿¡å·å¯¾é›‘éŸ³æ¯”ï¼ˆå¤§ãã„ã»ã©è‰¯ã„ï¼‰")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸš€ ãƒ•ãƒ«ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆä½œæˆé–‹å§‹\\n")
    
    try:
        # è¨­å®šèª­ã¿è¾¼ã¿
        config = load_config()
        print("âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        print("ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«å¸‚å ´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
        data = generate_sample_data(1000)
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(data)}ä»¶")
        
        # ãƒ•ãƒ«ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼è¨ˆç®—
        smoother_results = calculate_all_smoothers_full(data)
        
        # çµ±è¨ˆè¨ˆç®—ãƒ»è¡¨ç¤º
        stats = calculate_full_smoother_statistics(smoother_results)
        print_full_statistics(stats)
        
        # ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
        create_full_comparison_chart(data, smoother_results, config)
        
        print("\\nğŸ‰ ãƒ•ãƒ«ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆä½œæˆå®Œäº†!")
        
    except KeyboardInterrupt:
        print("\\nâ¹ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        traceback.print_exc()


if __name__ == "__main__":
    main()