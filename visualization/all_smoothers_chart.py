#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ã™ã¹ã¦ã®ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆ

indicators/smoother/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã™ã¹ã¦ã®ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚’æ¯”è¼ƒã™ã‚‹matplotlibãƒãƒ£ãƒ¼ãƒˆ:
- UltimateSmoother: ã‚¸ãƒ§ãƒ³ãƒ»ã‚¨ãƒ¼ãƒ©ãƒ¼ã‚ºã®ã‚¢ãƒ«ãƒ†ã‚£ãƒ¡ãƒƒãƒˆã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼
- SuperSmoother: 2æ¥µã¨3æ¥µã®ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼
- FRAMA: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«é©å¿œç§»å‹•å¹³å‡
- UnscentedKalmanFilter: ç„¡é¦™æ–™ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
- AdaptiveKalman: é©å¿œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
"""

import sys
import os
import traceback
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Union

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.gridspec import GridSpec
import yaml

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®è¿½åŠ 
try:
    from data_loader import DataLoader
except ImportError:
    print("Warning: DataLoader not found. Using fallback data generation.")
    DataLoader = None

# ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from indicators.smoother.ultimate_smoother import UltimateSmoother
    from indicators.smoother.super_smoother import SuperSmoother  
    from indicators.smoother.frama import FRAMA
    from indicators.smoother.unscented_kalman_filter import UnscentedKalmanFilter
    from indicators.smoother.adaptive_kalman import AdaptiveKalman
    
    print("âœ… ã™ã¹ã¦ã®ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®èª­ã¿è¾¼ã¿å®Œäº†")
    
except ImportError as e:
    print(f"âŒ ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
    print("Fallback: Numbaé–¢æ•°ã‚’ç›´æ¥ä½¿ç”¨ã—ã¾ã™")
    
    # Numbaé–¢æ•°ã®ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from indicators.smoother.ultimate_smoother import calculate_ultimate_smoother
    from indicators.smoother.super_smoother import calculate_super_smoother_numba
    from indicators.smoother.frama import calculate_frama_core
    from indicators.smoother.unscented_kalman_filter import calculate_unscented_kalman_filter, estimate_volatility
    from indicators.smoother.adaptive_kalman import adaptive_kalman_filter


def load_config() -> Dict:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    config_path = project_root / "config.yaml"
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        print("Warning: config.yaml not found. Using default settings.")
        return {
            'binance_data': {
                'symbol': 'SOL',
                'timeframe': '4h',
                'start': '2023-01-01',
                'end': '2024-12-31'
            }
        }


def load_market_data(config: Dict) -> pd.DataFrame:
    """å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    if DataLoader is not None:
        try:
            # è¨­å®šã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
            binance_config = config.get('binance_data', {})
            symbol = binance_config.get('symbol', 'SOL')
            timeframe = binance_config.get('timeframe', '4h')
            
            loader = DataLoader(config)
            data = loader.load_binance_data()
            
            if data is not None and len(data) > 0:
                print(f"âœ… å¸‚å ´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {symbol} {timeframe} ({len(data)}ä»¶)")
                return data
            else:
                print("âš ï¸ å¸‚å ´ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
                
        except Exception as e:
            print(f"âš ï¸ DataLoaderä½¿ç”¨ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    print("ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
    return generate_sample_data()


def generate_sample_data(num_points: int = 1000) -> pd.DataFrame:
    """ãƒªã‚¢ãƒ«ãªå¸‚å ´ãƒ‡ãƒ¼ã‚¿é¢¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    np.random.seed(42)
    
    # æ—¥ä»˜ç¯„å›²ã‚’ç”Ÿæˆ
    dates = pd.date_range(start='2023-01-01', periods=num_points, freq='4H')
    
    # åŸºæœ¬ä¾¡æ ¼ãƒˆãƒ¬ãƒ³ãƒ‰
    trend = np.linspace(100, 180, num_points)
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯
    random_walk = np.cumsum(np.random.randn(num_points) * 0.5)
    
    # å‘¨æœŸçš„å¤‰å‹•
    cycle1 = 5 * np.sin(2 * np.pi * np.arange(num_points) / 50)
    cycle2 = 3 * np.sin(2 * np.pi * np.arange(num_points) / 100)
    
    # ãƒã‚¤ã‚º
    noise = np.random.randn(num_points) * 1.5
    
    # ä¾¡æ ¼ã‚·ãƒªãƒ¼ã‚ºã®åˆæˆ
    close_prices = trend + random_walk + cycle1 + cycle2 + noise
    
    # OHLCç”Ÿæˆ
    high_offset = np.abs(np.random.randn(num_points)) * 2
    low_offset = np.abs(np.random.randn(num_points)) * 2
    open_offset = np.random.randn(num_points) * 1
    
    data = pd.DataFrame({
        'timestamp': dates,
        'open': close_prices + open_offset,
        'high': close_prices + high_offset,
        'low': close_prices - low_offset,
        'close': close_prices,
        'volume': np.random.lognormal(8, 1, num_points)
    })
    
    # ä¾¡æ ¼ã®æ•´åˆæ€§ã‚’ä¿ã¤
    data['high'] = np.maximum.reduce([data['open'], data['high'], data['close']])
    data['low'] = np.minimum.reduce([data['open'], data['low'], data['close']])
    
    return data


def create_smoother_instances() -> Dict:
    """ã™ã¹ã¦ã®ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ"""
    smoothers = {}
    
    try:
        # UltimateSmoother (å›ºå®šæœŸé–“ãƒ¢ãƒ¼ãƒ‰)
        smoothers['UltimateSmoother'] = UltimateSmoother(
            period=20.0,
            src_type='close',
            period_mode='fixed'  # å‹•çš„ãƒ¢ãƒ¼ãƒ‰ã¯ä¾å­˜é–¢ä¿‚ãŒè¤‡é›‘ãªãŸã‚å›ºå®šãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
        )
        print("âœ… UltimateSmootherä½œæˆå®Œäº†")
        
    except Exception as e:
        print(f"âš ï¸ UltimateSmootherä½œæˆå¤±æ•—: {e}")
        smoothers['UltimateSmoother'] = None
    
    try:
        # SuperSmoother (2æ¥µ)
        smoothers['SuperSmoother_2pole'] = SuperSmoother(
            length=15,
            num_poles=2,
            src_type='close'
        )
        print("âœ… SuperSmoother(2æ¥µ)ä½œæˆå®Œäº†")
        
    except Exception as e:
        print(f"âš ï¸ SuperSmoother(2æ¥µ)ä½œæˆå¤±æ•—: {e}")
        smoothers['SuperSmoother_2pole'] = None
        
    try:
        # SuperSmoother (3æ¥µ)
        smoothers['SuperSmoother_3pole'] = SuperSmoother(
            length=15,
            num_poles=3,
            src_type='close'
        )
        print("âœ… SuperSmoother(3æ¥µ)ä½œæˆå®Œäº†")
        
    except Exception as e:
        print(f"âš ï¸ SuperSmoother(3æ¥µ)ä½œæˆå¤±æ•—: {e}")
        smoothers['SuperSmoother_3pole'] = None
    
    try:
        # FRAMA
        smoothers['FRAMA'] = FRAMA(
            period=16,  # å¶æ•°ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹
            src_type='hl2',
            fc=1,
            sc=198
        )
        print("âœ… FRAMAä½œæˆå®Œäº†")
        
    except Exception as e:
        print(f"âš ï¸ FRAMAä½œæˆå¤±æ•—: {e}")
        smoothers['FRAMA'] = None
    
    try:
        # UnscentedKalmanFilter
        smoothers['UKF'] = UnscentedKalmanFilter(
            src_type='close',
            alpha=0.001,
            beta=2.0,
            kappa=0.0,
            process_noise_scale=0.001,
            volatility_window=10,
            adaptive_noise=True
        )
        print("âœ… UKFä½œæˆå®Œäº†")
        
    except Exception as e:
        print(f"âš ï¸ UKFä½œæˆå¤±æ•—: {e}")
        smoothers['UKF'] = None
    
    try:
        # AdaptiveKalman
        smoothers['AdaptiveKalman'] = AdaptiveKalman(
            process_noise=1e-5,
            src_type='close',
            min_observation_noise=1e-6,
            adaptation_window=5
        )
        print("âœ… AdaptiveKalmanä½œæˆå®Œäº†")
        
    except Exception as e:
        print(f"âš ï¸ AdaptiveKalmanä½œæˆå¤±æ•—: {e}")
        smoothers['AdaptiveKalman'] = None
    
    return smoothers


def calculate_all_smoothers(data: pd.DataFrame, smoothers: Dict) -> Dict[str, np.ndarray]:
    """ã™ã¹ã¦ã®ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚’è¨ˆç®—"""
    results = {}
    prices = data['close'].values
    
    print("\nğŸ“Š ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼è¨ˆç®—é–‹å§‹...")
    
    for name, smoother in smoothers.items():
        if smoother is None:
            print(f"â­ï¸  {name}: ã‚¹ã‚­ãƒƒãƒ—ï¼ˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆå¤±æ•—ï¼‰")
            continue
            
        try:
            print(f"ğŸ”„ {name} è¨ˆç®—ä¸­...")
            
            if name == 'UltimateSmoother':
                result = smoother.calculate(data)
                results[name] = result.values
                
            elif name.startswith('SuperSmoother'):
                result = smoother.calculate(data)
                results[name] = result.values
                
            elif name == 'FRAMA':
                result = smoother.calculate(data)
                results[name] = result.values
                
            elif name == 'UKF':
                result = smoother.calculate(data)
                results[name] = result.filtered_values
                
            elif name == 'AdaptiveKalman':
                result = smoother.calculate(data)
                results[name] = result.filtered_signal
                
            print(f"âœ… {name} è¨ˆç®—å®Œäº†")
            
        except Exception as e:
            print(f"âŒ {name} è¨ˆç®—å¤±æ•—: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®ä¾¡æ ¼ã‚’ä½¿ç”¨
            results[name] = prices.copy()
    
    # å…ƒã®ä¾¡æ ¼ã‚‚è¿½åŠ 
    results['Original'] = prices
    
    return results


def create_comparison_chart(data: pd.DataFrame, smoother_results: Dict[str, np.ndarray], config: Dict):
    """æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ"""
    print("\nğŸ¨ ãƒãƒ£ãƒ¼ãƒˆä½œæˆä¸­...")
    
    # è¨­å®š
    symbol = config.get('binance_data', {}).get('symbol', 'SOL')
    timeframe = config.get('binance_data', {}).get('timeframe', '4h')
    
    # æ—¥ä»˜ã®æº–å‚™
    if 'timestamp' in data.columns:
        dates = pd.to_datetime(data['timestamp'])
    else:
        dates = data.index
    
    # ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆ
    colors = {
        'Original': '#333333',
        'UltimateSmoother': '#FF6B6B',
        'SuperSmoother_2pole': '#4ECDC4', 
        'SuperSmoother_3pole': '#45B7D1',
        'FRAMA': '#96CEB4',
        'UKF': '#FFEAA7',
        'AdaptiveKalman': '#DDA0DD'
    }
    
    # ãƒ•ã‚£ã‚®ãƒ¥ã‚¢ã¨ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆè¨­å®š
    fig = plt.figure(figsize=(16, 12))
    gs = GridSpec(3, 2, height_ratios=[3, 1, 1], hspace=0.3, wspace=0.3)
    
    # ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒ¼ãƒˆ
    ax_main = fig.add_subplot(gs[0, :])
    
    # ãƒ‡ãƒ¼ã‚¿ç¯„å›²ã®åˆ¶é™ï¼ˆæœ€æ–°1000ç‚¹ï¼‰
    display_range = min(1000, len(data))
    start_idx = max(0, len(data) - display_range)
    
    dates_display = dates[start_idx:]
    
    # ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆ
    for name, values in smoother_results.items():
        if len(values) > 0:
            values_display = values[start_idx:]
            line_width = 2.5 if name == 'Original' else 1.5
            alpha = 0.8 if name == 'Original' else 0.7
            
            ax_main.plot(dates_display, values_display, 
                        label=name, color=colors.get(name, '#888888'),
                        linewidth=line_width, alpha=alpha)
    
    ax_main.set_title(f'å…¨ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼æ¯”è¼ƒ - {symbol} {timeframe}', fontsize=16, fontweight='bold')
    ax_main.set_ylabel('ä¾¡æ ¼', fontsize=12)
    ax_main.grid(True, alpha=0.3)
    ax_main.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    # Xè»¸ã®æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    ax_main.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))
    ax_main.xaxis.set_major_locator(mdates.WeekdayLocator(interval=2))
    plt.setp(ax_main.xaxis.get_majorticklabels(), rotation=45)
    
    # çµ±è¨ˆã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ1: å…ƒä¾¡æ ¼ã¨ã®å·®åˆ†
    ax_diff = fig.add_subplot(gs[1, :])
    original_values = smoother_results['Original'][start_idx:]
    
    for name, values in smoother_results.items():
        if name != 'Original' and len(values) > 0:
            values_display = values[start_idx:]
            diff = values_display - original_values
            ax_diff.plot(dates_display, diff, 
                        label=f'{name} - Original', 
                        color=colors.get(name, '#888888'),
                        linewidth=1.2, alpha=0.7)
    
    ax_diff.set_title('å…ƒä¾¡æ ¼ã¨ã®å·®åˆ†', fontsize=12, fontweight='bold')
    ax_diff.set_ylabel('å·®åˆ†', fontsize=10)
    ax_diff.grid(True, alpha=0.3)
    ax_diff.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax_diff.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    # Xè»¸ã®æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    ax_diff.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))
    ax_diff.xaxis.set_major_locator(mdates.WeekdayLocator(interval=2))
    plt.setp(ax_diff.xaxis.get_majorticklabels(), rotation=45)
    
    # çµ±è¨ˆã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ2: ç§»å‹•å¹³å‡ã‹ã‚‰ã®ä¹–é›¢
    ax_dev = fig.add_subplot(gs[2, :])
    ma_period = 20
    original_ma = np.convolve(original_values, np.ones(ma_period)/ma_period, mode='same')
    
    for name, values in smoother_results.items():
        if len(values) > 0:
            values_display = values[start_idx:]
            deviation = ((values_display - original_ma) / original_ma) * 100
            ax_dev.plot(dates_display, deviation, 
                       label=f'{name}', 
                       color=colors.get(name, '#888888'),
                       linewidth=1.2, alpha=0.7)
    
    ax_dev.set_title(f'ç§»å‹•å¹³å‡(MA{ma_period})ã‹ã‚‰ã®ä¹–é›¢ç‡ (%)', fontsize=12, fontweight='bold')
    ax_dev.set_ylabel('ä¹–é›¢ç‡ (%)', fontsize=10)
    ax_dev.set_xlabel('æ—¥æ™‚', fontsize=10)
    ax_dev.grid(True, alpha=0.3)
    ax_dev.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax_dev.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    # Xè»¸ã®æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    ax_dev.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))
    ax_dev.xaxis.set_major_locator(mdates.WeekdayLocator(interval=2))
    plt.setp(ax_dev.xaxis.get_majorticklabels(), rotation=45)
    
    # ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«
    fig.suptitle(f'å…¨ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼æ¯”è¼ƒåˆ†æ\n{symbol} {timeframe} - æœ€æ–° {display_range} ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ', 
                fontsize=18, fontweight='bold', y=0.98)
    
    plt.tight_layout()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"all_smoothers_comparison_{symbol}_{timeframe}_{timestamp}.png"
    filepath = project_root / filename
    
    try:
        plt.savefig(filepath, dpi=300, bbox_inches='tight', 
                   facecolor='white', edgecolor='none')
        print(f"ğŸ“ ãƒãƒ£ãƒ¼ãƒˆä¿å­˜å®Œäº†: {filepath}")
        
    except Exception as e:
        print(f"âš ï¸ ãƒãƒ£ãƒ¼ãƒˆä¿å­˜å¤±æ•—: {e}")
    
    plt.show()


def calculate_smoother_statistics(smoother_results: Dict[str, np.ndarray]) -> Dict:
    """ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã®çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—"""
    stats = {}
    original = smoother_results.get('Original', np.array([]))
    
    if len(original) == 0:
        return stats
    
    for name, values in smoother_results.items():
        if name == 'Original' or len(values) == 0:
            continue
            
        # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨
        valid_mask = ~np.isnan(values) & ~np.isnan(original)
        if not np.any(valid_mask):
            continue
            
        valid_values = values[valid_mask]
        valid_original = original[valid_mask]
        
        # çµ±è¨ˆè¨ˆç®—
        mae = np.mean(np.abs(valid_values - valid_original))
        rmse = np.sqrt(np.mean((valid_values - valid_original) ** 2))
        
        # ç›¸é–¢ä¿‚æ•°
        correlation = np.corrcoef(valid_values, valid_original)[0, 1]
        
        # ãƒ©ã‚°è¨ˆç®—ï¼ˆé…å»¶åº¦ï¼‰
        lag = calculate_lag(valid_original, valid_values)
        
        # å¹³æ»‘åº¦ï¼ˆé€£ç¶šã™ã‚‹å€¤ã®å·®ã®æ¨™æº–åå·®ï¼‰
        smoothness = np.std(np.diff(valid_values))
        
        stats[name] = {
            'MAE': mae,
            'RMSE': rmse,
            'Correlation': correlation,
            'Lag': lag,
            'Smoothness': smoothness,
            'Data_Points': len(valid_values)
        }
    
    return stats


def calculate_lag(original: np.ndarray, smoothed: np.ndarray, max_lag: int = 20) -> int:
    """ãƒ©ã‚°ï¼ˆé…å»¶ï¼‰ã‚’è¨ˆç®—"""
    if len(original) < max_lag * 2:
        return 0
        
    best_correlation = -1
    best_lag = 0
    
    for lag in range(max_lag + 1):
        if lag == 0:
            corr = np.corrcoef(original, smoothed)[0, 1]
        else:
            corr = np.corrcoef(original[:-lag], smoothed[lag:])[0, 1]
        
        if corr > best_correlation:
            best_correlation = corr
            best_lag = lag
    
    return best_lag


def print_statistics(stats: Dict):
    """çµ±è¨ˆæƒ…å ±ã‚’å°åˆ·"""
    print("\nğŸ“Š ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼æ€§èƒ½çµ±è¨ˆ:")
    print("=" * 80)
    print(f"{'ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼å':<20} {'MAE':<8} {'RMSE':<8} {'ç›¸é–¢':<6} {'é…å»¶':<6} {'å¹³æ»‘åº¦':<8} {'ãƒ‡ãƒ¼ã‚¿ç‚¹':<8}")
    print("-" * 80)
    
    for name, stat in stats.items():
        print(f"{name:<20} {stat['MAE']:<8.3f} {stat['RMSE']:<8.3f} "
              f"{stat['Correlation']:<6.3f} {stat['Lag']:<6} "
              f"{stat['Smoothness']:<8.3f} {stat['Data_Points']:<8}")
    
    print("=" * 80)
    print("MAE: å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰")
    print("RMSE: äºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·®ï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰")
    print("ç›¸é–¢: å…ƒä¾¡æ ¼ã¨ã®ç›¸é–¢ä¿‚æ•°ï¼ˆ1ã«è¿‘ã„ã»ã©è‰¯ã„ï¼‰")
    print("é…å»¶: é…å»¶ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰")
    print("å¹³æ»‘åº¦: å¹³æ»‘ã•ã®æŒ‡æ¨™ï¼ˆå°ã•ã„ã»ã©æ»‘ã‚‰ã‹ï¼‰")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸš€ å…¨ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆä½œæˆé–‹å§‹\n")
    
    try:
        # è¨­å®šèª­ã¿è¾¼ã¿
        config = load_config()
        print("âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        
        # å¸‚å ´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        data = load_market_data(config)
        
        if data is None or len(data) == 0:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        # ãƒ‡ãƒ¼ã‚¿ã®æœ€å°è¦ä»¶ç¢ºèª
        if len(data) < 100:
            print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã¾ã™ã€‚æœ€ä½100ä»¶å¿…è¦ã§ã™ã€‚")
            return
        
        # ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        smoothers = create_smoother_instances()
        
        # æœ‰åŠ¹ãªã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã®ç¢ºèª
        valid_smoothers = {k: v for k, v in smoothers.items() if v is not None}
        if not valid_smoothers:
            print("âŒ æœ‰åŠ¹ãªã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        print(f"ğŸ“ˆ æœ‰åŠ¹ãªã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼æ•°: {len(valid_smoothers)}")
        
        # å…¨ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼è¨ˆç®—
        smoother_results = calculate_all_smoothers(data, valid_smoothers)
        
        # çµ±è¨ˆè¨ˆç®—
        stats = calculate_smoother_statistics(smoother_results)
        print_statistics(stats)
        
        # ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
        create_comparison_chart(data, smoother_results, config)
        
        print("\nğŸ‰ å…¨ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆä½œæˆå®Œäº†!")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print("è©³ç´°ã‚¨ãƒ©ãƒ¼:")
        traceback.print_exc()


if __name__ == "__main__":
    main()