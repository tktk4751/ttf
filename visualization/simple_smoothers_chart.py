#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ã‚·ãƒ³ãƒ—ãƒ«ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆ

ã™ã¹ã¦ã®ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚’ç›´æ¥Numbaé–¢æ•°ã§å®Ÿè£…ã—ã€å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å›é¿:
- UltimateSmoother: ã‚¸ãƒ§ãƒ³ãƒ»ã‚¨ãƒ¼ãƒ©ãƒ¼ã‚ºã®ã‚¢ãƒ«ãƒ†ã‚£ãƒ¡ãƒƒãƒˆã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼
- SuperSmoother: 2æ¥µã¨3æ¥µã®ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼
- FRAMA: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«é©å¿œç§»å‹•å¹³å‡
- UnscentedKalmanFilter: ç„¡é¦™æ–™ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼  
- AdaptiveKalman: é©å¿œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
"""

import sys
import os
import traceback
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Union, Tuple

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.gridspec import GridSpec
import yaml
from numba import njit
import math

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def load_config() -> Dict:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    config_path = project_root / "config.yaml"
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        print("Warning: config.yaml not found. Using default settings.")
        return {
            'binance_data': {
                'symbol': 'SOL',
                'timeframe': '4h',
                'start': '2023-01-01',
                'end': '2024-12-31'
            }
        }


def generate_sample_data(num_points: int = 1000) -> pd.DataFrame:
    """ãƒªã‚¢ãƒ«ãªå¸‚å ´ãƒ‡ãƒ¼ã‚¿é¢¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    np.random.seed(42)
    
    # æ—¥ä»˜ç¯„å›²ã‚’ç”Ÿæˆ
    dates = pd.date_range(start='2023-01-01', periods=num_points, freq='4H')
    
    # åŸºæœ¬ä¾¡æ ¼ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆå¤šæ§˜ãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    trend = np.linspace(100, 180, num_points)
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯
    random_walk = np.cumsum(np.random.randn(num_points) * 0.5)
    
    # è¤‡æ•°ã®å‘¨æœŸçš„å¤‰å‹•
    cycle1 = 8 * np.sin(2 * np.pi * np.arange(num_points) / 50)  # çŸ­æœŸã‚µã‚¤ã‚¯ãƒ«
    cycle2 = 5 * np.sin(2 * np.pi * np.arange(num_points) / 100) # ä¸­æœŸã‚µã‚¤ã‚¯ãƒ«
    cycle3 = 3 * np.sin(2 * np.pi * np.arange(num_points) / 200) # é•·æœŸã‚µã‚¤ã‚¯ãƒ«
    
    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼
    volatility = 1 + 0.5 * np.sin(2 * np.pi * np.arange(num_points) / 150)
    noise = np.random.randn(num_points) * volatility
    
    # ä¾¡æ ¼ã‚·ãƒªãƒ¼ã‚ºã®åˆæˆ
    close_prices = trend + random_walk + cycle1 + cycle2 + cycle3 + noise
    
    # OHLCç”Ÿæˆ
    high_offset = np.abs(np.random.randn(num_points)) * volatility
    low_offset = np.abs(np.random.randn(num_points)) * volatility
    open_offset = np.random.randn(num_points) * 0.5
    
    data = pd.DataFrame({
        'timestamp': dates,
        'open': close_prices + open_offset,
        'high': close_prices + high_offset,
        'low': close_prices - low_offset,
        'close': close_prices,
        'volume': np.random.lognormal(8, 1, num_points)
    })
    
    # ä¾¡æ ¼ã®æ•´åˆæ€§ã‚’ä¿ã¤
    data['high'] = np.maximum.reduce([data['open'], data['high'], data['close']])
    data['low'] = np.minimum.reduce([data['open'], data['low'], data['close']])
    
    return data


# ===== Numba Smoother Functions =====

@njit(fastmath=True, cache=True)
def calculate_ultimate_smoother_numba(price: np.ndarray, period: float = 20.0) -> np.ndarray:
    """ã‚¢ãƒ«ãƒ†ã‚£ãƒ¡ãƒƒãƒˆã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼è¨ˆç®—"""
    length = len(price)
    
    # ä¿‚æ•°ã®è¨ˆç®—
    a1 = math.exp(-1.414 * math.pi / period)
    b1 = 2.0 * a1 * math.cos(1.414 * math.pi / period)
    c2 = b1
    c3 = -a1 * a1
    c1 = (1.0 + c2 - c3) / 4.0
    
    ultimate_smoother = np.zeros(length, dtype=np.float64)
    
    # åˆæœŸå€¤
    for i in range(min(3, length)):
        ultimate_smoother[i] = price[i]
    
    # è¨ˆç®—
    for i in range(3, length):
        if i >= 2:
            ultimate_smoother[i] = ((1.0 - c1) * price[i] + 
                                   (2.0 * c1 - c2) * price[i-1] - 
                                   (c1 + c3) * price[i-2] + 
                                   c2 * ultimate_smoother[i-1] + 
                                   c3 * ultimate_smoother[i-2])
        else:
            ultimate_smoother[i] = price[i]
    
    return ultimate_smoother


@njit(fastmath=True, cache=True)
def calculate_super_smoother_2pole_numba(source: np.ndarray, length: int) -> np.ndarray:
    """2æ¥µã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼è¨ˆç®—"""
    data_length = len(source)
    result = np.zeros(data_length)
    
    if data_length < 3 or length < 2:
        return result
    
    # ä¿‚æ•°è¨ˆç®—
    PI = 2 * math.asin(1)
    arg = math.sqrt(2) * PI / length
    a1 = math.exp(-arg)
    b1 = 2 * a1 * math.cos(arg)
    
    coef3 = -math.pow(a1, 2)
    coef2 = b1
    coef1 = 1 - coef2 - coef3
    
    # åˆæœŸå€¤
    result[0] = source[0]
    if data_length > 1:
        result[1] = source[1]
    
    # è¨ˆç®—
    for i in range(2, data_length):
        if not np.isnan(source[i]):
            result[i] = (coef1 * source[i] + 
                        coef2 * result[i-1] + 
                        coef3 * result[i-2])
        else:
            result[i] = result[i-1]
    
    return result


@njit(fastmath=True, cache=True)
def calculate_super_smoother_3pole_numba(source: np.ndarray, length: int) -> np.ndarray:
    """3æ¥µã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼è¨ˆç®—"""
    data_length = len(source)
    result = np.zeros(data_length)
    
    if data_length < 4 or length < 2:
        return result
    
    # ä¿‚æ•°è¨ˆç®—
    PI = 2 * math.asin(1)
    arg = PI / length
    a1 = math.exp(-arg)
    b1 = 2 * a1 * math.cos(1.738 * arg)
    c1 = math.pow(a1, 2)
    
    coef4 = math.pow(c1, 2)
    coef3 = -(c1 + b1 * c1)
    coef2 = b1 + c1
    coef1 = 1 - coef2 - coef3 - coef4
    
    # åˆæœŸå€¤
    result[0] = source[0]
    if data_length > 1:
        result[1] = source[1]
    if data_length > 2:
        result[2] = source[2]
    
    # è¨ˆç®—
    for i in range(3, data_length):
        if not np.isnan(source[i]):
            result[i] = (coef1 * source[i] + 
                        coef2 * result[i-1] + 
                        coef3 * result[i-2] + 
                        coef4 * result[i-3])
        else:
            result[i] = result[i-1]
    
    return result


@njit(fastmath=True, cache=True)
def calculate_frama_simple_numba(price: np.ndarray, high: np.ndarray, low: np.ndarray, 
                                n: int, fc: int, sc: int) -> np.ndarray:
    """FRAMAç°¡æ˜“ç‰ˆè¨ˆç®—"""
    length = len(price)
    frama = np.zeros(length, dtype=np.float64)
    
    # åˆæœŸå€¤
    for i in range(length):
        frama[i] = price[i] if i < n else np.nan
    
    # w = log(2/(SC+1))
    w = np.log(2.0 / (sc + 1))
    
    # è¨ˆç®—
    for i in range(n, length):
        if np.isnan(price[i]):
            frama[i] = frama[i-1] if i > 0 else np.nan
            continue
        
        len1 = n // 2
        
        # H1, L1
        h1 = -np.inf
        l1 = np.inf
        for j in range(len1):
            if i - j >= 0:
                if high[i - j] > h1:
                    h1 = high[i - j]
                if low[i - j] < l1:
                    l1 = low[i - j]
        
        n1 = (h1 - l1) / len1
        
        # H2, L2
        h2 = -np.inf
        l2 = np.inf
        for j in range(len1, n):
            if i - j >= 0:
                if high[i - j] > h2:
                    h2 = high[i - j]
                if low[i - j] < l2:
                    l2 = low[i - j]
        
        n2 = (h2 - l2) / len1
        
        # H3, L3
        h3 = -np.inf
        l3 = np.inf
        for j in range(n):
            if i - j >= 0:
                if high[i - j] > h3:
                    h3 = high[i - j]
                if low[i - j] < l3:
                    l3 = low[i - j]
        
        n3 = (h3 - l3) / n
        
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè¨ˆç®—
        if n1 > 0 and n2 > 0 and n3 > 0:
            dimen = (np.log(n1 + n2) - np.log(n3)) / np.log(2.0)
        else:
            dimen = 1.0
        
        # ã‚¢ãƒ«ãƒ•ã‚¡è¨ˆç®—
        alpha1 = np.exp(w * (dimen - 1.0))
        
        if alpha1 > 1.0:
            oldalpha = 1.0
        elif alpha1 < 0.01:
            oldalpha = 0.01
        else:
            oldalpha = alpha1
        
        oldN = (2.0 - oldalpha) / oldalpha
        N = (((sc - fc) * (oldN - 1.0)) / (sc - 1.0)) + fc
        alpha_ = 2.0 / (N + 1.0)
        
        min_alpha = 2.0 / (sc + 1.0)
        if alpha_ < min_alpha:
            final_alpha = min_alpha
        elif alpha_ > 1.0:
            final_alpha = 1.0
        else:
            final_alpha = alpha_
        
        # FRAMAè¨ˆç®—
        if i == n:
            frama[i] = price[i]
        else:
            frama[i] = (1.0 - final_alpha) * frama[i-1] + final_alpha * price[i]
    
    return frama


@njit(fastmath=True, cache=True)
def calculate_adaptive_kalman_numba(signal: np.ndarray, process_noise: float = 1e-5) -> np.ndarray:
    """é©å¿œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨ˆç®—"""
    length = len(signal)
    filtered_signal = np.zeros(length)
    
    if length > 0:
        state = signal[0]
        error_cov = 1.0
        filtered_signal[0] = state
    
    for i in range(1, length):
        # äºˆæ¸¬
        predicted_state = state
        predicted_covariance = error_cov + process_noise
        
        # é©å¿œãƒã‚¤ã‚ºæ¨å®š
        if i > 5:
            recent_variance = 0.0
            for j in range(min(5, i)):
                if i - j >= 0:
                    diff = signal[i-j] - filtered_signal[i-j]
                    recent_variance += diff * diff
            observation_noise = recent_variance / 5.0 + 1e-6
        else:
            observation_noise = 1e-3
        
        # ã‚«ãƒ«ãƒãƒ³ã‚²ã‚¤ãƒ³
        kalman_gain = predicted_covariance / (predicted_covariance + observation_noise)
        
        # æ›´æ–°
        innovation = signal[i] - predicted_state
        state = predicted_state + kalman_gain * innovation
        error_cov = (1 - kalman_gain) * predicted_covariance
        
        filtered_signal[i] = state
    
    return filtered_signal


@njit(fastmath=True, cache=True)
def calculate_simple_ukf_numba(prices: np.ndarray, alpha: float = 0.001) -> np.ndarray:
    """UKFç°¡æ˜“ç‰ˆè¨ˆç®—"""
    n = len(prices)
    filtered_prices = np.zeros(n)
    
    if n < 5:
        return prices.copy()
    
    # åˆæœŸçŠ¶æ…‹ [ä¾¡æ ¼, é€Ÿåº¦, åŠ é€Ÿåº¦]
    x = np.array([prices[0], 0.0, 0.0])
    P = np.array([[1.0, 0.0, 0.0], [0.0, 0.1, 0.0], [0.0, 0.0, 0.01]])
    Q = np.array([[0.001, 0.0, 0.0], [0.0, 0.0001, 0.0], [0.0, 0.0, 0.00001]])
    
    filtered_prices[0] = prices[0]
    
    for t in range(1, n):
        # ç°¡æ˜“äºˆæ¸¬
        x[0] = x[0] + x[1] + 0.5 * x[2]
        x[1] = x[1] * 0.95 + x[2]
        x[2] = x[2] * 0.9
        
        # å…±åˆ†æ•£æ›´æ–°
        for i in range(3):
            for j in range(3):
                P[i, j] += Q[i, j]
        
        # è¦³æ¸¬ãƒã‚¤ã‚º
        if t >= 10:
            window_var = 0.0
            for k in range(10):
                if t - k >= 0:
                    diff = prices[t-k] - filtered_prices[t-k]
                    window_var += diff * diff
            R = window_var / 10.0 + 0.0001
        else:
            R = 0.01
        
        # ã‚«ãƒ«ãƒãƒ³ã‚²ã‚¤ãƒ³ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        K0 = P[0, 0] / (P[0, 0] + R)
        
        # çŠ¶æ…‹æ›´æ–°
        innovation = prices[t] - x[0]
        x[0] = x[0] + K0 * innovation
        
        # å…±åˆ†æ•£æ›´æ–°
        P[0, 0] = (1 - K0) * P[0, 0]
        
        filtered_prices[t] = x[0]
    
    return filtered_prices


def calculate_all_smoothers_simple(data: pd.DataFrame) -> Dict[str, np.ndarray]:
    """ã™ã¹ã¦ã®ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚’è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    results = {}
    
    # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    close_prices = data['close'].values.astype(np.float64)
    high_prices = data['high'].values.astype(np.float64)
    low_prices = data['low'].values.astype(np.float64)
    
    print("ğŸ“Š ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼è¨ˆç®—é–‹å§‹...")
    
    try:
        # Ultimate Smoother
        print("ğŸ”„ Ultimate Smoother è¨ˆç®—ä¸­...")
        results['UltimateSmoother'] = calculate_ultimate_smoother_numba(close_prices, 20.0)
        print("âœ… Ultimate Smoother å®Œäº†")
        
    except Exception as e:
        print(f"âŒ Ultimate Smoother å¤±æ•—: {e}")
        results['UltimateSmoother'] = close_prices.copy()
    
    try:
        # Super Smoother 2-pole
        print("ğŸ”„ Super Smoother (2æ¥µ) è¨ˆç®—ä¸­...")
        results['SuperSmoother_2pole'] = calculate_super_smoother_2pole_numba(close_prices, 15)
        print("âœ… Super Smoother (2æ¥µ) å®Œäº†")
        
    except Exception as e:
        print(f"âŒ Super Smoother (2æ¥µ) å¤±æ•—: {e}")
        results['SuperSmoother_2pole'] = close_prices.copy()
    
    try:
        # Super Smoother 3-pole
        print("ğŸ”„ Super Smoother (3æ¥µ) è¨ˆç®—ä¸­...")
        results['SuperSmoother_3pole'] = calculate_super_smoother_3pole_numba(close_prices, 15)
        print("âœ… Super Smoother (3æ¥µ) å®Œäº†")
        
    except Exception as e:
        print(f"âŒ Super Smoother (3æ¥µ) å¤±æ•—: {e}")
        results['SuperSmoother_3pole'] = close_prices.copy()
    
    try:
        # FRAMA
        print("ğŸ”„ FRAMA è¨ˆç®—ä¸­...")
        results['FRAMA'] = calculate_frama_simple_numba(close_prices, high_prices, low_prices, 16, 1, 198)
        print("âœ… FRAMA å®Œäº†")
        
    except Exception as e:
        print(f"âŒ FRAMA å¤±æ•—: {e}")
        results['FRAMA'] = close_prices.copy()
    
    try:
        # Adaptive Kalman
        print("ğŸ”„ Adaptive Kalman è¨ˆç®—ä¸­...")
        results['AdaptiveKalman'] = calculate_adaptive_kalman_numba(close_prices, 1e-5)
        print("âœ… Adaptive Kalman å®Œäº†")
        
    except Exception as e:
        print(f"âŒ Adaptive Kalman å¤±æ•—: {e}")
        results['AdaptiveKalman'] = close_prices.copy()
    
    try:
        # Simple UKF
        print("ğŸ”„ UKF (ç°¡æ˜“ç‰ˆ) è¨ˆç®—ä¸­...")
        results['UKF_Simple'] = calculate_simple_ukf_numba(close_prices, 0.001)
        print("âœ… UKF (ç°¡æ˜“ç‰ˆ) å®Œäº†")
        
    except Exception as e:
        print(f"âŒ UKF (ç°¡æ˜“ç‰ˆ) å¤±æ•—: {e}")
        results['UKF_Simple'] = close_prices.copy()
    
    # å…ƒã®ä¾¡æ ¼
    results['Original'] = close_prices
    
    return results


def create_comparison_chart(data: pd.DataFrame, smoother_results: Dict[str, np.ndarray], config: Dict):
    """æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ"""
    print("\nğŸ¨ ãƒãƒ£ãƒ¼ãƒˆä½œæˆä¸­...")
    
    symbol = config.get('binance_data', {}).get('symbol', 'SOL')
    timeframe = config.get('binance_data', {}).get('timeframe', '4h')
    
    # æ—¥ä»˜ã®æº–å‚™
    if 'timestamp' in data.columns:
        dates = pd.to_datetime(data['timestamp'])
    else:
        dates = data.index
    
    # ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆ
    colors = {
        'Original': '#333333',
        'UltimateSmoother': '#FF6B6B',
        'SuperSmoother_2pole': '#4ECDC4', 
        'SuperSmoother_3pole': '#45B7D1',
        'FRAMA': '#96CEB4',
        'UKF_Simple': '#FFEAA7',
        'AdaptiveKalman': '#DDA0DD'
    }
    
    # ãƒ•ã‚£ã‚®ãƒ¥ã‚¢è¨­å®š
    fig = plt.figure(figsize=(16, 12))
    gs = GridSpec(4, 2, height_ratios=[3, 1, 1, 1], hspace=0.3, wspace=0.3)
    
    # ãƒ‡ãƒ¼ã‚¿ç¯„å›²ã®åˆ¶é™
    display_range = min(500, len(data))
    start_idx = max(0, len(data) - display_range)
    dates_display = dates[start_idx:]
    
    # ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒ¼ãƒˆ
    ax_main = fig.add_subplot(gs[0, :])
    
    # ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆ
    for name, values in smoother_results.items():
        if len(values) > 0:
            values_display = values[start_idx:]
            line_width = 2.5 if name == 'Original' else 1.5
            alpha = 0.9 if name == 'Original' else 0.7
            
            ax_main.plot(dates_display, values_display, 
                        label=name, color=colors.get(name, '#888888'),
                        linewidth=line_width, alpha=alpha)
    
    ax_main.set_title(f'å…¨ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼æ¯”è¼ƒ - {symbol} {timeframe}', fontsize=16, fontweight='bold')
    ax_main.set_ylabel('ä¾¡æ ¼', fontsize=12)
    ax_main.grid(True, alpha=0.3)
    ax_main.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    # å·®åˆ†ãƒãƒ£ãƒ¼ãƒˆ
    ax_diff = fig.add_subplot(gs[1, :])
    original_values = smoother_results['Original'][start_idx:]
    
    for name, values in smoother_results.items():
        if name != 'Original' and len(values) > 0:
            values_display = values[start_idx:]
            diff = values_display - original_values
            ax_diff.plot(dates_display, diff, 
                        label=f'{name} - Original', 
                        color=colors.get(name, '#888888'),
                        linewidth=1.2, alpha=0.7)
    
    ax_diff.set_title('å…ƒä¾¡æ ¼ã¨ã®å·®åˆ†', fontsize=12, fontweight='bold')
    ax_diff.set_ylabel('å·®åˆ†', fontsize=10)
    ax_diff.grid(True, alpha=0.3)
    ax_diff.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax_diff.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    # ç§»å‹•å¹³å‡ä¹–é›¢ç‡ãƒãƒ£ãƒ¼ãƒˆ
    ax_dev = fig.add_subplot(gs[2, :])
    ma_period = 20
    original_ma = np.convolve(original_values, np.ones(ma_period)/ma_period, mode='same')
    
    for name, values in smoother_results.items():
        if len(values) > 0:
            values_display = values[start_idx:]
            deviation = ((values_display - original_ma) / original_ma) * 100
            ax_dev.plot(dates_display, deviation, 
                       label=f'{name}', 
                       color=colors.get(name, '#888888'),
                       linewidth=1.2, alpha=0.7)
    
    ax_dev.set_title(f'ç§»å‹•å¹³å‡(MA{ma_period})ã‹ã‚‰ã®ä¹–é›¢ç‡ (%)', fontsize=12, fontweight='bold')
    ax_dev.set_ylabel('ä¹–é›¢ç‡ (%)', fontsize=10)
    ax_dev.grid(True, alpha=0.3)
    ax_dev.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax_dev.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒãƒ£ãƒ¼ãƒˆ
    ax_vol = fig.add_subplot(gs[3, :])
    
    for name, values in smoother_results.items():
        if len(values) > 0:
            values_display = values[start_idx:]
            # ãƒ­ãƒ¼ãƒªãƒ³ã‚°æ¨™æº–åå·®ã§ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’è¨ˆç®—
            window = 20
            volatility = pd.Series(values_display).rolling(window=window, min_periods=1).std()
            ax_vol.plot(dates_display, volatility, 
                       label=f'{name}', 
                       color=colors.get(name, '#888888'),
                       linewidth=1.2, alpha=0.7)
    
    ax_vol.set_title(f'ãƒ­ãƒ¼ãƒªãƒ³ã‚°ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ (çª“{window})', fontsize=12, fontweight='bold')
    ax_vol.set_ylabel('ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£', fontsize=10)
    ax_vol.set_xlabel('æ—¥æ™‚', fontsize=10)
    ax_vol.grid(True, alpha=0.3)
    ax_vol.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    # æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¨­å®š
    for ax in [ax_main, ax_diff, ax_dev, ax_vol]:
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))
        ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=3))
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    fig.suptitle(f'å…¨ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼æ¯”è¼ƒåˆ†æ\n{symbol} {timeframe} - æœ€æ–° {display_range} ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ', 
                fontsize=18, fontweight='bold', y=0.98)
    
    plt.tight_layout()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"all_smoothers_comparison_{symbol}_{timeframe}_{timestamp}.png"
    filepath = project_root / filename
    
    try:
        plt.savefig(filepath, dpi=300, bbox_inches='tight', 
                   facecolor='white', edgecolor='none')
        print(f"ğŸ“ ãƒãƒ£ãƒ¼ãƒˆä¿å­˜å®Œäº†: {filepath}")
        
    except Exception as e:
        print(f"âš ï¸ ãƒãƒ£ãƒ¼ãƒˆä¿å­˜å¤±æ•—: {e}")
    
    plt.show()


def calculate_smoother_statistics(smoother_results: Dict[str, np.ndarray]) -> Dict:
    """çµ±è¨ˆè¨ˆç®—"""
    stats = {}
    original = smoother_results.get('Original', np.array([]))
    
    if len(original) == 0:
        return stats
    
    for name, values in smoother_results.items():
        if name == 'Original' or len(values) == 0:
            continue
            
        # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã®ã¿
        valid_mask = ~np.isnan(values) & ~np.isnan(original)
        if not np.any(valid_mask):
            continue
            
        valid_values = values[valid_mask]
        valid_original = original[valid_mask]
        
        # çµ±è¨ˆè¨ˆç®—
        mae = np.mean(np.abs(valid_values - valid_original))
        rmse = np.sqrt(np.mean((valid_values - valid_original) ** 2))
        correlation = np.corrcoef(valid_values, valid_original)[0, 1]
        smoothness = np.std(np.diff(valid_values))
        
        stats[name] = {
            'MAE': mae,
            'RMSE': rmse,
            'Correlation': correlation,
            'Smoothness': smoothness,
            'Data_Points': len(valid_values)
        }
    
    return stats


def print_statistics(stats: Dict):
    """çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º"""
    print("\nğŸ“Š ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼æ€§èƒ½çµ±è¨ˆ:")
    print("=" * 80)
    print(f"{'ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼å':<20} {'MAE':<8} {'RMSE':<8} {'ç›¸é–¢':<6} {'å¹³æ»‘åº¦':<8} {'ãƒ‡ãƒ¼ã‚¿ç‚¹':<8}")
    print("-" * 80)
    
    for name, stat in stats.items():
        print(f"{name:<20} {stat['MAE']:<8.3f} {stat['RMSE']:<8.3f} "
              f"{stat['Correlation']:<6.3f} {stat['Smoothness']:<8.3f} {stat['Data_Points']:<8}")
    
    print("=" * 80)
    print("MAE: å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰")
    print("RMSE: äºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·®ï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰") 
    print("ç›¸é–¢: å…ƒä¾¡æ ¼ã¨ã®ç›¸é–¢ä¿‚æ•°ï¼ˆ1ã«è¿‘ã„ã»ã©è‰¯ã„ï¼‰")
    print("å¹³æ»‘åº¦: å¹³æ»‘ã•ã®æŒ‡æ¨™ï¼ˆå°ã•ã„ã»ã©æ»‘ã‚‰ã‹ï¼‰")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸš€ å…¨ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆä½œæˆé–‹å§‹\n")
    
    try:
        # è¨­å®šèª­ã¿è¾¼ã¿
        config = load_config()
        print("âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        print("ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«å¸‚å ´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
        data = generate_sample_data(1000)
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(data)}ä»¶")
        
        # ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼è¨ˆç®—
        smoother_results = calculate_all_smoothers_simple(data)
        
        # çµ±è¨ˆè¨ˆç®—ãƒ»è¡¨ç¤º
        stats = calculate_smoother_statistics(smoother_results)
        print_statistics(stats)
        
        # ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
        create_comparison_chart(data, smoother_results, config)
        
        print("\nğŸ‰ å…¨ã‚¹ãƒ ãƒ¼ã‚¶ãƒ¼æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆä½œæˆå®Œäº†!")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        traceback.print_exc()


if __name__ == "__main__":
    main()