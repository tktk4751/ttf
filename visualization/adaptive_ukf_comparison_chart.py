#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ§  **Four Adaptive UKF Methods - Real Market Data Chart** ğŸ§ 

å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ã§4ã¤ã®Adaptive UKFæ‰‹æ³•ã‚’æ¯”è¼ƒè¡¨ç¤ºï¼š
1. æ¨™æº–UKF (åŸºæº–)
2. ç§ã®å®Ÿè£…ç‰ˆAUKF (çµ±è¨ˆçš„ç›£è¦–ãƒ»é©å¿œåˆ¶å¾¡)
3. è«–æ–‡ç‰ˆAUKF (Ge et al. 2019 - ç›¸äº’ç›¸é–¢ç†è«–)
4. Neuralç‰ˆAUKF (Levy & Klein 2025 - CNN ProcessNet)
"""

import os
import yaml
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import mplfinance as mpf
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List
import warnings
import sys

# ãƒ‘ã‚¹è¨­å®š
project_root = Path(__file__).parent.parent
if project_root not in sys.path:
    sys.path.append(str(project_root))

# ãƒ‡ãƒ¼ã‚¿å–å¾—ã®ãŸã‚ã®ä¾å­˜é–¢ä¿‚
try:
    from data.data_loader import DataLoader, CSVDataSource
    from data.data_processor import DataProcessor
    from data.binance_data_source import BinanceDataSource
except ImportError:
    print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")

# 4ã¤ã®ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
try:
    from indicators.unscented_kalman_filter import UnscentedKalmanFilter
    from indicators.adaptive_ukf import AdaptiveUnscentedKalmanFilter
    from indicators.academic_adaptive_ukf import AcademicAdaptiveUnscentedKalmanFilter
    from indicators.neural_adaptive_ukf import NeuralAdaptiveUnscentedKalmanFilter
except ImportError as e:
    print(f"âš ï¸ ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

# è¨­å®š
warnings.filterwarnings('ignore')


class AdaptiveUKFComparisonChart:
    """
    4ã¤ã®Adaptive UKFæ‰‹æ³•ã‚’å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿ã§æ¯”è¼ƒè¡¨ç¤ºã™ã‚‹ãƒãƒ£ãƒ¼ãƒˆã‚¯ãƒ©ã‚¹
    
    ç‰¹å¾´ï¼š
    - ãƒ­ãƒ¼ã‚½ã‚¯è¶³ã¨å‡ºæ¥é«˜
    - 4ã¤ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœã®é‡ã­åˆã‚ã›è¡¨ç¤º
    - æ€§èƒ½æŒ‡æ¨™ã®æ¯”è¼ƒãƒ‘ãƒãƒ«
    - é©å¿œæ€§æŒ‡æ¨™ã®è¡¨ç¤º
    - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›¸å ´ãƒ‡ãƒ¼ã‚¿å¯¾å¿œ
    """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.data = None
        self.filters = {}
        self.results = {}
        self.performance_metrics = {}
        self.fig = None
        self.axes = None
    
    def load_data_from_config(self, config_path: str) -> pd.DataFrame:
        """
        è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            å‡¦ç†æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        """
        print("ğŸ§  **Four Adaptive UKF Comparison Chart** ğŸ§ ")
        print("="*60)
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
            
        # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        binance_config = config.get('binance_data', {})
        data_dir = binance_config.get('data_dir', 'data/binance')
        binance_data_source = BinanceDataSource(data_dir)
        
        # CSVãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã¯ãƒ€ãƒŸãƒ¼ã¨ã—ã¦æ¸¡ã™ï¼ˆBinanceãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®ã¿ã‚’ä½¿ç”¨ï¼‰
        dummy_csv_source = CSVDataSource("dummy")
        data_loader = DataLoader(
            data_source=dummy_csv_source,
            binance_data_source=binance_data_source
        )
        data_processor = DataProcessor()
        
        # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‡¦ç†
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ãƒ»å‡¦ç†ä¸­...")
        raw_data = data_loader.load_data_from_config(config)
        processed_data = {
            symbol: data_processor.process(df)
            for symbol, df in raw_data.items()
        }
        
        # æœ€åˆã®ã‚·ãƒ³ãƒœãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        first_symbol = next(iter(processed_data))
        self.data = processed_data[first_symbol]
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {first_symbol}")
        print(f"   æœŸé–“: {self.data.index.min()} â†’ {self.data.index.max()}")
        print(f"   ãƒ‡ãƒ¼ã‚¿æ•°: {len(self.data)}")
        print(f"   ä¾¡æ ¼ç¯„å›²: ${self.data['close'].min():.2f} - ${self.data['close'].max():.2f}")
        
        return self.data
    
    def load_simple_data(self, csv_path: str) -> pd.DataFrame:
        """
        ç°¡å˜ãªCSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
        
        Args:
            csv_path: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            å‡¦ç†æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        """
        print("ğŸ“Š **CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...**")
        
        try:
            # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            df = pd.read_csv(csv_path, index_col=0, parse_dates=True)
            
            # å¿…è¦ãªåˆ—ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            required_cols = ['open', 'high', 'low', 'close']
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                print(f"âš ï¸ ä¸è¶³ã—ã¦ã„ã‚‹åˆ—: {missing_cols}")
                # closeã®ã¿ã§ç–‘ä¼¼OHLCãƒ‡ãƒ¼ã‚¿ä½œæˆ
                if 'close' in df.columns:
                    df['open'] = df['close'].shift(1).fillna(df['close'])
                    df['high'] = df['close'] * 1.01
                    df['low'] = df['close'] * 0.99
                else:
                    raise ValueError("closeã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            # volumeåˆ—ãŒãªã„å ´åˆã¯ä½œæˆ
            if 'volume' not in df.columns:
                df['volume'] = 1000000  # ãƒ€ãƒŸãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ 
            
            self.data = df
            
            print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
            print(f"   æœŸé–“: {self.data.index.min()} â†’ {self.data.index.max()}")
            print(f"   ãƒ‡ãƒ¼ã‚¿æ•°: {len(self.data)}")
            print(f"   ä¾¡æ ¼ç¯„å›²: ${self.data['close'].min():.2f} - ${self.data['close'].max():.2f}")
            
            return self.data
            
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise

    def calculate_filters(self,
                         src_type: str = 'close',
                         window_size: int = 100) -> None:
        """
        4ã¤ã®Adaptive UKFæ‰‹æ³•ã‚’è¨ˆç®—ã™ã‚‹
        
        Args:
            src_type: ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—
            window_size: Neuralç‰ˆã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
        """
        if self.data is None:
            raise ValueError("ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            
        print("\nğŸ”„ **4ã¤ã®Adaptive UKFæ‰‹æ³•ã‚’è¨ˆç®—ä¸­...**")
        
        # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        if src_type in self.data.columns:
            price_data = self.data[src_type].values
        else:
            price_data = self.data['close'].values
            print(f"   âš ï¸ {src_type}ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€closeã‚’ä½¿ç”¨")
        
        print(f"   ğŸ“ˆ ä½¿ç”¨ä¾¡æ ¼: {src_type}, ãƒ‡ãƒ¼ã‚¿æ•°: {len(price_data)}")
        
        # 1. æ¨™æº–UKFï¼ˆåŸºæº–ï¼‰
        print("   1ï¸âƒ£ æ¨™æº–UKFè¨ˆç®—ä¸­...")
        try:
            self.filters['Standard UKF'] = UnscentedKalmanFilter(src_type=src_type)
            self.results['Standard UKF'] = self.filters['Standard UKF'].calculate(self.data)
            print("      âœ… æ¨™æº–UKFå®Œäº†")
        except Exception as e:
            print(f"      âŒ æ¨™æº–UKFã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.results['Standard UKF'] = None
        
        # 2. ç§ã®å®Ÿè£…ç‰ˆAUKFï¼ˆçµ±è¨ˆçš„ç›£è¦–ãƒ»é©å¿œåˆ¶å¾¡ï¼‰
        print("   2ï¸âƒ£ ç§ã®å®Ÿè£…ç‰ˆAUKFè¨ˆç®—ä¸­...")
        try:
            self.filters['My AUKF'] = AdaptiveUnscentedKalmanFilter(src_type=src_type)
            self.results['My AUKF'] = self.filters['My AUKF'].calculate(self.data)
            print("      âœ… ç§ã®å®Ÿè£…ç‰ˆAUKFå®Œäº†")
        except Exception as e:
            print(f"      âŒ ç§ã®å®Ÿè£…ç‰ˆAUKFã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.results['My AUKF'] = None
        
        # 3. è«–æ–‡ç‰ˆAUKFï¼ˆGe et al. 2019 - ç›¸äº’ç›¸é–¢ç†è«–ï¼‰
        print("   3ï¸âƒ£ è«–æ–‡ç‰ˆAUKF (Ge et al. 2019) è¨ˆç®—ä¸­...")
        try:
            self.filters['Academic AUKF'] = AcademicAdaptiveUnscentedKalmanFilter(src_type=src_type)
            self.results['Academic AUKF'] = self.filters['Academic AUKF'].calculate(self.data)
            print("      âœ… è«–æ–‡ç‰ˆAUKFå®Œäº†")
        except Exception as e:
            print(f"      âŒ è«–æ–‡ç‰ˆAUKFã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.results['Academic AUKF'] = None
        
        # 4. Neuralç‰ˆAUKFï¼ˆLevy & Klein 2025 - CNN ProcessNetï¼‰
        print("   4ï¸âƒ£ Neuralç‰ˆAUKF (Levy & Klein 2025) è¨ˆç®—ä¸­...")
        try:
            self.filters['Neural AUKF'] = NeuralAdaptiveUnscentedKalmanFilter(
                src_type=src_type, 
                window_size=window_size
            )
            self.results['Neural AUKF'] = self.filters['Neural AUKF'].calculate(self.data)
            print("      âœ… Neuralç‰ˆAUKFå®Œäº†")
        except Exception as e:
            print(f"      âŒ Neuralç‰ˆAUKFã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.results['Neural AUKF'] = None
        
        # æ€§èƒ½æŒ‡æ¨™è¨ˆç®—
        self._calculate_performance_metrics(price_data)
        
        print("ğŸ‰ **4ã¤ã®Adaptive UKFè¨ˆç®—å®Œäº†ï¼**")
    
    def _calculate_performance_metrics(self, true_prices: np.ndarray) -> None:
        """æ€§èƒ½æŒ‡æ¨™ã‚’è¨ˆç®—"""
        print("\nğŸ“Š **æ€§èƒ½æŒ‡æ¨™è¨ˆç®—ä¸­...**")
        
        valid_results = {name: result for name, result in self.results.items() if result is not None}
        
        for method_name, result in valid_results.items():
            filtered_values = result.filtered_values
            
            # RMSEè¨ˆç®—
            if len(filtered_values) == len(true_prices):
                rmse = np.sqrt(np.mean((filtered_values - true_prices) ** 2))
                mae = np.mean(np.abs(filtered_values - true_prices))
                
                # é…å»¶è¨ˆç®—ï¼ˆç›¸é–¢ã®ãƒ”ãƒ¼ã‚¯ä½ç½®ï¼‰
                correlation = np.correlate(filtered_values, true_prices, mode='full')
                lag = np.argmax(correlation) - len(true_prices) + 1
                
                # å¹³æ»‘æ€§ï¼ˆäºŒéšå·®åˆ†ã®æ¨™æº–åå·®ï¼‰
                smoothness = np.std(np.diff(filtered_values, n=2))
                
                self.performance_metrics[method_name] = {
                    'RMSE': rmse,
                    'MAE': mae,
                    'Lag': abs(lag),
                    'Smoothness': smoothness,
                    'Filter_Type': self._get_filter_type(method_name)
                }
                
                print(f"   ğŸ“ˆ {method_name}: RMSE={rmse:.4f}, MAE={mae:.4f}, Lag={abs(lag)}, Smoothness={smoothness:.4f}")
            else:
                print(f"   âš ï¸ {method_name}: ãƒ‡ãƒ¼ã‚¿é•·ä¸ä¸€è‡´")
        
        # åŸºæº–ï¼ˆæ¨™æº–UKFï¼‰ã‹ã‚‰ã®æ”¹å–„ç‡è¨ˆç®—
        if 'Standard UKF' in self.performance_metrics:
            baseline_rmse = self.performance_metrics['Standard UKF']['RMSE']
            for method_name, metrics in self.performance_metrics.items():
                if method_name != 'Standard UKF':
                    improvement = (baseline_rmse - metrics['RMSE']) / baseline_rmse * 100
                    metrics['Improvement'] = improvement
                    print(f"   ğŸš€ {method_name}: æ”¹å–„ç‡ {improvement:+.1f}%")
        
        print("âœ… æ€§èƒ½æŒ‡æ¨™è¨ˆç®—å®Œäº†")
    
    def _get_filter_type(self, method_name: str) -> str:
        """ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¿ã‚¤ãƒ—ã‚’å–å¾—"""
        if 'Standard' in method_name:
            return 'baseline'
        elif 'My' in method_name:
            return 'statistical_adaptive'
        elif 'Academic' in method_name:
            return 'mathematical_rigorous'
        elif 'Neural' in method_name:
            return 'neural_adaptive'
        else:
            return 'unknown'
    
    def plot(self, 
            title: str = "4ã¤ã®Adaptive UKFæ¯”è¼ƒ - å®Ÿéš›ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿", 
            start_date: Optional[str] = None,
            end_date: Optional[str] = None,
            show_volume: bool = True,
            figsize: Tuple[int, int] = (16, 14),
            style: str = 'yahoo',
            savefig: Optional[str] = None) -> None:
        """
        ãƒ­ãƒ¼ã‚½ã‚¯è¶³ãƒãƒ£ãƒ¼ãƒˆã¨4ã¤ã®Adaptive UKFæ‰‹æ³•ã‚’æç”»ã™ã‚‹
        """
        if self.data is None:
            raise ValueError("ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            
        if not self.results:
            raise ValueError("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãŒè¨ˆç®—ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚calculate_filters()ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        
        print("\nğŸ¨ **ãƒãƒ£ãƒ¼ãƒˆæç”»ä¸­...**")
        
        # ãƒ‡ãƒ¼ã‚¿ã®æœŸé–“çµã‚Šè¾¼ã¿
        df = self.data.copy()
        if start_date:
            df = df[df.index >= pd.to_datetime(start_date)]
        if end_date:
            df = df[df.index <= pd.to_datetime(end_date)]
            
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«è¿½åŠ 
        valid_results = {name: result for name, result in self.results.items() if result is not None}
        
        for method_name, result in valid_results.items():
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å€¤
            if len(result.filtered_values) == len(self.data):
                full_df = pd.DataFrame(
                    index=self.data.index,
                    data={f'{method_name}_filtered': result.filtered_values}
                )
                df = df.join(full_df)
                
                # ä¸ç¢ºå®Ÿæ€§ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
                if hasattr(result, 'uncertainty'):
                    uncertainty_df = pd.DataFrame(
                        index=self.data.index,
                        data={f'{method_name}_uncertainty': result.uncertainty}
                    )
                    df = df.join(uncertainty_df)
        
        print(f"   ğŸ“Š ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº† - è¡Œæ•°: {len(df)}")
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¡¨ç¤ºç”¨ã®è‰²è¨­å®š
        filter_colors = {
            'Standard UKF': 'gray',
            'My AUKF': 'blue',
            'Academic AUKF': 'red',
            'Neural AUKF': 'green'
        }
        
        # mplfinanceã§ãƒ—ãƒ­ãƒƒãƒˆç”¨ã®è¨­å®š
        main_plots = []
        
        # å„ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®çµæœã‚’ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒ¼ãƒˆã«è¿½åŠ 
        for method_name in valid_results.keys():
            col_name = f'{method_name}_filtered'
            if col_name in df.columns:
                color = filter_colors.get(method_name, 'purple')
                alpha = 0.6 if 'Standard' in method_name else 0.8
                width = 1.5 if 'Standard' in method_name else 2.0
                
                main_plots.append(
                    mpf.make_addplot(df[col_name], color=color, width=width, alpha=alpha, label=method_name)
                )
        
        # mplfinanceã®è¨­å®š
        kwargs = dict(
            type='candle',
            figsize=figsize,
            title=title,
            style=style,
            datetime_format='%Y-%m-%d',
            xrotation=45,
            returnfig=True
        )
        
        # å‡ºæ¥é«˜è¨­å®š
        if show_volume and 'volume' in df.columns:
            kwargs['volume'] = True
        else:
            kwargs['volume'] = False
        
        # ãƒ—ãƒ­ãƒƒãƒˆè¨­å®š
        if main_plots:
            kwargs['addplot'] = main_plots
        
        # ãƒ—ãƒ­ãƒƒãƒˆå®Ÿè¡Œ
        fig, axes = mpf.plot(df, **kwargs)
        
        # å‡¡ä¾‹ã®è¿½åŠ 
        if main_plots:
            legend_labels = list(valid_results.keys())
            axes[0].legend(legend_labels, loc='upper left', fontsize=9)
        
        self.fig = fig
        self.axes = axes
        
        # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
        self._print_chart_statistics(df, valid_results)
        
        # ä¿å­˜ã¾ãŸã¯è¡¨ç¤º
        if savefig:
            plt.savefig(savefig, dpi=150, bbox_inches='tight')
            print(f"ğŸ“Š ãƒãƒ£ãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {savefig}")
        else:
            plt.tight_layout()
            plt.show()
    
    def _print_chart_statistics(self, df: pd.DataFrame, valid_results: dict) -> None:
        """ãƒãƒ£ãƒ¼ãƒˆçµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º"""
        print(f"\nğŸ“Š **ãƒãƒ£ãƒ¼ãƒˆçµ±è¨ˆæƒ…å ±**")
        print(f"   ğŸ“… è¡¨ç¤ºæœŸé–“: {df.index.min()} â†’ {df.index.max()}")
        print(f"   ğŸ“ˆ ä¾¡æ ¼ç¯„å›²: ${df['close'].min():.2f} - ${df['close'].max():.2f}")
        print(f"   ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}")
        
        print(f"\nğŸ¯ **ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ€§èƒ½ãƒ©ãƒ³ã‚­ãƒ³ã‚°:**")
        if self.performance_metrics:
            # RMSEé †ã§ã‚½ãƒ¼ãƒˆ
            sorted_metrics = sorted(self.performance_metrics.items(), key=lambda x: x[1]['RMSE'])
            for i, (method_name, metrics) in enumerate(sorted_metrics, 1):
                medal = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else f"{i}ä½"
                improvement = metrics.get('Improvement', 0)
                print(f"   {medal} {method_name}: RMSE={metrics['RMSE']:.4f} ({improvement:+.1f}%)")
    
    def get_performance_summary(self) -> pd.DataFrame:
        """æ€§èƒ½æŒ‡æ¨™ã®ã‚µãƒãƒªãƒ¼ã‚’DataFrameã¨ã—ã¦å–å¾—"""
        if not self.performance_metrics:
            return pd.DataFrame()
        
        return pd.DataFrame(self.performance_metrics).T


def create_test_config() -> str:
    """ãƒ†ã‚¹ãƒˆç”¨ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
    config_content = """
# 4ã¤ã®Adaptive UKFæ¯”è¼ƒãƒ†ã‚¹ãƒˆç”¨è¨­å®š

binance_data:
  data_dir: "data/binance"
  symbols:
    - "BTCUSDT"
  intervals:
    - "1h"
  start_date: "2024-01-01"
  end_date: "2024-06-01"
  limit: 1000

data_processing:
  remove_duplicates: true
  fill_missing: true
  min_volume: 0
"""
    
    config_path = "config_adaptive_ukf_test.yaml"
    with open(config_path, 'w', encoding='utf-8') as f:
        f.write(config_content)
    
    print(f"âœ… ãƒ†ã‚¹ãƒˆç”¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ: {config_path}")
    return config_path


def create_sample_data(filename: str = "sample_market_data.csv", n_points: int = 500) -> str:
    """ã‚µãƒ³ãƒ—ãƒ«ç›¸å ´ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    print("ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ç›¸å ´ãƒ‡ãƒ¼ã‚¿ä½œæˆä¸­...")
    
    # æ™‚ç³»åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
    dates = pd.date_range(start='2024-01-01', periods=n_points, freq='1H')
    
    # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ + ãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰
    np.random.seed(42)
    base_price = 50000  # åˆæœŸä¾¡æ ¼
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†
    trend = np.linspace(0, 0.2, n_points)
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯
    returns = np.random.normal(0, 0.02, n_points)
    log_prices = np.log(base_price) + np.cumsum(returns) + trend
    prices = np.exp(log_prices)
    
    # OHLCç”Ÿæˆ
    df = pd.DataFrame(index=dates)
    df['close'] = prices
    df['open'] = df['close'].shift(1).fillna(df['close'])
    
    # High/Lowç”Ÿæˆï¼ˆCloseã‚’åŸºæº–ã«Â±1-3%ã®ç¯„å›²ï¼‰
    high_factor = 1 + np.random.uniform(0.001, 0.03, n_points)
    low_factor = 1 - np.random.uniform(0.001, 0.03, n_points)
    
    df['high'] = np.maximum(df['close'] * high_factor, np.maximum(df['close'], df['open']))
    df['low'] = np.minimum(df['close'] * low_factor, np.minimum(df['close'], df['open']))
    
    # ãƒœãƒªãƒ¥ãƒ¼ãƒ ç”Ÿæˆ
    df['volume'] = np.random.uniform(100000, 1000000, n_points)
    
    # ä¿å­˜
    df.to_csv(filename)
    print(f"âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {filename}")
    return filename


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•° - ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    import argparse
    
    parser = argparse.ArgumentParser(description='4ã¤ã®Adaptive UKFæ‰‹æ³•ã®ç›¸å ´ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒ')
    parser.add_argument('--config', '-c', type=str, help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆæœªæŒ‡å®šæ™‚ã¯ãƒ†ã‚¹ãƒˆç”¨è¨­å®šã‚’ä½œæˆï¼‰')
    parser.add_argument('--csv', type=str, help='CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä»£ã‚ã‚Šã«ä½¿ç”¨ï¼‰')
    parser.add_argument('--start', '-s', type=str, help='è¡¨ç¤ºé–‹å§‹æ—¥ (YYYY-MM-DD)')
    parser.add_argument('--end', '-e', type=str, help='è¡¨ç¤ºçµ‚äº†æ—¥ (YYYY-MM-DD)')
    parser.add_argument('--output', '-o', type=str, help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--src-type', type=str, default='close', help='ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—')
    parser.add_argument('--window-size', type=int, default=50, help='Neuralç‰ˆã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º')
    parser.add_argument('--create-sample', action='store_true', help='ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆãƒ†ã‚¹ãƒˆ')
    args = parser.parse_args()
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆãƒ†ã‚¹ãƒˆ
    if args.create_sample:
        sample_file = create_sample_data()
        args.csv = sample_file
    
    try:
        # ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ
        chart = AdaptiveUKFComparisonChart()
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        if args.csv:
            # CSVã‹ã‚‰èª­ã¿è¾¼ã¿
            chart.load_simple_data(args.csv)
        elif args.config:
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
            chart.load_data_from_config(args.config)
        else:
            # ãƒ†ã‚¹ãƒˆç”¨è¨­å®šä½œæˆ
            print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã™...")
            sample_file = create_sample_data()
            chart.load_simple_data(sample_file)
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨ˆç®—
        chart.calculate_filters(
            src_type=args.src_type,
            window_size=args.window_size
        )
        
        # ãƒãƒ£ãƒ¼ãƒˆæç”»
        chart.plot(
            start_date=args.start,
            end_date=args.end,
            savefig=args.output
        )
        
        # æ€§èƒ½ã‚µãƒãƒªãƒ¼ä¿å­˜
        performance_df = chart.get_performance_summary()
        if not performance_df.empty:
            summary_path = "output/adaptive_ukf_market_performance.csv"
            os.makedirs("output", exist_ok=True)
            performance_df.to_csv(summary_path)
            print(f"ğŸ“Š æ€§èƒ½ã‚µãƒãƒªãƒ¼ä¿å­˜: {summary_path}")
        
        print("\nğŸ‰ **4ã¤ã®Adaptive UKFç›¸å ´ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒå®Œäº†ï¼**")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        print("   - ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        print("   - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ã„å½¢å¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        print("   - å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")


if __name__ == "__main__":
    main() 