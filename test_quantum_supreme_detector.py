#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é‡å­æœ€å¼·ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã®ãƒ†ã‚¹ãƒˆ
"""

import sys
import os
import time
import numpy as np
import pandas as pd

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

try:
    from indicators.trend_filter.quantum_supreme_trend_cycle_detector import (
        QuantumSupremeTrendCycleDetector,
        calculate_quantum_supreme_trend_cycle,
        ultra_precision_dft_engine,
        quantum_harmonic_oscillator_cycle_detector,
        advanced_wavelet_transform_analysis,
        fractal_dimension_analysis,
        information_entropy_analysis,
        phase_space_reconstruction
    )
    print("é‡å­æœ€å¼·ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã‚’æ­£å¸¸ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ")
except ImportError as e:
    print(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    print("åŸºæœ¬çš„ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é–¢æ•°ã®ã¿ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™")
    
    # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é–¢æ•°ã‚’ç›´æ¥å®šç¾©ï¼ˆæœ€å°é™ã®ãƒ†ã‚¹ãƒˆç”¨ï¼‰
    from numba import njit
    
    @njit
    def simple_dft_test(data):
        """ç°¡å˜ãªDFTãƒ†ã‚¹ãƒˆ"""
        n = len(data)
        result = np.zeros(n)
        for i in range(10, n):
            # ç°¡å˜ãªå‘¨æœŸæ¤œå‡º
            window = data[i-10:i]
            max_power = 0.0
            best_period = 10.0
            
            for period in range(5, 15):
                power = 0.0
                for j in range(len(window)):
                    angle = 2 * np.pi * j / period
                    power += window[j] * np.cos(angle)
                
                if abs(power) > abs(max_power):
                    max_power = power
                    best_period = period
            
            result[i] = best_period
        return result


def generate_test_data(n=500):
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    np.random.seed(42)
    
    # è¤‡é›‘ãªå¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    prices = [100.0]
    for i in range(1, n):
        # è¤‡æ•°ã®å‘¨æœŸçš„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        trend = 0.001 * np.sin(2 * np.pi * i / 100)
        cycle1 = 0.005 * np.sin(2 * np.pi * i / 20)
        cycle2 = 0.003 * np.sin(2 * np.pi * i / 50)
        noise = np.random.normal(0, 0.002)
        
        change = trend + cycle1 + cycle2 + noise
        prices.append(prices[-1] * (1 + change))
    
    # OHLC ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
    data = []
    for i, close in enumerate(prices):
        daily_range = abs(np.random.normal(0, close * 0.008))
        high = close + daily_range * np.random.uniform(0.4, 1.0)
        low = close - daily_range * np.random.uniform(0.4, 1.0)
        
        if i == 0:
            open_price = close
        else:
            gap = np.random.normal(0, close * 0.003)
            open_price = prices[i-1] + gap
        
        # è«–ç†çš„æ•´åˆæ€§ã®ç¢ºä¿
        high = max(high, open_price, close)
        low = min(low, open_price, close)
        
        data.append({
            'open': open_price,
            'high': high,
            'low': low,
            'close': close,
            'volume': np.random.uniform(1000, 10000)
        })
    
    return pd.DataFrame(data)


def test_core_algorithms():
    """ã‚³ã‚¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    print("=== ã‚³ã‚¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ†ã‚¹ãƒˆ ===")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    test_data = np.random.randn(200) * 0.1 + 100
    test_data = test_data.astype(np.float64)
    
    try:
        print("1. è¶…é«˜ç²¾åº¦DFTè§£æã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒ†ã‚¹ãƒˆ...")
        start_time = time.time()
        dft_periods, dft_power, dft_coherence, dft_purity = ultra_precision_dft_engine(test_data)
        dft_time = time.time() - start_time
        
        print(f"   DFTè§£æå®Œäº†: {dft_time:.3f}ç§’")
        print(f"   å¹³å‡æœŸé–“: {np.mean(dft_periods[dft_periods > 0]):.2f}")
        print(f"   å¹³å‡ç´”åº¦: {np.mean(dft_purity[dft_purity > 0]):.4f}")
        print(f"   å¹³å‡ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹: {np.mean(dft_coherence[dft_coherence > 0]):.4f}")
        
    except Exception as e:
        print(f"   DFTã‚¨ãƒ©ãƒ¼: {e}")
    
    try:
        print("\n2. é‡å­èª¿å’ŒæŒ¯å‹•å­æ¤œå‡ºå™¨ã®ãƒ†ã‚¹ãƒˆ...")
        start_time = time.time()
        qphase, qamp, qenergy, qcoh = quantum_harmonic_oscillator_cycle_detector(test_data)
        quantum_time = time.time() - start_time
        
        print(f"   é‡å­è§£æå®Œäº†: {quantum_time:.3f}ç§’")
        print(f"   å¹³å‡æŒ¯å¹…: {np.mean(qamp[qamp > 0]):.4f}")
        print(f"   å¹³å‡ã‚¨ãƒãƒ«ã‚®ãƒ¼: {np.mean(qenergy[qenergy > 0]):.4f}")
        print(f"   å¹³å‡ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹: {np.mean(qcoh[qcoh > 0]):.4f}")
        
    except Exception as e:
        print(f"   é‡å­è§£æã‚¨ãƒ©ãƒ¼: {e}")
    
    try:
        print("\n3. ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå¤‰æ›ã®ãƒ†ã‚¹ãƒˆ...")
        start_time = time.time()
        scales = np.array([2, 4, 8, 16], dtype=np.float64)
        wcoeffs, wtrend, wcycle = advanced_wavelet_transform_analysis(test_data, scales)
        wavelet_time = time.time() - start_time
        
        print(f"   ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆè§£æå®Œäº†: {wavelet_time:.3f}ç§’")
        print(f"   ä¿‚æ•°å½¢çŠ¶: {wcoeffs.shape}")
        print(f"   å¹³å‡ãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†: {np.mean(wtrend):.4f}")
        print(f"   å¹³å‡ã‚µã‚¤ã‚¯ãƒ«æˆåˆ†: {np.mean(wcycle):.4f}")
        
    except Exception as e:
        print(f"   ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    try:
        print("\n4. ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒè§£æã®ãƒ†ã‚¹ãƒˆ...")
        start_time = time.time()
        fdim, hurst, mstruct = fractal_dimension_analysis(test_data)
        fractal_time = time.time() - start_time
        
        print(f"   ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è§£æå®Œäº†: {fractal_time:.3f}ç§’")
        print(f"   å¹³å‡ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ: {np.mean(fdim[fdim > 0]):.4f}")
        print(f"   å¹³å‡ãƒãƒ¼ã‚¹ãƒˆæŒ‡æ•°: {np.mean(hurst[hurst > 0]):.4f}")
        print(f"   å¸‚å ´æ§‹é€ ç¯„å›²: {np.min(mstruct)} - {np.max(mstruct)}")
        
    except Exception as e:
        print(f"   ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
    
    try:
        print("\n5. ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è§£æã®ãƒ†ã‚¹ãƒˆ...")
        start_time = time.time()
        shannon, tsallis, infoflow = information_entropy_analysis(test_data)
        entropy_time = time.time() - start_time
        
        print(f"   ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è§£æå®Œäº†: {entropy_time:.3f}ç§’")
        print(f"   å¹³å‡ã‚·ãƒ£ãƒãƒ³ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {np.mean(shannon[shannon > 0]):.4f}")
        print(f"   å¹³å‡ãƒ„ã‚¡ãƒªã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {np.mean(tsallis[tsallis > 0]):.4f}")
        print(f"   æƒ…å ±æµå‹•æ€§ç¯„å›²: {np.min(infoflow)} - {np.max(infoflow)}")
        
    except Exception as e:
        print(f"   ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
    
    try:
        print("\n6. ä½ç›¸ç©ºé–“å†æ§‹æˆã®ãƒ†ã‚¹ãƒˆ...")
        start_time = time.time()
        pvolume, lyap, corrdim = phase_space_reconstruction(test_data)
        phase_time = time.time() - start_time
        
        print(f"   ä½ç›¸ç©ºé–“è§£æå®Œäº†: {phase_time:.3f}ç§’")
        print(f"   å¹³å‡ä½ç›¸ç©ºé–“ä½“ç©: {np.mean(pvolume[pvolume > 0]):.4f}")
        print(f"   å¹³å‡ãƒªã‚¢ãƒ—ãƒãƒ•æŒ‡æ•°: {np.mean(lyap[np.isfinite(lyap)]):.4f}")
        print(f"   å¹³å‡ç›¸é–¢æ¬¡å…ƒ: {np.mean(corrdim[corrdim > 0]):.4f}")
        
    except Exception as e:
        print(f"   ä½ç›¸ç©ºé–“ã‚¨ãƒ©ãƒ¼: {e}")


def test_full_detector():
    """ãƒ•ãƒ«æ¤œå‡ºå™¨ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n=== ãƒ•ãƒ«æ¤œå‡ºå™¨ãƒ†ã‚¹ãƒˆ ===")
    
    try:
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        df = generate_test_data(300)  # è¨ˆç®—æ™‚é–“çŸ­ç¸®ã®ãŸã‚300ãƒã‚¤ãƒ³ãƒˆ
        print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(df)}è¡Œ")
        print(f"ä¾¡æ ¼ç¯„å›²: {df['close'].min():.4f} - {df['close'].max():.4f}")
        
        # é‡å­æœ€å¼·æ¤œå‡ºå™¨ã‚’ãƒ†ã‚¹ãƒˆ
        detector = QuantumSupremeTrendCycleDetector(
            quantum_levels=10,  # è¨ˆç®—æ™‚é–“çŸ­ç¸®
            quantum_window=50,
            wavelet_scales=[2, 4, 8, 16],
            ensemble_learning_rate=0.02,
            use_kalman_filter=False,  # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯ç„¡åŠ¹åŒ–
            fractal_window=30,
            entropy_window=30
        )
        
        print("\né‡å­æœ€å¼·æ¤œå‡ºå™¨è¨ˆç®—é–‹å§‹...")
        start_time = time.time()
        result = detector.calculate(df)
        end_time = time.time()
        
        print(f"è¨ˆç®—å®Œäº†: {end_time - start_time:.2f}ç§’")
        print(f"å“è³ªã‚¹ã‚³ã‚¢: {result.quality_score:.4f}")
        print(f"ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {result.algorithm_version}")
        
        # çµ±è¨ˆæƒ…å ±
        valid_count = len(result.trend_mode)
        trend_ratio = np.mean(result.trend_mode)
        cycle_ratio = np.mean(result.cycle_mode)
        avg_confidence = np.mean(result.confidence)
        
        print(f"\nçµæœçµ±è¨ˆ:")
        print(f"  æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ: {valid_count}")
        print(f"  ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¢ãƒ¼ãƒ‰æ¯”ç‡: {trend_ratio:.2%}")
        print(f"  ã‚µã‚¤ã‚¯ãƒ«ãƒ¢ãƒ¼ãƒ‰æ¯”ç‡: {cycle_ratio:.2%}")
        print(f"  å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.4f}")
        
        # ä¿¡å·çµ±è¨ˆ
        buy_signals = np.sum(result.signal > 0)
        sell_signals = np.sum(result.signal < 0)
        neutral_signals = np.sum(result.signal == 0)
        
        print(f"\nä¿¡å·çµ±è¨ˆ:")
        print(f"  è²·ã„ã‚·ã‚°ãƒŠãƒ«: {buy_signals}")
        print(f"  å£²ã‚Šã‚·ã‚°ãƒŠãƒ«: {sell_signals}")
        print(f"  ä¸­ç«‹ã‚·ã‚°ãƒŠãƒ«: {neutral_signals}")
        
        # é«˜åº¦ãªçµ±è¨ˆ
        print(f"\né«˜åº¦çµ±è¨ˆ:")
        print(f"  å¹³å‡ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ: {np.mean(result.fractal_dimension[result.fractal_dimension > 0]):.4f}")
        print(f"  å¹³å‡ãƒãƒ¼ã‚¹ãƒˆæŒ‡æ•°: {np.mean(result.hurst_exponent[result.hurst_exponent > 0]):.4f}")
        print(f"  å¹³å‡ã‚·ãƒ£ãƒãƒ³ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {np.mean(result.shannon_entropy[result.shannon_entropy > 0]):.4f}")
        print(f"  å¹³å‡é‡å­æŒ¯å¹…: {np.mean(result.quantum_amplitude[result.quantum_amplitude > 0]):.4f}")
        
        return True
        
    except Exception as e:
        print(f"ãƒ•ãƒ«æ¤œå‡ºå™¨ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False


def benchmark_performance():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
    print("\n=== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ ===")
    
    data_sizes = [100, 200, 300]
    
    for size in data_sizes:
        print(f"\nãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {size}ãƒã‚¤ãƒ³ãƒˆ")
        
        try:
            df = generate_test_data(size)
            
            # è»½é‡è¨­å®šã§å®Ÿè¡Œ
            detector = QuantumSupremeTrendCycleDetector(
                quantum_levels=8,
                quantum_window=40,
                wavelet_scales=[2, 4, 8],
                use_kalman_filter=False,
                fractal_window=25,
                entropy_window=25
            )
            
            start_time = time.time()
            result = detector.calculate(df)
            execution_time = time.time() - start_time
            
            points_per_second = size / execution_time
            
            print(f"  å®Ÿè¡Œæ™‚é–“: {execution_time:.3f}ç§’")
            print(f"  å‡¦ç†é€Ÿåº¦: {points_per_second:.1f}ãƒã‚¤ãƒ³ãƒˆ/ç§’")
            print(f"  å“è³ªã‚¹ã‚³ã‚¢: {result.quality_score:.4f}")
            
        except Exception as e:
            print(f"  ã‚µã‚¤ã‚º{size}ã§ã‚¨ãƒ©ãƒ¼: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=== é‡å­æœ€å¼·ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ - çµ±åˆãƒ†ã‚¹ãƒˆ ===")
    print("äººé¡å²ä¸Šæœ€å¼·ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚µã‚¤ã‚¯ãƒ«åˆ¤åˆ¥ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ")
    print("")
    
    # 1. ã‚³ã‚¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ãƒ†ã‚¹ãƒˆ
    test_core_algorithms()
    
    # 2. ãƒ•ãƒ«æ¤œå‡ºå™¨ã®ãƒ†ã‚¹ãƒˆ
    success = test_full_detector()
    
    # 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    if success:
        benchmark_performance()
    
    print("\n=== çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº† ===")
    
    if success:
        print("âœ… å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
        print("ğŸš€ é‡å­æœ€å¼·ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºå™¨ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
    else:
        print("âŒ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        print("âš ï¸  ä¾å­˜é–¢ä¿‚ã‚„ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„")


if __name__ == "__main__":
    main()