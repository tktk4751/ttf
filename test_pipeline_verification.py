#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ã‚°ãƒ©ãƒ³ãƒ‰ã‚µã‚¤ã‚¯ãƒ«MAã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¤œè¨¼ãƒ†ã‚¹ãƒˆ
ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼â†’ã‚¹ãƒ ãƒ¼ã‚µãƒ¼â†’ã‚°ãƒ©ãƒ³ãƒ‰ã‚µã‚¤ã‚¯ãƒ«MAã®é †åºã‚’ç¢ºèª
"""

import numpy as np
import pandas as pd
import sys
import os

# ãƒ‘ã‚¹ã®è¨­å®š
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_processing_pipeline():
    """å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
    print("=== ã‚°ãƒ©ãƒ³ãƒ‰ã‚µã‚¤ã‚¯ãƒ«MA ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¤œè¨¼ ===")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
    np.random.seed(42)
    dates = pd.date_range('2024-01-01', periods=50, freq='h')
    prices = 100 + np.cumsum(np.random.normal(0, 0.5, 50))
    
    data = pd.DataFrame({
        'open': prices * 0.999,
        'high': prices * 1.002,
        'low': prices * 0.998,
        'close': prices,
        'volume': np.random.uniform(1000, 5000, 50)
    }, index=dates)
    
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(data)}ä»¶")
    print(f"ä¾¡æ ¼ç¯„å›²: {data['close'].min():.2f} - {data['close'].max():.2f}")
    
    # 1. ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ã®æŠ½å‡ºã‚’ãƒ†ã‚¹ãƒˆ
    print("\n1. ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ:")
    try:
        from indicators.price_source import PriceSource
        close_prices = PriceSource.calculate_source(data, 'close')
        hlc3_prices = PriceSource.calculate_source(data, 'hlc3')
        
        print(f"  âœ“ Closeä¾¡æ ¼: {len(close_prices)}ä»¶, å¹³å‡ {np.mean(close_prices):.2f}")
        print(f"  âœ“ HLC3ä¾¡æ ¼: {len(hlc3_prices)}ä»¶, å¹³å‡ {np.mean(hlc3_prices):.2f}")
    except Exception as e:
        print(f"  âœ— ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    # 2. çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®ãƒ†ã‚¹ãƒˆ
    print("\n2. çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ãƒ†ã‚¹ãƒˆ:")
    try:
        from indicators.smoother.unified_smoother import UnifiedSmoother
        
        # FRAMA ã‚¹ãƒ ãƒ¼ã‚µãƒ¼
        frama_smoother = UnifiedSmoother(smoother_type='frama', src_type='close')
        frama_result = frama_smoother.calculate(data)
        
        print(f"  âœ“ FRAMA: {len(frama_result.values)}ä»¶, å¹³å‡ {np.nanmean(frama_result.values):.2f}")
        print(f"    è¿½åŠ ãƒ‡ãƒ¼ã‚¿: {list(frama_result.additional_data.keys())}")
        
        # Zero Lag EMA
        zlema_smoother = UnifiedSmoother(smoother_type='zero_lag_ema', src_type='close')
        zlema_result = zlema_smoother.calculate(data)
        
        print(f"  âœ“ ZLEMA: {len(zlema_result.values)}ä»¶, å¹³å‡ {np.nanmean(zlema_result.values):.2f}")
        
    except Exception as e:
        print(f"  âœ— çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    # 3. çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ãƒ†ã‚¹ãƒˆ
    print("\n3. çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ†ã‚¹ãƒˆ:")
    try:
        from indicators.kalman.unified_kalman import UnifiedKalman
        
        # é©å¿œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        adaptive_kalman = UnifiedKalman(filter_type='adaptive', src_type='close')
        adaptive_result = adaptive_kalman.calculate(data)
        
        print(f"  âœ“ é©å¿œã‚«ãƒ«ãƒãƒ³: {len(adaptive_result.values)}ä»¶, å¹³å‡ {np.nanmean(adaptive_result.values):.2f}")
        print(f"    è¿½åŠ ãƒ‡ãƒ¼ã‚¿: {list(adaptive_result.additional_data.keys())}")
        
        # é‡å­é©å¿œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        quantum_kalman = UnifiedKalman(filter_type='quantum_adaptive', src_type='close')
        quantum_result = quantum_kalman.calculate(data)
        
        print(f"  âœ“ é‡å­é©å¿œã‚«ãƒ«ãƒãƒ³: {len(quantum_result.values)}ä»¶, å¹³å‡ {np.nanmean(quantum_result.values):.2f}")
        
    except Exception as e:
        print(f"  âœ— çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    # 4. ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é †åºã®ç¢ºèª
    print("\n4. ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é †åºç¢ºèª:")
    try:
        # ã‚¹ãƒ†ãƒƒãƒ—1: å…ƒä¾¡æ ¼
        original_prices = PriceSource.calculate_source(data, 'close')
        print(f"  å…ƒä¾¡æ ¼å¹³å‡: {np.mean(original_prices):.4f}")
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
        kalman_filter = UnifiedKalman(filter_type='adaptive', src_type='close')
        kalman_result = kalman_filter.calculate(data)
        kalman_filtered = kalman_result.values
        print(f"  ã‚«ãƒ«ãƒãƒ³å¾Œå¹³å‡: {np.nanmean(kalman_filtered):.4f}")
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: ã‚«ãƒ«ãƒãƒ³æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã§ã‚¹ãƒ ãƒ¼ã‚µãƒ¼é©ç”¨
        # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœã‚’æ–°ã—ã„DataFrameã¨ã—ã¦ä½œæˆ
        filtered_data = data.copy()
        filtered_data['close'] = kalman_filtered
        
        smoother = UnifiedSmoother(smoother_type='frama', src_type='close')
        smoother_result = smoother.calculate(filtered_data)
        smoothed_values = smoother_result.values
        print(f"  ã‚¹ãƒ ãƒ¼ã‚µãƒ¼å¾Œå¹³å‡: {np.nanmean(smoothed_values):.4f}")
        
        # å¤‰åŒ–ã®ç¢ºèª
        orig_std = np.std(original_prices)
        kalman_std = np.nanstd(kalman_filtered)
        smooth_std = np.nanstd(smoothed_values)
        
        print(f"  æ¨™æº–åå·®ã®å¤‰åŒ–:")
        print(f"    å…ƒä¾¡æ ¼: {orig_std:.4f}")
        print(f"    ã‚«ãƒ«ãƒãƒ³å¾Œ: {kalman_std:.4f} ({kalman_std/orig_std:.2f}å€)")
        print(f"    ã‚¹ãƒ ãƒ¼ã‚µãƒ¼å¾Œ: {smooth_std:.4f} ({smooth_std/orig_std:.2f}å€)")
        
        print("  âœ“ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é †åºç¢ºèªå®Œäº†")
        
    except Exception as e:
        print(f"  âœ— ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é †åºç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    # 5. çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰
    print("\n5. çµ±åˆã‚·ã‚¹ãƒ†ãƒ æ¦‚å¿µãƒ†ã‚¹ãƒˆ:")
    try:
        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã‚’æ¨¡æ“¬
        print("  å‡¦ç†ãƒ•ãƒ­ãƒ¼: å…ƒä¾¡æ ¼ â†’ ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ â†’ ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ â†’ ã‚°ãƒ©ãƒ³ãƒ‰ã‚µã‚¤ã‚¯ãƒ«MA")
        
        # å„ã‚¹ãƒ†ãƒƒãƒ—ã®åŠ¹æœã‚’ç¢ºèª
        step1_data = original_prices
        step2_data = kalman_filtered
        step3_data = smoothed_values
        
        # ãƒã‚¤ã‚ºé™¤å»åŠ¹æœã®æ¸¬å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
        step1_noise = np.std(np.diff(step1_data))
        step2_noise = np.nanstd(np.diff(step2_data))
        step3_noise = np.nanstd(np.diff(step3_data))
        
        print(f"  ä¾¡æ ¼å¤‰å‹•ï¼ˆãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ï¼‰ã®æ¨ç§»:")
        print(f"    ã‚¹ãƒ†ãƒƒãƒ—1ï¼ˆå…ƒä¾¡æ ¼ï¼‰: {step1_noise:.4f}")
        print(f"    ã‚¹ãƒ†ãƒƒãƒ—2ï¼ˆã‚«ãƒ«ãƒãƒ³ï¼‰: {step2_noise:.4f} ({step2_noise/step1_noise:.2f}å€)")
        print(f"    ã‚¹ãƒ†ãƒƒãƒ—3ï¼ˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ï¼‰: {step3_noise:.4f} ({step3_noise/step1_noise:.2f}å€)")
        
        if step3_noise < step1_noise:
            print("  âœ“ ãƒã‚¤ã‚ºé™¤å»åŠ¹æœã‚’ç¢ºèª")
        else:
            print("  ! ãƒã‚¤ã‚ºé™¤å»åŠ¹æœãŒä¸æ˜ç¢º")
        
        print("  âœ“ çµ±åˆã‚·ã‚¹ãƒ†ãƒ æ¦‚å¿µãƒ†ã‚¹ãƒˆå®Œäº†")
        
    except Exception as e:
        print(f"  âœ— çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    return True

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    success = test_processing_pipeline()
    
    if success:
        print("\nğŸ‰ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¤œè¨¼æˆåŠŸï¼")
        print("\nâœ“ ç¢ºèªã•ã‚ŒãŸãƒã‚¤ãƒ³ãƒˆ:")
        print("  - ä¾¡æ ¼ã‚½ãƒ¼ã‚¹ã®æ­£å¸¸ãªæŠ½å‡º")
        print("  - çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®å‹•ä½œç¢ºèª")
        print("  - çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‹•ä½œç¢ºèª")
        print("  - ã‚«ãƒ«ãƒãƒ³â†’ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ã®å‡¦ç†é †åºç¢ºèª")
        print("  - å„æ®µéšã§ã®ãƒã‚¤ã‚ºé™¤å»åŠ¹æœç¢ºèª")
        print("\nğŸ“‹ å®Ÿè£…çŠ¶æ³:")
        print("  âœ“ çµ±åˆã‚¹ãƒ ãƒ¼ã‚µãƒ¼ï¼ˆFRAMAã€ZLEMAç­‰ï¼‰")
        print("  âœ“ çµ±åˆã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆé©å¿œã€é‡å­é©å¿œç­‰ï¼‰")
        print("  âœ“ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†é †åºï¼ˆã‚½ãƒ¼ã‚¹â†’ã‚«ãƒ«ãƒãƒ³â†’ã‚¹ãƒ ãƒ¼ã‚µãƒ¼ï¼‰")
        print("  âœ“ å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ç‹¬ç«‹å‹•ä½œç¢ºèª")
    else:
        print("\nâš ï¸ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¤œè¨¼ã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ")
    
    return success

if __name__ == "__main__":
    main()